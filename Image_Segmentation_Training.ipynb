{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#If you need a new visdom server for visualization, run this command in a terminal\n",
    "# python -m visdom.server\n",
    "#then navigate here http://localhost:8097"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import loss\n",
    "import argparse\n",
    "import os\n",
    "from util import util\n",
    "import torch\n",
    "import models\n",
    "import data\n",
    "import time\n",
    "from options.train_options import TrainOptions\n",
    "from data import create_dataset\n",
    "from models import create_model\n",
    "from util.visualizer import Visualizer\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt={#BASE OPTIONS\n",
    "    #path to images (should have subfolders trainA, trainB, valA, valB, etc)\n",
    "    \"dataroot\":\"./datasets/prostate_segmentation//\",\n",
    "\n",
    "    \n",
    "    #'name of the experiment. It decides where to store samples and models\n",
    "    \"name\":\"facades_pix2pix\",\n",
    "    \n",
    "    #gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU\n",
    "    \"gpu_ids\":[0,1],\n",
    "    \n",
    "    # models are saved here\n",
    "    \n",
    "    \"checkpoints_dir\":\"./checkpoints\",\n",
    "    \n",
    "    # chooses which model to use. [cycle_gan | pix2pix | test | colorization]\n",
    "    \"model\":\"pix2pixHD\",\n",
    "    # instance normalization or batch normalization [instance | batch | none]\n",
    "    \"norm\":\"instance\",\n",
    "    'use_dropout':True,\n",
    "    'data_type':16,\n",
    "    'verbose':True,\n",
    "    'batchSize':1,\n",
    "    'loadSize':1024,\n",
    "    'fineSize':512,\n",
    "    'label_nc':35,\n",
    "    'input_nc':3,\n",
    "    'output_nc':3,\n",
    "    'resize_or_crop':'scale_width',\n",
    "    'serial_batches':True,\n",
    "    'no_flip':True,\n",
    "    'nThreads':8,\n",
    "    'max_dataset_size':float(\"inf\"),\n",
    "    'display_winsize':512,\n",
    "    'tf_log':True,\n",
    "    'netG':'global',\n",
    "    'ngf':64,\n",
    "    'n_downsample_global':4,\n",
    "    'n_blocks_global':9,\n",
    "    'n_blocks_local':3,\n",
    "    'n_local_enhancers':1,\n",
    "    'niter_fix_global':0,\n",
    "    'no_instance':True,\n",
    "    'instance_feat':True\n",
    "    'label_feat':True,\n",
    "    'feat_num':3,\n",
    "    'load_features':True,\n",
    "    'n_downsample_E':4,\n",
    "    'nef':16,\n",
    "    'n_clusters':10\n",
    "    }\n",
    "class Map(dict):\n",
    "    \"\"\"\n",
    "    Example:\n",
    "    m = Map({'first_name': 'Eduardo'}, last_name='Pool', age=24, sports=['Soccer'])\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Map, self).__init__(*args, **kwargs)\n",
    "        for arg in args:\n",
    "            if isinstance(arg, dict):\n",
    "                for k, v in arg.items():\n",
    "                    self[k] = v\n",
    "\n",
    "        if kwargs:\n",
    "            for k, v in kwargs.items():\n",
    "                self[k] = v\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        return self.get(attr)\n",
    "\n",
    "    def __setattr__(self, key, value):\n",
    "        self.__setitem__(key, value)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        super(Map, self).__setitem__(key, value)\n",
    "        self.__dict__.update({key: value})\n",
    "\n",
    "    def __delattr__(self, item):\n",
    "        self.__delitem__(item)\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        super(Map, self).__delitem__(key)\n",
    "        del self.__dict__[key]\n",
    "opt = Map(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 400\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/facades_pix2pix/latest_net_G.pth\n",
      "loading the model from ./checkpoints/facades_pix2pix/latest_net_D.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Networks initialized -------------\n",
      "DataParallel(\n",
      "  (module): UnetGenerator(\n",
      "    (model): UnetSkipConnectionBlock(\n",
      "      (model): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): UnetSkipConnectionBlock(\n",
      "          (model): Sequential(\n",
      "            (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "            (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (3): UnetSkipConnectionBlock(\n",
      "              (model): Sequential(\n",
      "                (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (3): UnetSkipConnectionBlock(\n",
      "                  (model): Sequential(\n",
      "                    (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                    (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (3): UnetSkipConnectionBlock(\n",
      "                      (model): Sequential(\n",
      "                        (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                        (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                        (3): UnetSkipConnectionBlock(\n",
      "                          (model): Sequential(\n",
      "                            (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                            (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                            (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                            (3): UnetSkipConnectionBlock(\n",
      "                              (model): Sequential(\n",
      "                                (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                                (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                                (3): UnetSkipConnectionBlock(\n",
      "                                  (model): Sequential(\n",
      "                                    (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                                    (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                    (2): ReLU(inplace)\n",
      "                                    (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                                  )\n",
      "                                )\n",
      "                                (4): ReLU(inplace)\n",
      "                                (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                              )\n",
      "                            )\n",
      "                            (4): ReLU(inplace)\n",
      "                            (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                            (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                          )\n",
      "                        )\n",
      "                        (4): ReLU(inplace)\n",
      "                        (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                        (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                      )\n",
      "                    )\n",
      "                    (4): ReLU(inplace)\n",
      "                    (5): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                )\n",
      "                (4): ReLU(inplace)\n",
      "                (5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (4): ReLU(inplace)\n",
      "            (5): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): ReLU(inplace)\n",
      "        (3): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "        (4): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "DataParallel(\n",
      "  (module): NLayerDiscriminator(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network D] Total number of parameters : 2.769 M\n",
      "-----------------------------------------------\n",
      "(epoch: 1, iters: 300, time: 0.054, data: 0.172) G_GAN: 8.462 G_L1: 0.271 D_real: 0.001 D_fake: 0.000 \n",
      "saving the model at the end of epoch 1, iters 402\n",
      "End of epoch 1 / 200 \t Time Taken: 25 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 198, time: 0.072, data: 0.002) G_GAN: 8.193 G_L1: 0.323 D_real: 0.000 D_fake: 0.001 \n",
      "saving the model at the end of epoch 2, iters 804\n",
      "End of epoch 2 / 200 \t Time Taken: 20 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 3, iters: 96, time: 0.054, data: 0.004) G_GAN: 9.353 G_L1: 0.341 D_real: 0.000 D_fake: 0.000 \n",
      "(epoch: 3, iters: 396, time: 0.067, data: 0.003) G_GAN: 12.317 G_L1: 0.329 D_real: 0.000 D_fake: 0.000 \n",
      "saving the latest model (epoch 3, total_iters 1200)\n",
      "saving the model at the end of epoch 3, iters 1206\n",
      "End of epoch 3 / 200 \t Time Taken: 23 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 4, iters: 294, time: 0.056, data: 0.002) G_GAN: 9.161 G_L1: 0.355 D_real: 0.000 D_fake: 0.000 \n",
      "saving the model at the end of epoch 4, iters 1608\n",
      "End of epoch 4 / 200 \t Time Taken: 18 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 5, iters: 192, time: 0.070, data: 0.004) G_GAN: 7.919 G_L1: 0.326 D_real: 0.001 D_fake: 0.001 \n",
      "saving the model at the end of epoch 5, iters 2010\n",
      "End of epoch 5 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 6, iters: 90, time: 0.053, data: 0.004) G_GAN: 11.477 G_L1: 0.372 D_real: 0.001 D_fake: 0.000 \n",
      "(epoch: 6, iters: 390, time: 0.071, data: 0.002) G_GAN: 11.832 G_L1: 0.304 D_real: 0.000 D_fake: 0.000 \n",
      "saving the latest model (epoch 6, total_iters 2400)\n",
      "saving the model at the end of epoch 6, iters 2412\n",
      "End of epoch 6 / 200 \t Time Taken: 20 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 7, iters: 288, time: 0.054, data: 0.002) G_GAN: 12.572 G_L1: 0.296 D_real: 0.000 D_fake: 0.000 \n",
      "saving the model at the end of epoch 7, iters 2814\n",
      "End of epoch 7 / 200 \t Time Taken: 20 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 8, iters: 186, time: 0.072, data: 0.002) G_GAN: 12.711 G_L1: 0.343 D_real: 0.000 D_fake: 0.000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the model at the end of epoch 8, iters 3216\n",
      "End of epoch 8 / 200 \t Time Taken: 21 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 9, iters: 84, time: 0.054, data: 0.003) G_GAN: 6.985 G_L1: 0.286 D_real: 0.035 D_fake: 0.000 \n",
      "(epoch: 9, iters: 384, time: 0.071, data: 0.003) G_GAN: 0.967 G_L1: 0.393 D_real: 1.147 D_fake: 1.142 \n",
      "saving the latest model (epoch 9, total_iters 3600)\n",
      "saving the model at the end of epoch 9, iters 3618\n",
      "End of epoch 9 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 10, iters: 282, time: 0.054, data: 0.004) G_GAN: 0.673 G_L1: 0.271 D_real: 0.894 D_fake: 0.653 \n",
      "saving the model at the end of epoch 10, iters 4020\n",
      "End of epoch 10 / 200 \t Time Taken: 17 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 11, iters: 180, time: 0.067, data: 0.004) G_GAN: 0.657 G_L1: 0.309 D_real: 0.727 D_fake: 0.745 \n",
      "saving the model at the end of epoch 11, iters 4422\n",
      "End of epoch 11 / 200 \t Time Taken: 21 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 12, iters: 78, time: 0.054, data: 0.004) G_GAN: 0.748 G_L1: 0.225 D_real: 0.657 D_fake: 0.713 \n",
      "(epoch: 12, iters: 378, time: 0.068, data: 0.003) G_GAN: 0.746 G_L1: 0.219 D_real: 1.009 D_fake: 0.434 \n",
      "saving the latest model (epoch 12, total_iters 4800)\n",
      "saving the model at the end of epoch 12, iters 4824\n",
      "End of epoch 12 / 200 \t Time Taken: 24 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 13, iters: 276, time: 0.054, data: 0.003) G_GAN: 0.387 G_L1: 0.221 D_real: 1.228 D_fake: 0.294 \n",
      "saving the model at the end of epoch 13, iters 5226\n",
      "End of epoch 13 / 200 \t Time Taken: 20 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 14, iters: 174, time: 0.068, data: 0.004) G_GAN: 1.340 G_L1: 0.236 D_real: 0.555 D_fake: 0.421 \n",
      "saving the model at the end of epoch 14, iters 5628\n",
      "End of epoch 14 / 200 \t Time Taken: 19 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 15, iters: 72, time: 0.054, data: 0.003) G_GAN: 2.752 G_L1: 0.220 D_real: 0.137 D_fake: 0.939 \n",
      "(epoch: 15, iters: 372, time: 0.070, data: 0.003) G_GAN: 5.119 G_L1: 0.277 D_real: 0.183 D_fake: 0.005 \n",
      "saving the latest model (epoch 15, total_iters 6000)\n",
      "saving the model at the end of epoch 15, iters 6030\n",
      "End of epoch 15 / 200 \t Time Taken: 25 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 16, iters: 270, time: 0.054, data: 0.002) G_GAN: 4.441 G_L1: 0.284 D_real: 0.081 D_fake: 0.289 \n",
      "saving the model at the end of epoch 16, iters 6432\n",
      "End of epoch 16 / 200 \t Time Taken: 21 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 17, iters: 168, time: 0.068, data: 0.003) G_GAN: 4.076 G_L1: 0.257 D_real: 0.015 D_fake: 0.043 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e857121392b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtotal_iters\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mepoch_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# unpack data from dataset and apply preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# calculate loss functions, get gradients, update network weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/vasant/4tb1/USF_Internship/ct_conversion/codes/pix2pix_alan/models/pix2pix_model.py\u001b[0m in \u001b[0;36mset_input\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \"\"\"\n\u001b[1;32m     85\u001b[0m         \u001b[0mAtoB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'AtoB'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mAtoB\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'B'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'B'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mAtoB\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'A'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A_paths'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mAtoB\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'B_paths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(opt)  # create a dataset given opt.dataset_mode and other options\n",
    "dataset_size = len(dataset)    # get the number of images in the dataset.\n",
    "print('The number of training images = %d' % dataset_size)\n",
    "\n",
    "model = create_model(opt)      # create a model given opt.model and other options\n",
    "model.setup(opt)               # regular setup: load and print networks; create schedulers\n",
    "visualizer = Visualizer(opt)   # create a visualizer that display/save images and plots\n",
    "total_iters = 0                # the total number of training iterations\n",
    "\n",
    "for epoch in range(opt.epoch_count, opt.niter + opt.niter_decay + 1):    # outer loop for different epochs; we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>\n",
    "    epoch_start_time = time.time()  # timer for entire epoch\n",
    "    iter_data_time = time.time()    # timer for data loading per iteration\n",
    "    epoch_iter = 0                  # the number of training iterations in current epoch, reset to 0 every epoch\n",
    "\n",
    "    for i, data in enumerate(dataset):  # inner loop within one epoch\n",
    "        iter_start_time = time.time()  # timer for computation per iteration\n",
    "        if total_iters % opt.print_freq == 0:\n",
    "            t_data = iter_start_time - iter_data_time\n",
    "        visualizer.reset()\n",
    "        total_iters += opt.batch_size\n",
    "        epoch_iter += opt.batch_size\n",
    "        model.set_input(data)         # unpack data from dataset and apply preprocessing\n",
    "        model.optimize_parameters()   # calculate loss functions, get gradients, update network weights\n",
    "\n",
    "        if total_iters % opt.display_freq == 0:   # display images on visdom and save images to a HTML file\n",
    "            save_result = total_iters % opt.update_html_freq == 0\n",
    "            model.compute_visuals()\n",
    "            visualizer.display_current_results(model.get_current_visuals(), epoch, save_result)\n",
    "\n",
    "        if total_iters % opt.print_freq == 0:    # print training losses and save logging information to the disk\n",
    "            losses = model.get_current_losses()\n",
    "            t_comp = (time.time() - iter_start_time) / opt.batch_size\n",
    "            visualizer.print_current_losses(epoch, epoch_iter, losses, t_comp, t_data)\n",
    "            if opt.display_id > 0:\n",
    "                visualizer.plot_current_losses(epoch, float(epoch_iter) / dataset_size, losses)\n",
    "\n",
    "        if total_iters % opt.save_latest_freq == 0:   # cache our latest model every <save_latest_freq> iterations\n",
    "            print('saving the latest model (epoch %d, total_iters %d)' % (epoch, total_iters))\n",
    "            save_suffix = 'iter_%d' % total_iters if opt.save_by_iter else 'latest'\n",
    "            model.save_networks(save_suffix)\n",
    "\n",
    "        iter_data_time = time.time()\n",
    "    if epoch % opt.save_epoch_freq == 0:              # cache our model every <save_epoch_freq> epochs\n",
    "        print('saving the model at the end of epoch %d, iters %d' % (epoch, total_iters))\n",
    "        model.save_networks('latest')\n",
    "        model.save_networks(epoch)\n",
    "\n",
    "    print('End of epoch %d / %d \\t Time Taken: %d sec' % (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
    "    model.update_learning_rate()                     # update learning rates at the end of every epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
