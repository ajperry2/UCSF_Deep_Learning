{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt={#BASE OPTIONS\n",
    "    \"dataroot\":\"./datasets/prostate_segmentation/\",\n",
    "    'phase':'train',\n",
    "    'image_size':256\n",
    "}\n",
    "class Map(dict):\n",
    "    \"\"\"\n",
    "    Example:\n",
    "    m = Map({'first_name': 'Eduardo'}, last_name='Pool', age=24, sports=['Soccer'])\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Map, self).__init__(*args, **kwargs)\n",
    "        for arg in args:\n",
    "            if isinstance(arg, dict):\n",
    "                for k, v in arg.items():\n",
    "                    self[k] = v\n",
    "\n",
    "        if kwargs:\n",
    "            for k, v in kwargs.items():\n",
    "                self[k] = v\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        return self.get(attr)\n",
    "\n",
    "    def __setattr__(self, key, value):\n",
    "        self.__setitem__(key, value)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        super(Map, self).__setitem__(key, value)\n",
    "        self.__dict__.update({key: value})\n",
    "\n",
    "    def __delattr__(self, item):\n",
    "        self.__delitem__(item)\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        super(Map, self).__delitem__(key)\n",
    "        del self.__dict__[key]\n",
    "opt = Map(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlignedDataset(Dataset):\n",
    "    def __init__(self,opt):\n",
    "        #dataroot\n",
    "        self.opt = opt\n",
    "        self.root = opt.dataroot\n",
    "        self.dir = os.path.join(opt.dataroot,'train')\n",
    "        self.picPaths = sorted(glob(self.dir+'/*'))\n",
    "        self.name = 'Aligned'\n",
    "    def __getitem__(self,index):\n",
    "        ab_path = self.picPaths[index]\n",
    "        ab = Image.open(ab_path).convert('RGB')\n",
    "        side = self.opt.image_size\n",
    "        A = ab.crop((0,0,side,side)).resize((self.opt.image_size,self.opt.image_size),Image.BICUBIC)\n",
    "        B = ab.crop((side,0,side,side)).resize((self.opt.image_size,self.opt.image_size),Image.BICUBIC)\n",
    "        \n",
    "        A = transforms.ToTensor()(A)\n",
    "        B = transforms.ToTensor()(B)\n",
    "\n",
    "        A = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(A)\n",
    "        B = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(B)\n",
    "        \n",
    "        return {'A':A,'B':B,\n",
    "                'A_paths': ab_path, 'B_paths': ab_path}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.picPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AlignedDataset(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class uNet(nn.Module):\n",
    "    def __init__(self,opt):\n",
    "        self.image_size = opt.image_size\n",
    "        self.layers = {}\n",
    "        while self.image_size > 1:\n",
    "            key = 'conv_'+str(self.image_size)\n",
    "            self.layers[key] = nn.Conv2d(in_channels = self.image_size,out_channels= int(self.image_size/2),stride=2,kernel_size=4)\n",
    "            self.image_size=int(self.image_size /2)\n",
    "        self.layers['downRelu'] = nn.LeakyReLU(negative_slope=0.2,True)\n",
    "        self.layers['norm'] = nn.BatchNorm2d(negative_slope=0.2,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "64\n",
      "32\n",
      "16\n",
      "8\n",
      "4\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "unet = uNet(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv_256': Conv2d(256, 128, kernel_size=(4, 4), stride=(2, 2)),\n",
       " 'conv_128': Conv2d(128, 64, kernel_size=(4, 4), stride=(2, 2)),\n",
       " 'conv_64': Conv2d(64, 32, kernel_size=(4, 4), stride=(2, 2)),\n",
       " 'conv_32': Conv2d(32, 16, kernel_size=(4, 4), stride=(2, 2)),\n",
       " 'conv_16': Conv2d(16, 8, kernel_size=(4, 4), stride=(2, 2)),\n",
       " 'conv_8': Conv2d(8, 4, kernel_size=(4, 4), stride=(2, 2)),\n",
       " 'conv_4': Conv2d(4, 2, kernel_size=(4, 4), stride=(2, 2)),\n",
       " 'conv_2': Conv2d(2, 1, kernel_size=(4, 4), stride=(2, 2))}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
