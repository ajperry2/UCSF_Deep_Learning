{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from util import util\n",
    "import torch\n",
    "import models\n",
    "import data\n",
    "import time\n",
    "from options.train_options import TrainOptions\n",
    "from data import create_dataset\n",
    "from models import create_model\n",
    "from util.visualizer import Visualizer\n",
    "import torch.nn as nn\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "option_json=easydict.EasyDict({#BASE OPTIONS\n",
    "    \"name\":\"experiment_name\",\n",
    "    \"gpu_ids\":[0,1],\n",
    "    \"checkpoints_dir\":\"./checkpoints\",\n",
    "    \"model\":\"cycle_gan\",\n",
    "    \"input_nc\":1,\n",
    "    \"output_nc\":1,\n",
    "    \"ngf\":64,\n",
    "    \"ndf\":64,\n",
    "    \"netD\":\"basic\",\n",
    "    \"netG\":\"resnet_9blocks\",\n",
    "    \"n_layers_D\":3,\n",
    "    \"norm\":\"batch\",\n",
    "    \"init_type\":\"normal\",\n",
    "    \"init_gain\":0.02,\n",
    "    \"no_dropout\":\"store_true\",\n",
    "    \"dataset_mode\":\"unaligned\",\n",
    "    \"direction\":\"AtoB\",\n",
    "    \"serial_batches\":\"store_true\",\n",
    "    \"num_threads\":4,\n",
    "    \"batch_size\":1,\n",
    "    \"load_size\":256,\n",
    "    \"crop_size\":256,\n",
    "    \"max_dataset_size\":float('inf'),\n",
    "    \"preprocess\":\"resize_and_crop\",\n",
    "    \"no_flip\":\"store_true\",\n",
    "    \"display_winsize\":\"256\",\n",
    "    \"epoch\":\"latest\",\n",
    "    \"load_iter\":0,\n",
    "    \"verbose\":\"store_true\",\n",
    "    \"suffix\":\"\", #TRAIN OPTIONS\n",
    "    \"isTrain\":True,\n",
    "    \"display_freq\":200,\n",
    "    \"display_ncols\":4,\n",
    "    \"display_id\":1,\n",
    "    \"display_server\":\"http://localhost\",\n",
    "    \"display_env\":\"main\",\n",
    "    \"display_port\":8097,\n",
    "    \"update_html_freq\":1000,\n",
    "    \"print_freq\":100,\n",
    "    \"no_html\":\"store_true\",\n",
    "    \"save_latest_freq\":400,\n",
    "    \"save_epoch_freq\":1,\n",
    "    \"save_by_iter\":\"store_true\",\n",
    "    \"continue_train\":\"store_true\",\n",
    "    \"epoch_count\":1,\n",
    "    \"phase_train\":\"train\",\n",
    "    \"dataroot\":'./processed',\n",
    "    \"niter\":100,\n",
    "    \"niter_decay\":100,\n",
    "    \"beta1\":0.5,\n",
    "    \"lr\":0.0002,\n",
    "    \"gan_mode\":'vanilla',\n",
    "    \"pool_size\":50,\n",
    "    \"lr_policy\":\"lambda\",\n",
    "    'lambda_A':10.0,\n",
    "    'lambda_B':10.0, \n",
    "    'lambda_identity':0.5, \n",
    "    \"lr_decay_iters\":50,#TEST OPTIONS\n",
    "    \"ntest\":float(\"inf\"),\n",
    "    \"results_dir\":'./results/',\n",
    "    \"aspect_ratio\":1.0,\n",
    "    \"phase_test\":'test',\n",
    "    \"eval\":\"store_true\",\n",
    "    \"num_test\":50\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset [UnalignedDataset] was created\n",
      "The number of training images = 2423\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [CycleGANModel] was created\n",
      "loading the model from ./checkpoints/experiment_name/latest_net_G_A.pth\n",
      "loading the model from ./checkpoints/experiment_name/latest_net_G_B.pth\n",
      "loading the model from ./checkpoints/experiment_name/latest_net_D_A.pth\n",
      "loading the model from ./checkpoints/experiment_name/latest_net_D_B.pth\n",
      "---------- Networks initialized -------------\n",
      "DataParallel(\n",
      "  (module): ResnetGenerator(\n",
      "    (model): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): Conv2d(1, 64, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace)\n",
      "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU(inplace)\n",
      "      (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (9): ReLU(inplace)\n",
      "      (10): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (11): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (12): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (13): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (14): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (15): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (16): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (17): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (18): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (19): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (20): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (21): ReLU(inplace)\n",
      "      (22): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (23): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (24): ReLU(inplace)\n",
      "      (25): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (26): Conv2d(64, 1, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (27): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network G_A] Total number of parameters : 11.371 M\n",
      "DataParallel(\n",
      "  (module): ResnetGenerator(\n",
      "    (model): Sequential(\n",
      "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (1): Conv2d(1, 64, kernel_size=(7, 7), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace)\n",
      "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU(inplace)\n",
      "      (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (9): ReLU(inplace)\n",
      "      (10): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (11): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (12): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (13): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (14): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (15): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (16): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (17): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (18): ResnetBlock(\n",
      "        (conv_block): Sequential(\n",
      "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU(inplace)\n",
      "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (19): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (20): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (21): ReLU(inplace)\n",
      "      (22): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (23): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (24): ReLU(inplace)\n",
      "      (25): ReflectionPad2d((3, 3, 3, 3))\n",
      "      (26): Conv2d(64, 1, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (27): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network G_B] Total number of parameters : 11.371 M\n",
      "DataParallel(\n",
      "  (module): NLayerDiscriminator(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network D_A] Total number of parameters : 2.764 M\n",
      "DataParallel(\n",
      "  (module): NLayerDiscriminator(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network D_B] Total number of parameters : 2.764 M\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#train_opt = TrainOptions().parse(option_json)   # get training options\n",
    "\n",
    "dataset = create_dataset(option_json)  # create a dataset given opt.dataset_mode and other options\n",
    "dataset_size = len(dataset)    # get the number of images in the dataset.\n",
    "print('The number of training images = %d' % dataset_size)\n",
    "\n",
    "model = create_model(option_json)      # create a model given opt.model and other options\n",
    "model = nn.DataParallel(model)    \n",
    "model.module.setup(option_json)               # regular setup: load and print networks; create schedulers\n",
    "visualizer = Visualizer(option_json)   # create a visualizer that display/save images and plots\n",
    "total_iters = 0                # the total number of training iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset [UnalignedDataset] was created\n",
      "(epoch: 1, iters: 100, time: 0.243, data: 0.117) D_A: 0.584 G_A: 1.335 cycle_A: 0.574 idt_A: 0.093 D_B: 0.217 G_B: 2.257 cycle_B: 0.404 idt_B: 0.143 \n",
      "(epoch: 1, iters: 200, time: 0.400, data: 0.001) D_A: 0.104 G_A: 1.403 cycle_A: 0.668 idt_A: 0.118 D_B: 0.171 G_B: 2.190 cycle_B: 0.830 idt_B: 0.175 \n",
      "(epoch: 1, iters: 300, time: 0.243, data: 0.001) D_A: 0.103 G_A: 1.885 cycle_A: 0.341 idt_A: 0.066 D_B: 0.238 G_B: 2.475 cycle_B: 0.372 idt_B: 0.104 \n",
      "(epoch: 1, iters: 400, time: 0.333, data: 0.001) D_A: 0.092 G_A: 0.973 cycle_A: 0.268 idt_A: 0.069 D_B: 0.183 G_B: 0.527 cycle_B: 0.279 idt_B: 0.095 \n",
      "saving the latest model (epoch 1, total_iters 400)\n",
      "(epoch: 1, iters: 500, time: 0.243, data: 0.001) D_A: 0.420 G_A: 3.965 cycle_A: 0.600 idt_A: 0.105 D_B: 0.808 G_B: 3.870 cycle_B: 0.643 idt_B: 0.178 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-4:\n",
      "Process Process-3:\n",
      "Process Process-2:\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/vasant/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-832b1eb473f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mepoch_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0moption_json\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# unpack data from dataset and apply preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# calculate loss functions, get gradients, update network weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_iters\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0moption_json\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# display images on visdom and save images to a HTML file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/vasant/4tb1/USF_Internship/ct_conversion/codes/pytorch-CycleGAN-and-pix2pix-master (copy)/models/cycle_gan_model.py\u001b[0m in \u001b[0;36moptimize_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_requires_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetD_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetD_B\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_G\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# D_A and D_B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/vasant/4tb1/USF_Internship/ct_conversion/codes/pytorch-CycleGAN-and-pix2pix-master (copy)/models/cycle_gan_model.py\u001b[0m in \u001b[0;36mbackward_G\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;31m# combined loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_G\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_G_A\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_G_B\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_cycle_A\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_cycle_B\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_idt_A\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_idt_B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(option_json.epoch_count, option_json.niter + option_json.niter_decay + 1):    # outer loop for different epochs; we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>\n",
    "    dataset = create_dataset(option_json)  # create a dataset given opt.dataset_mode and other options\n",
    "    epoch_start_time = time.time()  # timer for entire epoch\n",
    "    iter_data_time = time.time()    # timer for data loading per iteration\n",
    "    epoch_iter = 0                  # the number of training iterations in current epoch, reset to 0 every epoch\n",
    "\n",
    "    for i, data in enumerate(dataset):  # inner loop within one epoch\n",
    "        iter_start_time = time.time()  # timer for computation per iteration\n",
    "        if total_iters % option_json.print_freq == 0:\n",
    "            t_data = iter_start_time - iter_data_time\n",
    "        visualizer.reset()\n",
    "        total_iters += option_json.batch_size\n",
    "        epoch_iter += option_json.batch_size\n",
    "        model.module.set_input(data)         # unpack data from dataset and apply preprocessing\n",
    "        model.module.optimize_parameters()   # calculate loss functions, get gradients, update network weights\n",
    "\n",
    "        if total_iters % option_json.display_freq == 0:   # display images on visdom and save images to a HTML file\n",
    "            save_result = total_iters % option_json.update_html_freq == 0\n",
    "            model.module.compute_visuals()\n",
    "            visualizer.display_current_results(model.module.get_current_visuals(), epoch, save_result)\n",
    "\n",
    "        if total_iters % option_json.print_freq == 0:    # print training losses and save logging information to the disk\n",
    "            losses = model.module.get_current_losses()\n",
    "            t_comp = (time.time() - iter_start_time) / option_json.batch_size\n",
    "            visualizer.print_current_losses(epoch, epoch_iter, losses, t_comp, t_data)\n",
    "            if option_json.display_id > 0:\n",
    "                visualizer.plot_current_losses(epoch, float(epoch_iter) / dataset_size, losses)\n",
    "\n",
    "        if total_iters % option_json.save_latest_freq == 0:   # cache our latest model every <save_latest_freq> iterations\n",
    "            print('saving the latest model (epoch %d, total_iters %d)' % (epoch, total_iters))\n",
    "            save_suffix = 'iter_%d' % total_iters if option_json.save_by_iter else 'latest'\n",
    "            model.module.save_networks(save_suffix)\n",
    "\n",
    "        iter_data_time = time.time()\n",
    "    if epoch % option_json.save_epoch_freq == 0:              # cache our model every <save_epoch_freq> epochs\n",
    "        print('saving the model at the end of epoch %d, iters %d' % (epoch, total_iters))\n",
    "        model.module.save_networks('latest')\n",
    "        model.module.save_networks(epoch)\n",
    "\n",
    "    print('End of epoch %d / %d \\t Time Taken: %d sec' % (epoch, option_json.niter + option_json.niter_decay, time.time() - epoch_start_time))\n",
    "    model.module.update_learning_rate()                     # update learning rates at the end of every epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
