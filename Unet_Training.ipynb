{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#If you need a new visdom server for visualization, run this command in a terminal\n",
    "# python -m visdom.server\n",
    "#then navigate here http://localhost:8097"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "from data import CreateDataLoader\n",
    "from models import create_model\n",
    "from util.visualizer import Visualizer\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt={#BASE OPTIONS\n",
    "    #path to images (should have subfolders trainA, trainB, valA, valB, etc)\n",
    "    \"dataroot\":\"./datasets/prostate_segmentation/\",\n",
    "\n",
    "    \n",
    "    #'name of the experiment. It decides where to store samples and models\n",
    "    \"name\":\"prostate_cycle_gan\",\n",
    "    \n",
    "    #gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU\n",
    "    \"gpu_ids\":[0,1],\n",
    "    \n",
    "    # models are saved here\n",
    "    \n",
    "    \"checkpoints_dir\":\"./checkpoints\",\n",
    "    \n",
    "    # chooses which model to use. [cycle_gan | pix2pix | test | colorization]\n",
    "    \"model\":\"pix2pix\",\n",
    "    # instance normalization or batch normalization [instance | batch | none]\n",
    "    \"norm\":\"instance\",\n",
    "    'use_dropout':True,\n",
    "    'data_type':16,\n",
    "    'verbose':True,\n",
    "    'batchSize':1,\n",
    "    'which_direction':'AtoB',\n",
    "    'loadSize':286,\n",
    "    'fineSize':256,\n",
    "    'label_nc':35,\n",
    "    'input_nc':3,\n",
    "    'output_nc':1,\n",
    "    'ngf':64,\n",
    "    'ndf':64,\n",
    "    'which_model_netD':'basic',\n",
    "    'which_model_netG':'unet_256',\n",
    "    'n_layers_D':3,\n",
    "    'dataset_mode':'aligned',\n",
    "    'nThreads':8,\n",
    "    'serial_batches':True,\n",
    "    'display_winsize':256,\n",
    "    'display_id':1,\n",
    "    'display_server':'http://localhost',\n",
    "    \"display_env\":\"main\",\n",
    "    'display_port':8097,\n",
    "    'no_dropout':False,\n",
    "    'max_dataset_size':float(\"inf\"),\n",
    "    'resize_or_crop':'resize_and_crop',\n",
    "    'no_flip':True,\n",
    "    'init_type':'kaiming',\n",
    "    'init_gain':0.02,\n",
    "    'verbose':True,\n",
    "    'suffix':'',\n",
    "    #TRAIN OPTIONS\n",
    "    'isTrain':True,\n",
    "    'display_freq':100,\n",
    "    'display_ncols':4,\n",
    "    'update_html_freq':1000,\n",
    "    'print_freq':100,\n",
    "    'save_latest_freq':5000,\n",
    "    'save_epoch_freq':5,\n",
    "    'continue_train':False,\n",
    "    'epoch_count':1,\n",
    "    'phase':'train',\n",
    "    'which_epoch':'200',\n",
    "    'niter':100,\n",
    "    'niter_decay':100,\n",
    "    'beta1':0.5,\n",
    "    'lr':0.0002,\n",
    "    'no_lsgan':True,\n",
    "    'pool_size':50,\n",
    "    'no_html':True,\n",
    "    'lr_policy':'lambda',\n",
    "    'lr_decay_iters':1,\n",
    "    'lambda_identity':0.5,\n",
    "    'lambda_B':10.0,\n",
    "    'lambda_A':10.0,\n",
    "    'lambda_L1':50.0\n",
    "    }\n",
    "class Map(dict):\n",
    "    \"\"\"\n",
    "    Example:\n",
    "    m = Map({'first_name': 'Eduardo'}, last_name='Pool', age=24, sports=['Soccer'])\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Map, self).__init__(*args, **kwargs)\n",
    "        for arg in args:\n",
    "            if isinstance(arg, dict):\n",
    "                for k, v in arg.items():\n",
    "                    self[k] = v\n",
    "\n",
    "        if kwargs:\n",
    "            for k, v in kwargs.items():\n",
    "                self[k] = v\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        return self.get(attr)\n",
    "\n",
    "    def __setattr__(self, key, value):\n",
    "        self.__setitem__(key, value)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        super(Map, self).__setitem__(key, value)\n",
    "        self.__dict__.update({key: value})\n",
    "\n",
    "    def __delattr__(self, item):\n",
    "        self.__delitem__(item)\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        super(Map, self).__delitem__(key)\n",
    "        del self.__dict__[key]\n",
    "opt = Map(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(opt):\n",
    "    data_loader = CreateDataLoader(opt)\n",
    "    dataset = data_loader.load_data()\n",
    "    dataset_size = len(data_loader)\n",
    "    print('The number of training images = %d' % dataset_size)\n",
    "\n",
    "    model = create_model(opt)      # create a model given opt.model and other options\n",
    "    model.setup(opt)               # regular setup: load and print networks; create schedulers\n",
    "    visualizer = Visualizer(opt)   # create a visualizer that display/save images and plots\n",
    "    total_steps = 0                # the total number of training iterations\n",
    "\n",
    "    for epoch in range(opt.epoch_count, opt.niter + opt.niter_decay + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        iter_data_time = time.time()\n",
    "        epoch_iter = 0\n",
    "\n",
    "        for i, data in enumerate(dataset):\n",
    "            iter_start_time = time.time()\n",
    "            if total_steps % opt.print_freq == 0:\n",
    "                t_data = iter_start_time - iter_data_time\n",
    "            visualizer.reset()\n",
    "            total_steps += opt.batchSize\n",
    "            epoch_iter += opt.batchSize\n",
    "            model.set_input(data)\n",
    "            model.optimize_parameters()\n",
    "\n",
    "            if total_steps % opt.display_freq == 0:\n",
    "                save_result = total_steps % opt.update_html_freq == 0\n",
    "                visualizer.display_current_results(model.get_current_visuals(), epoch, save_result)\n",
    "\n",
    "            if total_steps % opt.print_freq == 0:\n",
    "                losses = model.get_current_losses()\n",
    "                t = (time.time() - iter_start_time) / opt.batchSize\n",
    "                visualizer.print_current_losses(epoch, epoch_iter, losses, t, t_data)\n",
    "                if opt.display_id > 0:\n",
    "                    visualizer.plot_current_losses(epoch, float(epoch_iter) / dataset_size, opt, losses)\n",
    "\n",
    "            if total_steps % opt.save_latest_freq == 0:\n",
    "                print('saving the latest model (epoch %d, total_steps %d)' %\n",
    "                      (epoch, total_steps))\n",
    "                model.save_networks('latest')\n",
    "\n",
    "            iter_data_time = time.time()\n",
    "        if epoch % opt.save_epoch_freq == 0:\n",
    "            print('saving the model at the end of epoch %d, iters %d' %\n",
    "                  (epoch, total_steps))\n",
    "            model.save_networks('latest')\n",
    "            model.save_networks(epoch)\n",
    "\n",
    "        print('End of epoch %d / %d \\t Time Taken: %d sec' %\n",
    "              (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
    "        model.update_learning_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 2280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "DataParallel(\n",
      "  (module): UnetGenerator(\n",
      "    (model): UnetSkipConnectionBlock(\n",
      "      (model): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): UnetSkipConnectionBlock(\n",
      "          (model): Sequential(\n",
      "            (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "            (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (3): UnetSkipConnectionBlock(\n",
      "              (model): Sequential(\n",
      "                (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (3): UnetSkipConnectionBlock(\n",
      "                  (model): Sequential(\n",
      "                    (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                    (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (3): UnetSkipConnectionBlock(\n",
      "                      (model): Sequential(\n",
      "                        (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                        (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                        (3): UnetSkipConnectionBlock(\n",
      "                          (model): Sequential(\n",
      "                            (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                            (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                            (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                            (3): UnetSkipConnectionBlock(\n",
      "                              (model): Sequential(\n",
      "                                (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                                (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                                (3): UnetSkipConnectionBlock(\n",
      "                                  (model): Sequential(\n",
      "                                    (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                                    (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                    (2): ReLU(inplace)\n",
      "                                    (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                                  )\n",
      "                                )\n",
      "                                (4): ReLU(inplace)\n",
      "                                (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                                (7): Dropout(p=0.5)\n",
      "                              )\n",
      "                            )\n",
      "                            (4): ReLU(inplace)\n",
      "                            (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                            (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                            (7): Dropout(p=0.5)\n",
      "                          )\n",
      "                        )\n",
      "                        (4): ReLU(inplace)\n",
      "                        (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                        (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                        (7): Dropout(p=0.5)\n",
      "                      )\n",
      "                    )\n",
      "                    (4): ReLU(inplace)\n",
      "                    (5): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                )\n",
      "                (4): ReLU(inplace)\n",
      "                (5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (4): ReLU(inplace)\n",
      "            (5): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): ReLU(inplace)\n",
      "        (3): ConvTranspose2d(128, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "        (4): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network G] Total number of parameters : 54.410 M\n",
      "DataParallel(\n",
      "  (module): NLayerDiscriminator(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(4, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (3): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (5): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (6): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (7): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (8): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "      (9): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network D] Total number of parameters : 2.765 M\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-145060d39a88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoints_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoints_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_opt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-8d3d41bd70c3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtotal_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mepoch_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/vasant/4tb1/USF_Internship/ct_conversion/codes/NucleiSegmentation/models/pix2pix_model.py\u001b[0m in \u001b[0;36mset_input\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mAtoB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhich_direction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'AtoB'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mAtoB\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'B'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'B'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mAtoB\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'A'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A_paths'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mAtoB\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'B_paths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "droupouts = [0,0.1,0.25,0.4]\n",
    "for drop_out in droupouts:\n",
    "        new_opt = Map(opt)\n",
    "        new_opt.drop_out\n",
    "        new_opt.name = 'prostate_cyc_batch_'+'_lr_'+str(learning_rate)+'_batch'+str(batch_size)\n",
    "        if not os.path.exists(os.path.join(new_opt.checkpoints_dir,new_opt.name)):\n",
    "            os.mkdir(os.path.join(new_opt.checkpoints_dir,new_opt.name))\n",
    "        train(new_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 2280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "DataParallel(\n",
      "  (module): UnetGenerator(\n",
      "    (model): UnetSkipConnectionBlock(\n",
      "      (model): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): UnetSkipConnectionBlock(\n",
      "          (model): Sequential(\n",
      "            (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "            (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (3): UnetSkipConnectionBlock(\n",
      "              (model): Sequential(\n",
      "                (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (3): UnetSkipConnectionBlock(\n",
      "                  (model): Sequential(\n",
      "                    (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                    (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (3): UnetSkipConnectionBlock(\n",
      "                      (model): Sequential(\n",
      "                        (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                        (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                        (3): UnetSkipConnectionBlock(\n",
      "                          (model): Sequential(\n",
      "                            (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                            (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                            (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                            (3): UnetSkipConnectionBlock(\n",
      "                              (model): Sequential(\n",
      "                                (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                                (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                                (3): UnetSkipConnectionBlock(\n",
      "                                  (model): Sequential(\n",
      "                                    (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                                    (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                    (2): ReLU(inplace)\n",
      "                                    (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                                  )\n",
      "                                )\n",
      "                                (4): ReLU(inplace)\n",
      "                                (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                                (7): Dropout(p=0.5)\n",
      "                              )\n",
      "                            )\n",
      "                            (4): ReLU(inplace)\n",
      "                            (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                            (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                            (7): Dropout(p=0.5)\n",
      "                          )\n",
      "                        )\n",
      "                        (4): ReLU(inplace)\n",
      "                        (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                        (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                        (7): Dropout(p=0.5)\n",
      "                      )\n",
      "                    )\n",
      "                    (4): ReLU(inplace)\n",
      "                    (5): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                )\n",
      "                (4): ReLU(inplace)\n",
      "                (5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (4): ReLU(inplace)\n",
      "            (5): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): ReLU(inplace)\n",
      "        (3): ConvTranspose2d(128, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "        (4): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network G] Total number of parameters : 54.410 M\n",
      "DataParallel(\n",
      "  (module): NLayerDiscriminator(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(4, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (3): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (5): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (6): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (7): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (8): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "      (9): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network D] Total number of parameters : 2.765 M\n",
      "-----------------------------------------------\n",
      "(epoch: 1, iters: 100, time: 0.079, data: 0.424) G_GAN: 0.973 G_L1: 5.348 D_real: 0.443 D_fake: 0.760 \n",
      "(epoch: 1, iters: 200, time: 0.073, data: 0.001) G_GAN: 0.576 G_L1: 0.007 D_real: 0.468 D_fake: 0.789 \n",
      "(epoch: 1, iters: 300, time: 0.075, data: 0.001) G_GAN: 0.673 G_L1: 0.006 D_real: 0.680 D_fake: 0.701 \n",
      "(epoch: 1, iters: 400, time: 0.072, data: 0.002) G_GAN: 0.696 G_L1: 1.442 D_real: 0.678 D_fake: 0.692 \n",
      "(epoch: 1, iters: 500, time: 0.071, data: 0.001) G_GAN: 0.737 G_L1: 0.015 D_real: 0.740 D_fake: 0.649 \n",
      "(epoch: 1, iters: 600, time: 0.072, data: 0.001) G_GAN: 0.714 G_L1: 0.007 D_real: 0.715 D_fake: 0.666 \n",
      "(epoch: 1, iters: 700, time: 0.072, data: 0.001) G_GAN: 0.727 G_L1: 1.922 D_real: 0.658 D_fake: 0.665 \n",
      "(epoch: 1, iters: 800, time: 0.077, data: 0.001) G_GAN: 0.716 G_L1: 0.003 D_real: 0.743 D_fake: 0.640 \n",
      "(epoch: 1, iters: 900, time: 0.078, data: 0.002) G_GAN: 0.662 G_L1: 0.000 D_real: 0.662 D_fake: 0.687 \n",
      "(epoch: 1, iters: 1000, time: 0.075, data: 0.002) G_GAN: 0.739 G_L1: 1.679 D_real: 0.648 D_fake: 0.665 \n",
      "(epoch: 1, iters: 1100, time: 0.071, data: 0.002) G_GAN: 0.762 G_L1: 0.011 D_real: 0.841 D_fake: 0.613 \n",
      "(epoch: 1, iters: 1200, time: 0.075, data: 0.002) G_GAN: 0.729 G_L1: 0.003 D_real: 0.737 D_fake: 0.651 \n",
      "(epoch: 1, iters: 1300, time: 0.074, data: 0.002) G_GAN: 0.732 G_L1: 1.744 D_real: 0.623 D_fake: 0.665 \n",
      "(epoch: 1, iters: 1400, time: 0.075, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.804 D_fake: 0.596 \n",
      "(epoch: 1, iters: 1500, time: 0.072, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.726 D_fake: 0.661 \n",
      "(epoch: 1, iters: 1600, time: 0.072, data: 0.002) G_GAN: 0.738 G_L1: 2.124 D_real: 0.604 D_fake: 0.662 \n",
      "(epoch: 1, iters: 1700, time: 0.073, data: 0.001) G_GAN: 0.777 G_L1: 0.004 D_real: 0.793 D_fake: 0.604 \n",
      "(epoch: 1, iters: 1800, time: 0.071, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.724 D_fake: 0.658 \n",
      "(epoch: 1, iters: 1900, time: 0.072, data: 0.002) G_GAN: 0.747 G_L1: 3.703 D_real: 0.568 D_fake: 0.660 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 1, iters: 2000, time: 0.075, data: 0.001) G_GAN: 0.768 G_L1: 0.000 D_real: 0.778 D_fake: 0.616 \n",
      "(epoch: 1, iters: 2100, time: 0.072, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.717 D_fake: 0.671 \n",
      "(epoch: 1, iters: 2200, time: 0.077, data: 0.001) G_GAN: 0.789 G_L1: 1.586 D_real: 0.638 D_fake: 0.631 \n",
      "End of epoch 1 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 2, iters: 20, time: 0.072, data: 0.002) G_GAN: 0.737 G_L1: 0.001 D_real: 0.735 D_fake: 0.649 \n",
      "(epoch: 2, iters: 120, time: 0.073, data: 0.001) G_GAN: 0.725 G_L1: 0.002 D_real: 0.735 D_fake: 0.653 \n",
      "(epoch: 2, iters: 220, time: 0.071, data: 0.001) G_GAN: 0.726 G_L1: 2.749 D_real: 0.570 D_fake: 0.678 \n",
      "(epoch: 2, iters: 320, time: 0.072, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.751 D_fake: 0.639 \n",
      "(epoch: 2, iters: 420, time: 0.074, data: 0.001) G_GAN: 0.719 G_L1: 0.001 D_real: 0.728 D_fake: 0.660 \n",
      "(epoch: 2, iters: 520, time: 0.074, data: 0.002) G_GAN: 0.736 G_L1: 1.419 D_real: 0.614 D_fake: 0.661 \n",
      "(epoch: 2, iters: 620, time: 0.074, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.738 D_fake: 0.651 \n",
      "(epoch: 2, iters: 720, time: 0.073, data: 0.001) G_GAN: 0.733 G_L1: 0.001 D_real: 0.699 D_fake: 0.696 \n",
      "(epoch: 2, iters: 820, time: 0.073, data: 0.002) G_GAN: 0.740 G_L1: 1.824 D_real: 0.597 D_fake: 0.660 \n",
      "(epoch: 2, iters: 920, time: 0.070, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.748 D_fake: 0.638 \n",
      "(epoch: 2, iters: 1020, time: 0.071, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.729 D_fake: 0.660 \n",
      "(epoch: 2, iters: 1120, time: 0.078, data: 0.001) G_GAN: 0.825 G_L1: 1.958 D_real: 0.713 D_fake: 0.577 \n",
      "(epoch: 2, iters: 1220, time: 0.079, data: 0.002) G_GAN: 0.780 G_L1: 0.000 D_real: 0.818 D_fake: 0.587 \n",
      "(epoch: 2, iters: 1320, time: 0.073, data: 0.001) G_GAN: 0.711 G_L1: 0.000 D_real: 0.714 D_fake: 0.670 \n",
      "(epoch: 2, iters: 1420, time: 0.072, data: 0.001) G_GAN: 0.748 G_L1: 2.010 D_real: 0.638 D_fake: 0.649 \n",
      "(epoch: 2, iters: 1520, time: 0.072, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.716 D_fake: 0.665 \n",
      "(epoch: 2, iters: 1620, time: 0.074, data: 0.001) G_GAN: 0.704 G_L1: 0.000 D_real: 0.746 D_fake: 0.660 \n",
      "(epoch: 2, iters: 1720, time: 0.071, data: 0.002) G_GAN: 0.746 G_L1: 3.150 D_real: 0.595 D_fake: 0.642 \n",
      "(epoch: 2, iters: 1820, time: 0.075, data: 0.002) G_GAN: 0.764 G_L1: 0.003 D_real: 0.791 D_fake: 0.620 \n",
      "(epoch: 2, iters: 1920, time: 0.074, data: 0.003) G_GAN: 0.724 G_L1: 0.000 D_real: 0.726 D_fake: 0.662 \n",
      "(epoch: 2, iters: 2020, time: 0.073, data: 0.003) G_GAN: 0.736 G_L1: 1.672 D_real: 0.623 D_fake: 0.655 \n",
      "(epoch: 2, iters: 2120, time: 0.072, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.811 D_fake: 0.591 \n",
      "(epoch: 2, iters: 2220, time: 0.071, data: 0.002) G_GAN: 0.652 G_L1: 0.000 D_real: 0.653 D_fake: 0.686 \n",
      "End of epoch 2 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 3, iters: 40, time: 0.073, data: 0.002) G_GAN: 0.744 G_L1: 1.820 D_real: 0.619 D_fake: 0.655 \n",
      "(epoch: 3, iters: 140, time: 0.072, data: 0.001) G_GAN: 0.784 G_L1: 0.000 D_real: 0.794 D_fake: 0.603 \n",
      "(epoch: 3, iters: 240, time: 0.073, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.749 D_fake: 0.643 \n",
      "(epoch: 3, iters: 340, time: 0.073, data: 0.001) G_GAN: 0.757 G_L1: 1.290 D_real: 0.662 D_fake: 0.633 \n",
      "(epoch: 3, iters: 440, time: 0.073, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.757 D_fake: 0.633 \n",
      "saving the latest model (epoch 3, total_steps 5000)\n",
      "(epoch: 3, iters: 540, time: 0.072, data: 0.002) G_GAN: 0.633 G_L1: 0.000 D_real: 0.651 D_fake: 0.736 \n",
      "(epoch: 3, iters: 640, time: 0.071, data: 0.001) G_GAN: 0.743 G_L1: 2.681 D_real: 0.602 D_fake: 0.655 \n",
      "(epoch: 3, iters: 740, time: 0.071, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.761 D_fake: 0.636 \n",
      "(epoch: 3, iters: 840, time: 0.071, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.691 D_fake: 0.698 \n",
      "(epoch: 3, iters: 940, time: 0.072, data: 0.002) G_GAN: 0.757 G_L1: 3.230 D_real: 0.600 D_fake: 0.643 \n",
      "(epoch: 3, iters: 1040, time: 0.072, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.751 D_fake: 0.641 \n",
      "(epoch: 3, iters: 1140, time: 0.077, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.734 D_fake: 0.647 \n",
      "(epoch: 3, iters: 1240, time: 0.075, data: 0.002) G_GAN: 0.752 G_L1: 2.398 D_real: 0.612 D_fake: 0.646 \n",
      "(epoch: 3, iters: 1340, time: 0.072, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.741 D_fake: 0.646 \n",
      "(epoch: 3, iters: 1440, time: 0.077, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.739 D_fake: 0.649 \n",
      "(epoch: 3, iters: 1540, time: 0.077, data: 0.002) G_GAN: 0.737 G_L1: 1.506 D_real: 0.610 D_fake: 0.662 \n",
      "(epoch: 3, iters: 1640, time: 0.073, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.757 D_fake: 0.634 \n",
      "(epoch: 3, iters: 1740, time: 0.075, data: 0.002) G_GAN: 0.732 G_L1: 0.001 D_real: 0.743 D_fake: 0.647 \n",
      "(epoch: 3, iters: 1840, time: 0.072, data: 0.002) G_GAN: 0.741 G_L1: 0.842 D_real: 0.647 D_fake: 0.650 \n",
      "(epoch: 3, iters: 1940, time: 0.071, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.754 D_fake: 0.637 \n",
      "(epoch: 3, iters: 2040, time: 0.074, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.728 D_fake: 0.660 \n",
      "(epoch: 3, iters: 2140, time: 0.073, data: 0.002) G_GAN: 0.769 G_L1: 0.917 D_real: 0.654 D_fake: 0.660 \n",
      "(epoch: 3, iters: 2240, time: 0.073, data: 0.002) G_GAN: 0.754 G_L1: 0.001 D_real: 0.762 D_fake: 0.630 \n",
      "End of epoch 3 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 4, iters: 60, time: 0.075, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.731 D_fake: 0.652 \n",
      "(epoch: 4, iters: 160, time: 0.073, data: 0.001) G_GAN: 0.746 G_L1: 2.185 D_real: 0.608 D_fake: 0.653 \n",
      "(epoch: 4, iters: 260, time: 0.072, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.748 D_fake: 0.644 \n",
      "(epoch: 4, iters: 360, time: 0.072, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.733 D_fake: 0.653 \n",
      "(epoch: 4, iters: 460, time: 0.072, data: 0.002) G_GAN: 0.748 G_L1: 2.057 D_real: 0.610 D_fake: 0.651 \n",
      "(epoch: 4, iters: 560, time: 0.077, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.745 D_fake: 0.645 \n",
      "(epoch: 4, iters: 660, time: 0.072, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.733 D_fake: 0.656 \n",
      "(epoch: 4, iters: 760, time: 0.072, data: 0.002) G_GAN: 0.737 G_L1: 2.005 D_real: 0.603 D_fake: 0.657 \n",
      "(epoch: 4, iters: 860, time: 0.071, data: 0.002) G_GAN: 0.000 G_L1: 0.000 D_real: 0.630 D_fake: 0.631 \n",
      "(epoch: 4, iters: 960, time: 0.072, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.728 D_fake: 0.660 \n",
      "(epoch: 4, iters: 1060, time: 0.072, data: 0.001) G_GAN: 0.684 G_L1: 0.700 D_real: 0.645 D_fake: 0.709 \n",
      "(epoch: 4, iters: 1160, time: 0.071, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.744 D_fake: 0.676 \n",
      "(epoch: 4, iters: 1260, time: 0.074, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.701 D_fake: 0.686 \n",
      "(epoch: 4, iters: 1360, time: 0.074, data: 0.002) G_GAN: 0.717 G_L1: 2.029 D_real: 0.618 D_fake: 0.687 \n",
      "(epoch: 4, iters: 1460, time: 0.070, data: 0.002) G_GAN: 0.749 G_L1: 0.001 D_real: 0.782 D_fake: 0.614 \n",
      "(epoch: 4, iters: 1560, time: 0.075, data: 0.003) G_GAN: 0.711 G_L1: 0.000 D_real: 0.726 D_fake: 0.661 \n",
      "(epoch: 4, iters: 1660, time: 0.073, data: 0.002) G_GAN: 0.739 G_L1: 1.703 D_real: 0.628 D_fake: 0.668 \n",
      "(epoch: 4, iters: 1760, time: 0.072, data: 0.002) G_GAN: 0.723 G_L1: 0.001 D_real: 0.755 D_fake: 0.640 \n",
      "(epoch: 4, iters: 1860, time: 0.071, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.701 D_fake: 0.679 \n",
      "(epoch: 4, iters: 1960, time: 0.072, data: 0.001) G_GAN: 0.756 G_L1: 2.015 D_real: 0.615 D_fake: 0.667 \n",
      "(epoch: 4, iters: 2060, time: 0.075, data: 0.002) G_GAN: 0.702 G_L1: 0.001 D_real: 0.719 D_fake: 0.669 \n",
      "(epoch: 4, iters: 2160, time: 0.076, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.728 D_fake: 0.660 \n",
      "(epoch: 4, iters: 2260, time: 0.073, data: 0.002) G_GAN: 0.757 G_L1: 2.747 D_real: 0.597 D_fake: 0.669 \n",
      "End of epoch 4 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 5, iters: 80, time: 0.075, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.784 D_fake: 0.609 \n",
      "(epoch: 5, iters: 180, time: 0.073, data: 0.001) G_GAN: 0.707 G_L1: 0.000 D_real: 0.728 D_fake: 0.651 \n",
      "(epoch: 5, iters: 280, time: 0.071, data: 0.002) G_GAN: 0.741 G_L1: 1.028 D_real: 0.636 D_fake: 0.669 \n",
      "(epoch: 5, iters: 380, time: 0.072, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.763 D_fake: 0.628 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 5, iters: 480, time: 0.073, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.711 D_fake: 0.677 \n",
      "(epoch: 5, iters: 580, time: 0.072, data: 0.002) G_GAN: 0.780 G_L1: 3.522 D_real: 0.586 D_fake: 0.655 \n",
      "(epoch: 5, iters: 680, time: 0.071, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.775 D_fake: 0.622 \n",
      "(epoch: 5, iters: 780, time: 0.075, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.708 D_fake: 0.680 \n",
      "(epoch: 5, iters: 880, time: 0.070, data: 0.002) G_GAN: 0.726 G_L1: 2.562 D_real: 0.570 D_fake: 0.682 \n",
      "saving the latest model (epoch 5, total_steps 10000)\n",
      "(epoch: 5, iters: 980, time: 0.073, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.765 D_fake: 0.626 \n",
      "(epoch: 5, iters: 1080, time: 0.075, data: 0.001) G_GAN: 0.679 G_L1: 0.000 D_real: 0.685 D_fake: 0.704 \n",
      "(epoch: 5, iters: 1180, time: 0.074, data: 0.002) G_GAN: 0.781 G_L1: 2.010 D_real: 0.614 D_fake: 0.654 \n",
      "(epoch: 5, iters: 1280, time: 0.072, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.778 D_fake: 0.621 \n",
      "(epoch: 5, iters: 1380, time: 0.074, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.719 D_fake: 0.672 \n",
      "(epoch: 5, iters: 1480, time: 0.073, data: 0.001) G_GAN: 0.738 G_L1: 1.798 D_real: 0.602 D_fake: 0.675 \n",
      "(epoch: 5, iters: 1580, time: 0.073, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.762 D_fake: 0.630 \n",
      "(epoch: 5, iters: 1680, time: 0.075, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.710 D_fake: 0.676 \n",
      "(epoch: 5, iters: 1780, time: 0.075, data: 0.002) G_GAN: 0.763 G_L1: 2.503 D_real: 0.597 D_fake: 0.662 \n",
      "(epoch: 5, iters: 1880, time: 0.076, data: 0.001) G_GAN: 0.749 G_L1: 0.000 D_real: 0.766 D_fake: 0.626 \n",
      "(epoch: 5, iters: 1980, time: 0.073, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.713 D_fake: 0.674 \n",
      "(epoch: 5, iters: 2080, time: 0.075, data: 0.001) G_GAN: 0.752 G_L1: 2.294 D_real: 0.596 D_fake: 0.665 \n",
      "(epoch: 5, iters: 2180, time: 0.074, data: 0.002) G_GAN: 0.769 G_L1: 0.001 D_real: 0.788 D_fake: 0.606 \n",
      "(epoch: 5, iters: 2280, time: 0.071, data: 0.001) G_GAN: 0.685 G_L1: 0.000 D_real: 0.708 D_fake: 0.681 \n",
      "saving the model at the end of epoch 5, iters 11400\n",
      "End of epoch 5 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 6, iters: 100, time: 0.074, data: 0.446) G_GAN: 0.746 G_L1: 2.471 D_real: 0.590 D_fake: 0.668 \n",
      "(epoch: 6, iters: 200, time: 0.076, data: 0.001) G_GAN: 0.752 G_L1: 0.001 D_real: 0.768 D_fake: 0.626 \n",
      "(epoch: 6, iters: 300, time: 0.072, data: 0.002) G_GAN: 0.705 G_L1: 0.002 D_real: 0.719 D_fake: 0.669 \n",
      "(epoch: 6, iters: 400, time: 0.073, data: 0.002) G_GAN: 0.730 G_L1: 1.391 D_real: 0.613 D_fake: 0.681 \n",
      "(epoch: 6, iters: 500, time: 0.074, data: 0.002) G_GAN: 0.752 G_L1: 0.001 D_real: 0.761 D_fake: 0.631 \n",
      "(epoch: 6, iters: 600, time: 0.075, data: 0.002) G_GAN: 0.711 G_L1: 0.001 D_real: 0.734 D_fake: 0.655 \n",
      "(epoch: 6, iters: 700, time: 0.073, data: 0.002) G_GAN: 0.744 G_L1: 1.918 D_real: 0.601 D_fake: 0.667 \n",
      "(epoch: 6, iters: 800, time: 0.072, data: 0.001) G_GAN: 0.755 G_L1: 0.000 D_real: 0.767 D_fake: 0.625 \n",
      "(epoch: 6, iters: 900, time: 0.070, data: 0.003) G_GAN: 0.696 G_L1: 0.000 D_real: 0.716 D_fake: 0.671 \n",
      "(epoch: 6, iters: 1000, time: 0.072, data: 0.002) G_GAN: 0.742 G_L1: 1.676 D_real: 0.612 D_fake: 0.661 \n",
      "(epoch: 6, iters: 1100, time: 0.072, data: 0.002) G_GAN: 0.716 G_L1: 0.007 D_real: 0.783 D_fake: 0.636 \n",
      "(epoch: 6, iters: 1200, time: 0.072, data: 0.002) G_GAN: 0.703 G_L1: 0.001 D_real: 0.721 D_fake: 0.666 \n",
      "(epoch: 6, iters: 1300, time: 0.074, data: 0.002) G_GAN: 0.746 G_L1: 1.744 D_real: 0.615 D_fake: 0.656 \n",
      "(epoch: 6, iters: 1400, time: 0.072, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.764 D_fake: 0.628 \n",
      "(epoch: 6, iters: 1500, time: 0.072, data: 0.001) G_GAN: 0.719 G_L1: 0.000 D_real: 0.732 D_fake: 0.656 \n",
      "(epoch: 6, iters: 1600, time: 0.073, data: 0.002) G_GAN: 0.738 G_L1: 2.087 D_real: 0.596 D_fake: 0.661 \n",
      "(epoch: 6, iters: 1700, time: 0.072, data: 0.002) G_GAN: 0.764 G_L1: 0.004 D_real: 0.781 D_fake: 0.617 \n",
      "(epoch: 6, iters: 1800, time: 0.071, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.735 D_fake: 0.657 \n",
      "(epoch: 6, iters: 1900, time: 0.075, data: 0.002) G_GAN: 0.747 G_L1: 3.683 D_real: 0.563 D_fake: 0.662 \n",
      "(epoch: 6, iters: 2000, time: 0.077, data: 0.002) G_GAN: 0.762 G_L1: 0.001 D_real: 0.765 D_fake: 0.627 \n",
      "(epoch: 6, iters: 2100, time: 0.072, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.742 D_fake: 0.646 \n",
      "(epoch: 6, iters: 2200, time: 0.075, data: 0.002) G_GAN: 0.843 G_L1: 1.587 D_real: 0.683 D_fake: 0.582 \n",
      "End of epoch 6 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 7, iters: 20, time: 0.074, data: 0.002) G_GAN: 0.692 G_L1: 0.001 D_real: 0.754 D_fake: 0.635 \n",
      "(epoch: 7, iters: 120, time: 0.075, data: 0.001) G_GAN: 0.685 G_L1: 0.000 D_real: 0.713 D_fake: 0.673 \n",
      "(epoch: 7, iters: 220, time: 0.076, data: 0.002) G_GAN: 0.753 G_L1: 2.749 D_real: 0.592 D_fake: 0.655 \n",
      "(epoch: 7, iters: 320, time: 0.072, data: 0.001) G_GAN: 0.753 G_L1: 0.000 D_real: 0.759 D_fake: 0.632 \n",
      "(epoch: 7, iters: 420, time: 0.072, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.724 D_fake: 0.665 \n",
      "(epoch: 7, iters: 520, time: 0.072, data: 0.002) G_GAN: 0.737 G_L1: 1.418 D_real: 0.606 D_fake: 0.668 \n",
      "(epoch: 7, iters: 620, time: 0.074, data: 0.002) G_GAN: 0.729 G_L1: 0.001 D_real: 0.739 D_fake: 0.648 \n",
      "(epoch: 7, iters: 720, time: 0.075, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.723 D_fake: 0.666 \n",
      "(epoch: 7, iters: 820, time: 0.071, data: 0.001) G_GAN: 0.741 G_L1: 1.824 D_real: 0.609 D_fake: 0.660 \n",
      "(epoch: 7, iters: 920, time: 0.076, data: 0.001) G_GAN: 0.770 G_L1: 0.000 D_real: 0.823 D_fake: 0.586 \n",
      "(epoch: 7, iters: 1020, time: 0.075, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.733 D_fake: 0.657 \n",
      "(epoch: 7, iters: 1120, time: 0.072, data: 0.002) G_GAN: 0.781 G_L1: 1.954 D_real: 0.644 D_fake: 0.624 \n",
      "(epoch: 7, iters: 1220, time: 0.072, data: 0.002) G_GAN: 0.756 G_L1: 0.001 D_real: 0.763 D_fake: 0.626 \n",
      "(epoch: 7, iters: 1320, time: 0.072, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.729 D_fake: 0.663 \n",
      "saving the latest model (epoch 7, total_steps 15000)\n",
      "(epoch: 7, iters: 1420, time: 0.077, data: 0.002) G_GAN: 0.737 G_L1: 2.003 D_real: 0.600 D_fake: 0.663 \n",
      "(epoch: 7, iters: 1520, time: 0.075, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.750 D_fake: 0.644 \n",
      "(epoch: 7, iters: 1620, time: 0.072, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.742 D_fake: 0.651 \n",
      "(epoch: 7, iters: 1720, time: 0.073, data: 0.001) G_GAN: 0.751 G_L1: 3.150 D_real: 0.581 D_fake: 0.649 \n",
      "(epoch: 7, iters: 1820, time: 0.072, data: 0.002) G_GAN: 0.768 G_L1: 0.003 D_real: 0.774 D_fake: 0.613 \n",
      "(epoch: 7, iters: 1920, time: 0.071, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.731 D_fake: 0.660 \n",
      "(epoch: 7, iters: 2020, time: 0.071, data: 0.001) G_GAN: 0.743 G_L1: 1.669 D_real: 0.613 D_fake: 0.655 \n",
      "(epoch: 7, iters: 2120, time: 0.073, data: 0.002) G_GAN: 0.741 G_L1: 0.001 D_real: 0.747 D_fake: 0.644 \n",
      "(epoch: 7, iters: 2220, time: 0.072, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.732 D_fake: 0.655 \n",
      "End of epoch 7 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 8, iters: 40, time: 0.073, data: 0.003) G_GAN: 0.750 G_L1: 1.820 D_real: 0.613 D_fake: 0.656 \n",
      "(epoch: 8, iters: 140, time: 0.071, data: 0.001) G_GAN: 0.772 G_L1: 0.001 D_real: 0.784 D_fake: 0.610 \n",
      "(epoch: 8, iters: 240, time: 0.071, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.739 D_fake: 0.650 \n",
      "(epoch: 8, iters: 340, time: 0.073, data: 0.001) G_GAN: 0.740 G_L1: 1.290 D_real: 0.626 D_fake: 0.657 \n",
      "(epoch: 8, iters: 440, time: 0.072, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.760 D_fake: 0.632 \n",
      "(epoch: 8, iters: 540, time: 0.076, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.719 D_fake: 0.673 \n",
      "(epoch: 8, iters: 640, time: 0.076, data: 0.002) G_GAN: 0.750 G_L1: 2.668 D_real: 0.587 D_fake: 0.658 \n",
      "(epoch: 8, iters: 740, time: 0.072, data: 0.002) G_GAN: 0.769 G_L1: 0.000 D_real: 0.776 D_fake: 0.620 \n",
      "(epoch: 8, iters: 840, time: 0.075, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.737 D_fake: 0.652 \n",
      "(epoch: 8, iters: 940, time: 0.074, data: 0.002) G_GAN: 0.749 G_L1: 3.230 D_real: 0.575 D_fake: 0.653 \n",
      "(epoch: 8, iters: 1040, time: 0.076, data: 0.002) G_GAN: 0.750 G_L1: 0.006 D_real: 0.754 D_fake: 0.637 \n",
      "(epoch: 8, iters: 1140, time: 0.076, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.732 D_fake: 0.656 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 8, iters: 1240, time: 0.073, data: 0.002) G_GAN: 0.745 G_L1: 2.386 D_real: 0.593 D_fake: 0.655 \n",
      "(epoch: 8, iters: 1340, time: 0.070, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.746 D_fake: 0.644 \n",
      "(epoch: 8, iters: 1440, time: 0.076, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.732 D_fake: 0.657 \n",
      "(epoch: 8, iters: 1540, time: 0.075, data: 0.002) G_GAN: 0.736 G_L1: 1.488 D_real: 0.603 D_fake: 0.660 \n",
      "(epoch: 8, iters: 1640, time: 0.073, data: 0.003) G_GAN: 0.748 G_L1: 0.000 D_real: 0.754 D_fake: 0.638 \n",
      "(epoch: 8, iters: 1740, time: 0.074, data: 0.002) G_GAN: 0.730 G_L1: 0.004 D_real: 0.740 D_fake: 0.649 \n",
      "(epoch: 8, iters: 1840, time: 0.075, data: 0.002) G_GAN: 0.738 G_L1: 0.842 D_real: 0.635 D_fake: 0.655 \n",
      "(epoch: 8, iters: 1940, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.755 D_fake: 0.635 \n",
      "(epoch: 8, iters: 2040, time: 0.073, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.730 D_fake: 0.664 \n",
      "(epoch: 8, iters: 2140, time: 0.073, data: 0.002) G_GAN: 0.735 G_L1: 0.918 D_real: 0.632 D_fake: 0.662 \n",
      "(epoch: 8, iters: 2240, time: 0.074, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.745 D_fake: 0.644 \n",
      "End of epoch 8 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 9, iters: 60, time: 0.075, data: 0.002) G_GAN: 0.722 G_L1: 0.004 D_real: 0.730 D_fake: 0.659 \n",
      "(epoch: 9, iters: 160, time: 0.075, data: 0.001) G_GAN: 0.733 G_L1: 2.143 D_real: 0.604 D_fake: 0.652 \n",
      "(epoch: 9, iters: 260, time: 0.075, data: 0.002) G_GAN: 0.729 G_L1: 0.073 D_real: 0.736 D_fake: 0.654 \n",
      "(epoch: 9, iters: 360, time: 0.074, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.730 D_fake: 0.658 \n",
      "(epoch: 9, iters: 460, time: 0.077, data: 0.002) G_GAN: 0.736 G_L1: 2.082 D_real: 0.600 D_fake: 0.658 \n",
      "(epoch: 9, iters: 560, time: 0.073, data: 0.002) G_GAN: 0.742 G_L1: 0.002 D_real: 0.743 D_fake: 0.647 \n",
      "(epoch: 9, iters: 660, time: 0.076, data: 0.002) G_GAN: 0.730 G_L1: 0.001 D_real: 0.737 D_fake: 0.650 \n",
      "(epoch: 9, iters: 760, time: 0.074, data: 0.002) G_GAN: 0.724 G_L1: 1.936 D_real: 0.602 D_fake: 0.688 \n",
      "(epoch: 9, iters: 860, time: 0.076, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.768 D_fake: 0.625 \n",
      "(epoch: 9, iters: 960, time: 0.072, data: 0.002) G_GAN: 0.726 G_L1: 0.007 D_real: 0.730 D_fake: 0.658 \n",
      "(epoch: 9, iters: 1060, time: 0.076, data: 0.001) G_GAN: 0.730 G_L1: 0.700 D_real: 0.660 D_fake: 0.662 \n",
      "(epoch: 9, iters: 1160, time: 0.072, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.763 D_fake: 0.629 \n",
      "(epoch: 9, iters: 1260, time: 0.070, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.738 D_fake: 0.649 \n",
      "(epoch: 9, iters: 1360, time: 0.075, data: 0.002) G_GAN: 0.730 G_L1: 2.029 D_real: 0.602 D_fake: 0.666 \n",
      "(epoch: 9, iters: 1460, time: 0.071, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.761 D_fake: 0.638 \n",
      "(epoch: 9, iters: 1560, time: 0.075, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.743 D_fake: 0.647 \n",
      "(epoch: 9, iters: 1660, time: 0.071, data: 0.002) G_GAN: 0.739 G_L1: 1.693 D_real: 0.615 D_fake: 0.689 \n",
      "(epoch: 9, iters: 1760, time: 0.073, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.749 D_fake: 0.645 \n",
      "saving the latest model (epoch 9, total_steps 20000)\n",
      "(epoch: 9, iters: 1860, time: 0.072, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.739 D_fake: 0.652 \n",
      "(epoch: 9, iters: 1960, time: 0.071, data: 0.002) G_GAN: 0.743 G_L1: 2.015 D_real: 0.604 D_fake: 0.657 \n",
      "(epoch: 9, iters: 2060, time: 0.073, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.745 D_fake: 0.643 \n",
      "(epoch: 9, iters: 2160, time: 0.073, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.730 D_fake: 0.658 \n",
      "(epoch: 9, iters: 2260, time: 0.075, data: 0.002) G_GAN: 0.722 G_L1: 2.749 D_real: 0.567 D_fake: 0.677 \n",
      "End of epoch 9 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 10, iters: 80, time: 0.072, data: 0.003) G_GAN: 0.759 G_L1: 0.000 D_real: 0.765 D_fake: 0.630 \n",
      "(epoch: 10, iters: 180, time: 0.074, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.742 D_fake: 0.649 \n",
      "(epoch: 10, iters: 280, time: 0.073, data: 0.002) G_GAN: 0.729 G_L1: 1.027 D_real: 0.612 D_fake: 0.672 \n",
      "(epoch: 10, iters: 380, time: 0.071, data: 0.001) G_GAN: 0.761 G_L1: 0.000 D_real: 0.766 D_fake: 0.626 \n",
      "(epoch: 10, iters: 480, time: 0.076, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.709 D_fake: 0.679 \n",
      "(epoch: 10, iters: 580, time: 0.074, data: 0.002) G_GAN: 0.735 G_L1: 3.536 D_real: 0.557 D_fake: 0.665 \n",
      "(epoch: 10, iters: 680, time: 0.072, data: 0.001) G_GAN: 0.755 G_L1: 0.000 D_real: 0.758 D_fake: 0.634 \n",
      "(epoch: 10, iters: 780, time: 0.072, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.730 D_fake: 0.649 \n",
      "(epoch: 10, iters: 880, time: 0.071, data: 0.002) G_GAN: 0.763 G_L1: 2.568 D_real: 0.575 D_fake: 0.660 \n",
      "(epoch: 10, iters: 980, time: 0.071, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.740 D_fake: 0.650 \n",
      "(epoch: 10, iters: 1080, time: 0.075, data: 0.002) G_GAN: 0.666 G_L1: 0.000 D_real: 0.682 D_fake: 0.703 \n",
      "(epoch: 10, iters: 1180, time: 0.077, data: 0.003) G_GAN: 0.776 G_L1: 2.010 D_real: 0.616 D_fake: 0.626 \n",
      "(epoch: 10, iters: 1280, time: 0.076, data: 0.002) G_GAN: 0.744 G_L1: 0.001 D_real: 0.744 D_fake: 0.642 \n",
      "(epoch: 10, iters: 1380, time: 0.074, data: 0.002) G_GAN: 0.719 G_L1: 0.001 D_real: 0.727 D_fake: 0.663 \n",
      "(epoch: 10, iters: 1480, time: 0.071, data: 0.002) G_GAN: 0.731 G_L1: 1.780 D_real: 0.608 D_fake: 0.673 \n",
      "(epoch: 10, iters: 1580, time: 0.071, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.759 D_fake: 0.632 \n",
      "(epoch: 10, iters: 1680, time: 0.070, data: 0.002) G_GAN: 0.692 G_L1: 0.003 D_real: 0.704 D_fake: 0.684 \n",
      "(epoch: 10, iters: 1780, time: 0.077, data: 0.002) G_GAN: 0.757 G_L1: 2.503 D_real: 0.601 D_fake: 0.658 \n",
      "(epoch: 10, iters: 1880, time: 0.075, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.766 D_fake: 0.624 \n",
      "(epoch: 10, iters: 1980, time: 0.075, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.729 D_fake: 0.659 \n",
      "(epoch: 10, iters: 2080, time: 0.073, data: 0.003) G_GAN: 0.737 G_L1: 2.293 D_real: 0.584 D_fake: 0.674 \n",
      "(epoch: 10, iters: 2180, time: 0.072, data: 0.002) G_GAN: 0.774 G_L1: 0.000 D_real: 0.788 D_fake: 0.606 \n",
      "(epoch: 10, iters: 2280, time: 0.071, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.728 D_fake: 0.660 \n",
      "saving the model at the end of epoch 10, iters 22800\n",
      "End of epoch 10 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 11, iters: 100, time: 0.073, data: 0.427) G_GAN: 0.740 G_L1: 2.477 D_real: 0.584 D_fake: 0.664 \n",
      "(epoch: 11, iters: 200, time: 0.074, data: 0.002) G_GAN: 0.745 G_L1: 0.001 D_real: 0.761 D_fake: 0.642 \n",
      "(epoch: 11, iters: 300, time: 0.073, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.717 D_fake: 0.671 \n",
      "(epoch: 11, iters: 400, time: 0.074, data: 0.001) G_GAN: 0.735 G_L1: 1.377 D_real: 0.615 D_fake: 0.662 \n",
      "(epoch: 11, iters: 500, time: 0.075, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.763 D_fake: 0.629 \n",
      "(epoch: 11, iters: 600, time: 0.073, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.751 D_fake: 0.636 \n",
      "(epoch: 11, iters: 700, time: 0.078, data: 0.002) G_GAN: 0.736 G_L1: 1.845 D_real: 0.611 D_fake: 0.651 \n",
      "(epoch: 11, iters: 800, time: 0.075, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.750 D_fake: 0.641 \n",
      "(epoch: 11, iters: 900, time: 0.071, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.733 D_fake: 0.656 \n",
      "(epoch: 11, iters: 1000, time: 0.072, data: 0.002) G_GAN: 0.742 G_L1: 1.671 D_real: 0.615 D_fake: 0.655 \n",
      "(epoch: 11, iters: 1100, time: 0.072, data: 0.002) G_GAN: 0.745 G_L1: 0.001 D_real: 0.756 D_fake: 0.636 \n",
      "(epoch: 11, iters: 1200, time: 0.072, data: 0.002) G_GAN: 0.734 G_L1: 0.006 D_real: 0.740 D_fake: 0.655 \n",
      "(epoch: 11, iters: 1300, time: 0.074, data: 0.002) G_GAN: 0.741 G_L1: 1.744 D_real: 0.619 D_fake: 0.655 \n",
      "(epoch: 11, iters: 1400, time: 0.074, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.755 D_fake: 0.637 \n",
      "(epoch: 11, iters: 1500, time: 0.072, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.729 D_fake: 0.660 \n",
      "(epoch: 11, iters: 1600, time: 0.076, data: 0.002) G_GAN: 0.713 G_L1: 1.963 D_real: 0.601 D_fake: 0.671 \n",
      "(epoch: 11, iters: 1700, time: 0.074, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.666 \n",
      "(epoch: 11, iters: 1800, time: 0.074, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.712 D_fake: 0.676 \n",
      "(epoch: 11, iters: 1900, time: 0.072, data: 0.002) G_GAN: 0.705 G_L1: 3.427 D_real: 0.564 D_fake: 0.704 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 11, iters: 2000, time: 0.071, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.788 D_fake: 0.613 \n",
      "(epoch: 11, iters: 2100, time: 0.074, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.720 D_fake: 0.667 \n",
      "(epoch: 11, iters: 2200, time: 0.073, data: 0.002) G_GAN: 0.743 G_L1: 1.583 D_real: 0.625 D_fake: 0.651 \n",
      "saving the latest model (epoch 11, total_steps 25000)\n",
      "End of epoch 11 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 12, iters: 20, time: 0.074, data: 0.003) G_GAN: 0.738 G_L1: 0.000 D_real: 0.738 D_fake: 0.658 \n",
      "(epoch: 12, iters: 120, time: 0.074, data: 0.004) G_GAN: 0.729 G_L1: 0.000 D_real: 0.736 D_fake: 0.654 \n",
      "(epoch: 12, iters: 220, time: 0.077, data: 0.002) G_GAN: 0.727 G_L1: 2.707 D_real: 0.577 D_fake: 0.667 \n",
      "(epoch: 12, iters: 320, time: 0.072, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.745 D_fake: 0.644 \n",
      "(epoch: 12, iters: 420, time: 0.073, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.729 D_fake: 0.668 \n",
      "(epoch: 12, iters: 520, time: 0.074, data: 0.002) G_GAN: 0.730 G_L1: 1.336 D_real: 0.626 D_fake: 0.658 \n",
      "(epoch: 12, iters: 620, time: 0.074, data: 0.001) G_GAN: 0.744 G_L1: 0.051 D_real: 0.748 D_fake: 0.647 \n",
      "(epoch: 12, iters: 720, time: 0.073, data: 0.002) G_GAN: 0.727 G_L1: 0.018 D_real: 0.733 D_fake: 0.655 \n",
      "(epoch: 12, iters: 820, time: 0.075, data: 0.002) G_GAN: 0.737 G_L1: 1.759 D_real: 0.616 D_fake: 0.667 \n",
      "(epoch: 12, iters: 920, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.776 D_fake: 0.619 \n",
      "(epoch: 12, iters: 1020, time: 0.072, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.739 D_fake: 0.648 \n",
      "(epoch: 12, iters: 1120, time: 0.073, data: 0.002) G_GAN: 0.725 G_L1: 1.930 D_real: 0.599 D_fake: 0.682 \n",
      "(epoch: 12, iters: 1220, time: 0.072, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.747 D_fake: 0.647 \n",
      "(epoch: 12, iters: 1320, time: 0.073, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.734 D_fake: 0.656 \n",
      "(epoch: 12, iters: 1420, time: 0.072, data: 0.002) G_GAN: 0.736 G_L1: 1.978 D_real: 0.604 D_fake: 0.655 \n",
      "(epoch: 12, iters: 1520, time: 0.071, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.741 D_fake: 0.669 \n",
      "(epoch: 12, iters: 1620, time: 0.075, data: 0.001) G_GAN: 0.729 G_L1: 0.057 D_real: 0.737 D_fake: 0.656 \n",
      "(epoch: 12, iters: 1720, time: 0.075, data: 0.001) G_GAN: 0.744 G_L1: 3.149 D_real: 0.580 D_fake: 0.648 \n",
      "(epoch: 12, iters: 1820, time: 0.073, data: 0.002) G_GAN: 0.753 G_L1: 0.002 D_real: 0.754 D_fake: 0.634 \n",
      "(epoch: 12, iters: 1920, time: 0.071, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.726 D_fake: 0.667 \n",
      "(epoch: 12, iters: 2020, time: 0.075, data: 0.002) G_GAN: 0.733 G_L1: 1.647 D_real: 0.618 D_fake: 0.660 \n",
      "(epoch: 12, iters: 2120, time: 0.074, data: 0.002) G_GAN: 0.728 G_L1: 0.002 D_real: 0.752 D_fake: 0.658 \n",
      "(epoch: 12, iters: 2220, time: 0.074, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.738 D_fake: 0.643 \n",
      "End of epoch 12 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 13, iters: 40, time: 0.079, data: 0.003) G_GAN: 0.742 G_L1: 1.820 D_real: 0.615 D_fake: 0.652 \n",
      "(epoch: 13, iters: 140, time: 0.073, data: 0.001) G_GAN: 0.756 G_L1: 0.001 D_real: 0.760 D_fake: 0.635 \n",
      "(epoch: 13, iters: 240, time: 0.072, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.734 D_fake: 0.657 \n",
      "(epoch: 13, iters: 340, time: 0.073, data: 0.002) G_GAN: 0.744 G_L1: 1.291 D_real: 0.641 D_fake: 0.649 \n",
      "(epoch: 13, iters: 440, time: 0.072, data: 0.002) G_GAN: 0.738 G_L1: 0.001 D_real: 0.743 D_fake: 0.657 \n",
      "(epoch: 13, iters: 540, time: 0.071, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.718 D_fake: 0.672 \n",
      "(epoch: 13, iters: 640, time: 0.073, data: 0.002) G_GAN: 0.734 G_L1: 2.543 D_real: 0.595 D_fake: 0.670 \n",
      "(epoch: 13, iters: 740, time: 0.071, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.747 D_fake: 0.646 \n",
      "(epoch: 13, iters: 840, time: 0.075, data: 0.002) G_GAN: 0.708 G_L1: 0.002 D_real: 0.717 D_fake: 0.671 \n",
      "(epoch: 13, iters: 940, time: 0.073, data: 0.002) G_GAN: 0.691 G_L1: 2.998 D_real: 0.572 D_fake: 0.745 \n",
      "(epoch: 13, iters: 1040, time: 0.072, data: 0.002) G_GAN: 0.747 G_L1: 0.055 D_real: 0.755 D_fake: 0.640 \n",
      "(epoch: 13, iters: 1140, time: 0.072, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.742 D_fake: 0.647 \n",
      "(epoch: 13, iters: 1240, time: 0.070, data: 0.002) G_GAN: 0.739 G_L1: 2.190 D_real: 0.613 D_fake: 0.669 \n",
      "(epoch: 13, iters: 1340, time: 0.073, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.744 D_fake: 0.651 \n",
      "(epoch: 13, iters: 1440, time: 0.075, data: 0.002) G_GAN: 0.735 G_L1: 0.032 D_real: 0.740 D_fake: 0.650 \n",
      "(epoch: 13, iters: 1540, time: 0.072, data: 0.002) G_GAN: 0.726 G_L1: 1.368 D_real: 0.620 D_fake: 0.660 \n",
      "(epoch: 13, iters: 1640, time: 0.073, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.739 D_fake: 0.655 \n",
      "(epoch: 13, iters: 1740, time: 0.073, data: 0.002) G_GAN: 0.731 G_L1: 0.019 D_real: 0.736 D_fake: 0.653 \n",
      "(epoch: 13, iters: 1840, time: 0.076, data: 0.002) G_GAN: 0.748 G_L1: 0.842 D_real: 0.672 D_fake: 0.649 \n",
      "(epoch: 13, iters: 1940, time: 0.076, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.757 D_fake: 0.640 \n",
      "(epoch: 13, iters: 2040, time: 0.072, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.730 D_fake: 0.660 \n",
      "(epoch: 13, iters: 2140, time: 0.075, data: 0.002) G_GAN: 0.780 G_L1: 0.919 D_real: 0.668 D_fake: 0.645 \n",
      "(epoch: 13, iters: 2240, time: 0.073, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.780 D_fake: 0.636 \n",
      "End of epoch 13 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 14, iters: 60, time: 0.077, data: 0.002) G_GAN: 0.725 G_L1: 0.002 D_real: 0.736 D_fake: 0.641 \n",
      "(epoch: 14, iters: 160, time: 0.072, data: 0.002) G_GAN: 0.739 G_L1: 2.185 D_real: 0.605 D_fake: 0.668 \n",
      "(epoch: 14, iters: 260, time: 0.073, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.746 D_fake: 0.650 \n",
      "(epoch: 14, iters: 360, time: 0.075, data: 0.002) G_GAN: 0.721 G_L1: 0.033 D_real: 0.727 D_fake: 0.662 \n",
      "saving the latest model (epoch 14, total_steps 30000)\n",
      "(epoch: 14, iters: 460, time: 0.072, data: 0.002) G_GAN: 0.753 G_L1: 2.059 D_real: 0.625 D_fake: 0.665 \n",
      "(epoch: 14, iters: 560, time: 0.075, data: 0.004) G_GAN: 0.731 G_L1: 0.000 D_real: 0.732 D_fake: 0.657 \n",
      "(epoch: 14, iters: 660, time: 0.074, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.741 D_fake: 0.646 \n",
      "(epoch: 14, iters: 760, time: 0.071, data: 0.002) G_GAN: 0.727 G_L1: 1.712 D_real: 0.612 D_fake: 0.670 \n",
      "(epoch: 14, iters: 860, time: 0.074, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.759 D_fake: 0.631 \n",
      "(epoch: 14, iters: 960, time: 0.074, data: 0.003) G_GAN: 0.735 G_L1: 0.000 D_real: 0.643 D_fake: 0.749 \n",
      "(epoch: 14, iters: 1060, time: 0.075, data: 0.002) G_GAN: 0.702 G_L1: 0.699 D_real: 0.681 D_fake: 0.687 \n",
      "(epoch: 14, iters: 1160, time: 0.071, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.739 D_fake: 0.650 \n",
      "(epoch: 14, iters: 1260, time: 0.070, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.698 D_fake: 0.687 \n",
      "(epoch: 14, iters: 1360, time: 0.072, data: 0.002) G_GAN: 0.735 G_L1: 2.029 D_real: 0.609 D_fake: 0.666 \n",
      "(epoch: 14, iters: 1460, time: 0.071, data: 0.002) G_GAN: 0.766 G_L1: 0.000 D_real: 0.776 D_fake: 0.617 \n",
      "(epoch: 14, iters: 1560, time: 0.075, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.730 D_fake: 0.658 \n",
      "(epoch: 14, iters: 1660, time: 0.072, data: 0.002) G_GAN: 0.738 G_L1: 1.703 D_real: 0.618 D_fake: 0.655 \n",
      "(epoch: 14, iters: 1760, time: 0.074, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.759 D_fake: 0.632 \n",
      "(epoch: 14, iters: 1860, time: 0.072, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.714 D_fake: 0.677 \n",
      "(epoch: 14, iters: 1960, time: 0.074, data: 0.002) G_GAN: 0.744 G_L1: 2.015 D_real: 0.595 D_fake: 0.661 \n",
      "(epoch: 14, iters: 2060, time: 0.070, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.743 D_fake: 0.648 \n",
      "(epoch: 14, iters: 2160, time: 0.072, data: 0.002) G_GAN: 0.675 G_L1: 0.000 D_real: 0.683 D_fake: 0.703 \n",
      "(epoch: 14, iters: 2260, time: 0.071, data: 0.002) G_GAN: 0.742 G_L1: 2.749 D_real: 0.583 D_fake: 0.656 \n",
      "End of epoch 14 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 15, iters: 80, time: 0.073, data: 0.003) G_GAN: 0.759 G_L1: 0.000 D_real: 0.771 D_fake: 0.626 \n",
      "(epoch: 15, iters: 180, time: 0.072, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.752 D_fake: 0.640 \n",
      "(epoch: 15, iters: 280, time: 0.071, data: 0.002) G_GAN: 0.738 G_L1: 1.026 D_real: 0.625 D_fake: 0.659 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 15, iters: 380, time: 0.076, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.745 D_fake: 0.645 \n",
      "(epoch: 15, iters: 480, time: 0.074, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.749 D_fake: 0.639 \n",
      "(epoch: 15, iters: 580, time: 0.074, data: 0.002) G_GAN: 0.772 G_L1: 3.541 D_real: 0.561 D_fake: 0.657 \n",
      "(epoch: 15, iters: 680, time: 0.075, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.758 D_fake: 0.633 \n",
      "(epoch: 15, iters: 780, time: 0.076, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.730 D_fake: 0.659 \n",
      "(epoch: 15, iters: 880, time: 0.072, data: 0.002) G_GAN: 0.775 G_L1: 2.571 D_real: 0.579 D_fake: 0.647 \n",
      "(epoch: 15, iters: 980, time: 0.076, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.756 D_fake: 0.635 \n",
      "(epoch: 15, iters: 1080, time: 0.073, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.724 D_fake: 0.664 \n",
      "(epoch: 15, iters: 1180, time: 0.075, data: 0.002) G_GAN: 0.745 G_L1: 2.021 D_real: 0.605 D_fake: 0.650 \n",
      "(epoch: 15, iters: 1280, time: 0.076, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.750 D_fake: 0.643 \n",
      "(epoch: 15, iters: 1380, time: 0.071, data: 0.002) G_GAN: 0.669 G_L1: 0.000 D_real: 0.724 D_fake: 0.658 \n",
      "(epoch: 15, iters: 1480, time: 0.079, data: 0.003) G_GAN: 0.745 G_L1: 1.813 D_real: 0.605 D_fake: 0.649 \n",
      "(epoch: 15, iters: 1580, time: 0.072, data: 0.001) G_GAN: 0.744 G_L1: 0.000 D_real: 0.749 D_fake: 0.641 \n",
      "(epoch: 15, iters: 1680, time: 0.071, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.741 D_fake: 0.648 \n",
      "(epoch: 15, iters: 1780, time: 0.073, data: 0.002) G_GAN: 0.755 G_L1: 2.503 D_real: 0.590 D_fake: 0.644 \n",
      "(epoch: 15, iters: 1880, time: 0.072, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.750 D_fake: 0.639 \n",
      "(epoch: 15, iters: 1980, time: 0.077, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.737 D_fake: 0.653 \n",
      "(epoch: 15, iters: 2080, time: 0.074, data: 0.001) G_GAN: 0.722 G_L1: 2.297 D_real: 0.581 D_fake: 0.682 \n",
      "(epoch: 15, iters: 2180, time: 0.072, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.770 D_fake: 0.620 \n",
      "(epoch: 15, iters: 2280, time: 0.070, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.737 D_fake: 0.655 \n",
      "saving the model at the end of epoch 15, iters 34200\n",
      "End of epoch 15 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 16, iters: 100, time: 0.075, data: 0.457) G_GAN: 0.736 G_L1: 2.485 D_real: 0.588 D_fake: 0.660 \n",
      "(epoch: 16, iters: 200, time: 0.075, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.750 D_fake: 0.641 \n",
      "(epoch: 16, iters: 300, time: 0.073, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.732 D_fake: 0.655 \n",
      "(epoch: 16, iters: 400, time: 0.072, data: 0.002) G_GAN: 0.735 G_L1: 1.437 D_real: 0.613 D_fake: 0.660 \n",
      "(epoch: 16, iters: 500, time: 0.072, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.752 D_fake: 0.635 \n",
      "(epoch: 16, iters: 600, time: 0.075, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.749 D_fake: 0.638 \n",
      "(epoch: 16, iters: 700, time: 0.073, data: 0.001) G_GAN: 0.757 G_L1: 1.919 D_real: 0.603 D_fake: 0.691 \n",
      "(epoch: 16, iters: 800, time: 0.073, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.758 D_fake: 0.633 \n",
      "saving the latest model (epoch 16, total_steps 35000)\n",
      "(epoch: 16, iters: 900, time: 0.074, data: 0.002) G_GAN: 0.500 G_L1: 0.000 D_real: 0.628 D_fake: 0.745 \n",
      "(epoch: 16, iters: 1000, time: 0.071, data: 0.002) G_GAN: 0.749 G_L1: 1.678 D_real: 0.611 D_fake: 0.656 \n",
      "(epoch: 16, iters: 1100, time: 0.079, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.756 D_fake: 0.633 \n",
      "(epoch: 16, iters: 1200, time: 0.072, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.748 D_fake: 0.642 \n",
      "(epoch: 16, iters: 1300, time: 0.074, data: 0.002) G_GAN: 0.747 G_L1: 1.744 D_real: 0.615 D_fake: 0.654 \n",
      "(epoch: 16, iters: 1400, time: 0.075, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.769 D_fake: 0.623 \n",
      "(epoch: 16, iters: 1500, time: 0.071, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.733 D_fake: 0.656 \n",
      "(epoch: 16, iters: 1600, time: 0.073, data: 0.002) G_GAN: 0.741 G_L1: 2.124 D_real: 0.591 D_fake: 0.658 \n",
      "(epoch: 16, iters: 1700, time: 0.076, data: 0.004) G_GAN: 0.775 G_L1: 0.000 D_real: 0.778 D_fake: 0.616 \n",
      "(epoch: 16, iters: 1800, time: 0.073, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.742 D_fake: 0.649 \n",
      "(epoch: 16, iters: 1900, time: 0.075, data: 0.002) G_GAN: 0.755 G_L1: 3.702 D_real: 0.559 D_fake: 0.649 \n",
      "(epoch: 16, iters: 2000, time: 0.072, data: 0.002) G_GAN: 0.777 G_L1: 0.000 D_real: 0.783 D_fake: 0.613 \n",
      "(epoch: 16, iters: 2100, time: 0.073, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.744 D_fake: 0.646 \n",
      "(epoch: 16, iters: 2200, time: 0.073, data: 0.001) G_GAN: 0.759 G_L1: 1.583 D_real: 0.607 D_fake: 0.650 \n",
      "End of epoch 16 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 17, iters: 20, time: 0.076, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.747 D_fake: 0.643 \n",
      "(epoch: 17, iters: 120, time: 0.072, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.741 D_fake: 0.647 \n",
      "(epoch: 17, iters: 220, time: 0.072, data: 0.002) G_GAN: 0.747 G_L1: 2.749 D_real: 0.575 D_fake: 0.657 \n",
      "(epoch: 17, iters: 320, time: 0.073, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.765 D_fake: 0.628 \n",
      "(epoch: 17, iters: 420, time: 0.075, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.739 D_fake: 0.649 \n",
      "(epoch: 17, iters: 520, time: 0.072, data: 0.002) G_GAN: 0.758 G_L1: 1.419 D_real: 0.611 D_fake: 0.652 \n",
      "(epoch: 17, iters: 620, time: 0.071, data: 0.002) G_GAN: 0.766 G_L1: 0.000 D_real: 0.776 D_fake: 0.633 \n",
      "(epoch: 17, iters: 720, time: 0.074, data: 0.003) G_GAN: 0.728 G_L1: 0.000 D_real: 0.740 D_fake: 0.650 \n",
      "(epoch: 17, iters: 820, time: 0.074, data: 0.002) G_GAN: 0.749 G_L1: 1.824 D_real: 0.602 D_fake: 0.652 \n",
      "(epoch: 17, iters: 920, time: 0.071, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.756 D_fake: 0.627 \n",
      "(epoch: 17, iters: 1020, time: 0.071, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.714 D_fake: 0.672 \n",
      "(epoch: 17, iters: 1120, time: 0.073, data: 0.002) G_GAN: 0.739 G_L1: 1.957 D_real: 0.588 D_fake: 0.660 \n",
      "(epoch: 17, iters: 1220, time: 0.072, data: 0.001) G_GAN: 0.752 G_L1: 0.000 D_real: 0.758 D_fake: 0.632 \n",
      "(epoch: 17, iters: 1320, time: 0.075, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.739 D_fake: 0.650 \n",
      "(epoch: 17, iters: 1420, time: 0.072, data: 0.002) G_GAN: 0.750 G_L1: 2.010 D_real: 0.589 D_fake: 0.651 \n",
      "(epoch: 17, iters: 1520, time: 0.073, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.754 D_fake: 0.638 \n",
      "(epoch: 17, iters: 1620, time: 0.071, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.741 D_fake: 0.648 \n",
      "(epoch: 17, iters: 1720, time: 0.072, data: 0.002) G_GAN: 0.742 G_L1: 3.150 D_real: 0.559 D_fake: 0.654 \n",
      "(epoch: 17, iters: 1820, time: 0.076, data: 0.002) G_GAN: 0.780 G_L1: 0.000 D_real: 0.792 D_fake: 0.606 \n",
      "(epoch: 17, iters: 1920, time: 0.075, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.743 D_fake: 0.643 \n",
      "(epoch: 17, iters: 2020, time: 0.075, data: 0.002) G_GAN: 0.749 G_L1: 1.672 D_real: 0.600 D_fake: 0.650 \n",
      "(epoch: 17, iters: 2120, time: 0.072, data: 0.001) G_GAN: 0.620 G_L1: 0.000 D_real: 0.732 D_fake: 0.663 \n",
      "(epoch: 17, iters: 2220, time: 0.071, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.734 D_fake: 0.654 \n",
      "End of epoch 17 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 18, iters: 40, time: 0.074, data: 0.002) G_GAN: 0.741 G_L1: 1.820 D_real: 0.596 D_fake: 0.656 \n",
      "(epoch: 18, iters: 140, time: 0.080, data: 0.001) G_GAN: 0.770 G_L1: 0.000 D_real: 0.781 D_fake: 0.614 \n",
      "(epoch: 18, iters: 240, time: 0.072, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.740 D_fake: 0.649 \n",
      "(epoch: 18, iters: 340, time: 0.072, data: 0.002) G_GAN: 0.745 G_L1: 1.290 D_real: 0.618 D_fake: 0.652 \n",
      "(epoch: 18, iters: 440, time: 0.072, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.738 D_fake: 0.639 \n",
      "(epoch: 18, iters: 540, time: 0.074, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.749 D_fake: 0.641 \n",
      "(epoch: 18, iters: 640, time: 0.075, data: 0.002) G_GAN: 0.750 G_L1: 2.682 D_real: 0.577 D_fake: 0.651 \n",
      "(epoch: 18, iters: 740, time: 0.074, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.771 D_fake: 0.624 \n",
      "(epoch: 18, iters: 840, time: 0.073, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.739 D_fake: 0.653 \n",
      "(epoch: 18, iters: 940, time: 0.073, data: 0.002) G_GAN: 0.751 G_L1: 3.230 D_real: 0.581 D_fake: 0.655 \n",
      "(epoch: 18, iters: 1040, time: 0.071, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.769 D_fake: 0.623 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 18, iters: 1140, time: 0.071, data: 0.002) G_GAN: 0.657 G_L1: 0.000 D_real: 0.642 D_fake: 0.748 \n",
      "(epoch: 18, iters: 1240, time: 0.071, data: 0.002) G_GAN: 0.749 G_L1: 2.399 D_real: 0.600 D_fake: 0.646 \n",
      "saving the latest model (epoch 18, total_steps 40000)\n",
      "(epoch: 18, iters: 1340, time: 0.071, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.745 D_fake: 0.646 \n",
      "(epoch: 18, iters: 1440, time: 0.073, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.740 D_fake: 0.648 \n",
      "(epoch: 18, iters: 1540, time: 0.071, data: 0.002) G_GAN: 0.746 G_L1: 1.508 D_real: 0.603 D_fake: 0.653 \n",
      "(epoch: 18, iters: 1640, time: 0.073, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.640 \n",
      "(epoch: 18, iters: 1740, time: 0.076, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.748 D_fake: 0.638 \n",
      "(epoch: 18, iters: 1840, time: 0.074, data: 0.002) G_GAN: 0.751 G_L1: 0.842 D_real: 0.644 D_fake: 0.635 \n",
      "(epoch: 18, iters: 1940, time: 0.076, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.764 D_fake: 0.633 \n",
      "(epoch: 18, iters: 2040, time: 0.072, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.739 D_fake: 0.651 \n",
      "(epoch: 18, iters: 2140, time: 0.072, data: 0.002) G_GAN: 0.787 G_L1: 0.917 D_real: 0.648 D_fake: 0.652 \n",
      "(epoch: 18, iters: 2240, time: 0.071, data: 0.002) G_GAN: 0.778 G_L1: 0.000 D_real: 0.800 D_fake: 0.593 \n",
      "End of epoch 18 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 19, iters: 60, time: 0.073, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.734 D_fake: 0.658 \n",
      "(epoch: 19, iters: 160, time: 0.075, data: 0.002) G_GAN: 0.753 G_L1: 2.187 D_real: 0.598 D_fake: 0.649 \n",
      "(epoch: 19, iters: 260, time: 0.072, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.783 D_fake: 0.613 \n",
      "(epoch: 19, iters: 360, time: 0.075, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.739 D_fake: 0.650 \n",
      "(epoch: 19, iters: 460, time: 0.074, data: 0.001) G_GAN: 0.743 G_L1: 2.055 D_real: 0.599 D_fake: 0.652 \n",
      "(epoch: 19, iters: 560, time: 0.075, data: 0.002) G_GAN: 0.766 G_L1: 0.000 D_real: 0.771 D_fake: 0.624 \n",
      "(epoch: 19, iters: 660, time: 0.071, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.745 D_fake: 0.636 \n",
      "(epoch: 19, iters: 760, time: 0.075, data: 0.002) G_GAN: 0.736 G_L1: 2.009 D_real: 0.585 D_fake: 0.659 \n",
      "(epoch: 19, iters: 860, time: 0.071, data: 0.002) G_GAN: 0.777 G_L1: 0.000 D_real: 0.784 D_fake: 0.611 \n",
      "(epoch: 19, iters: 960, time: 0.075, data: 0.001) G_GAN: 0.749 G_L1: 0.000 D_real: 0.765 D_fake: 0.627 \n",
      "(epoch: 19, iters: 1060, time: 0.074, data: 0.001) G_GAN: 0.732 G_L1: 0.699 D_real: 0.641 D_fake: 0.664 \n",
      "(epoch: 19, iters: 1160, time: 0.074, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.770 D_fake: 0.623 \n",
      "(epoch: 19, iters: 1260, time: 0.070, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.743 D_fake: 0.644 \n",
      "(epoch: 19, iters: 1360, time: 0.073, data: 0.002) G_GAN: 0.749 G_L1: 2.029 D_real: 0.596 D_fake: 0.655 \n",
      "(epoch: 19, iters: 1460, time: 0.076, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.771 D_fake: 0.624 \n",
      "(epoch: 19, iters: 1560, time: 0.072, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.743 D_fake: 0.645 \n",
      "(epoch: 19, iters: 1660, time: 0.072, data: 0.002) G_GAN: 0.748 G_L1: 1.703 D_real: 0.609 D_fake: 0.647 \n",
      "(epoch: 19, iters: 1760, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.757 D_fake: 0.635 \n",
      "(epoch: 19, iters: 1860, time: 0.075, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.731 D_fake: 0.658 \n",
      "(epoch: 19, iters: 1960, time: 0.075, data: 0.002) G_GAN: 0.744 G_L1: 2.015 D_real: 0.595 D_fake: 0.656 \n",
      "(epoch: 19, iters: 2060, time: 0.074, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.746 D_fake: 0.644 \n",
      "(epoch: 19, iters: 2160, time: 0.074, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.725 D_fake: 0.664 \n",
      "(epoch: 19, iters: 2260, time: 0.071, data: 0.002) G_GAN: 0.747 G_L1: 2.749 D_real: 0.569 D_fake: 0.657 \n",
      "End of epoch 19 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 20, iters: 80, time: 0.073, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.770 D_fake: 0.630 \n",
      "(epoch: 20, iters: 180, time: 0.073, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.744 D_fake: 0.638 \n",
      "(epoch: 20, iters: 280, time: 0.073, data: 0.002) G_GAN: 0.749 G_L1: 1.026 D_real: 0.634 D_fake: 0.644 \n",
      "(epoch: 20, iters: 380, time: 0.075, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.737 D_fake: 0.651 \n",
      "(epoch: 20, iters: 480, time: 0.072, data: 0.001) G_GAN: 0.717 G_L1: 0.000 D_real: 0.736 D_fake: 0.651 \n",
      "(epoch: 20, iters: 580, time: 0.071, data: 0.002) G_GAN: 0.754 G_L1: 3.541 D_real: 0.560 D_fake: 0.648 \n",
      "(epoch: 20, iters: 680, time: 0.075, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.785 D_fake: 0.618 \n",
      "(epoch: 20, iters: 780, time: 0.072, data: 0.002) G_GAN: 0.658 G_L1: 0.000 D_real: 0.671 D_fake: 0.699 \n",
      "(epoch: 20, iters: 880, time: 0.072, data: 0.002) G_GAN: 0.754 G_L1: 2.571 D_real: 0.563 D_fake: 0.660 \n",
      "(epoch: 20, iters: 980, time: 0.071, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.749 D_fake: 0.651 \n",
      "(epoch: 20, iters: 1080, time: 0.071, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.723 D_fake: 0.665 \n",
      "(epoch: 20, iters: 1180, time: 0.076, data: 0.002) G_GAN: 0.765 G_L1: 2.021 D_real: 0.605 D_fake: 0.648 \n",
      "(epoch: 20, iters: 1280, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.757 D_fake: 0.634 \n",
      "(epoch: 20, iters: 1380, time: 0.074, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.749 D_fake: 0.640 \n",
      "(epoch: 20, iters: 1480, time: 0.073, data: 0.002) G_GAN: 0.748 G_L1: 1.813 D_real: 0.605 D_fake: 0.648 \n",
      "(epoch: 20, iters: 1580, time: 0.075, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.750 D_fake: 0.640 \n",
      "(epoch: 20, iters: 1680, time: 0.076, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.748 D_fake: 0.642 \n",
      "saving the latest model (epoch 20, total_steps 45000)\n",
      "(epoch: 20, iters: 1780, time: 0.071, data: 0.002) G_GAN: 0.753 G_L1: 2.503 D_real: 0.590 D_fake: 0.645 \n",
      "(epoch: 20, iters: 1880, time: 0.072, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.748 D_fake: 0.643 \n",
      "(epoch: 20, iters: 1980, time: 0.072, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.740 D_fake: 0.650 \n",
      "(epoch: 20, iters: 2080, time: 0.075, data: 0.001) G_GAN: 0.747 G_L1: 2.297 D_real: 0.581 D_fake: 0.655 \n",
      "(epoch: 20, iters: 2180, time: 0.072, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.776 D_fake: 0.622 \n",
      "(epoch: 20, iters: 2280, time: 0.071, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.726 D_fake: 0.650 \n",
      "saving the model at the end of epoch 20, iters 45600\n",
      "End of epoch 20 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 21, iters: 100, time: 0.077, data: 0.433) G_GAN: 0.753 G_L1: 2.485 D_real: 0.594 D_fake: 0.644 \n",
      "(epoch: 21, iters: 200, time: 0.073, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.739 D_fake: 0.642 \n",
      "(epoch: 21, iters: 300, time: 0.074, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.737 D_fake: 0.655 \n",
      "(epoch: 21, iters: 400, time: 0.073, data: 0.002) G_GAN: 0.742 G_L1: 1.437 D_real: 0.610 D_fake: 0.646 \n",
      "(epoch: 21, iters: 500, time: 0.075, data: 0.003) G_GAN: 0.737 G_L1: 0.000 D_real: 0.739 D_fake: 0.652 \n",
      "(epoch: 21, iters: 600, time: 0.076, data: 0.003) G_GAN: 0.731 G_L1: 0.000 D_real: 0.740 D_fake: 0.651 \n",
      "(epoch: 21, iters: 700, time: 0.074, data: 0.001) G_GAN: 0.747 G_L1: 1.919 D_real: 0.589 D_fake: 0.662 \n",
      "(epoch: 21, iters: 800, time: 0.076, data: 0.001) G_GAN: 0.759 G_L1: 0.000 D_real: 0.763 D_fake: 0.629 \n",
      "(epoch: 21, iters: 900, time: 0.077, data: 0.002) G_GAN: 0.632 G_L1: 0.000 D_real: 0.737 D_fake: 0.635 \n",
      "(epoch: 21, iters: 1000, time: 0.073, data: 0.002) G_GAN: 0.759 G_L1: 1.678 D_real: 0.608 D_fake: 0.649 \n",
      "(epoch: 21, iters: 1100, time: 0.076, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.813 D_fake: 0.632 \n",
      "(epoch: 21, iters: 1200, time: 0.072, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.741 D_fake: 0.646 \n",
      "(epoch: 21, iters: 1300, time: 0.072, data: 0.002) G_GAN: 0.738 G_L1: 1.744 D_real: 0.604 D_fake: 0.656 \n",
      "(epoch: 21, iters: 1400, time: 0.073, data: 0.002) G_GAN: 0.791 G_L1: 0.000 D_real: 0.812 D_fake: 0.591 \n",
      "(epoch: 21, iters: 1500, time: 0.073, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.740 D_fake: 0.652 \n",
      "(epoch: 21, iters: 1600, time: 0.073, data: 0.002) G_GAN: 0.742 G_L1: 2.124 D_real: 0.590 D_fake: 0.650 \n",
      "(epoch: 21, iters: 1700, time: 0.076, data: 0.002) G_GAN: 0.768 G_L1: 0.000 D_real: 0.776 D_fake: 0.625 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 21, iters: 1800, time: 0.078, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.745 D_fake: 0.644 \n",
      "(epoch: 21, iters: 1900, time: 0.078, data: 0.003) G_GAN: 0.746 G_L1: 3.702 D_real: 0.550 D_fake: 0.654 \n",
      "(epoch: 21, iters: 2000, time: 0.075, data: 0.002) G_GAN: 0.762 G_L1: 0.000 D_real: 0.764 D_fake: 0.627 \n",
      "(epoch: 21, iters: 2100, time: 0.073, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.737 D_fake: 0.649 \n",
      "(epoch: 21, iters: 2200, time: 0.076, data: 0.002) G_GAN: 0.747 G_L1: 1.583 D_real: 0.609 D_fake: 0.648 \n",
      "End of epoch 21 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 22, iters: 20, time: 0.076, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.754 D_fake: 0.637 \n",
      "(epoch: 22, iters: 120, time: 0.076, data: 0.004) G_GAN: 0.736 G_L1: 0.000 D_real: 0.744 D_fake: 0.645 \n",
      "(epoch: 22, iters: 220, time: 0.074, data: 0.002) G_GAN: 0.748 G_L1: 2.749 D_real: 0.576 D_fake: 0.649 \n",
      "(epoch: 22, iters: 320, time: 0.071, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.750 D_fake: 0.641 \n",
      "(epoch: 22, iters: 420, time: 0.075, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.736 D_fake: 0.653 \n",
      "(epoch: 22, iters: 520, time: 0.074, data: 0.002) G_GAN: 0.745 G_L1: 1.419 D_real: 0.608 D_fake: 0.650 \n",
      "(epoch: 22, iters: 620, time: 0.071, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.641 \n",
      "(epoch: 22, iters: 720, time: 0.074, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.734 D_fake: 0.656 \n",
      "(epoch: 22, iters: 820, time: 0.072, data: 0.002) G_GAN: 0.747 G_L1: 1.824 D_real: 0.599 D_fake: 0.652 \n",
      "(epoch: 22, iters: 920, time: 0.076, data: 0.002) G_GAN: 0.774 G_L1: 0.000 D_real: 0.789 D_fake: 0.609 \n",
      "(epoch: 22, iters: 1020, time: 0.072, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.737 D_fake: 0.653 \n",
      "(epoch: 22, iters: 1120, time: 0.072, data: 0.002) G_GAN: 0.744 G_L1: 1.957 D_real: 0.595 D_fake: 0.652 \n",
      "(epoch: 22, iters: 1220, time: 0.077, data: 0.001) G_GAN: 0.751 G_L1: 0.000 D_real: 0.753 D_fake: 0.639 \n",
      "(epoch: 22, iters: 1320, time: 0.074, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.742 D_fake: 0.648 \n",
      "(epoch: 22, iters: 1420, time: 0.074, data: 0.002) G_GAN: 0.746 G_L1: 2.010 D_real: 0.592 D_fake: 0.649 \n",
      "(epoch: 22, iters: 1520, time: 0.073, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.749 D_fake: 0.642 \n",
      "(epoch: 22, iters: 1620, time: 0.075, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.743 D_fake: 0.647 \n",
      "(epoch: 22, iters: 1720, time: 0.071, data: 0.002) G_GAN: 0.753 G_L1: 3.150 D_real: 0.566 D_fake: 0.644 \n",
      "(epoch: 22, iters: 1820, time: 0.073, data: 0.002) G_GAN: 0.772 G_L1: 0.000 D_real: 0.778 D_fake: 0.620 \n",
      "(epoch: 22, iters: 1920, time: 0.072, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.748 D_fake: 0.642 \n",
      "(epoch: 22, iters: 2020, time: 0.075, data: 0.002) G_GAN: 0.754 G_L1: 1.672 D_real: 0.603 D_fake: 0.644 \n",
      "(epoch: 22, iters: 2120, time: 0.071, data: 0.002) G_GAN: 0.771 G_L1: 0.000 D_real: 0.800 D_fake: 0.608 \n",
      "saving the latest model (epoch 22, total_steps 50000)\n",
      "(epoch: 22, iters: 2220, time: 0.073, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.734 D_fake: 0.654 \n",
      "End of epoch 22 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 23, iters: 40, time: 0.072, data: 0.002) G_GAN: 0.746 G_L1: 1.820 D_real: 0.597 D_fake: 0.650 \n",
      "(epoch: 23, iters: 140, time: 0.071, data: 0.001) G_GAN: 0.761 G_L1: 0.000 D_real: 0.763 D_fake: 0.630 \n",
      "(epoch: 23, iters: 240, time: 0.073, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.753 D_fake: 0.637 \n",
      "(epoch: 23, iters: 340, time: 0.076, data: 0.002) G_GAN: 0.739 G_L1: 1.290 D_real: 0.609 D_fake: 0.656 \n",
      "(epoch: 23, iters: 440, time: 0.075, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.757 D_fake: 0.629 \n",
      "(epoch: 23, iters: 540, time: 0.071, data: 0.004) G_GAN: 0.733 G_L1: 0.000 D_real: 0.739 D_fake: 0.649 \n",
      "(epoch: 23, iters: 640, time: 0.071, data: 0.002) G_GAN: 0.747 G_L1: 2.682 D_real: 0.573 D_fake: 0.651 \n",
      "(epoch: 23, iters: 740, time: 0.073, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.766 D_fake: 0.625 \n",
      "(epoch: 23, iters: 840, time: 0.074, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.752 D_fake: 0.641 \n",
      "(epoch: 23, iters: 940, time: 0.072, data: 0.002) G_GAN: 0.881 G_L1: 3.230 D_real: 0.634 D_fake: 0.585 \n",
      "(epoch: 23, iters: 1040, time: 0.074, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.788 D_fake: 0.620 \n",
      "(epoch: 23, iters: 1140, time: 0.073, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.717 D_fake: 0.671 \n",
      "(epoch: 23, iters: 1240, time: 0.074, data: 0.002) G_GAN: 0.748 G_L1: 2.399 D_real: 0.585 D_fake: 0.652 \n",
      "(epoch: 23, iters: 1340, time: 0.072, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.751 D_fake: 0.639 \n",
      "(epoch: 23, iters: 1440, time: 0.073, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.737 D_fake: 0.653 \n",
      "(epoch: 23, iters: 1540, time: 0.070, data: 0.002) G_GAN: 0.743 G_L1: 1.508 D_real: 0.598 D_fake: 0.657 \n",
      "(epoch: 23, iters: 1640, time: 0.073, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.759 D_fake: 0.635 \n",
      "(epoch: 23, iters: 1740, time: 0.072, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.748 D_fake: 0.642 \n",
      "(epoch: 23, iters: 1840, time: 0.071, data: 0.002) G_GAN: 0.747 G_L1: 0.842 D_real: 0.641 D_fake: 0.644 \n",
      "(epoch: 23, iters: 1940, time: 0.071, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.760 D_fake: 0.634 \n",
      "(epoch: 23, iters: 2040, time: 0.075, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.743 D_fake: 0.647 \n",
      "(epoch: 23, iters: 2140, time: 0.073, data: 0.002) G_GAN: 0.784 G_L1: 0.917 D_real: 0.647 D_fake: 0.628 \n",
      "(epoch: 23, iters: 2240, time: 0.074, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.792 D_fake: 0.596 \n",
      "End of epoch 23 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 24, iters: 60, time: 0.072, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.733 D_fake: 0.653 \n",
      "(epoch: 24, iters: 160, time: 0.076, data: 0.001) G_GAN: 0.743 G_L1: 2.187 D_real: 0.586 D_fake: 0.654 \n",
      "(epoch: 24, iters: 260, time: 0.074, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.755 D_fake: 0.637 \n",
      "(epoch: 24, iters: 360, time: 0.075, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.741 D_fake: 0.648 \n",
      "(epoch: 24, iters: 460, time: 0.077, data: 0.002) G_GAN: 0.747 G_L1: 2.055 D_real: 0.594 D_fake: 0.647 \n",
      "(epoch: 24, iters: 560, time: 0.071, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.793 D_fake: 0.606 \n",
      "(epoch: 24, iters: 660, time: 0.073, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.754 D_fake: 0.637 \n",
      "(epoch: 24, iters: 760, time: 0.071, data: 0.002) G_GAN: 0.746 G_L1: 2.009 D_real: 0.595 D_fake: 0.646 \n",
      "(epoch: 24, iters: 860, time: 0.074, data: 0.002) G_GAN: 0.770 G_L1: 0.000 D_real: 0.790 D_fake: 0.599 \n",
      "(epoch: 24, iters: 960, time: 0.075, data: 0.001) G_GAN: 0.749 G_L1: 0.000 D_real: 0.764 D_fake: 0.629 \n",
      "(epoch: 24, iters: 1060, time: 0.071, data: 0.002) G_GAN: 0.746 G_L1: 0.699 D_real: 0.661 D_fake: 0.647 \n",
      "(epoch: 24, iters: 1160, time: 0.074, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.771 D_fake: 0.624 \n",
      "(epoch: 24, iters: 1260, time: 0.070, data: 0.003) G_GAN: 0.740 G_L1: 0.000 D_real: 0.745 D_fake: 0.648 \n",
      "(epoch: 24, iters: 1360, time: 0.073, data: 0.002) G_GAN: 0.745 G_L1: 2.029 D_real: 0.600 D_fake: 0.649 \n",
      "(epoch: 24, iters: 1460, time: 0.071, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.759 D_fake: 0.633 \n",
      "(epoch: 24, iters: 1560, time: 0.074, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.740 D_fake: 0.650 \n",
      "(epoch: 24, iters: 1660, time: 0.074, data: 0.002) G_GAN: 0.747 G_L1: 1.703 D_real: 0.602 D_fake: 0.652 \n",
      "(epoch: 24, iters: 1760, time: 0.074, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.757 D_fake: 0.637 \n",
      "(epoch: 24, iters: 1860, time: 0.077, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.740 D_fake: 0.648 \n",
      "(epoch: 24, iters: 1960, time: 0.075, data: 0.002) G_GAN: 0.750 G_L1: 2.015 D_real: 0.601 D_fake: 0.645 \n",
      "(epoch: 24, iters: 2060, time: 0.074, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.752 D_fake: 0.639 \n",
      "(epoch: 24, iters: 2160, time: 0.072, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.731 D_fake: 0.663 \n",
      "(epoch: 24, iters: 2260, time: 0.072, data: 0.002) G_GAN: 0.789 G_L1: 2.749 D_real: 0.592 D_fake: 0.655 \n",
      "End of epoch 24 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 25, iters: 80, time: 0.077, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.761 D_fake: 0.631 \n",
      "(epoch: 25, iters: 180, time: 0.072, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.745 D_fake: 0.645 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 25, iters: 280, time: 0.072, data: 0.002) G_GAN: 0.735 G_L1: 1.026 D_real: 0.614 D_fake: 0.657 \n",
      "saving the latest model (epoch 25, total_steps 55000)\n",
      "(epoch: 25, iters: 380, time: 0.073, data: 0.002) G_GAN: 0.762 G_L1: 0.000 D_real: 0.766 D_fake: 0.625 \n",
      "(epoch: 25, iters: 480, time: 0.072, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.743 D_fake: 0.647 \n",
      "(epoch: 25, iters: 580, time: 0.073, data: 0.002) G_GAN: 0.751 G_L1: 3.541 D_real: 0.557 D_fake: 0.649 \n",
      "(epoch: 25, iters: 680, time: 0.072, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.761 D_fake: 0.630 \n",
      "(epoch: 25, iters: 780, time: 0.077, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.741 D_fake: 0.649 \n",
      "(epoch: 25, iters: 880, time: 0.071, data: 0.002) G_GAN: 0.781 G_L1: 2.571 D_real: 0.588 D_fake: 0.634 \n",
      "(epoch: 25, iters: 980, time: 0.071, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.756 D_fake: 0.635 \n",
      "(epoch: 25, iters: 1080, time: 0.073, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.731 D_fake: 0.658 \n",
      "(epoch: 25, iters: 1180, time: 0.073, data: 0.002) G_GAN: 0.754 G_L1: 2.021 D_real: 0.606 D_fake: 0.640 \n",
      "(epoch: 25, iters: 1280, time: 0.073, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.756 D_fake: 0.637 \n",
      "(epoch: 25, iters: 1380, time: 0.072, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.745 D_fake: 0.645 \n",
      "(epoch: 25, iters: 1480, time: 0.073, data: 0.002) G_GAN: 0.745 G_L1: 1.813 D_real: 0.598 D_fake: 0.647 \n",
      "(epoch: 25, iters: 1580, time: 0.072, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.747 D_fake: 0.643 \n",
      "(epoch: 25, iters: 1680, time: 0.074, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.750 D_fake: 0.642 \n",
      "(epoch: 25, iters: 1780, time: 0.074, data: 0.002) G_GAN: 0.750 G_L1: 2.503 D_real: 0.583 D_fake: 0.645 \n",
      "(epoch: 25, iters: 1880, time: 0.070, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.748 D_fake: 0.644 \n",
      "(epoch: 25, iters: 1980, time: 0.073, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.747 D_fake: 0.645 \n",
      "(epoch: 25, iters: 2080, time: 0.071, data: 0.001) G_GAN: 0.744 G_L1: 2.297 D_real: 0.579 D_fake: 0.651 \n",
      "(epoch: 25, iters: 2180, time: 0.072, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.762 D_fake: 0.632 \n",
      "(epoch: 25, iters: 2280, time: 0.070, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.748 D_fake: 0.638 \n",
      "saving the model at the end of epoch 25, iters 57000\n",
      "End of epoch 25 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 26, iters: 100, time: 0.072, data: 0.434) G_GAN: 0.750 G_L1: 2.485 D_real: 0.582 D_fake: 0.649 \n",
      "(epoch: 26, iters: 200, time: 0.071, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.757 D_fake: 0.637 \n",
      "(epoch: 26, iters: 300, time: 0.072, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.736 D_fake: 0.656 \n",
      "(epoch: 26, iters: 400, time: 0.073, data: 0.002) G_GAN: 0.747 G_L1: 1.437 D_real: 0.604 D_fake: 0.662 \n",
      "(epoch: 26, iters: 500, time: 0.075, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.748 D_fake: 0.644 \n",
      "(epoch: 26, iters: 600, time: 0.072, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.749 D_fake: 0.644 \n",
      "(epoch: 26, iters: 700, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 1.919 D_real: 0.594 D_fake: 0.652 \n",
      "(epoch: 26, iters: 800, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.754 D_fake: 0.639 \n",
      "(epoch: 26, iters: 900, time: 0.070, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.734 D_fake: 0.653 \n",
      "(epoch: 26, iters: 1000, time: 0.072, data: 0.002) G_GAN: 0.751 G_L1: 1.678 D_real: 0.597 D_fake: 0.648 \n",
      "(epoch: 26, iters: 1100, time: 0.072, data: 0.001) G_GAN: 0.763 G_L1: 0.000 D_real: 0.832 D_fake: 0.627 \n",
      "(epoch: 26, iters: 1200, time: 0.072, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.731 D_fake: 0.660 \n",
      "(epoch: 26, iters: 1300, time: 0.072, data: 0.002) G_GAN: 0.744 G_L1: 1.744 D_real: 0.605 D_fake: 0.648 \n",
      "(epoch: 26, iters: 1400, time: 0.075, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.760 D_fake: 0.635 \n",
      "(epoch: 26, iters: 1500, time: 0.074, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.740 D_fake: 0.649 \n",
      "(epoch: 26, iters: 1600, time: 0.075, data: 0.001) G_GAN: 0.742 G_L1: 2.124 D_real: 0.585 D_fake: 0.653 \n",
      "(epoch: 26, iters: 1700, time: 0.072, data: 0.001) G_GAN: 0.771 G_L1: 0.000 D_real: 0.775 D_fake: 0.621 \n",
      "(epoch: 26, iters: 1800, time: 0.072, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.750 D_fake: 0.642 \n",
      "(epoch: 26, iters: 1900, time: 0.075, data: 0.002) G_GAN: 0.782 G_L1: 3.702 D_real: 0.553 D_fake: 0.646 \n",
      "(epoch: 26, iters: 2000, time: 0.071, data: 0.002) G_GAN: 0.762 G_L1: 0.000 D_real: 0.764 D_fake: 0.626 \n",
      "(epoch: 26, iters: 2100, time: 0.074, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.726 D_fake: 0.657 \n",
      "(epoch: 26, iters: 2200, time: 0.074, data: 0.002) G_GAN: 0.733 G_L1: 1.583 D_real: 0.586 D_fake: 0.665 \n",
      "End of epoch 26 / 200 \t Time Taken: 107 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 27, iters: 20, time: 0.073, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.772 D_fake: 0.624 \n",
      "(epoch: 27, iters: 120, time: 0.071, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.746 D_fake: 0.646 \n",
      "(epoch: 27, iters: 220, time: 0.072, data: 0.003) G_GAN: 0.752 G_L1: 2.749 D_real: 0.580 D_fake: 0.643 \n",
      "(epoch: 27, iters: 320, time: 0.072, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.753 D_fake: 0.638 \n",
      "(epoch: 27, iters: 420, time: 0.075, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.747 D_fake: 0.640 \n",
      "(epoch: 27, iters: 520, time: 0.071, data: 0.002) G_GAN: 0.739 G_L1: 1.419 D_real: 0.599 D_fake: 0.658 \n",
      "(epoch: 27, iters: 620, time: 0.072, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.749 D_fake: 0.641 \n",
      "(epoch: 27, iters: 720, time: 0.076, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.727 D_fake: 0.666 \n",
      "saving the latest model (epoch 27, total_steps 60000)\n",
      "(epoch: 27, iters: 820, time: 0.072, data: 0.002) G_GAN: 0.739 G_L1: 1.824 D_real: 0.590 D_fake: 0.654 \n",
      "(epoch: 27, iters: 920, time: 0.071, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.792 D_fake: 0.604 \n",
      "(epoch: 27, iters: 1020, time: 0.076, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.747 D_fake: 0.643 \n",
      "(epoch: 27, iters: 1120, time: 0.071, data: 0.002) G_GAN: 0.744 G_L1: 1.957 D_real: 0.592 D_fake: 0.650 \n",
      "(epoch: 27, iters: 1220, time: 0.072, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.753 D_fake: 0.640 \n",
      "(epoch: 27, iters: 1320, time: 0.075, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.746 D_fake: 0.646 \n",
      "(epoch: 27, iters: 1420, time: 0.071, data: 0.002) G_GAN: 0.748 G_L1: 2.010 D_real: 0.594 D_fake: 0.646 \n",
      "(epoch: 27, iters: 1520, time: 0.074, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.750 D_fake: 0.642 \n",
      "(epoch: 27, iters: 1620, time: 0.071, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.749 D_fake: 0.645 \n",
      "(epoch: 27, iters: 1720, time: 0.071, data: 0.002) G_GAN: 0.757 G_L1: 3.150 D_real: 0.560 D_fake: 0.645 \n",
      "(epoch: 27, iters: 1820, time: 0.072, data: 0.002) G_GAN: 0.769 G_L1: 0.000 D_real: 0.773 D_fake: 0.623 \n",
      "(epoch: 27, iters: 1920, time: 0.075, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.747 D_fake: 0.644 \n",
      "(epoch: 27, iters: 2020, time: 0.073, data: 0.002) G_GAN: 0.751 G_L1: 1.672 D_real: 0.608 D_fake: 0.645 \n",
      "(epoch: 27, iters: 2120, time: 0.074, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.784 D_fake: 0.612 \n",
      "(epoch: 27, iters: 2220, time: 0.073, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.731 D_fake: 0.660 \n",
      "End of epoch 27 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 28, iters: 40, time: 0.073, data: 0.002) G_GAN: 0.752 G_L1: 1.820 D_real: 0.602 D_fake: 0.646 \n",
      "(epoch: 28, iters: 140, time: 0.073, data: 0.001) G_GAN: 0.764 G_L1: 0.000 D_real: 0.769 D_fake: 0.624 \n",
      "(epoch: 28, iters: 240, time: 0.071, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.754 D_fake: 0.639 \n",
      "(epoch: 28, iters: 340, time: 0.073, data: 0.002) G_GAN: 0.747 G_L1: 1.290 D_real: 0.611 D_fake: 0.648 \n",
      "(epoch: 28, iters: 440, time: 0.071, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.756 D_fake: 0.634 \n",
      "(epoch: 28, iters: 540, time: 0.072, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.741 D_fake: 0.648 \n",
      "(epoch: 28, iters: 640, time: 0.076, data: 0.002) G_GAN: 0.752 G_L1: 2.682 D_real: 0.575 D_fake: 0.646 \n",
      "(epoch: 28, iters: 740, time: 0.072, data: 0.001) G_GAN: 0.763 G_L1: 0.000 D_real: 0.765 D_fake: 0.628 \n",
      "(epoch: 28, iters: 840, time: 0.071, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.747 D_fake: 0.640 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 28, iters: 940, time: 0.074, data: 0.002) G_GAN: 0.757 G_L1: 3.230 D_real: 0.567 D_fake: 0.648 \n",
      "(epoch: 28, iters: 1040, time: 0.073, data: 0.002) G_GAN: 0.772 G_L1: 0.000 D_real: 0.779 D_fake: 0.614 \n",
      "(epoch: 28, iters: 1140, time: 0.073, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.734 D_fake: 0.652 \n",
      "(epoch: 28, iters: 1240, time: 0.071, data: 0.002) G_GAN: 0.749 G_L1: 2.399 D_real: 0.582 D_fake: 0.648 \n",
      "(epoch: 28, iters: 1340, time: 0.071, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.752 D_fake: 0.639 \n",
      "(epoch: 28, iters: 1440, time: 0.074, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.747 D_fake: 0.646 \n",
      "(epoch: 28, iters: 1540, time: 0.071, data: 0.002) G_GAN: 0.749 G_L1: 1.508 D_real: 0.595 D_fake: 0.653 \n",
      "(epoch: 28, iters: 1640, time: 0.076, data: 0.001) G_GAN: 0.760 G_L1: 0.000 D_real: 0.764 D_fake: 0.629 \n",
      "(epoch: 28, iters: 1740, time: 0.075, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.755 D_fake: 0.636 \n",
      "(epoch: 28, iters: 1840, time: 0.072, data: 0.002) G_GAN: 0.746 G_L1: 0.842 D_real: 0.621 D_fake: 0.644 \n",
      "(epoch: 28, iters: 1940, time: 0.072, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.767 D_fake: 0.625 \n",
      "(epoch: 28, iters: 2040, time: 0.074, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.746 D_fake: 0.645 \n",
      "(epoch: 28, iters: 2140, time: 0.072, data: 0.002) G_GAN: 0.819 G_L1: 0.917 D_real: 0.725 D_fake: 0.567 \n",
      "(epoch: 28, iters: 2240, time: 0.072, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.742 D_fake: 0.648 \n",
      "End of epoch 28 / 200 \t Time Taken: 107 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 29, iters: 60, time: 0.076, data: 0.001) G_GAN: 0.717 G_L1: 0.000 D_real: 0.730 D_fake: 0.655 \n",
      "(epoch: 29, iters: 160, time: 0.074, data: 0.001) G_GAN: 0.743 G_L1: 2.187 D_real: 0.585 D_fake: 0.641 \n",
      "(epoch: 29, iters: 260, time: 0.072, data: 0.002) G_GAN: 0.772 G_L1: 0.000 D_real: 0.776 D_fake: 0.651 \n",
      "(epoch: 29, iters: 360, time: 0.074, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.746 D_fake: 0.645 \n",
      "(epoch: 29, iters: 460, time: 0.072, data: 0.002) G_GAN: 0.755 G_L1: 2.055 D_real: 0.599 D_fake: 0.643 \n",
      "(epoch: 29, iters: 560, time: 0.073, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.753 D_fake: 0.641 \n",
      "(epoch: 29, iters: 660, time: 0.074, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.750 D_fake: 0.639 \n",
      "(epoch: 29, iters: 760, time: 0.071, data: 0.002) G_GAN: 0.739 G_L1: 2.009 D_real: 0.580 D_fake: 0.655 \n",
      "(epoch: 29, iters: 860, time: 0.072, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.772 D_fake: 0.616 \n",
      "(epoch: 29, iters: 960, time: 0.071, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.725 D_fake: 0.660 \n",
      "(epoch: 29, iters: 1060, time: 0.074, data: 0.002) G_GAN: 0.729 G_L1: 0.699 D_real: 0.630 D_fake: 0.662 \n",
      "(epoch: 29, iters: 1160, time: 0.070, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.760 D_fake: 0.631 \n",
      "saving the latest model (epoch 29, total_steps 65000)\n",
      "(epoch: 29, iters: 1260, time: 0.071, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.747 D_fake: 0.644 \n",
      "(epoch: 29, iters: 1360, time: 0.075, data: 0.002) G_GAN: 0.747 G_L1: 2.029 D_real: 0.594 D_fake: 0.647 \n",
      "(epoch: 29, iters: 1460, time: 0.070, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.750 D_fake: 0.640 \n",
      "(epoch: 29, iters: 1560, time: 0.071, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.739 D_fake: 0.654 \n",
      "(epoch: 29, iters: 1660, time: 0.071, data: 0.002) G_GAN: 0.746 G_L1: 1.703 D_real: 0.595 D_fake: 0.650 \n",
      "(epoch: 29, iters: 1760, time: 0.074, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.754 D_fake: 0.638 \n",
      "(epoch: 29, iters: 1860, time: 0.074, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.733 D_fake: 0.657 \n",
      "(epoch: 29, iters: 1960, time: 0.074, data: 0.001) G_GAN: 0.752 G_L1: 2.015 D_real: 0.595 D_fake: 0.642 \n",
      "(epoch: 29, iters: 2060, time: 0.071, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.241 D_fake: 2.993 \n",
      "(epoch: 29, iters: 2160, time: 0.074, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.741 D_fake: 0.649 \n",
      "(epoch: 29, iters: 2260, time: 0.071, data: 0.002) G_GAN: 0.753 G_L1: 2.749 D_real: 0.581 D_fake: 0.647 \n",
      "End of epoch 29 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 30, iters: 80, time: 0.072, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.760 D_fake: 0.631 \n",
      "(epoch: 30, iters: 180, time: 0.071, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.749 D_fake: 0.644 \n",
      "(epoch: 30, iters: 280, time: 0.074, data: 0.002) G_GAN: 0.745 G_L1: 1.026 D_real: 0.622 D_fake: 0.649 \n",
      "(epoch: 30, iters: 380, time: 0.072, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.748 D_fake: 0.643 \n",
      "(epoch: 30, iters: 480, time: 0.073, data: 0.004) G_GAN: 0.733 G_L1: 0.000 D_real: 0.744 D_fake: 0.645 \n",
      "(epoch: 30, iters: 580, time: 0.072, data: 0.003) G_GAN: 0.748 G_L1: 3.541 D_real: 0.556 D_fake: 0.652 \n",
      "(epoch: 30, iters: 680, time: 0.075, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.752 D_fake: 0.639 \n",
      "(epoch: 30, iters: 780, time: 0.073, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.730 D_fake: 0.658 \n",
      "(epoch: 30, iters: 880, time: 0.071, data: 0.002) G_GAN: 0.745 G_L1: 2.571 D_real: 0.564 D_fake: 0.657 \n",
      "(epoch: 30, iters: 980, time: 0.072, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.763 D_fake: 0.630 \n",
      "(epoch: 30, iters: 1080, time: 0.071, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.733 D_fake: 0.655 \n",
      "(epoch: 30, iters: 1180, time: 0.074, data: 0.002) G_GAN: 0.745 G_L1: 2.021 D_real: 0.594 D_fake: 0.650 \n",
      "(epoch: 30, iters: 1280, time: 0.075, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.757 D_fake: 0.639 \n",
      "(epoch: 30, iters: 1380, time: 0.072, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.744 D_fake: 0.644 \n",
      "(epoch: 30, iters: 1480, time: 0.071, data: 0.002) G_GAN: 0.746 G_L1: 1.813 D_real: 0.591 D_fake: 0.653 \n",
      "(epoch: 30, iters: 1580, time: 0.074, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.642 \n",
      "(epoch: 30, iters: 1680, time: 0.074, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.731 D_fake: 0.663 \n",
      "(epoch: 30, iters: 1780, time: 0.072, data: 0.002) G_GAN: 0.748 G_L1: 2.503 D_real: 0.580 D_fake: 0.649 \n",
      "(epoch: 30, iters: 1880, time: 0.076, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.753 D_fake: 0.638 \n",
      "(epoch: 30, iters: 1980, time: 0.072, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.750 D_fake: 0.642 \n",
      "(epoch: 30, iters: 2080, time: 0.075, data: 0.002) G_GAN: 0.728 G_L1: 2.297 D_real: 0.561 D_fake: 0.660 \n",
      "(epoch: 30, iters: 2180, time: 0.073, data: 0.002) G_GAN: 0.774 G_L1: 0.000 D_real: 0.783 D_fake: 0.613 \n",
      "(epoch: 30, iters: 2280, time: 0.070, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.763 D_fake: 0.628 \n",
      "saving the model at the end of epoch 30, iters 68400\n",
      "End of epoch 30 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 31, iters: 100, time: 0.073, data: 0.429) G_GAN: 0.750 G_L1: 2.485 D_real: 0.585 D_fake: 0.649 \n",
      "(epoch: 31, iters: 200, time: 0.071, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.763 D_fake: 0.628 \n",
      "(epoch: 31, iters: 300, time: 0.072, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.724 D_fake: 0.664 \n",
      "(epoch: 31, iters: 400, time: 0.074, data: 0.002) G_GAN: 0.743 G_L1: 1.437 D_real: 0.605 D_fake: 0.657 \n",
      "(epoch: 31, iters: 500, time: 0.071, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.755 D_fake: 0.636 \n",
      "(epoch: 31, iters: 600, time: 0.073, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.753 D_fake: 0.638 \n",
      "(epoch: 31, iters: 700, time: 0.073, data: 0.002) G_GAN: 0.751 G_L1: 1.919 D_real: 0.594 D_fake: 0.652 \n",
      "(epoch: 31, iters: 800, time: 0.075, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.751 D_fake: 0.640 \n",
      "(epoch: 31, iters: 900, time: 0.071, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.732 D_fake: 0.654 \n",
      "(epoch: 31, iters: 1000, time: 0.073, data: 0.002) G_GAN: 0.746 G_L1: 1.678 D_real: 0.597 D_fake: 0.654 \n",
      "(epoch: 31, iters: 1100, time: 0.075, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.768 D_fake: 0.626 \n",
      "(epoch: 31, iters: 1200, time: 0.072, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.741 D_fake: 0.648 \n",
      "(epoch: 31, iters: 1300, time: 0.071, data: 0.002) G_GAN: 0.742 G_L1: 1.744 D_real: 0.600 D_fake: 0.654 \n",
      "(epoch: 31, iters: 1400, time: 0.075, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.766 D_fake: 0.627 \n",
      "(epoch: 31, iters: 1500, time: 0.075, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.744 D_fake: 0.645 \n",
      "(epoch: 31, iters: 1600, time: 0.073, data: 0.002) G_GAN: 0.739 G_L1: 2.124 D_real: 0.581 D_fake: 0.657 \n",
      "saving the latest model (epoch 31, total_steps 70000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 31, iters: 1700, time: 0.072, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.773 D_fake: 0.624 \n",
      "(epoch: 31, iters: 1800, time: 0.076, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.751 D_fake: 0.640 \n",
      "(epoch: 31, iters: 1900, time: 0.075, data: 0.001) G_GAN: 0.747 G_L1: 3.702 D_real: 0.548 D_fake: 0.651 \n",
      "(epoch: 31, iters: 2000, time: 0.071, data: 0.002) G_GAN: 0.769 G_L1: 0.000 D_real: 0.773 D_fake: 0.624 \n",
      "(epoch: 31, iters: 2100, time: 0.071, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.729 D_fake: 0.658 \n",
      "(epoch: 31, iters: 2200, time: 0.072, data: 0.002) G_GAN: 0.728 G_L1: 1.583 D_real: 0.586 D_fake: 0.656 \n",
      "End of epoch 31 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 32, iters: 20, time: 0.073, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.760 D_fake: 0.634 \n",
      "(epoch: 32, iters: 120, time: 0.075, data: 0.004) G_GAN: 0.738 G_L1: 0.000 D_real: 0.745 D_fake: 0.646 \n",
      "(epoch: 32, iters: 220, time: 0.073, data: 0.002) G_GAN: 0.750 G_L1: 2.749 D_real: 0.575 D_fake: 0.646 \n",
      "(epoch: 32, iters: 320, time: 0.071, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.749 D_fake: 0.644 \n",
      "(epoch: 32, iters: 420, time: 0.075, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.742 D_fake: 0.654 \n",
      "(epoch: 32, iters: 520, time: 0.072, data: 0.002) G_GAN: 0.746 G_L1: 1.419 D_real: 0.605 D_fake: 0.647 \n",
      "(epoch: 32, iters: 620, time: 0.074, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.752 D_fake: 0.638 \n",
      "(epoch: 32, iters: 720, time: 0.072, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.725 D_fake: 0.667 \n",
      "(epoch: 32, iters: 820, time: 0.073, data: 0.003) G_GAN: 0.751 G_L1: 1.824 D_real: 0.601 D_fake: 0.646 \n",
      "(epoch: 32, iters: 920, time: 0.071, data: 0.002) G_GAN: 0.792 G_L1: 0.000 D_real: 0.815 D_fake: 0.582 \n",
      "(epoch: 32, iters: 1020, time: 0.074, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.745 D_fake: 0.647 \n",
      "(epoch: 32, iters: 1120, time: 0.072, data: 0.002) G_GAN: 0.731 G_L1: 1.957 D_real: 0.574 D_fake: 0.670 \n",
      "(epoch: 32, iters: 1220, time: 0.072, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.749 D_fake: 0.638 \n",
      "(epoch: 32, iters: 1320, time: 0.073, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.742 D_fake: 0.646 \n",
      "(epoch: 32, iters: 1420, time: 0.073, data: 0.001) G_GAN: 0.752 G_L1: 2.010 D_real: 0.594 D_fake: 0.643 \n",
      "(epoch: 32, iters: 1520, time: 0.073, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.748 D_fake: 0.643 \n",
      "(epoch: 32, iters: 1620, time: 0.074, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.751 D_fake: 0.638 \n",
      "(epoch: 32, iters: 1720, time: 0.072, data: 0.002) G_GAN: 0.747 G_L1: 3.150 D_real: 0.557 D_fake: 0.650 \n",
      "(epoch: 32, iters: 1820, time: 0.072, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.772 D_fake: 0.624 \n",
      "(epoch: 32, iters: 1920, time: 0.071, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.743 D_fake: 0.647 \n",
      "(epoch: 32, iters: 2020, time: 0.072, data: 0.002) G_GAN: 0.753 G_L1: 1.672 D_real: 0.606 D_fake: 0.641 \n",
      "(epoch: 32, iters: 2120, time: 0.071, data: 0.002) G_GAN: 0.657 G_L1: 0.000 D_real: 0.759 D_fake: 0.629 \n",
      "(epoch: 32, iters: 2220, time: 0.072, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.740 D_fake: 0.654 \n",
      "End of epoch 32 / 200 \t Time Taken: 107 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 33, iters: 40, time: 0.077, data: 0.002) G_GAN: 0.749 G_L1: 1.820 D_real: 0.593 D_fake: 0.646 \n",
      "(epoch: 33, iters: 140, time: 0.074, data: 0.003) G_GAN: 0.764 G_L1: 0.000 D_real: 0.770 D_fake: 0.626 \n",
      "(epoch: 33, iters: 240, time: 0.074, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.734 D_fake: 0.665 \n",
      "(epoch: 33, iters: 340, time: 0.071, data: 0.002) G_GAN: 0.742 G_L1: 1.290 D_real: 0.610 D_fake: 0.650 \n",
      "(epoch: 33, iters: 440, time: 0.073, data: 0.003) G_GAN: 0.755 G_L1: 0.000 D_real: 0.757 D_fake: 0.634 \n",
      "(epoch: 33, iters: 540, time: 0.072, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.738 D_fake: 0.654 \n",
      "(epoch: 33, iters: 640, time: 0.071, data: 0.003) G_GAN: 0.752 G_L1: 2.682 D_real: 0.572 D_fake: 0.647 \n",
      "(epoch: 33, iters: 740, time: 0.071, data: 0.001) G_GAN: 0.764 G_L1: 0.000 D_real: 0.765 D_fake: 0.627 \n",
      "(epoch: 33, iters: 840, time: 0.072, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.746 D_fake: 0.646 \n",
      "(epoch: 33, iters: 940, time: 0.072, data: 0.002) G_GAN: 0.779 G_L1: 3.230 D_real: 0.570 D_fake: 0.661 \n",
      "(epoch: 33, iters: 1040, time: 0.071, data: 0.003) G_GAN: 0.745 G_L1: 0.000 D_real: 0.753 D_fake: 0.640 \n",
      "(epoch: 33, iters: 1140, time: 0.074, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.715 D_fake: 0.661 \n",
      "(epoch: 33, iters: 1240, time: 0.072, data: 0.002) G_GAN: 0.762 G_L1: 2.399 D_real: 0.588 D_fake: 0.638 \n",
      "(epoch: 33, iters: 1340, time: 0.070, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.747 D_fake: 0.641 \n",
      "(epoch: 33, iters: 1440, time: 0.075, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.744 D_fake: 0.644 \n",
      "(epoch: 33, iters: 1540, time: 0.072, data: 0.002) G_GAN: 0.753 G_L1: 1.508 D_real: 0.594 D_fake: 0.649 \n",
      "(epoch: 33, iters: 1640, time: 0.073, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.757 D_fake: 0.633 \n",
      "(epoch: 33, iters: 1740, time: 0.072, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.747 D_fake: 0.643 \n",
      "(epoch: 33, iters: 1840, time: 0.072, data: 0.002) G_GAN: 0.746 G_L1: 0.842 D_real: 0.629 D_fake: 0.641 \n",
      "(epoch: 33, iters: 1940, time: 0.072, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.763 D_fake: 0.632 \n",
      "(epoch: 33, iters: 2040, time: 0.075, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.746 D_fake: 0.646 \n",
      "saving the latest model (epoch 33, total_steps 75000)\n",
      "(epoch: 33, iters: 2140, time: 0.073, data: 0.002) G_GAN: 0.752 G_L1: 0.917 D_real: 0.616 D_fake: 0.658 \n",
      "(epoch: 33, iters: 2240, time: 0.074, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.783 D_fake: 0.608 \n",
      "End of epoch 33 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 34, iters: 60, time: 0.076, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.732 D_fake: 0.656 \n",
      "(epoch: 34, iters: 160, time: 0.071, data: 0.001) G_GAN: 0.755 G_L1: 2.187 D_real: 0.586 D_fake: 0.648 \n",
      "(epoch: 34, iters: 260, time: 0.072, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.786 D_fake: 0.613 \n",
      "(epoch: 34, iters: 360, time: 0.072, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.739 D_fake: 0.651 \n",
      "(epoch: 34, iters: 460, time: 0.072, data: 0.002) G_GAN: 0.754 G_L1: 2.055 D_real: 0.592 D_fake: 0.651 \n",
      "(epoch: 34, iters: 560, time: 0.075, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.750 D_fake: 0.641 \n",
      "(epoch: 34, iters: 660, time: 0.074, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.738 D_fake: 0.670 \n",
      "(epoch: 34, iters: 760, time: 0.074, data: 0.002) G_GAN: 0.743 G_L1: 2.009 D_real: 0.584 D_fake: 0.658 \n",
      "(epoch: 34, iters: 860, time: 0.072, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.768 D_fake: 0.622 \n",
      "(epoch: 34, iters: 960, time: 0.075, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.757 D_fake: 0.635 \n",
      "(epoch: 34, iters: 1060, time: 0.072, data: 0.002) G_GAN: 0.733 G_L1: 0.699 D_real: 0.637 D_fake: 0.658 \n",
      "(epoch: 34, iters: 1160, time: 0.074, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.754 D_fake: 0.637 \n",
      "(epoch: 34, iters: 1260, time: 0.075, data: 0.003) G_GAN: 0.739 G_L1: 0.000 D_real: 0.745 D_fake: 0.645 \n",
      "(epoch: 34, iters: 1360, time: 0.075, data: 0.002) G_GAN: 0.745 G_L1: 2.029 D_real: 0.593 D_fake: 0.652 \n",
      "(epoch: 34, iters: 1460, time: 0.071, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.759 D_fake: 0.632 \n",
      "(epoch: 34, iters: 1560, time: 0.073, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.740 D_fake: 0.649 \n",
      "(epoch: 34, iters: 1660, time: 0.073, data: 0.001) G_GAN: 0.748 G_L1: 1.703 D_real: 0.603 D_fake: 0.647 \n",
      "(epoch: 34, iters: 1760, time: 0.074, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.757 D_fake: 0.637 \n",
      "(epoch: 34, iters: 1860, time: 0.074, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.745 D_fake: 0.646 \n",
      "(epoch: 34, iters: 1960, time: 0.074, data: 0.003) G_GAN: 0.752 G_L1: 2.015 D_real: 0.597 D_fake: 0.645 \n",
      "(epoch: 34, iters: 2060, time: 0.071, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.744 D_fake: 0.646 \n",
      "(epoch: 34, iters: 2160, time: 0.073, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.745 D_fake: 0.648 \n",
      "(epoch: 34, iters: 2260, time: 0.074, data: 0.002) G_GAN: 0.753 G_L1: 2.749 D_real: 0.569 D_fake: 0.649 \n",
      "End of epoch 34 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 35, iters: 80, time: 0.073, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.756 D_fake: 0.635 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 35, iters: 180, time: 0.072, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.750 D_fake: 0.643 \n",
      "(epoch: 35, iters: 280, time: 0.073, data: 0.002) G_GAN: 0.746 G_L1: 1.026 D_real: 0.619 D_fake: 0.650 \n",
      "(epoch: 35, iters: 380, time: 0.074, data: 0.002) G_GAN: 0.772 G_L1: 0.000 D_real: 0.774 D_fake: 0.628 \n",
      "(epoch: 35, iters: 480, time: 0.076, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.747 D_fake: 0.644 \n",
      "(epoch: 35, iters: 580, time: 0.071, data: 0.002) G_GAN: 0.748 G_L1: 3.541 D_real: 0.549 D_fake: 0.649 \n",
      "(epoch: 35, iters: 680, time: 0.073, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.753 D_fake: 0.636 \n",
      "(epoch: 35, iters: 780, time: 0.071, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.743 D_fake: 0.648 \n",
      "(epoch: 35, iters: 880, time: 0.072, data: 0.002) G_GAN: 0.761 G_L1: 2.571 D_real: 0.565 D_fake: 0.647 \n",
      "(epoch: 35, iters: 980, time: 0.072, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.771 D_fake: 0.623 \n",
      "(epoch: 35, iters: 1080, time: 0.076, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.728 D_fake: 0.660 \n",
      "(epoch: 35, iters: 1180, time: 0.072, data: 0.002) G_GAN: 0.749 G_L1: 2.021 D_real: 0.594 D_fake: 0.646 \n",
      "(epoch: 35, iters: 1280, time: 0.075, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.757 D_fake: 0.638 \n",
      "(epoch: 35, iters: 1380, time: 0.074, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.749 D_fake: 0.642 \n",
      "(epoch: 35, iters: 1480, time: 0.078, data: 0.002) G_GAN: 0.746 G_L1: 1.813 D_real: 0.593 D_fake: 0.651 \n",
      "(epoch: 35, iters: 1580, time: 0.073, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.750 D_fake: 0.642 \n",
      "(epoch: 35, iters: 1680, time: 0.076, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.729 D_fake: 0.654 \n",
      "(epoch: 35, iters: 1780, time: 0.072, data: 0.002) G_GAN: 0.750 G_L1: 2.503 D_real: 0.573 D_fake: 0.650 \n",
      "(epoch: 35, iters: 1880, time: 0.071, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.748 D_fake: 0.641 \n",
      "(epoch: 35, iters: 1980, time: 0.071, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.749 D_fake: 0.643 \n",
      "(epoch: 35, iters: 2080, time: 0.073, data: 0.002) G_GAN: 0.749 G_L1: 2.297 D_real: 0.570 D_fake: 0.653 \n",
      "(epoch: 35, iters: 2180, time: 0.073, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.769 D_fake: 0.627 \n",
      "(epoch: 35, iters: 2280, time: 0.074, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.765 D_fake: 0.631 \n",
      "saving the model at the end of epoch 35, iters 79800\n",
      "End of epoch 35 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 36, iters: 100, time: 0.074, data: 0.412) G_GAN: 0.754 G_L1: 2.485 D_real: 0.582 D_fake: 0.642 \n",
      "(epoch: 36, iters: 200, time: 0.071, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.750 D_fake: 0.641 \n",
      "saving the latest model (epoch 36, total_steps 80000)\n",
      "(epoch: 36, iters: 300, time: 0.074, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.717 D_fake: 0.667 \n",
      "(epoch: 36, iters: 400, time: 0.075, data: 0.002) G_GAN: 0.745 G_L1: 1.437 D_real: 0.602 D_fake: 0.646 \n",
      "(epoch: 36, iters: 500, time: 0.074, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.754 D_fake: 0.640 \n",
      "(epoch: 36, iters: 600, time: 0.074, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.751 D_fake: 0.647 \n",
      "(epoch: 36, iters: 700, time: 0.074, data: 0.002) G_GAN: 0.752 G_L1: 1.919 D_real: 0.595 D_fake: 0.645 \n",
      "(epoch: 36, iters: 800, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.755 D_fake: 0.639 \n",
      "(epoch: 36, iters: 900, time: 0.073, data: 0.002) G_GAN: 0.617 G_L1: 0.000 D_real: 0.533 D_fake: 0.799 \n",
      "(epoch: 36, iters: 1000, time: 0.075, data: 0.002) G_GAN: 0.750 G_L1: 1.678 D_real: 0.600 D_fake: 0.652 \n",
      "(epoch: 36, iters: 1100, time: 0.072, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.788 D_fake: 0.633 \n",
      "(epoch: 36, iters: 1200, time: 0.075, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.753 D_fake: 0.638 \n",
      "(epoch: 36, iters: 1300, time: 0.072, data: 0.002) G_GAN: 0.745 G_L1: 1.744 D_real: 0.600 D_fake: 0.649 \n",
      "(epoch: 36, iters: 1400, time: 0.074, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.766 D_fake: 0.627 \n",
      "(epoch: 36, iters: 1500, time: 0.076, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.743 D_fake: 0.648 \n",
      "(epoch: 36, iters: 1600, time: 0.071, data: 0.002) G_GAN: 0.746 G_L1: 2.124 D_real: 0.580 D_fake: 0.651 \n",
      "(epoch: 36, iters: 1700, time: 0.073, data: 0.002) G_GAN: 0.768 G_L1: 0.000 D_real: 0.773 D_fake: 0.629 \n",
      "(epoch: 36, iters: 1800, time: 0.074, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.748 D_fake: 0.643 \n",
      "(epoch: 36, iters: 1900, time: 0.073, data: 0.002) G_GAN: 0.749 G_L1: 3.702 D_real: 0.538 D_fake: 0.652 \n",
      "(epoch: 36, iters: 2000, time: 0.072, data: 0.002) G_GAN: 0.770 G_L1: 0.000 D_real: 0.772 D_fake: 0.622 \n",
      "(epoch: 36, iters: 2100, time: 0.074, data: 0.002) G_GAN: 0.678 G_L1: 0.000 D_real: 0.666 D_fake: 0.734 \n",
      "(epoch: 36, iters: 2200, time: 0.076, data: 0.002) G_GAN: 0.740 G_L1: 1.583 D_real: 0.596 D_fake: 0.649 \n",
      "End of epoch 36 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 37, iters: 20, time: 0.076, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.762 D_fake: 0.635 \n",
      "(epoch: 37, iters: 120, time: 0.073, data: 0.001) G_GAN: 0.744 G_L1: 0.000 D_real: 0.751 D_fake: 0.643 \n",
      "(epoch: 37, iters: 220, time: 0.075, data: 0.002) G_GAN: 0.747 G_L1: 2.749 D_real: 0.565 D_fake: 0.652 \n",
      "(epoch: 37, iters: 320, time: 0.072, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.756 D_fake: 0.636 \n",
      "(epoch: 37, iters: 420, time: 0.074, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.749 D_fake: 0.644 \n",
      "(epoch: 37, iters: 520, time: 0.071, data: 0.002) G_GAN: 0.757 G_L1: 1.419 D_real: 0.623 D_fake: 0.653 \n",
      "(epoch: 37, iters: 620, time: 0.072, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.755 D_fake: 0.637 \n",
      "(epoch: 37, iters: 720, time: 0.074, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.746 D_fake: 0.645 \n",
      "(epoch: 37, iters: 820, time: 0.072, data: 0.003) G_GAN: 0.744 G_L1: 1.824 D_real: 0.594 D_fake: 0.647 \n",
      "(epoch: 37, iters: 920, time: 0.073, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.732 D_fake: 0.655 \n",
      "(epoch: 37, iters: 1020, time: 0.072, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.743 D_fake: 0.649 \n",
      "(epoch: 37, iters: 1120, time: 0.075, data: 0.002) G_GAN: 0.756 G_L1: 1.957 D_real: 0.593 D_fake: 0.634 \n",
      "(epoch: 37, iters: 1220, time: 0.071, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.757 D_fake: 0.630 \n",
      "(epoch: 37, iters: 1320, time: 0.072, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.742 D_fake: 0.649 \n",
      "(epoch: 37, iters: 1420, time: 0.075, data: 0.002) G_GAN: 0.753 G_L1: 2.010 D_real: 0.591 D_fake: 0.647 \n",
      "(epoch: 37, iters: 1520, time: 0.072, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.751 D_fake: 0.641 \n",
      "(epoch: 37, iters: 1620, time: 0.073, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.745 D_fake: 0.646 \n",
      "(epoch: 37, iters: 1720, time: 0.075, data: 0.003) G_GAN: 0.756 G_L1: 3.150 D_real: 0.557 D_fake: 0.642 \n",
      "(epoch: 37, iters: 1820, time: 0.072, data: 0.002) G_GAN: 0.777 G_L1: 0.000 D_real: 0.781 D_fake: 0.618 \n",
      "(epoch: 37, iters: 1920, time: 0.071, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.745 D_fake: 0.632 \n",
      "(epoch: 37, iters: 2020, time: 0.071, data: 0.002) G_GAN: 0.754 G_L1: 1.672 D_real: 0.604 D_fake: 0.644 \n",
      "(epoch: 37, iters: 2120, time: 0.075, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.764 D_fake: 0.632 \n",
      "(epoch: 37, iters: 2220, time: 0.071, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.744 D_fake: 0.643 \n",
      "End of epoch 37 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 38, iters: 40, time: 0.076, data: 0.002) G_GAN: 0.750 G_L1: 1.820 D_real: 0.594 D_fake: 0.649 \n",
      "(epoch: 38, iters: 140, time: 0.074, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.763 D_fake: 0.629 \n",
      "(epoch: 38, iters: 240, time: 0.073, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.745 D_fake: 0.647 \n",
      "(epoch: 38, iters: 340, time: 0.074, data: 0.002) G_GAN: 0.742 G_L1: 1.290 D_real: 0.603 D_fake: 0.650 \n",
      "(epoch: 38, iters: 440, time: 0.071, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.753 D_fake: 0.634 \n",
      "(epoch: 38, iters: 540, time: 0.071, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.739 D_fake: 0.650 \n",
      "(epoch: 38, iters: 640, time: 0.073, data: 0.002) G_GAN: 0.753 G_L1: 2.682 D_real: 0.571 D_fake: 0.646 \n",
      "saving the latest model (epoch 38, total_steps 85000)\n",
      "(epoch: 38, iters: 740, time: 0.072, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.764 D_fake: 0.631 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 38, iters: 840, time: 0.075, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.748 D_fake: 0.645 \n",
      "(epoch: 38, iters: 940, time: 0.073, data: 0.002) G_GAN: 0.773 G_L1: 3.230 D_real: 0.562 D_fake: 0.644 \n",
      "(epoch: 38, iters: 1040, time: 0.072, data: 0.003) G_GAN: 0.742 G_L1: 0.000 D_real: 0.743 D_fake: 0.648 \n",
      "(epoch: 38, iters: 1140, time: 0.072, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.744 D_fake: 0.660 \n",
      "(epoch: 38, iters: 1240, time: 0.074, data: 0.002) G_GAN: 0.768 G_L1: 2.399 D_real: 0.590 D_fake: 0.636 \n",
      "(epoch: 38, iters: 1340, time: 0.074, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.753 D_fake: 0.637 \n",
      "(epoch: 38, iters: 1440, time: 0.075, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.743 D_fake: 0.646 \n",
      "(epoch: 38, iters: 1540, time: 0.071, data: 0.002) G_GAN: 0.748 G_L1: 1.508 D_real: 0.593 D_fake: 0.648 \n",
      "(epoch: 38, iters: 1640, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.756 D_fake: 0.638 \n",
      "(epoch: 38, iters: 1740, time: 0.079, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.752 D_fake: 0.641 \n",
      "(epoch: 38, iters: 1840, time: 0.072, data: 0.002) G_GAN: 0.751 G_L1: 0.842 D_real: 0.626 D_fake: 0.632 \n",
      "(epoch: 38, iters: 1940, time: 0.072, data: 0.002) G_GAN: 0.771 G_L1: 0.000 D_real: 0.779 D_fake: 0.619 \n",
      "(epoch: 38, iters: 2040, time: 0.074, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.738 D_fake: 0.654 \n",
      "(epoch: 38, iters: 2140, time: 0.071, data: 0.002) G_GAN: 0.752 G_L1: 0.917 D_real: 0.631 D_fake: 0.660 \n",
      "(epoch: 38, iters: 2240, time: 0.075, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.846 D_fake: 0.614 \n",
      "End of epoch 38 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 39, iters: 60, time: 0.076, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.718 D_fake: 0.664 \n",
      "(epoch: 39, iters: 160, time: 0.073, data: 0.001) G_GAN: 0.751 G_L1: 2.187 D_real: 0.588 D_fake: 0.647 \n",
      "(epoch: 39, iters: 260, time: 0.071, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.765 D_fake: 0.627 \n",
      "(epoch: 39, iters: 360, time: 0.071, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.737 D_fake: 0.651 \n",
      "(epoch: 39, iters: 460, time: 0.072, data: 0.002) G_GAN: 0.753 G_L1: 2.055 D_real: 0.589 D_fake: 0.647 \n",
      "(epoch: 39, iters: 560, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.752 D_fake: 0.641 \n",
      "(epoch: 39, iters: 660, time: 0.077, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.742 D_fake: 0.648 \n",
      "(epoch: 39, iters: 760, time: 0.072, data: 0.002) G_GAN: 0.740 G_L1: 2.009 D_real: 0.584 D_fake: 0.651 \n",
      "(epoch: 39, iters: 860, time: 0.073, data: 0.002) G_GAN: 0.780 G_L1: 0.000 D_real: 0.794 D_fake: 0.612 \n",
      "(epoch: 39, iters: 960, time: 0.073, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.758 D_fake: 0.633 \n",
      "(epoch: 39, iters: 1060, time: 0.072, data: 0.002) G_GAN: 0.734 G_L1: 0.699 D_real: 0.633 D_fake: 0.659 \n",
      "(epoch: 39, iters: 1160, time: 0.071, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.766 D_fake: 0.625 \n",
      "(epoch: 39, iters: 1260, time: 0.071, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.752 D_fake: 0.640 \n",
      "(epoch: 39, iters: 1360, time: 0.072, data: 0.002) G_GAN: 0.749 G_L1: 2.029 D_real: 0.594 D_fake: 0.644 \n",
      "(epoch: 39, iters: 1460, time: 0.072, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.774 D_fake: 0.628 \n",
      "(epoch: 39, iters: 1560, time: 0.072, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.745 D_fake: 0.647 \n",
      "(epoch: 39, iters: 1660, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 1.703 D_real: 0.602 D_fake: 0.645 \n",
      "(epoch: 39, iters: 1760, time: 0.074, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.756 D_fake: 0.636 \n",
      "(epoch: 39, iters: 1860, time: 0.073, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.745 D_fake: 0.644 \n",
      "(epoch: 39, iters: 1960, time: 0.074, data: 0.002) G_GAN: 0.754 G_L1: 2.015 D_real: 0.590 D_fake: 0.641 \n",
      "(epoch: 39, iters: 2060, time: 0.071, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.750 D_fake: 0.641 \n",
      "(epoch: 39, iters: 2160, time: 0.077, data: 0.003) G_GAN: 0.745 G_L1: 0.000 D_real: 0.753 D_fake: 0.638 \n",
      "(epoch: 39, iters: 2260, time: 0.075, data: 0.002) G_GAN: 0.794 G_L1: 2.749 D_real: 0.610 D_fake: 0.629 \n",
      "End of epoch 39 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 40, iters: 80, time: 0.073, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.754 D_fake: 0.638 \n",
      "(epoch: 40, iters: 180, time: 0.072, data: 0.003) G_GAN: 0.708 G_L1: 0.000 D_real: 0.722 D_fake: 0.671 \n",
      "(epoch: 40, iters: 280, time: 0.075, data: 0.002) G_GAN: 0.737 G_L1: 1.026 D_real: 0.612 D_fake: 0.655 \n",
      "(epoch: 40, iters: 380, time: 0.075, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.762 D_fake: 0.632 \n",
      "(epoch: 40, iters: 480, time: 0.077, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.744 D_fake: 0.647 \n",
      "(epoch: 40, iters: 580, time: 0.072, data: 0.002) G_GAN: 0.742 G_L1: 3.541 D_real: 0.544 D_fake: 0.655 \n",
      "(epoch: 40, iters: 680, time: 0.074, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.753 D_fake: 0.638 \n",
      "(epoch: 40, iters: 780, time: 0.075, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.749 D_fake: 0.641 \n",
      "(epoch: 40, iters: 880, time: 0.074, data: 0.002) G_GAN: 0.758 G_L1: 2.571 D_real: 0.579 D_fake: 0.632 \n",
      "(epoch: 40, iters: 980, time: 0.075, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.763 D_fake: 0.633 \n",
      "(epoch: 40, iters: 1080, time: 0.074, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.732 D_fake: 0.657 \n",
      "saving the latest model (epoch 40, total_steps 90000)\n",
      "(epoch: 40, iters: 1180, time: 0.072, data: 0.002) G_GAN: 0.751 G_L1: 2.021 D_real: 0.594 D_fake: 0.644 \n",
      "(epoch: 40, iters: 1280, time: 0.075, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.753 D_fake: 0.638 \n",
      "(epoch: 40, iters: 1380, time: 0.072, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.749 D_fake: 0.643 \n",
      "(epoch: 40, iters: 1480, time: 0.075, data: 0.002) G_GAN: 0.745 G_L1: 1.813 D_real: 0.590 D_fake: 0.648 \n",
      "(epoch: 40, iters: 1580, time: 0.071, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.751 D_fake: 0.642 \n",
      "(epoch: 40, iters: 1680, time: 0.073, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.756 D_fake: 0.637 \n",
      "(epoch: 40, iters: 1780, time: 0.075, data: 0.002) G_GAN: 0.751 G_L1: 2.503 D_real: 0.576 D_fake: 0.643 \n",
      "(epoch: 40, iters: 1880, time: 0.077, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.750 D_fake: 0.643 \n",
      "(epoch: 40, iters: 1980, time: 0.073, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.751 D_fake: 0.645 \n",
      "(epoch: 40, iters: 2080, time: 0.075, data: 0.002) G_GAN: 0.740 G_L1: 2.297 D_real: 0.570 D_fake: 0.651 \n",
      "(epoch: 40, iters: 2180, time: 0.071, data: 0.002) G_GAN: 0.879 G_L1: 0.000 D_real: 0.328 D_fake: 1.315 \n",
      "(epoch: 40, iters: 2280, time: 0.073, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.739 D_fake: 0.647 \n",
      "saving the model at the end of epoch 40, iters 91200\n",
      "End of epoch 40 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 41, iters: 100, time: 0.074, data: 0.408) G_GAN: 0.750 G_L1: 2.485 D_real: 0.582 D_fake: 0.645 \n",
      "(epoch: 41, iters: 200, time: 0.072, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.747 D_fake: 0.647 \n",
      "(epoch: 41, iters: 300, time: 0.074, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.740 D_fake: 0.648 \n",
      "(epoch: 41, iters: 400, time: 0.072, data: 0.002) G_GAN: 0.743 G_L1: 1.437 D_real: 0.599 D_fake: 0.647 \n",
      "(epoch: 41, iters: 500, time: 0.074, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.758 D_fake: 0.631 \n",
      "(epoch: 41, iters: 600, time: 0.074, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.751 D_fake: 0.642 \n",
      "(epoch: 41, iters: 700, time: 0.075, data: 0.002) G_GAN: 0.751 G_L1: 1.919 D_real: 0.588 D_fake: 0.643 \n",
      "(epoch: 41, iters: 800, time: 0.075, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.752 D_fake: 0.637 \n",
      "(epoch: 41, iters: 900, time: 0.075, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.607 D_fake: 0.782 \n",
      "(epoch: 41, iters: 1000, time: 0.073, data: 0.001) G_GAN: 0.749 G_L1: 1.678 D_real: 0.594 D_fake: 0.647 \n",
      "(epoch: 41, iters: 1100, time: 0.076, data: 0.002) G_GAN: 0.778 G_L1: 0.000 D_real: 0.798 D_fake: 0.613 \n",
      "(epoch: 41, iters: 1200, time: 0.073, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.728 D_fake: 0.661 \n",
      "(epoch: 41, iters: 1300, time: 0.072, data: 0.002) G_GAN: 0.739 G_L1: 1.744 D_real: 0.598 D_fake: 0.653 \n",
      "(epoch: 41, iters: 1400, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.754 D_fake: 0.633 \n",
      "(epoch: 41, iters: 1500, time: 0.075, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.747 D_fake: 0.647 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 41, iters: 1600, time: 0.072, data: 0.002) G_GAN: 0.741 G_L1: 2.124 D_real: 0.581 D_fake: 0.648 \n",
      "(epoch: 41, iters: 1700, time: 0.074, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.761 D_fake: 0.630 \n",
      "(epoch: 41, iters: 1800, time: 0.075, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.748 D_fake: 0.646 \n",
      "(epoch: 41, iters: 1900, time: 0.074, data: 0.002) G_GAN: 0.746 G_L1: 3.702 D_real: 0.542 D_fake: 0.650 \n",
      "(epoch: 41, iters: 2000, time: 0.075, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.762 D_fake: 0.631 \n",
      "(epoch: 41, iters: 2100, time: 0.073, data: 0.004) G_GAN: 0.727 G_L1: 0.000 D_real: 0.740 D_fake: 0.643 \n",
      "(epoch: 41, iters: 2200, time: 0.077, data: 0.002) G_GAN: 0.745 G_L1: 1.583 D_real: 0.595 D_fake: 0.647 \n",
      "End of epoch 41 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 42, iters: 20, time: 0.071, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.758 D_fake: 0.639 \n",
      "(epoch: 42, iters: 120, time: 0.073, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.750 D_fake: 0.641 \n",
      "(epoch: 42, iters: 220, time: 0.072, data: 0.002) G_GAN: 0.748 G_L1: 2.749 D_real: 0.567 D_fake: 0.647 \n",
      "(epoch: 42, iters: 320, time: 0.075, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.745 D_fake: 0.644 \n",
      "(epoch: 42, iters: 420, time: 0.075, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.743 D_fake: 0.647 \n",
      "(epoch: 42, iters: 520, time: 0.072, data: 0.002) G_GAN: 0.744 G_L1: 1.419 D_real: 0.602 D_fake: 0.649 \n",
      "(epoch: 42, iters: 620, time: 0.075, data: 0.003) G_GAN: 0.749 G_L1: 0.000 D_real: 0.751 D_fake: 0.641 \n",
      "(epoch: 42, iters: 720, time: 0.072, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.748 D_fake: 0.643 \n",
      "(epoch: 42, iters: 820, time: 0.072, data: 0.002) G_GAN: 0.749 G_L1: 1.824 D_real: 0.595 D_fake: 0.648 \n",
      "(epoch: 42, iters: 920, time: 0.073, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.778 D_fake: 0.618 \n",
      "(epoch: 42, iters: 1020, time: 0.072, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.743 D_fake: 0.648 \n",
      "(epoch: 42, iters: 1120, time: 0.071, data: 0.002) G_GAN: 0.737 G_L1: 1.957 D_real: 0.585 D_fake: 0.656 \n",
      "(epoch: 42, iters: 1220, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.754 D_fake: 0.636 \n",
      "(epoch: 42, iters: 1320, time: 0.072, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.744 D_fake: 0.646 \n",
      "(epoch: 42, iters: 1420, time: 0.072, data: 0.002) G_GAN: 0.751 G_L1: 2.010 D_real: 0.590 D_fake: 0.643 \n",
      "(epoch: 42, iters: 1520, time: 0.071, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.750 D_fake: 0.642 \n",
      "saving the latest model (epoch 42, total_steps 95000)\n",
      "(epoch: 42, iters: 1620, time: 0.071, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.749 D_fake: 0.642 \n",
      "(epoch: 42, iters: 1720, time: 0.075, data: 0.002) G_GAN: 0.752 G_L1: 3.150 D_real: 0.555 D_fake: 0.644 \n",
      "(epoch: 42, iters: 1820, time: 0.075, data: 0.003) G_GAN: 0.761 G_L1: 0.000 D_real: 0.763 D_fake: 0.631 \n",
      "(epoch: 42, iters: 1920, time: 0.074, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.747 D_fake: 0.630 \n",
      "(epoch: 42, iters: 2020, time: 0.072, data: 0.002) G_GAN: 0.754 G_L1: 1.672 D_real: 0.604 D_fake: 0.642 \n",
      "(epoch: 42, iters: 2120, time: 0.077, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.770 D_fake: 0.623 \n",
      "(epoch: 42, iters: 2220, time: 0.073, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.738 D_fake: 0.645 \n",
      "End of epoch 42 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 43, iters: 40, time: 0.075, data: 0.002) G_GAN: 0.746 G_L1: 1.820 D_real: 0.593 D_fake: 0.645 \n",
      "(epoch: 43, iters: 140, time: 0.072, data: 0.003) G_GAN: 0.768 G_L1: 0.000 D_real: 0.771 D_fake: 0.625 \n",
      "(epoch: 43, iters: 240, time: 0.076, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.754 D_fake: 0.637 \n",
      "(epoch: 43, iters: 340, time: 0.071, data: 0.002) G_GAN: 0.744 G_L1: 1.290 D_real: 0.604 D_fake: 0.650 \n",
      "(epoch: 43, iters: 440, time: 0.074, data: 0.003) G_GAN: 0.756 G_L1: 0.000 D_real: 0.757 D_fake: 0.635 \n",
      "(epoch: 43, iters: 540, time: 0.074, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.752 D_fake: 0.639 \n",
      "(epoch: 43, iters: 640, time: 0.073, data: 0.002) G_GAN: 0.751 G_L1: 2.682 D_real: 0.572 D_fake: 0.644 \n",
      "(epoch: 43, iters: 740, time: 0.075, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.769 D_fake: 0.626 \n",
      "(epoch: 43, iters: 840, time: 0.078, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.754 D_fake: 0.635 \n",
      "(epoch: 43, iters: 940, time: 0.073, data: 0.002) G_GAN: 0.778 G_L1: 3.230 D_real: 0.581 D_fake: 0.621 \n",
      "(epoch: 43, iters: 1040, time: 0.076, data: 0.003) G_GAN: 0.757 G_L1: 0.000 D_real: 0.760 D_fake: 0.631 \n",
      "(epoch: 43, iters: 1140, time: 0.073, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.740 D_fake: 0.652 \n",
      "(epoch: 43, iters: 1240, time: 0.072, data: 0.002) G_GAN: 0.759 G_L1: 2.399 D_real: 0.589 D_fake: 0.640 \n",
      "(epoch: 43, iters: 1340, time: 0.073, data: 0.003) G_GAN: 0.749 G_L1: 0.000 D_real: 0.750 D_fake: 0.642 \n",
      "(epoch: 43, iters: 1440, time: 0.071, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.748 D_fake: 0.644 \n",
      "(epoch: 43, iters: 1540, time: 0.072, data: 0.002) G_GAN: 0.746 G_L1: 1.508 D_real: 0.589 D_fake: 0.652 \n",
      "(epoch: 43, iters: 1640, time: 0.072, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.754 D_fake: 0.634 \n",
      "(epoch: 43, iters: 1740, time: 0.073, data: 0.004) G_GAN: 0.745 G_L1: 0.000 D_real: 0.751 D_fake: 0.640 \n",
      "(epoch: 43, iters: 1840, time: 0.071, data: 0.002) G_GAN: 0.751 G_L1: 0.842 D_real: 0.631 D_fake: 0.641 \n",
      "(epoch: 43, iters: 1940, time: 0.072, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.765 D_fake: 0.628 \n",
      "(epoch: 43, iters: 2040, time: 0.071, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.754 D_fake: 0.639 \n",
      "(epoch: 43, iters: 2140, time: 0.075, data: 0.002) G_GAN: 0.782 G_L1: 0.917 D_real: 0.651 D_fake: 0.639 \n",
      "(epoch: 43, iters: 2240, time: 0.072, data: 0.002) G_GAN: 0.785 G_L1: 0.000 D_real: 0.794 D_fake: 0.595 \n",
      "End of epoch 43 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 44, iters: 60, time: 0.074, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.718 D_fake: 0.671 \n",
      "(epoch: 44, iters: 160, time: 0.072, data: 0.002) G_GAN: 0.743 G_L1: 2.187 D_real: 0.580 D_fake: 0.652 \n",
      "(epoch: 44, iters: 260, time: 0.072, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.765 D_fake: 0.631 \n",
      "(epoch: 44, iters: 360, time: 0.074, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.745 D_fake: 0.644 \n",
      "(epoch: 44, iters: 460, time: 0.075, data: 0.002) G_GAN: 0.762 G_L1: 2.055 D_real: 0.596 D_fake: 0.636 \n",
      "(epoch: 44, iters: 560, time: 0.074, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.751 D_fake: 0.641 \n",
      "(epoch: 44, iters: 660, time: 0.071, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.741 D_fake: 0.645 \n",
      "(epoch: 44, iters: 760, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 2.009 D_real: 0.590 D_fake: 0.647 \n",
      "(epoch: 44, iters: 860, time: 0.071, data: 0.003) G_GAN: 0.740 G_L1: 0.000 D_real: 0.751 D_fake: 0.640 \n",
      "(epoch: 44, iters: 960, time: 0.074, data: 0.002) G_GAN: 0.770 G_L1: 0.000 D_real: 0.783 D_fake: 0.612 \n",
      "(epoch: 44, iters: 1060, time: 0.071, data: 0.002) G_GAN: 0.734 G_L1: 0.699 D_real: 0.633 D_fake: 0.657 \n",
      "(epoch: 44, iters: 1160, time: 0.071, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.767 D_fake: 0.627 \n",
      "(epoch: 44, iters: 1260, time: 0.072, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.747 D_fake: 0.644 \n",
      "(epoch: 44, iters: 1360, time: 0.071, data: 0.002) G_GAN: 0.748 G_L1: 2.029 D_real: 0.585 D_fake: 0.655 \n",
      "(epoch: 44, iters: 1460, time: 0.072, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.758 D_fake: 0.632 \n",
      "(epoch: 44, iters: 1560, time: 0.072, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.748 D_fake: 0.646 \n",
      "(epoch: 44, iters: 1660, time: 0.076, data: 0.002) G_GAN: 0.752 G_L1: 1.703 D_real: 0.598 D_fake: 0.642 \n",
      "(epoch: 44, iters: 1760, time: 0.074, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.757 D_fake: 0.636 \n",
      "(epoch: 44, iters: 1860, time: 0.077, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.750 D_fake: 0.642 \n",
      "(epoch: 44, iters: 1960, time: 0.073, data: 0.002) G_GAN: 0.752 G_L1: 2.015 D_real: 0.589 D_fake: 0.642 \n",
      "saving the latest model (epoch 44, total_steps 100000)\n",
      "(epoch: 44, iters: 2060, time: 0.073, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.642 \n",
      "(epoch: 44, iters: 2160, time: 0.075, data: 0.003) G_GAN: 0.761 G_L1: 0.000 D_real: 0.769 D_fake: 0.624 \n",
      "(epoch: 44, iters: 2260, time: 0.072, data: 0.002) G_GAN: 0.766 G_L1: 2.749 D_real: 0.581 D_fake: 0.631 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 44 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 45, iters: 80, time: 0.074, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.756 D_fake: 0.636 \n",
      "(epoch: 45, iters: 180, time: 0.074, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.758 D_fake: 0.638 \n",
      "(epoch: 45, iters: 280, time: 0.074, data: 0.002) G_GAN: 0.748 G_L1: 1.026 D_real: 0.620 D_fake: 0.648 \n",
      "(epoch: 45, iters: 380, time: 0.077, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.753 D_fake: 0.638 \n",
      "(epoch: 45, iters: 480, time: 0.074, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.753 D_fake: 0.639 \n",
      "(epoch: 45, iters: 580, time: 0.074, data: 0.002) G_GAN: 0.750 G_L1: 3.541 D_real: 0.546 D_fake: 0.649 \n",
      "(epoch: 45, iters: 680, time: 0.076, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.758 D_fake: 0.636 \n",
      "(epoch: 45, iters: 780, time: 0.076, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.742 D_fake: 0.647 \n",
      "(epoch: 45, iters: 880, time: 0.075, data: 0.002) G_GAN: 0.747 G_L1: 2.571 D_real: 0.555 D_fake: 0.658 \n",
      "(epoch: 45, iters: 980, time: 0.074, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.763 D_fake: 0.634 \n",
      "(epoch: 45, iters: 1080, time: 0.077, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.729 D_fake: 0.661 \n",
      "(epoch: 45, iters: 1180, time: 0.076, data: 0.002) G_GAN: 0.765 G_L1: 2.021 D_real: 0.602 D_fake: 0.635 \n",
      "(epoch: 45, iters: 1280, time: 0.075, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.757 D_fake: 0.635 \n",
      "(epoch: 45, iters: 1380, time: 0.073, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.751 D_fake: 0.631 \n",
      "(epoch: 45, iters: 1480, time: 0.073, data: 0.002) G_GAN: 0.749 G_L1: 1.813 D_real: 0.589 D_fake: 0.648 \n",
      "(epoch: 45, iters: 1580, time: 0.072, data: 0.003) G_GAN: 0.751 G_L1: 0.000 D_real: 0.753 D_fake: 0.639 \n",
      "(epoch: 45, iters: 1680, time: 0.073, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.748 D_fake: 0.645 \n",
      "(epoch: 45, iters: 1780, time: 0.075, data: 0.003) G_GAN: 0.746 G_L1: 2.503 D_real: 0.568 D_fake: 0.646 \n",
      "(epoch: 45, iters: 1880, time: 0.074, data: 0.003) G_GAN: 0.753 G_L1: 0.000 D_real: 0.756 D_fake: 0.638 \n",
      "(epoch: 45, iters: 1980, time: 0.074, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.751 D_fake: 0.642 \n",
      "(epoch: 45, iters: 2080, time: 0.074, data: 0.003) G_GAN: 0.758 G_L1: 2.297 D_real: 0.575 D_fake: 0.643 \n",
      "(epoch: 45, iters: 2180, time: 0.073, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.767 D_fake: 0.627 \n",
      "(epoch: 45, iters: 2280, time: 0.075, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.750 D_fake: 0.642 \n",
      "saving the model at the end of epoch 45, iters 102600\n",
      "End of epoch 45 / 200 \t Time Taken: 113 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 46, iters: 100, time: 0.078, data: 0.431) G_GAN: 0.757 G_L1: 2.485 D_real: 0.577 D_fake: 0.641 \n",
      "(epoch: 46, iters: 200, time: 0.075, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.752 D_fake: 0.637 \n",
      "(epoch: 46, iters: 300, time: 0.073, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.739 D_fake: 0.651 \n",
      "(epoch: 46, iters: 400, time: 0.075, data: 0.002) G_GAN: 0.746 G_L1: 1.437 D_real: 0.600 D_fake: 0.656 \n",
      "(epoch: 46, iters: 500, time: 0.073, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.770 D_fake: 0.627 \n",
      "(epoch: 46, iters: 600, time: 0.074, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.759 D_fake: 0.635 \n",
      "(epoch: 46, iters: 700, time: 0.077, data: 0.004) G_GAN: 0.775 G_L1: 1.919 D_real: 0.599 D_fake: 0.632 \n",
      "(epoch: 46, iters: 800, time: 0.073, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.752 D_fake: 0.639 \n",
      "(epoch: 46, iters: 900, time: 0.075, data: 0.002) G_GAN: 0.803 G_L1: 0.000 D_real: 0.809 D_fake: 0.572 \n",
      "(epoch: 46, iters: 1000, time: 0.077, data: 0.002) G_GAN: 0.754 G_L1: 1.678 D_real: 0.590 D_fake: 0.648 \n",
      "(epoch: 46, iters: 1100, time: 0.073, data: 0.001) G_GAN: 0.773 G_L1: 0.000 D_real: 0.821 D_fake: 0.619 \n",
      "(epoch: 46, iters: 1200, time: 0.075, data: 0.003) G_GAN: 0.747 G_L1: 0.000 D_real: 0.752 D_fake: 0.638 \n",
      "(epoch: 46, iters: 1300, time: 0.073, data: 0.002) G_GAN: 0.752 G_L1: 1.744 D_real: 0.605 D_fake: 0.643 \n",
      "(epoch: 46, iters: 1400, time: 0.074, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.763 D_fake: 0.633 \n",
      "(epoch: 46, iters: 1500, time: 0.073, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.744 D_fake: 0.646 \n",
      "(epoch: 46, iters: 1600, time: 0.076, data: 0.002) G_GAN: 0.747 G_L1: 2.124 D_real: 0.581 D_fake: 0.646 \n",
      "(epoch: 46, iters: 1700, time: 0.076, data: 0.002) G_GAN: 0.768 G_L1: 0.000 D_real: 0.770 D_fake: 0.625 \n",
      "(epoch: 46, iters: 1800, time: 0.077, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.750 D_fake: 0.639 \n",
      "(epoch: 46, iters: 1900, time: 0.076, data: 0.002) G_GAN: 0.757 G_L1: 3.702 D_real: 0.532 D_fake: 0.647 \n",
      "(epoch: 46, iters: 2000, time: 0.074, data: 0.002) G_GAN: 0.766 G_L1: 0.000 D_real: 0.771 D_fake: 0.627 \n",
      "(epoch: 46, iters: 2100, time: 0.074, data: 0.003) G_GAN: 0.726 G_L1: 0.000 D_real: 0.736 D_fake: 0.646 \n",
      "(epoch: 46, iters: 2200, time: 0.073, data: 0.002) G_GAN: 0.782 G_L1: 1.583 D_real: 0.601 D_fake: 0.624 \n",
      "End of epoch 46 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 47, iters: 20, time: 0.079, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.758 D_fake: 0.638 \n",
      "(epoch: 47, iters: 120, time: 0.076, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.753 D_fake: 0.642 \n",
      "saving the latest model (epoch 47, total_steps 105000)\n",
      "(epoch: 47, iters: 220, time: 0.073, data: 0.002) G_GAN: 0.758 G_L1: 2.749 D_real: 0.565 D_fake: 0.637 \n",
      "(epoch: 47, iters: 320, time: 0.073, data: 0.001) G_GAN: 0.752 G_L1: 0.000 D_real: 0.754 D_fake: 0.640 \n",
      "(epoch: 47, iters: 420, time: 0.074, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.744 D_fake: 0.647 \n",
      "(epoch: 47, iters: 520, time: 0.073, data: 0.002) G_GAN: 0.749 G_L1: 1.419 D_real: 0.605 D_fake: 0.645 \n",
      "(epoch: 47, iters: 620, time: 0.073, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.758 D_fake: 0.639 \n",
      "(epoch: 47, iters: 720, time: 0.077, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.751 D_fake: 0.639 \n",
      "(epoch: 47, iters: 820, time: 0.072, data: 0.002) G_GAN: 0.748 G_L1: 1.824 D_real: 0.589 D_fake: 0.649 \n",
      "(epoch: 47, iters: 920, time: 0.076, data: 0.002) G_GAN: 0.762 G_L1: 0.000 D_real: 0.783 D_fake: 0.603 \n",
      "(epoch: 47, iters: 1020, time: 0.076, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.737 D_fake: 0.650 \n",
      "(epoch: 47, iters: 1120, time: 0.075, data: 0.002) G_GAN: 0.746 G_L1: 1.957 D_real: 0.573 D_fake: 0.680 \n",
      "(epoch: 47, iters: 1220, time: 0.074, data: 0.003) G_GAN: 0.750 G_L1: 0.000 D_real: 0.753 D_fake: 0.637 \n",
      "(epoch: 47, iters: 1320, time: 0.077, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.742 D_fake: 0.649 \n",
      "(epoch: 47, iters: 1420, time: 0.076, data: 0.001) G_GAN: 0.757 G_L1: 2.010 D_real: 0.588 D_fake: 0.638 \n",
      "(epoch: 47, iters: 1520, time: 0.075, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.751 D_fake: 0.642 \n",
      "(epoch: 47, iters: 1620, time: 0.073, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.751 D_fake: 0.641 \n",
      "(epoch: 47, iters: 1720, time: 0.073, data: 0.002) G_GAN: 0.754 G_L1: 3.150 D_real: 0.559 D_fake: 0.643 \n",
      "(epoch: 47, iters: 1820, time: 0.072, data: 0.002) G_GAN: 0.770 G_L1: 0.000 D_real: 0.771 D_fake: 0.625 \n",
      "(epoch: 47, iters: 1920, time: 0.071, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.749 D_fake: 0.640 \n",
      "(epoch: 47, iters: 2020, time: 0.072, data: 0.002) G_GAN: 0.756 G_L1: 1.672 D_real: 0.603 D_fake: 0.639 \n",
      "(epoch: 47, iters: 2120, time: 0.073, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.758 D_fake: 0.638 \n",
      "(epoch: 47, iters: 2220, time: 0.072, data: 0.002) G_GAN: 0.674 G_L1: 0.000 D_real: 0.707 D_fake: 0.686 \n",
      "End of epoch 47 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 48, iters: 40, time: 0.074, data: 0.002) G_GAN: 0.743 G_L1: 1.820 D_real: 0.584 D_fake: 0.650 \n",
      "(epoch: 48, iters: 140, time: 0.073, data: 0.006) G_GAN: 0.759 G_L1: 0.000 D_real: 0.759 D_fake: 0.630 \n",
      "(epoch: 48, iters: 240, time: 0.071, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.755 D_fake: 0.639 \n",
      "(epoch: 48, iters: 340, time: 0.075, data: 0.002) G_GAN: 0.751 G_L1: 1.290 D_real: 0.612 D_fake: 0.641 \n",
      "(epoch: 48, iters: 440, time: 0.074, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.752 D_fake: 0.637 \n",
      "(epoch: 48, iters: 540, time: 0.072, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.740 D_fake: 0.648 \n",
      "(epoch: 48, iters: 640, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 2.682 D_real: 0.567 D_fake: 0.648 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 48, iters: 740, time: 0.072, data: 0.002) G_GAN: 0.769 G_L1: 0.000 D_real: 0.791 D_fake: 0.611 \n",
      "(epoch: 48, iters: 840, time: 0.072, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.753 D_fake: 0.628 \n",
      "(epoch: 48, iters: 940, time: 0.072, data: 0.002) G_GAN: 0.766 G_L1: 3.230 D_real: 0.573 D_fake: 0.635 \n",
      "(epoch: 48, iters: 1040, time: 0.072, data: 0.002) G_GAN: 0.773 G_L1: 0.000 D_real: 0.780 D_fake: 0.619 \n",
      "(epoch: 48, iters: 1140, time: 0.075, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.732 D_fake: 0.633 \n",
      "(epoch: 48, iters: 1240, time: 0.071, data: 0.004) G_GAN: 0.742 G_L1: 2.399 D_real: 0.574 D_fake: 0.652 \n",
      "(epoch: 48, iters: 1340, time: 0.070, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.759 D_fake: 0.633 \n",
      "(epoch: 48, iters: 1440, time: 0.072, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.730 D_fake: 0.658 \n",
      "(epoch: 48, iters: 1540, time: 0.072, data: 0.002) G_GAN: 0.758 G_L1: 1.508 D_real: 0.601 D_fake: 0.637 \n",
      "(epoch: 48, iters: 1640, time: 0.073, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.751 D_fake: 0.640 \n",
      "(epoch: 48, iters: 1740, time: 0.073, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.746 D_fake: 0.644 \n",
      "(epoch: 48, iters: 1840, time: 0.074, data: 0.002) G_GAN: 0.745 G_L1: 0.842 D_real: 0.627 D_fake: 0.645 \n",
      "(epoch: 48, iters: 1940, time: 0.074, data: 0.002) G_GAN: 0.766 G_L1: 0.000 D_real: 0.789 D_fake: 0.625 \n",
      "(epoch: 48, iters: 2040, time: 0.074, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.743 D_fake: 0.647 \n",
      "(epoch: 48, iters: 2140, time: 0.072, data: 0.002) G_GAN: 0.757 G_L1: 0.917 D_real: 0.635 D_fake: 0.647 \n",
      "(epoch: 48, iters: 2240, time: 0.072, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.775 D_fake: 0.607 \n",
      "End of epoch 48 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 49, iters: 60, time: 0.073, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.737 D_fake: 0.656 \n",
      "(epoch: 49, iters: 160, time: 0.078, data: 0.001) G_GAN: 0.748 G_L1: 2.187 D_real: 0.584 D_fake: 0.648 \n",
      "(epoch: 49, iters: 260, time: 0.072, data: 0.002) G_GAN: 0.769 G_L1: 0.000 D_real: 0.772 D_fake: 0.625 \n",
      "(epoch: 49, iters: 360, time: 0.071, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.740 D_fake: 0.648 \n",
      "(epoch: 49, iters: 460, time: 0.072, data: 0.002) G_GAN: 0.763 G_L1: 2.055 D_real: 0.602 D_fake: 0.636 \n",
      "(epoch: 49, iters: 560, time: 0.075, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.759 D_fake: 0.634 \n",
      "saving the latest model (epoch 49, total_steps 110000)\n",
      "(epoch: 49, iters: 660, time: 0.072, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.754 D_fake: 0.639 \n",
      "(epoch: 49, iters: 760, time: 0.076, data: 0.002) G_GAN: 0.750 G_L1: 2.009 D_real: 0.587 D_fake: 0.641 \n",
      "(epoch: 49, iters: 860, time: 0.071, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.758 D_fake: 0.633 \n",
      "(epoch: 49, iters: 960, time: 0.072, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.759 D_fake: 0.635 \n",
      "(epoch: 49, iters: 1060, time: 0.072, data: 0.002) G_GAN: 0.741 G_L1: 0.699 D_real: 0.636 D_fake: 0.653 \n",
      "(epoch: 49, iters: 1160, time: 0.071, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.759 D_fake: 0.632 \n",
      "(epoch: 49, iters: 1260, time: 0.071, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.747 D_fake: 0.643 \n",
      "(epoch: 49, iters: 1360, time: 0.074, data: 0.002) G_GAN: 0.744 G_L1: 2.029 D_real: 0.584 D_fake: 0.648 \n",
      "(epoch: 49, iters: 1460, time: 0.073, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.752 D_fake: 0.639 \n",
      "(epoch: 49, iters: 1560, time: 0.073, data: 0.003) G_GAN: 0.734 G_L1: 0.000 D_real: 0.740 D_fake: 0.647 \n",
      "(epoch: 49, iters: 1660, time: 0.073, data: 0.002) G_GAN: 0.744 G_L1: 1.703 D_real: 0.593 D_fake: 0.650 \n",
      "(epoch: 49, iters: 1760, time: 0.074, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.757 D_fake: 0.635 \n",
      "(epoch: 49, iters: 1860, time: 0.073, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.747 D_fake: 0.646 \n",
      "(epoch: 49, iters: 1960, time: 0.076, data: 0.002) G_GAN: 0.755 G_L1: 2.015 D_real: 0.590 D_fake: 0.643 \n",
      "(epoch: 49, iters: 2060, time: 0.070, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.748 D_fake: 0.641 \n",
      "(epoch: 49, iters: 2160, time: 0.072, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.745 D_fake: 0.646 \n",
      "(epoch: 49, iters: 2260, time: 0.071, data: 0.003) G_GAN: 0.781 G_L1: 2.749 D_real: 0.516 D_fake: 0.704 \n",
      "End of epoch 49 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 50, iters: 80, time: 0.073, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.802 D_fake: 0.617 \n",
      "(epoch: 50, iters: 180, time: 0.072, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.748 D_fake: 0.646 \n",
      "(epoch: 50, iters: 280, time: 0.075, data: 0.002) G_GAN: 0.749 G_L1: 1.026 D_real: 0.618 D_fake: 0.642 \n",
      "(epoch: 50, iters: 380, time: 0.077, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.756 D_fake: 0.639 \n",
      "(epoch: 50, iters: 480, time: 0.075, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.749 D_fake: 0.643 \n",
      "(epoch: 50, iters: 580, time: 0.076, data: 0.002) G_GAN: 0.748 G_L1: 3.541 D_real: 0.543 D_fake: 0.649 \n",
      "(epoch: 50, iters: 680, time: 0.073, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.751 D_fake: 0.639 \n",
      "(epoch: 50, iters: 780, time: 0.072, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.750 D_fake: 0.640 \n",
      "(epoch: 50, iters: 880, time: 0.072, data: 0.002) G_GAN: 0.757 G_L1: 2.571 D_real: 0.573 D_fake: 0.634 \n",
      "(epoch: 50, iters: 980, time: 0.074, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.760 D_fake: 0.632 \n",
      "(epoch: 50, iters: 1080, time: 0.071, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.729 D_fake: 0.657 \n",
      "(epoch: 50, iters: 1180, time: 0.074, data: 0.002) G_GAN: 0.757 G_L1: 2.021 D_real: 0.598 D_fake: 0.635 \n",
      "(epoch: 50, iters: 1280, time: 0.075, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.759 D_fake: 0.632 \n",
      "(epoch: 50, iters: 1380, time: 0.072, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.749 D_fake: 0.642 \n",
      "(epoch: 50, iters: 1480, time: 0.076, data: 0.002) G_GAN: 0.730 G_L1: 1.813 D_real: 0.575 D_fake: 0.665 \n",
      "(epoch: 50, iters: 1580, time: 0.072, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.753 D_fake: 0.639 \n",
      "(epoch: 50, iters: 1680, time: 0.076, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.751 D_fake: 0.641 \n",
      "(epoch: 50, iters: 1780, time: 0.070, data: 0.001) G_GAN: 0.747 G_L1: 2.503 D_real: 0.575 D_fake: 0.645 \n",
      "(epoch: 50, iters: 1880, time: 0.075, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.752 D_fake: 0.645 \n",
      "(epoch: 50, iters: 1980, time: 0.076, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.753 D_fake: 0.642 \n",
      "(epoch: 50, iters: 2080, time: 0.074, data: 0.003) G_GAN: 0.747 G_L1: 2.297 D_real: 0.572 D_fake: 0.647 \n",
      "(epoch: 50, iters: 2180, time: 0.077, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.753 D_fake: 0.636 \n",
      "(epoch: 50, iters: 2280, time: 0.070, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.745 D_fake: 0.630 \n",
      "saving the model at the end of epoch 50, iters 114000\n",
      "End of epoch 50 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 51, iters: 100, time: 0.077, data: 0.424) G_GAN: 0.747 G_L1: 2.485 D_real: 0.570 D_fake: 0.652 \n",
      "(epoch: 51, iters: 200, time: 0.072, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.758 D_fake: 0.639 \n",
      "(epoch: 51, iters: 300, time: 0.074, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.745 D_fake: 0.647 \n",
      "(epoch: 51, iters: 400, time: 0.071, data: 0.002) G_GAN: 0.742 G_L1: 1.437 D_real: 0.597 D_fake: 0.655 \n",
      "(epoch: 51, iters: 500, time: 0.072, data: 0.003) G_GAN: 0.753 G_L1: 0.000 D_real: 0.754 D_fake: 0.640 \n",
      "(epoch: 51, iters: 600, time: 0.072, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.756 D_fake: 0.637 \n",
      "(epoch: 51, iters: 700, time: 0.071, data: 0.002) G_GAN: 0.751 G_L1: 1.919 D_real: 0.587 D_fake: 0.643 \n",
      "(epoch: 51, iters: 800, time: 0.072, data: 0.003) G_GAN: 0.750 G_L1: 0.000 D_real: 0.752 D_fake: 0.638 \n",
      "(epoch: 51, iters: 900, time: 0.072, data: 0.001) G_GAN: 0.686 G_L1: 0.000 D_real: 0.698 D_fake: 0.661 \n",
      "(epoch: 51, iters: 1000, time: 0.074, data: 0.002) G_GAN: 0.750 G_L1: 1.678 D_real: 0.595 D_fake: 0.647 \n",
      "saving the latest model (epoch 51, total_steps 115000)\n",
      "(epoch: 51, iters: 1100, time: 0.072, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.797 D_fake: 0.624 \n",
      "(epoch: 51, iters: 1200, time: 0.073, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.758 D_fake: 0.638 \n",
      "(epoch: 51, iters: 1300, time: 0.072, data: 0.002) G_GAN: 0.754 G_L1: 1.744 D_real: 0.603 D_fake: 0.646 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 51, iters: 1400, time: 0.074, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.762 D_fake: 0.631 \n",
      "(epoch: 51, iters: 1500, time: 0.073, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.747 D_fake: 0.645 \n",
      "(epoch: 51, iters: 1600, time: 0.073, data: 0.002) G_GAN: 0.744 G_L1: 2.124 D_real: 0.577 D_fake: 0.646 \n",
      "(epoch: 51, iters: 1700, time: 0.075, data: 0.003) G_GAN: 0.767 G_L1: 0.000 D_real: 0.769 D_fake: 0.627 \n",
      "(epoch: 51, iters: 1800, time: 0.074, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.752 D_fake: 0.639 \n",
      "(epoch: 51, iters: 1900, time: 0.072, data: 0.002) G_GAN: 0.754 G_L1: 3.702 D_real: 0.541 D_fake: 0.643 \n",
      "(epoch: 51, iters: 2000, time: 0.072, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.775 D_fake: 0.623 \n",
      "(epoch: 51, iters: 2100, time: 0.075, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.689 D_fake: 0.701 \n",
      "(epoch: 51, iters: 2200, time: 0.075, data: 0.002) G_GAN: 0.748 G_L1: 1.583 D_real: 0.592 D_fake: 0.648 \n",
      "End of epoch 51 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 52, iters: 20, time: 0.073, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.748 D_fake: 0.638 \n",
      "(epoch: 52, iters: 120, time: 0.072, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.751 D_fake: 0.644 \n",
      "(epoch: 52, iters: 220, time: 0.075, data: 0.002) G_GAN: 0.760 G_L1: 2.749 D_real: 0.568 D_fake: 0.635 \n",
      "(epoch: 52, iters: 320, time: 0.072, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.755 D_fake: 0.635 \n",
      "(epoch: 52, iters: 420, time: 0.074, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.750 D_fake: 0.647 \n",
      "(epoch: 52, iters: 520, time: 0.072, data: 0.002) G_GAN: 0.745 G_L1: 1.419 D_real: 0.599 D_fake: 0.644 \n",
      "(epoch: 52, iters: 620, time: 0.075, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.751 D_fake: 0.641 \n",
      "(epoch: 52, iters: 720, time: 0.073, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.752 D_fake: 0.640 \n",
      "(epoch: 52, iters: 820, time: 0.073, data: 0.002) G_GAN: 0.739 G_L1: 1.824 D_real: 0.579 D_fake: 0.654 \n",
      "(epoch: 52, iters: 920, time: 0.074, data: 0.002) G_GAN: 0.781 G_L1: 0.000 D_real: 0.809 D_fake: 0.596 \n",
      "(epoch: 52, iters: 1020, time: 0.071, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.738 D_fake: 0.650 \n",
      "(epoch: 52, iters: 1120, time: 0.071, data: 0.002) G_GAN: 0.820 G_L1: 1.957 D_real: 0.620 D_fake: 0.611 \n",
      "(epoch: 52, iters: 1220, time: 0.073, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.757 D_fake: 0.634 \n",
      "(epoch: 52, iters: 1320, time: 0.072, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.743 D_fake: 0.647 \n",
      "(epoch: 52, iters: 1420, time: 0.073, data: 0.001) G_GAN: 0.759 G_L1: 2.010 D_real: 0.590 D_fake: 0.638 \n",
      "(epoch: 52, iters: 1520, time: 0.073, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.755 D_fake: 0.640 \n",
      "(epoch: 52, iters: 1620, time: 0.071, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.738 D_fake: 0.646 \n",
      "(epoch: 52, iters: 1720, time: 0.076, data: 0.002) G_GAN: 0.760 G_L1: 3.150 D_real: 0.566 D_fake: 0.638 \n",
      "(epoch: 52, iters: 1820, time: 0.073, data: 0.002) G_GAN: 0.772 G_L1: 0.000 D_real: 0.776 D_fake: 0.626 \n",
      "(epoch: 52, iters: 1920, time: 0.072, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.734 D_fake: 0.647 \n",
      "(epoch: 52, iters: 2020, time: 0.075, data: 0.002) G_GAN: 0.757 G_L1: 1.672 D_real: 0.604 D_fake: 0.639 \n",
      "(epoch: 52, iters: 2120, time: 0.076, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.789 D_fake: 0.642 \n",
      "(epoch: 52, iters: 2220, time: 0.073, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.730 D_fake: 0.659 \n",
      "End of epoch 52 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 53, iters: 40, time: 0.074, data: 0.002) G_GAN: 0.747 G_L1: 1.820 D_real: 0.587 D_fake: 0.656 \n",
      "(epoch: 53, iters: 140, time: 0.071, data: 0.003) G_GAN: 0.757 G_L1: 0.000 D_real: 0.759 D_fake: 0.634 \n",
      "(epoch: 53, iters: 240, time: 0.072, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.756 D_fake: 0.636 \n",
      "(epoch: 53, iters: 340, time: 0.074, data: 0.002) G_GAN: 0.749 G_L1: 1.290 D_real: 0.610 D_fake: 0.646 \n",
      "(epoch: 53, iters: 440, time: 0.075, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.746 D_fake: 0.645 \n",
      "(epoch: 53, iters: 540, time: 0.071, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.742 D_fake: 0.647 \n",
      "(epoch: 53, iters: 640, time: 0.073, data: 0.002) G_GAN: 0.753 G_L1: 2.682 D_real: 0.565 D_fake: 0.643 \n",
      "(epoch: 53, iters: 740, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.754 D_fake: 0.638 \n",
      "(epoch: 53, iters: 840, time: 0.072, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.747 D_fake: 0.645 \n",
      "(epoch: 53, iters: 940, time: 0.076, data: 0.002) G_GAN: 0.869 G_L1: 3.230 D_real: 0.608 D_fake: 0.578 \n",
      "(epoch: 53, iters: 1040, time: 0.073, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.741 D_fake: 0.645 \n",
      "(epoch: 53, iters: 1140, time: 0.077, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.741 D_fake: 0.636 \n",
      "(epoch: 53, iters: 1240, time: 0.072, data: 0.002) G_GAN: 0.751 G_L1: 2.399 D_real: 0.571 D_fake: 0.645 \n",
      "(epoch: 53, iters: 1340, time: 0.074, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.748 D_fake: 0.640 \n",
      "(epoch: 53, iters: 1440, time: 0.072, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.761 D_fake: 0.641 \n",
      "saving the latest model (epoch 53, total_steps 120000)\n",
      "(epoch: 53, iters: 1540, time: 0.077, data: 0.002) G_GAN: 0.746 G_L1: 1.508 D_real: 0.581 D_fake: 0.651 \n",
      "(epoch: 53, iters: 1640, time: 0.075, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.758 D_fake: 0.637 \n",
      "(epoch: 53, iters: 1740, time: 0.073, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.760 D_fake: 0.635 \n",
      "(epoch: 53, iters: 1840, time: 0.075, data: 0.002) G_GAN: 0.756 G_L1: 0.842 D_real: 0.628 D_fake: 0.633 \n",
      "(epoch: 53, iters: 1940, time: 0.071, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.770 D_fake: 0.632 \n",
      "(epoch: 53, iters: 2040, time: 0.075, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.751 D_fake: 0.644 \n",
      "(epoch: 53, iters: 2140, time: 0.072, data: 0.002) G_GAN: 0.769 G_L1: 0.917 D_real: 0.640 D_fake: 0.628 \n",
      "(epoch: 53, iters: 2240, time: 0.076, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.750 D_fake: 0.633 \n",
      "End of epoch 53 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 54, iters: 60, time: 0.073, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.748 D_fake: 0.642 \n",
      "(epoch: 54, iters: 160, time: 0.071, data: 0.001) G_GAN: 0.763 G_L1: 2.187 D_real: 0.598 D_fake: 0.668 \n",
      "(epoch: 54, iters: 260, time: 0.073, data: 0.002) G_GAN: 0.768 G_L1: 0.000 D_real: 0.770 D_fake: 0.626 \n",
      "(epoch: 54, iters: 360, time: 0.072, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.742 D_fake: 0.650 \n",
      "(epoch: 54, iters: 460, time: 0.074, data: 0.002) G_GAN: 0.774 G_L1: 2.055 D_real: 0.609 D_fake: 0.630 \n",
      "(epoch: 54, iters: 560, time: 0.075, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.758 D_fake: 0.635 \n",
      "(epoch: 54, iters: 660, time: 0.074, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.733 D_fake: 0.629 \n",
      "(epoch: 54, iters: 760, time: 0.072, data: 0.002) G_GAN: 0.751 G_L1: 2.009 D_real: 0.591 D_fake: 0.647 \n",
      "(epoch: 54, iters: 860, time: 0.070, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.759 D_fake: 0.649 \n",
      "(epoch: 54, iters: 960, time: 0.072, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.772 D_fake: 0.617 \n",
      "(epoch: 54, iters: 1060, time: 0.072, data: 0.002) G_GAN: 0.719 G_L1: 0.699 D_real: 0.617 D_fake: 0.677 \n",
      "(epoch: 54, iters: 1160, time: 0.070, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.770 D_fake: 0.628 \n",
      "(epoch: 54, iters: 1260, time: 0.070, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.751 D_fake: 0.640 \n",
      "(epoch: 54, iters: 1360, time: 0.074, data: 0.002) G_GAN: 0.755 G_L1: 2.029 D_real: 0.585 D_fake: 0.649 \n",
      "(epoch: 54, iters: 1460, time: 0.071, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.757 D_fake: 0.635 \n",
      "(epoch: 54, iters: 1560, time: 0.071, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.747 D_fake: 0.646 \n",
      "(epoch: 54, iters: 1660, time: 0.071, data: 0.002) G_GAN: 0.746 G_L1: 1.703 D_real: 0.592 D_fake: 0.649 \n",
      "(epoch: 54, iters: 1760, time: 0.071, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.763 D_fake: 0.636 \n",
      "(epoch: 54, iters: 1860, time: 0.072, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.745 D_fake: 0.647 \n",
      "(epoch: 54, iters: 1960, time: 0.073, data: 0.002) G_GAN: 0.748 G_L1: 2.015 D_real: 0.584 D_fake: 0.646 \n",
      "(epoch: 54, iters: 2060, time: 0.072, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.748 D_fake: 0.639 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 54, iters: 2160, time: 0.072, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.733 D_fake: 0.661 \n",
      "(epoch: 54, iters: 2260, time: 0.072, data: 0.002) G_GAN: 0.755 G_L1: 2.749 D_real: 0.562 D_fake: 0.643 \n",
      "End of epoch 54 / 200 \t Time Taken: 107 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 55, iters: 80, time: 0.074, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.643 \n",
      "(epoch: 55, iters: 180, time: 0.072, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.754 D_fake: 0.634 \n",
      "(epoch: 55, iters: 280, time: 0.075, data: 0.002) G_GAN: 0.748 G_L1: 1.026 D_real: 0.618 D_fake: 0.639 \n",
      "(epoch: 55, iters: 380, time: 0.072, data: 0.004) G_GAN: 0.763 G_L1: 0.000 D_real: 0.764 D_fake: 0.630 \n",
      "(epoch: 55, iters: 480, time: 0.075, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.747 D_fake: 0.643 \n",
      "(epoch: 55, iters: 580, time: 0.075, data: 0.002) G_GAN: 0.748 G_L1: 3.541 D_real: 0.544 D_fake: 0.648 \n",
      "(epoch: 55, iters: 680, time: 0.071, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.751 D_fake: 0.638 \n",
      "(epoch: 55, iters: 780, time: 0.071, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.748 D_fake: 0.644 \n",
      "(epoch: 55, iters: 880, time: 0.070, data: 0.002) G_GAN: 0.751 G_L1: 2.571 D_real: 0.564 D_fake: 0.647 \n",
      "(epoch: 55, iters: 980, time: 0.071, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.751 D_fake: 0.635 \n",
      "(epoch: 55, iters: 1080, time: 0.072, data: 0.003) G_GAN: 0.736 G_L1: 0.000 D_real: 0.740 D_fake: 0.652 \n",
      "(epoch: 55, iters: 1180, time: 0.072, data: 0.002) G_GAN: 0.750 G_L1: 2.021 D_real: 0.587 D_fake: 0.648 \n",
      "(epoch: 55, iters: 1280, time: 0.072, data: 0.002) G_GAN: 0.766 G_L1: 0.000 D_real: 0.775 D_fake: 0.613 \n",
      "(epoch: 55, iters: 1380, time: 0.072, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.746 D_fake: 0.646 \n",
      "(epoch: 55, iters: 1480, time: 0.072, data: 0.002) G_GAN: 0.749 G_L1: 1.813 D_real: 0.588 D_fake: 0.644 \n",
      "(epoch: 55, iters: 1580, time: 0.071, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.753 D_fake: 0.641 \n",
      "(epoch: 55, iters: 1680, time: 0.075, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.755 D_fake: 0.640 \n",
      "(epoch: 55, iters: 1780, time: 0.072, data: 0.003) G_GAN: 0.752 G_L1: 2.503 D_real: 0.571 D_fake: 0.643 \n",
      "(epoch: 55, iters: 1880, time: 0.072, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.752 D_fake: 0.638 \n",
      "saving the latest model (epoch 55, total_steps 125000)\n",
      "(epoch: 55, iters: 1980, time: 0.073, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.737 D_fake: 0.662 \n",
      "(epoch: 55, iters: 2080, time: 0.071, data: 0.002) G_GAN: 0.747 G_L1: 2.297 D_real: 0.571 D_fake: 0.647 \n",
      "(epoch: 55, iters: 2180, time: 0.071, data: 0.002) G_GAN: 0.762 G_L1: 0.000 D_real: 0.764 D_fake: 0.632 \n",
      "(epoch: 55, iters: 2280, time: 0.071, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.740 D_fake: 0.645 \n",
      "saving the model at the end of epoch 55, iters 125400\n",
      "End of epoch 55 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 56, iters: 100, time: 0.073, data: 0.418) G_GAN: 0.755 G_L1: 2.485 D_real: 0.571 D_fake: 0.643 \n",
      "(epoch: 56, iters: 200, time: 0.070, data: 0.003) G_GAN: 0.738 G_L1: 0.000 D_real: 0.752 D_fake: 0.648 \n",
      "(epoch: 56, iters: 300, time: 0.074, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.737 D_fake: 0.655 \n",
      "(epoch: 56, iters: 400, time: 0.074, data: 0.002) G_GAN: 0.746 G_L1: 1.437 D_real: 0.599 D_fake: 0.646 \n",
      "(epoch: 56, iters: 500, time: 0.072, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.754 D_fake: 0.639 \n",
      "(epoch: 56, iters: 600, time: 0.072, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.749 D_fake: 0.643 \n",
      "(epoch: 56, iters: 700, time: 0.072, data: 0.002) G_GAN: 0.780 G_L1: 1.919 D_real: 0.595 D_fake: 0.627 \n",
      "(epoch: 56, iters: 800, time: 0.074, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.747 D_fake: 0.642 \n",
      "(epoch: 56, iters: 900, time: 0.071, data: 0.002) G_GAN: 0.702 G_L1: 0.000 D_real: 0.712 D_fake: 0.679 \n",
      "(epoch: 56, iters: 1000, time: 0.075, data: 0.002) G_GAN: 0.764 G_L1: 1.678 D_real: 0.603 D_fake: 0.639 \n",
      "(epoch: 56, iters: 1100, time: 0.076, data: 0.002) G_GAN: 0.777 G_L1: 0.000 D_real: 0.865 D_fake: 0.641 \n",
      "(epoch: 56, iters: 1200, time: 0.075, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.754 D_fake: 0.637 \n",
      "(epoch: 56, iters: 1300, time: 0.074, data: 0.002) G_GAN: 0.753 G_L1: 1.744 D_real: 0.607 D_fake: 0.640 \n",
      "(epoch: 56, iters: 1400, time: 0.071, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.796 D_fake: 0.606 \n",
      "(epoch: 56, iters: 1500, time: 0.072, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.739 D_fake: 0.650 \n",
      "(epoch: 56, iters: 1600, time: 0.074, data: 0.002) G_GAN: 0.749 G_L1: 2.124 D_real: 0.582 D_fake: 0.646 \n",
      "(epoch: 56, iters: 1700, time: 0.072, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.758 D_fake: 0.632 \n",
      "(epoch: 56, iters: 1800, time: 0.074, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.731 D_fake: 0.661 \n",
      "(epoch: 56, iters: 1900, time: 0.071, data: 0.002) G_GAN: 0.752 G_L1: 3.702 D_real: 0.537 D_fake: 0.643 \n",
      "(epoch: 56, iters: 2000, time: 0.072, data: 0.002) G_GAN: 0.769 G_L1: 0.000 D_real: 0.776 D_fake: 0.627 \n",
      "(epoch: 56, iters: 2100, time: 0.075, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.731 D_fake: 0.652 \n",
      "(epoch: 56, iters: 2200, time: 0.074, data: 0.002) G_GAN: 0.754 G_L1: 1.583 D_real: 0.597 D_fake: 0.646 \n",
      "End of epoch 56 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 57, iters: 20, time: 0.073, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.754 D_fake: 0.639 \n",
      "(epoch: 57, iters: 120, time: 0.071, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.751 D_fake: 0.641 \n",
      "(epoch: 57, iters: 220, time: 0.071, data: 0.002) G_GAN: 0.744 G_L1: 2.749 D_real: 0.560 D_fake: 0.656 \n",
      "(epoch: 57, iters: 320, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.752 D_fake: 0.640 \n",
      "(epoch: 57, iters: 420, time: 0.072, data: 0.003) G_GAN: 0.746 G_L1: 0.000 D_real: 0.749 D_fake: 0.642 \n",
      "(epoch: 57, iters: 520, time: 0.074, data: 0.002) G_GAN: 0.752 G_L1: 1.419 D_real: 0.604 D_fake: 0.638 \n",
      "(epoch: 57, iters: 620, time: 0.075, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.757 D_fake: 0.638 \n",
      "(epoch: 57, iters: 720, time: 0.072, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.757 D_fake: 0.634 \n",
      "(epoch: 57, iters: 820, time: 0.073, data: 0.002) G_GAN: 0.750 G_L1: 1.824 D_real: 0.587 D_fake: 0.645 \n",
      "(epoch: 57, iters: 920, time: 0.075, data: 0.002) G_GAN: 0.768 G_L1: 0.000 D_real: 0.802 D_fake: 0.588 \n",
      "(epoch: 57, iters: 1020, time: 0.071, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.745 D_fake: 0.641 \n",
      "(epoch: 57, iters: 1120, time: 0.074, data: 0.002) G_GAN: 0.771 G_L1: 1.957 D_real: 0.605 D_fake: 0.666 \n",
      "(epoch: 57, iters: 1220, time: 0.074, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.756 D_fake: 0.641 \n",
      "(epoch: 57, iters: 1320, time: 0.071, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.749 D_fake: 0.643 \n",
      "(epoch: 57, iters: 1420, time: 0.072, data: 0.002) G_GAN: 0.764 G_L1: 2.010 D_real: 0.591 D_fake: 0.636 \n",
      "(epoch: 57, iters: 1520, time: 0.071, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.753 D_fake: 0.644 \n",
      "(epoch: 57, iters: 1620, time: 0.072, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.759 D_fake: 0.636 \n",
      "(epoch: 57, iters: 1720, time: 0.072, data: 0.002) G_GAN: 0.757 G_L1: 3.150 D_real: 0.554 D_fake: 0.636 \n",
      "(epoch: 57, iters: 1820, time: 0.073, data: 0.002) G_GAN: 0.775 G_L1: 0.000 D_real: 0.778 D_fake: 0.622 \n",
      "(epoch: 57, iters: 1920, time: 0.073, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.747 D_fake: 0.635 \n",
      "(epoch: 57, iters: 2020, time: 0.072, data: 0.002) G_GAN: 0.759 G_L1: 1.672 D_real: 0.598 D_fake: 0.639 \n",
      "(epoch: 57, iters: 2120, time: 0.071, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.769 D_fake: 0.607 \n",
      "(epoch: 57, iters: 2220, time: 0.071, data: 0.002) G_GAN: 0.657 G_L1: 0.000 D_real: 0.641 D_fake: 0.734 \n",
      "End of epoch 57 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 58, iters: 40, time: 0.073, data: 0.004) G_GAN: 0.756 G_L1: 1.820 D_real: 0.591 D_fake: 0.643 \n",
      "saving the latest model (epoch 58, total_steps 130000)\n",
      "(epoch: 58, iters: 140, time: 0.075, data: 0.003) G_GAN: 0.758 G_L1: 0.000 D_real: 0.760 D_fake: 0.637 \n",
      "(epoch: 58, iters: 240, time: 0.074, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.751 D_fake: 0.641 \n",
      "(epoch: 58, iters: 340, time: 0.071, data: 0.002) G_GAN: 0.749 G_L1: 1.290 D_real: 0.599 D_fake: 0.646 \n",
      "(epoch: 58, iters: 440, time: 0.070, data: 0.003) G_GAN: 0.752 G_L1: 0.000 D_real: 0.759 D_fake: 0.636 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 58, iters: 540, time: 0.071, data: 0.003) G_GAN: 0.722 G_L1: 0.000 D_real: 0.732 D_fake: 0.654 \n",
      "(epoch: 58, iters: 640, time: 0.072, data: 0.003) G_GAN: 0.751 G_L1: 2.682 D_real: 0.567 D_fake: 0.646 \n",
      "(epoch: 58, iters: 740, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.756 D_fake: 0.640 \n",
      "(epoch: 58, iters: 840, time: 0.070, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.746 D_fake: 0.646 \n",
      "(epoch: 58, iters: 940, time: 0.072, data: 0.002) G_GAN: 0.814 G_L1: 3.230 D_real: 0.583 D_fake: 0.612 \n",
      "(epoch: 58, iters: 1040, time: 0.075, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.780 D_fake: 0.621 \n",
      "(epoch: 58, iters: 1140, time: 0.071, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.719 D_fake: 0.666 \n",
      "(epoch: 58, iters: 1240, time: 0.073, data: 0.002) G_GAN: 0.764 G_L1: 2.399 D_real: 0.585 D_fake: 0.634 \n",
      "(epoch: 58, iters: 1340, time: 0.074, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.753 D_fake: 0.640 \n",
      "(epoch: 58, iters: 1440, time: 0.071, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.758 D_fake: 0.636 \n",
      "(epoch: 58, iters: 1540, time: 0.072, data: 0.002) G_GAN: 0.753 G_L1: 1.508 D_real: 0.593 D_fake: 0.648 \n",
      "(epoch: 58, iters: 1640, time: 0.072, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.757 D_fake: 0.635 \n",
      "(epoch: 58, iters: 1740, time: 0.072, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.754 D_fake: 0.636 \n",
      "(epoch: 58, iters: 1840, time: 0.072, data: 0.002) G_GAN: 0.767 G_L1: 0.842 D_real: 0.639 D_fake: 0.624 \n",
      "(epoch: 58, iters: 1940, time: 0.074, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.764 D_fake: 0.637 \n",
      "(epoch: 58, iters: 2040, time: 0.075, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.750 D_fake: 0.643 \n",
      "(epoch: 58, iters: 2140, time: 0.072, data: 0.002) G_GAN: 0.829 G_L1: 0.917 D_real: 0.670 D_fake: 0.650 \n",
      "(epoch: 58, iters: 2240, time: 0.073, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.780 D_fake: 0.617 \n",
      "End of epoch 58 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 59, iters: 60, time: 0.074, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.744 D_fake: 0.647 \n",
      "(epoch: 59, iters: 160, time: 0.074, data: 0.002) G_GAN: 0.756 G_L1: 2.187 D_real: 0.579 D_fake: 0.639 \n",
      "(epoch: 59, iters: 260, time: 0.074, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.763 D_fake: 0.639 \n",
      "(epoch: 59, iters: 360, time: 0.076, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.735 D_fake: 0.655 \n",
      "(epoch: 59, iters: 460, time: 0.072, data: 0.002) G_GAN: 0.772 G_L1: 2.055 D_real: 0.596 D_fake: 0.636 \n",
      "(epoch: 59, iters: 560, time: 0.073, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.753 D_fake: 0.640 \n",
      "(epoch: 59, iters: 660, time: 0.072, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.754 D_fake: 0.641 \n",
      "(epoch: 59, iters: 760, time: 0.072, data: 0.002) G_GAN: 0.653 G_L1: 2.009 D_real: 0.552 D_fake: 0.668 \n",
      "(epoch: 59, iters: 860, time: 0.073, data: 0.003) G_GAN: 0.737 G_L1: 0.000 D_real: 0.744 D_fake: 0.638 \n",
      "(epoch: 59, iters: 960, time: 0.073, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.785 D_fake: 0.613 \n",
      "(epoch: 59, iters: 1060, time: 0.072, data: 0.002) G_GAN: 0.741 G_L1: 0.699 D_real: 0.634 D_fake: 0.652 \n",
      "(epoch: 59, iters: 1160, time: 0.070, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.779 D_fake: 0.623 \n",
      "(epoch: 59, iters: 1260, time: 0.071, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.746 D_fake: 0.641 \n",
      "(epoch: 59, iters: 1360, time: 0.074, data: 0.002) G_GAN: 0.742 G_L1: 2.029 D_real: 0.581 D_fake: 0.651 \n",
      "(epoch: 59, iters: 1460, time: 0.073, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.767 D_fake: 0.629 \n",
      "(epoch: 59, iters: 1560, time: 0.071, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.745 D_fake: 0.648 \n",
      "(epoch: 59, iters: 1660, time: 0.075, data: 0.002) G_GAN: 0.757 G_L1: 1.703 D_real: 0.594 D_fake: 0.639 \n",
      "(epoch: 59, iters: 1760, time: 0.074, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.760 D_fake: 0.634 \n",
      "(epoch: 59, iters: 1860, time: 0.072, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.753 D_fake: 0.640 \n",
      "(epoch: 59, iters: 1960, time: 0.072, data: 0.002) G_GAN: 0.756 G_L1: 2.015 D_real: 0.591 D_fake: 0.639 \n",
      "(epoch: 59, iters: 2060, time: 0.071, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.742 D_fake: 0.648 \n",
      "(epoch: 59, iters: 2160, time: 0.075, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.749 D_fake: 0.651 \n",
      "(epoch: 59, iters: 2260, time: 0.071, data: 0.002) G_GAN: 0.751 G_L1: 2.749 D_real: 0.570 D_fake: 0.648 \n",
      "End of epoch 59 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 60, iters: 80, time: 0.073, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.773 D_fake: 0.627 \n",
      "(epoch: 60, iters: 180, time: 0.074, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.756 D_fake: 0.637 \n",
      "(epoch: 60, iters: 280, time: 0.073, data: 0.002) G_GAN: 0.746 G_L1: 1.026 D_real: 0.617 D_fake: 0.642 \n",
      "(epoch: 60, iters: 380, time: 0.072, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.758 D_fake: 0.657 \n",
      "(epoch: 60, iters: 480, time: 0.072, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.753 D_fake: 0.639 \n",
      "saving the latest model (epoch 60, total_steps 135000)\n",
      "(epoch: 60, iters: 580, time: 0.073, data: 0.002) G_GAN: 0.751 G_L1: 3.541 D_real: 0.542 D_fake: 0.648 \n",
      "(epoch: 60, iters: 680, time: 0.071, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.748 D_fake: 0.642 \n",
      "(epoch: 60, iters: 780, time: 0.074, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.745 D_fake: 0.647 \n",
      "(epoch: 60, iters: 880, time: 0.071, data: 0.003) G_GAN: 0.801 G_L1: 2.571 D_real: 0.576 D_fake: 0.628 \n",
      "(epoch: 60, iters: 980, time: 0.073, data: 0.002) G_GAN: 0.782 G_L1: 0.000 D_real: 0.772 D_fake: 0.613 \n",
      "(epoch: 60, iters: 1080, time: 0.072, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.725 D_fake: 0.662 \n",
      "(epoch: 60, iters: 1180, time: 0.072, data: 0.002) G_GAN: 0.750 G_L1: 2.021 D_real: 0.594 D_fake: 0.647 \n",
      "(epoch: 60, iters: 1280, time: 0.075, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.752 D_fake: 0.635 \n",
      "(epoch: 60, iters: 1380, time: 0.074, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.752 D_fake: 0.642 \n",
      "(epoch: 60, iters: 1480, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 1.813 D_real: 0.589 D_fake: 0.644 \n",
      "(epoch: 60, iters: 1580, time: 0.073, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.752 D_fake: 0.644 \n",
      "(epoch: 60, iters: 1680, time: 0.074, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.751 D_fake: 0.640 \n",
      "(epoch: 60, iters: 1780, time: 0.072, data: 0.002) G_GAN: 0.749 G_L1: 2.503 D_real: 0.573 D_fake: 0.647 \n",
      "(epoch: 60, iters: 1880, time: 0.075, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.753 D_fake: 0.642 \n",
      "(epoch: 60, iters: 1980, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.755 D_fake: 0.640 \n",
      "(epoch: 60, iters: 2080, time: 0.075, data: 0.002) G_GAN: 0.738 G_L1: 2.297 D_real: 0.559 D_fake: 0.655 \n",
      "(epoch: 60, iters: 2180, time: 0.075, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.760 D_fake: 0.637 \n",
      "(epoch: 60, iters: 2280, time: 0.072, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.753 D_fake: 0.646 \n",
      "saving the model at the end of epoch 60, iters 136800\n",
      "End of epoch 60 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 61, iters: 100, time: 0.075, data: 0.425) G_GAN: 0.764 G_L1: 2.485 D_real: 0.583 D_fake: 0.635 \n",
      "(epoch: 61, iters: 200, time: 0.071, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.723 D_fake: 0.666 \n",
      "(epoch: 61, iters: 300, time: 0.075, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.742 D_fake: 0.651 \n",
      "(epoch: 61, iters: 400, time: 0.075, data: 0.002) G_GAN: 0.744 G_L1: 1.437 D_real: 0.598 D_fake: 0.652 \n",
      "(epoch: 61, iters: 500, time: 0.074, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.755 D_fake: 0.639 \n",
      "(epoch: 61, iters: 600, time: 0.075, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.752 D_fake: 0.640 \n",
      "(epoch: 61, iters: 700, time: 0.073, data: 0.002) G_GAN: 0.760 G_L1: 1.919 D_real: 0.584 D_fake: 0.640 \n",
      "(epoch: 61, iters: 800, time: 0.071, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.747 D_fake: 0.646 \n",
      "(epoch: 61, iters: 900, time: 0.070, data: 0.004) G_GAN: 0.710 G_L1: 0.000 D_real: 0.727 D_fake: 0.648 \n",
      "(epoch: 61, iters: 1000, time: 0.074, data: 0.002) G_GAN: 0.764 G_L1: 1.678 D_real: 0.600 D_fake: 0.640 \n",
      "(epoch: 61, iters: 1100, time: 0.072, data: 0.002) G_GAN: 0.770 G_L1: 0.000 D_real: 0.783 D_fake: 0.624 \n",
      "(epoch: 61, iters: 1200, time: 0.074, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.754 D_fake: 0.643 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 61, iters: 1300, time: 0.075, data: 0.001) G_GAN: 0.765 G_L1: 1.744 D_real: 0.616 D_fake: 0.628 \n",
      "(epoch: 61, iters: 1400, time: 0.071, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.766 D_fake: 0.635 \n",
      "(epoch: 61, iters: 1500, time: 0.072, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.748 D_fake: 0.642 \n",
      "(epoch: 61, iters: 1600, time: 0.072, data: 0.002) G_GAN: 0.744 G_L1: 2.124 D_real: 0.570 D_fake: 0.648 \n",
      "(epoch: 61, iters: 1700, time: 0.072, data: 0.002) G_GAN: 0.771 G_L1: 0.000 D_real: 0.773 D_fake: 0.626 \n",
      "(epoch: 61, iters: 1800, time: 0.073, data: 0.003) G_GAN: 0.747 G_L1: 0.000 D_real: 0.752 D_fake: 0.634 \n",
      "(epoch: 61, iters: 1900, time: 0.072, data: 0.003) G_GAN: 0.756 G_L1: 3.702 D_real: 0.533 D_fake: 0.651 \n",
      "(epoch: 61, iters: 2000, time: 0.072, data: 0.003) G_GAN: 0.766 G_L1: 0.000 D_real: 0.777 D_fake: 0.625 \n",
      "(epoch: 61, iters: 2100, time: 0.071, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.727 D_fake: 0.639 \n",
      "(epoch: 61, iters: 2200, time: 0.072, data: 0.004) G_GAN: 0.751 G_L1: 1.583 D_real: 0.588 D_fake: 0.637 \n",
      "End of epoch 61 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 62, iters: 20, time: 0.077, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.741 D_fake: 0.645 \n",
      "(epoch: 62, iters: 120, time: 0.071, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.749 D_fake: 0.647 \n",
      "(epoch: 62, iters: 220, time: 0.072, data: 0.002) G_GAN: 0.759 G_L1: 2.749 D_real: 0.567 D_fake: 0.639 \n",
      "(epoch: 62, iters: 320, time: 0.072, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.752 D_fake: 0.639 \n",
      "(epoch: 62, iters: 420, time: 0.074, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.749 D_fake: 0.643 \n",
      "(epoch: 62, iters: 520, time: 0.071, data: 0.002) G_GAN: 0.751 G_L1: 1.419 D_real: 0.595 D_fake: 0.644 \n",
      "(epoch: 62, iters: 620, time: 0.074, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.756 D_fake: 0.638 \n",
      "(epoch: 62, iters: 720, time: 0.076, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.750 D_fake: 0.641 \n",
      "(epoch: 62, iters: 820, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 1.824 D_real: 0.580 D_fake: 0.647 \n",
      "(epoch: 62, iters: 920, time: 0.072, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.745 D_fake: 0.643 \n",
      "saving the latest model (epoch 62, total_steps 140000)\n",
      "(epoch: 62, iters: 1020, time: 0.072, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.748 D_fake: 0.645 \n",
      "(epoch: 62, iters: 1120, time: 0.073, data: 0.002) G_GAN: 0.761 G_L1: 1.957 D_real: 0.599 D_fake: 0.629 \n",
      "(epoch: 62, iters: 1220, time: 0.073, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.755 D_fake: 0.638 \n",
      "(epoch: 62, iters: 1320, time: 0.072, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.752 D_fake: 0.640 \n",
      "(epoch: 62, iters: 1420, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 2.010 D_real: 0.585 D_fake: 0.645 \n",
      "(epoch: 62, iters: 1520, time: 0.072, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.753 D_fake: 0.640 \n",
      "(epoch: 62, iters: 1620, time: 0.072, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.748 D_fake: 0.644 \n",
      "(epoch: 62, iters: 1720, time: 0.072, data: 0.002) G_GAN: 0.751 G_L1: 3.150 D_real: 0.557 D_fake: 0.643 \n",
      "(epoch: 62, iters: 1820, time: 0.073, data: 0.002) G_GAN: 0.773 G_L1: 0.000 D_real: 0.781 D_fake: 0.624 \n",
      "(epoch: 62, iters: 1920, time: 0.071, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.744 D_fake: 0.640 \n",
      "(epoch: 62, iters: 2020, time: 0.072, data: 0.002) G_GAN: 0.761 G_L1: 1.672 D_real: 0.604 D_fake: 0.637 \n",
      "(epoch: 62, iters: 2120, time: 0.071, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.764 D_fake: 0.636 \n",
      "(epoch: 62, iters: 2220, time: 0.071, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.722 D_fake: 0.655 \n",
      "End of epoch 62 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 63, iters: 40, time: 0.073, data: 0.002) G_GAN: 0.743 G_L1: 1.820 D_real: 0.578 D_fake: 0.643 \n",
      "(epoch: 63, iters: 140, time: 0.074, data: 0.001) G_GAN: 0.759 G_L1: 0.000 D_real: 0.760 D_fake: 0.628 \n",
      "(epoch: 63, iters: 240, time: 0.075, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.763 D_fake: 0.633 \n",
      "(epoch: 63, iters: 340, time: 0.075, data: 0.002) G_GAN: 0.753 G_L1: 1.290 D_real: 0.602 D_fake: 0.643 \n",
      "(epoch: 63, iters: 440, time: 0.072, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.752 D_fake: 0.641 \n",
      "(epoch: 63, iters: 540, time: 0.074, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.745 D_fake: 0.644 \n",
      "(epoch: 63, iters: 640, time: 0.074, data: 0.002) G_GAN: 0.752 G_L1: 2.682 D_real: 0.560 D_fake: 0.647 \n",
      "(epoch: 63, iters: 740, time: 0.076, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.758 D_fake: 0.633 \n",
      "(epoch: 63, iters: 840, time: 0.075, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.750 D_fake: 0.642 \n",
      "(epoch: 63, iters: 940, time: 0.072, data: 0.002) G_GAN: 0.773 G_L1: 3.230 D_real: 0.569 D_fake: 0.634 \n",
      "(epoch: 63, iters: 1040, time: 0.073, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.758 D_fake: 0.641 \n",
      "(epoch: 63, iters: 1140, time: 0.071, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.745 D_fake: 0.645 \n",
      "(epoch: 63, iters: 1240, time: 0.071, data: 0.002) G_GAN: 0.848 G_L1: 2.399 D_real: 0.628 D_fake: 0.561 \n",
      "(epoch: 63, iters: 1340, time: 0.071, data: 0.002) G_GAN: 0.645 G_L1: 0.000 D_real: 1.091 D_fake: 0.353 \n",
      "(epoch: 63, iters: 1440, time: 0.071, data: 0.001) G_GAN: 0.764 G_L1: 0.000 D_real: 0.770 D_fake: 0.608 \n",
      "(epoch: 63, iters: 1540, time: 0.071, data: 0.002) G_GAN: 0.743 G_L1: 1.508 D_real: 0.588 D_fake: 0.651 \n",
      "(epoch: 63, iters: 1640, time: 0.071, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.757 D_fake: 0.637 \n",
      "(epoch: 63, iters: 1740, time: 0.073, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.753 D_fake: 0.639 \n",
      "(epoch: 63, iters: 1840, time: 0.075, data: 0.002) G_GAN: 0.751 G_L1: 0.842 D_real: 0.624 D_fake: 0.642 \n",
      "(epoch: 63, iters: 1940, time: 0.072, data: 0.002) G_GAN: 0.772 G_L1: 0.000 D_real: 0.776 D_fake: 0.619 \n",
      "(epoch: 63, iters: 2040, time: 0.072, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.753 D_fake: 0.640 \n",
      "(epoch: 63, iters: 2140, time: 0.073, data: 0.002) G_GAN: 0.802 G_L1: 0.917 D_real: 0.663 D_fake: 0.603 \n",
      "(epoch: 63, iters: 2240, time: 0.072, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.780 D_fake: 0.622 \n",
      "End of epoch 63 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 64, iters: 60, time: 0.073, data: 0.003) G_GAN: 0.745 G_L1: 0.000 D_real: 0.750 D_fake: 0.640 \n",
      "(epoch: 64, iters: 160, time: 0.072, data: 0.002) G_GAN: 0.756 G_L1: 2.187 D_real: 0.582 D_fake: 0.639 \n",
      "(epoch: 64, iters: 260, time: 0.075, data: 0.002) G_GAN: 0.766 G_L1: 0.000 D_real: 0.777 D_fake: 0.624 \n",
      "(epoch: 64, iters: 360, time: 0.071, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.750 D_fake: 0.643 \n",
      "(epoch: 64, iters: 460, time: 0.072, data: 0.004) G_GAN: 0.761 G_L1: 2.055 D_real: 0.590 D_fake: 0.642 \n",
      "(epoch: 64, iters: 560, time: 0.072, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.749 D_fake: 0.645 \n",
      "(epoch: 64, iters: 660, time: 0.072, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.748 D_fake: 0.643 \n",
      "(epoch: 64, iters: 760, time: 0.071, data: 0.002) G_GAN: 0.755 G_L1: 2.009 D_real: 0.587 D_fake: 0.639 \n",
      "(epoch: 64, iters: 860, time: 0.070, data: 0.002) G_GAN: 0.762 G_L1: 0.000 D_real: 0.763 D_fake: 0.631 \n",
      "(epoch: 64, iters: 960, time: 0.071, data: 0.002) G_GAN: 0.771 G_L1: 0.000 D_real: 0.766 D_fake: 0.617 \n",
      "(epoch: 64, iters: 1060, time: 0.070, data: 0.002) G_GAN: 0.731 G_L1: 0.699 D_real: 0.621 D_fake: 0.662 \n",
      "(epoch: 64, iters: 1160, time: 0.072, data: 0.002) G_GAN: 0.768 G_L1: 0.000 D_real: 0.772 D_fake: 0.624 \n",
      "(epoch: 64, iters: 1260, time: 0.073, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.755 D_fake: 0.637 \n",
      "(epoch: 64, iters: 1360, time: 0.072, data: 0.002) G_GAN: 0.749 G_L1: 2.029 D_real: 0.586 D_fake: 0.637 \n",
      "saving the latest model (epoch 64, total_steps 145000)\n",
      "(epoch: 64, iters: 1460, time: 0.073, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.760 D_fake: 0.633 \n",
      "(epoch: 64, iters: 1560, time: 0.072, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.752 D_fake: 0.647 \n",
      "(epoch: 64, iters: 1660, time: 0.074, data: 0.002) G_GAN: 0.749 G_L1: 1.703 D_real: 0.595 D_fake: 0.649 \n",
      "(epoch: 64, iters: 1760, time: 0.071, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.758 D_fake: 0.635 \n",
      "(epoch: 64, iters: 1860, time: 0.073, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.751 D_fake: 0.639 \n",
      "(epoch: 64, iters: 1960, time: 0.072, data: 0.002) G_GAN: 0.751 G_L1: 2.015 D_real: 0.578 D_fake: 0.649 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 64, iters: 2060, time: 0.070, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.752 D_fake: 0.639 \n",
      "(epoch: 64, iters: 2160, time: 0.073, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.747 D_fake: 0.644 \n",
      "(epoch: 64, iters: 2260, time: 0.071, data: 0.003) G_GAN: 0.771 G_L1: 2.749 D_real: 0.584 D_fake: 0.634 \n",
      "End of epoch 64 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 65, iters: 80, time: 0.072, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.746 D_fake: 0.652 \n",
      "(epoch: 65, iters: 180, time: 0.073, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.752 D_fake: 0.633 \n",
      "(epoch: 65, iters: 280, time: 0.072, data: 0.002) G_GAN: 0.749 G_L1: 1.026 D_real: 0.620 D_fake: 0.649 \n",
      "(epoch: 65, iters: 380, time: 0.072, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.758 D_fake: 0.633 \n",
      "(epoch: 65, iters: 480, time: 0.074, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.753 D_fake: 0.638 \n",
      "(epoch: 65, iters: 580, time: 0.072, data: 0.004) G_GAN: 0.745 G_L1: 3.541 D_real: 0.541 D_fake: 0.651 \n",
      "(epoch: 65, iters: 680, time: 0.075, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.745 D_fake: 0.644 \n",
      "(epoch: 65, iters: 780, time: 0.071, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.753 D_fake: 0.641 \n",
      "(epoch: 65, iters: 880, time: 0.073, data: 0.002) G_GAN: 0.749 G_L1: 2.571 D_real: 0.566 D_fake: 0.629 \n",
      "(epoch: 65, iters: 980, time: 0.074, data: 0.002) G_GAN: 0.766 G_L1: 0.000 D_real: 0.771 D_fake: 0.622 \n",
      "(epoch: 65, iters: 1080, time: 0.072, data: 0.001) G_GAN: 0.721 G_L1: 0.000 D_real: 0.731 D_fake: 0.654 \n",
      "(epoch: 65, iters: 1180, time: 0.072, data: 0.002) G_GAN: 0.760 G_L1: 2.021 D_real: 0.598 D_fake: 0.638 \n",
      "(epoch: 65, iters: 1280, time: 0.072, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.762 D_fake: 0.630 \n",
      "(epoch: 65, iters: 1380, time: 0.072, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.750 D_fake: 0.640 \n",
      "(epoch: 65, iters: 1480, time: 0.072, data: 0.002) G_GAN: 0.754 G_L1: 1.813 D_real: 0.589 D_fake: 0.638 \n",
      "(epoch: 65, iters: 1580, time: 0.073, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.759 D_fake: 0.639 \n",
      "(epoch: 65, iters: 1680, time: 0.073, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.753 D_fake: 0.639 \n",
      "(epoch: 65, iters: 1780, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 2.503 D_real: 0.571 D_fake: 0.643 \n",
      "(epoch: 65, iters: 1880, time: 0.072, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.753 D_fake: 0.638 \n",
      "(epoch: 65, iters: 1980, time: 0.075, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.747 D_fake: 0.648 \n",
      "(epoch: 65, iters: 2080, time: 0.071, data: 0.002) G_GAN: 0.736 G_L1: 2.297 D_real: 0.561 D_fake: 0.651 \n",
      "(epoch: 65, iters: 2180, time: 0.071, data: 0.005) G_GAN: 0.773 G_L1: 0.000 D_real: 0.778 D_fake: 0.614 \n",
      "(epoch: 65, iters: 2280, time: 0.070, data: 0.002) G_GAN: 0.574 G_L1: 0.000 D_real: 0.672 D_fake: 0.694 \n",
      "saving the model at the end of epoch 65, iters 148200\n",
      "End of epoch 65 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 66, iters: 100, time: 0.075, data: 0.397) G_GAN: 0.758 G_L1: 2.485 D_real: 0.578 D_fake: 0.639 \n",
      "(epoch: 66, iters: 200, time: 0.074, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.760 D_fake: 0.632 \n",
      "(epoch: 66, iters: 300, time: 0.071, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.746 D_fake: 0.645 \n",
      "(epoch: 66, iters: 400, time: 0.075, data: 0.002) G_GAN: 0.749 G_L1: 1.437 D_real: 0.601 D_fake: 0.646 \n",
      "(epoch: 66, iters: 500, time: 0.071, data: 0.003) G_GAN: 0.756 G_L1: 0.000 D_real: 0.758 D_fake: 0.638 \n",
      "(epoch: 66, iters: 600, time: 0.071, data: 0.003) G_GAN: 0.750 G_L1: 0.000 D_real: 0.755 D_fake: 0.637 \n",
      "(epoch: 66, iters: 700, time: 0.072, data: 0.002) G_GAN: 0.759 G_L1: 1.919 D_real: 0.589 D_fake: 0.640 \n",
      "(epoch: 66, iters: 800, time: 0.071, data: 0.003) G_GAN: 0.753 G_L1: 0.000 D_real: 0.754 D_fake: 0.639 \n",
      "(epoch: 66, iters: 900, time: 0.071, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.750 D_fake: 0.625 \n",
      "(epoch: 66, iters: 1000, time: 0.071, data: 0.002) G_GAN: 0.741 G_L1: 1.678 D_real: 0.584 D_fake: 0.660 \n",
      "(epoch: 66, iters: 1100, time: 0.072, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.775 D_fake: 0.626 \n",
      "(epoch: 66, iters: 1200, time: 0.072, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.761 D_fake: 0.638 \n",
      "(epoch: 66, iters: 1300, time: 0.074, data: 0.002) G_GAN: 0.756 G_L1: 1.744 D_real: 0.611 D_fake: 0.638 \n",
      "(epoch: 66, iters: 1400, time: 0.075, data: 0.001) G_GAN: 0.761 G_L1: 0.000 D_real: 0.763 D_fake: 0.632 \n",
      "(epoch: 66, iters: 1500, time: 0.072, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.747 D_fake: 0.643 \n",
      "(epoch: 66, iters: 1600, time: 0.072, data: 0.002) G_GAN: 0.747 G_L1: 2.124 D_real: 0.575 D_fake: 0.648 \n",
      "(epoch: 66, iters: 1700, time: 0.072, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.768 D_fake: 0.629 \n",
      "(epoch: 66, iters: 1800, time: 0.074, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.752 D_fake: 0.640 \n",
      "saving the latest model (epoch 66, total_steps 150000)\n",
      "(epoch: 66, iters: 1900, time: 0.072, data: 0.002) G_GAN: 0.778 G_L1: 3.702 D_real: 0.557 D_fake: 0.639 \n",
      "(epoch: 66, iters: 2000, time: 0.072, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.761 D_fake: 0.635 \n",
      "(epoch: 66, iters: 2100, time: 0.074, data: 0.003) G_GAN: 0.740 G_L1: 0.000 D_real: 0.746 D_fake: 0.651 \n",
      "(epoch: 66, iters: 2200, time: 0.072, data: 0.002) G_GAN: 0.751 G_L1: 1.583 D_real: 0.590 D_fake: 0.647 \n",
      "End of epoch 66 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 67, iters: 20, time: 0.073, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.763 D_fake: 0.637 \n",
      "(epoch: 67, iters: 120, time: 0.074, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.750 D_fake: 0.635 \n",
      "(epoch: 67, iters: 220, time: 0.071, data: 0.002) G_GAN: 0.739 G_L1: 2.749 D_real: 0.556 D_fake: 0.655 \n",
      "(epoch: 67, iters: 320, time: 0.074, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.752 D_fake: 0.641 \n",
      "(epoch: 67, iters: 420, time: 0.071, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.748 D_fake: 0.647 \n",
      "(epoch: 67, iters: 520, time: 0.070, data: 0.002) G_GAN: 0.755 G_L1: 1.419 D_real: 0.606 D_fake: 0.643 \n",
      "(epoch: 67, iters: 620, time: 0.075, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.753 D_fake: 0.640 \n",
      "(epoch: 67, iters: 720, time: 0.072, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.748 D_fake: 0.638 \n",
      "(epoch: 67, iters: 820, time: 0.072, data: 0.002) G_GAN: 0.769 G_L1: 1.824 D_real: 0.603 D_fake: 0.634 \n",
      "(epoch: 67, iters: 920, time: 0.071, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.764 D_fake: 0.629 \n",
      "(epoch: 67, iters: 1020, time: 0.071, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.753 D_fake: 0.645 \n",
      "(epoch: 67, iters: 1120, time: 0.073, data: 0.002) G_GAN: 0.738 G_L1: 1.957 D_real: 0.576 D_fake: 0.652 \n",
      "(epoch: 67, iters: 1220, time: 0.073, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.756 D_fake: 0.637 \n",
      "(epoch: 67, iters: 1320, time: 0.072, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.749 D_fake: 0.644 \n",
      "(epoch: 67, iters: 1420, time: 0.076, data: 0.002) G_GAN: 0.762 G_L1: 2.010 D_real: 0.592 D_fake: 0.638 \n",
      "(epoch: 67, iters: 1520, time: 0.073, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.759 D_fake: 0.634 \n",
      "(epoch: 67, iters: 1620, time: 0.071, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.749 D_fake: 0.638 \n",
      "(epoch: 67, iters: 1720, time: 0.072, data: 0.002) G_GAN: 0.759 G_L1: 3.150 D_real: 0.556 D_fake: 0.639 \n",
      "(epoch: 67, iters: 1820, time: 0.072, data: 0.002) G_GAN: 0.769 G_L1: 0.000 D_real: 0.771 D_fake: 0.626 \n",
      "(epoch: 67, iters: 1920, time: 0.075, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.747 D_fake: 0.646 \n",
      "(epoch: 67, iters: 2020, time: 0.074, data: 0.002) G_GAN: 0.762 G_L1: 1.672 D_real: 0.607 D_fake: 0.635 \n",
      "(epoch: 67, iters: 2120, time: 0.072, data: 0.003) G_GAN: 0.751 G_L1: 0.000 D_real: 0.759 D_fake: 0.638 \n",
      "(epoch: 67, iters: 2220, time: 0.074, data: 0.003) G_GAN: 0.739 G_L1: 0.000 D_real: 0.747 D_fake: 0.646 \n",
      "End of epoch 67 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 68, iters: 40, time: 0.075, data: 0.002) G_GAN: 0.756 G_L1: 1.820 D_real: 0.583 D_fake: 0.627 \n",
      "(epoch: 68, iters: 140, time: 0.073, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.750 D_fake: 0.640 \n",
      "(epoch: 68, iters: 240, time: 0.074, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.747 D_fake: 0.646 \n",
      "(epoch: 68, iters: 340, time: 0.072, data: 0.002) G_GAN: 0.745 G_L1: 1.290 D_real: 0.596 D_fake: 0.648 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 68, iters: 440, time: 0.073, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.750 D_fake: 0.640 \n",
      "(epoch: 68, iters: 540, time: 0.074, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.743 D_fake: 0.645 \n",
      "(epoch: 68, iters: 640, time: 0.073, data: 0.002) G_GAN: 0.751 G_L1: 2.682 D_real: 0.562 D_fake: 0.647 \n",
      "(epoch: 68, iters: 740, time: 0.072, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.803 D_fake: 0.623 \n",
      "(epoch: 68, iters: 840, time: 0.072, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.745 D_fake: 0.645 \n",
      "(epoch: 68, iters: 940, time: 0.072, data: 0.002) G_GAN: 0.778 G_L1: 3.230 D_real: 0.568 D_fake: 0.624 \n",
      "(epoch: 68, iters: 1040, time: 0.071, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.757 D_fake: 0.637 \n",
      "(epoch: 68, iters: 1140, time: 0.072, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.748 D_fake: 0.647 \n",
      "(epoch: 68, iters: 1240, time: 0.071, data: 0.002) G_GAN: 0.846 G_L1: 2.399 D_real: 0.625 D_fake: 0.560 \n",
      "(epoch: 68, iters: 1340, time: 0.070, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.744 D_fake: 0.609 \n",
      "(epoch: 68, iters: 1440, time: 0.073, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.736 D_fake: 0.658 \n",
      "(epoch: 68, iters: 1540, time: 0.075, data: 0.002) G_GAN: 0.752 G_L1: 1.508 D_real: 0.587 D_fake: 0.644 \n",
      "(epoch: 68, iters: 1640, time: 0.072, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.759 D_fake: 0.638 \n",
      "(epoch: 68, iters: 1740, time: 0.071, data: 0.001) G_GAN: 0.751 G_L1: 0.000 D_real: 0.754 D_fake: 0.641 \n",
      "(epoch: 68, iters: 1840, time: 0.076, data: 0.002) G_GAN: 0.753 G_L1: 0.842 D_real: 0.625 D_fake: 0.640 \n",
      "(epoch: 68, iters: 1940, time: 0.075, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.766 D_fake: 0.628 \n",
      "(epoch: 68, iters: 2040, time: 0.075, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.751 D_fake: 0.641 \n",
      "(epoch: 68, iters: 2140, time: 0.073, data: 0.003) G_GAN: 0.730 G_L1: 0.917 D_real: 0.602 D_fake: 0.671 \n",
      "(epoch: 68, iters: 2240, time: 0.072, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.750 D_fake: 0.658 \n",
      "saving the latest model (epoch 68, total_steps 155000)\n",
      "End of epoch 68 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 69, iters: 60, time: 0.075, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.742 D_fake: 0.651 \n",
      "(epoch: 69, iters: 160, time: 0.073, data: 0.002) G_GAN: 0.789 G_L1: 2.187 D_real: 0.600 D_fake: 0.615 \n",
      "(epoch: 69, iters: 260, time: 0.075, data: 0.002) G_GAN: 0.822 G_L1: 0.000 D_real: 0.918 D_fake: 0.519 \n",
      "(epoch: 69, iters: 360, time: 0.071, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.739 D_fake: 0.652 \n",
      "(epoch: 69, iters: 460, time: 0.072, data: 0.002) G_GAN: 0.765 G_L1: 2.055 D_real: 0.595 D_fake: 0.635 \n",
      "(epoch: 69, iters: 560, time: 0.072, data: 0.001) G_GAN: 0.752 G_L1: 0.000 D_real: 0.754 D_fake: 0.639 \n",
      "(epoch: 69, iters: 660, time: 0.074, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.737 D_fake: 0.636 \n",
      "(epoch: 69, iters: 760, time: 0.072, data: 0.002) G_GAN: 0.732 G_L1: 2.009 D_real: 0.571 D_fake: 0.658 \n",
      "(epoch: 69, iters: 860, time: 0.072, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.744 D_fake: 0.638 \n",
      "(epoch: 69, iters: 960, time: 0.071, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.784 D_fake: 0.606 \n",
      "(epoch: 69, iters: 1060, time: 0.072, data: 0.002) G_GAN: 0.738 G_L1: 0.699 D_real: 0.630 D_fake: 0.657 \n",
      "(epoch: 69, iters: 1160, time: 0.071, data: 0.002) G_GAN: 0.782 G_L1: 0.000 D_real: 0.789 D_fake: 0.608 \n",
      "(epoch: 69, iters: 1260, time: 0.071, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.761 D_fake: 0.611 \n",
      "(epoch: 69, iters: 1360, time: 0.071, data: 0.002) G_GAN: 0.746 G_L1: 2.029 D_real: 0.584 D_fake: 0.647 \n",
      "(epoch: 69, iters: 1460, time: 0.072, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.763 D_fake: 0.637 \n",
      "(epoch: 69, iters: 1560, time: 0.072, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.752 D_fake: 0.640 \n",
      "(epoch: 69, iters: 1660, time: 0.074, data: 0.002) G_GAN: 0.755 G_L1: 1.703 D_real: 0.594 D_fake: 0.639 \n",
      "(epoch: 69, iters: 1760, time: 0.071, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.760 D_fake: 0.632 \n",
      "(epoch: 69, iters: 1860, time: 0.071, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.742 D_fake: 0.644 \n",
      "(epoch: 69, iters: 1960, time: 0.071, data: 0.003) G_GAN: 0.751 G_L1: 2.015 D_real: 0.586 D_fake: 0.643 \n",
      "(epoch: 69, iters: 2060, time: 0.075, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.750 D_fake: 0.636 \n",
      "(epoch: 69, iters: 2160, time: 0.075, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.755 D_fake: 0.639 \n",
      "(epoch: 69, iters: 2260, time: 0.071, data: 0.002) G_GAN: 0.743 G_L1: 2.749 D_real: 0.557 D_fake: 0.652 \n",
      "End of epoch 69 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 70, iters: 80, time: 0.072, data: 0.003) G_GAN: 0.754 G_L1: 0.000 D_real: 0.764 D_fake: 0.640 \n",
      "(epoch: 70, iters: 180, time: 0.071, data: 0.003) G_GAN: 0.753 G_L1: 0.000 D_real: 0.758 D_fake: 0.621 \n",
      "(epoch: 70, iters: 280, time: 0.075, data: 0.002) G_GAN: 0.750 G_L1: 1.026 D_real: 0.612 D_fake: 0.645 \n",
      "(epoch: 70, iters: 380, time: 0.073, data: 0.004) G_GAN: 0.759 G_L1: 0.000 D_real: 0.761 D_fake: 0.633 \n",
      "(epoch: 70, iters: 480, time: 0.075, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.747 D_fake: 0.644 \n",
      "(epoch: 70, iters: 580, time: 0.074, data: 0.002) G_GAN: 0.749 G_L1: 3.541 D_real: 0.542 D_fake: 0.652 \n",
      "(epoch: 70, iters: 680, time: 0.073, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.748 D_fake: 0.641 \n",
      "(epoch: 70, iters: 780, time: 0.074, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.751 D_fake: 0.642 \n",
      "(epoch: 70, iters: 880, time: 0.070, data: 0.002) G_GAN: 0.782 G_L1: 2.571 D_real: 0.576 D_fake: 0.625 \n",
      "(epoch: 70, iters: 980, time: 0.074, data: 0.003) G_GAN: 0.750 G_L1: 0.000 D_real: 0.751 D_fake: 0.639 \n",
      "(epoch: 70, iters: 1080, time: 0.074, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.737 D_fake: 0.653 \n",
      "(epoch: 70, iters: 1180, time: 0.075, data: 0.002) G_GAN: 0.738 G_L1: 2.021 D_real: 0.581 D_fake: 0.656 \n",
      "(epoch: 70, iters: 1280, time: 0.074, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.756 D_fake: 0.637 \n",
      "(epoch: 70, iters: 1380, time: 0.071, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.744 D_fake: 0.641 \n",
      "(epoch: 70, iters: 1480, time: 0.074, data: 0.002) G_GAN: 0.752 G_L1: 1.813 D_real: 0.585 D_fake: 0.638 \n",
      "(epoch: 70, iters: 1580, time: 0.071, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.754 D_fake: 0.640 \n",
      "(epoch: 70, iters: 1680, time: 0.071, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.755 D_fake: 0.637 \n",
      "(epoch: 70, iters: 1780, time: 0.072, data: 0.002) G_GAN: 0.756 G_L1: 2.503 D_real: 0.572 D_fake: 0.638 \n",
      "(epoch: 70, iters: 1880, time: 0.073, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.740 D_fake: 0.654 \n",
      "(epoch: 70, iters: 1980, time: 0.072, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.746 D_fake: 0.645 \n",
      "(epoch: 70, iters: 2080, time: 0.071, data: 0.002) G_GAN: 0.742 G_L1: 2.297 D_real: 0.566 D_fake: 0.646 \n",
      "(epoch: 70, iters: 2180, time: 0.075, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.758 D_fake: 0.639 \n",
      "(epoch: 70, iters: 2280, time: 0.070, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.753 D_fake: 0.641 \n",
      "saving the model at the end of epoch 70, iters 159600\n",
      "End of epoch 70 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 71, iters: 100, time: 0.074, data: 0.374) G_GAN: 0.760 G_L1: 2.485 D_real: 0.578 D_fake: 0.643 \n",
      "(epoch: 71, iters: 200, time: 0.070, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.758 D_fake: 0.644 \n",
      "(epoch: 71, iters: 300, time: 0.071, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.745 D_fake: 0.647 \n",
      "(epoch: 71, iters: 400, time: 0.075, data: 0.002) G_GAN: 0.753 G_L1: 1.437 D_real: 0.599 D_fake: 0.643 \n",
      "saving the latest model (epoch 71, total_steps 160000)\n",
      "(epoch: 71, iters: 500, time: 0.071, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.752 D_fake: 0.641 \n",
      "(epoch: 71, iters: 600, time: 0.075, data: 0.003) G_GAN: 0.751 G_L1: 0.000 D_real: 0.756 D_fake: 0.641 \n",
      "(epoch: 71, iters: 700, time: 0.075, data: 0.002) G_GAN: 0.776 G_L1: 1.919 D_real: 0.588 D_fake: 0.627 \n",
      "(epoch: 71, iters: 800, time: 0.071, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.755 D_fake: 0.638 \n",
      "(epoch: 71, iters: 900, time: 0.071, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.738 D_fake: 0.650 \n",
      "(epoch: 71, iters: 1000, time: 0.071, data: 0.002) G_GAN: 0.753 G_L1: 1.678 D_real: 0.587 D_fake: 0.651 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 71, iters: 1100, time: 0.076, data: 0.003) G_GAN: 0.760 G_L1: 0.000 D_real: 0.786 D_fake: 0.638 \n",
      "(epoch: 71, iters: 1200, time: 0.075, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.755 D_fake: 0.640 \n",
      "(epoch: 71, iters: 1300, time: 0.073, data: 0.002) G_GAN: 0.753 G_L1: 1.744 D_real: 0.601 D_fake: 0.646 \n",
      "(epoch: 71, iters: 1400, time: 0.075, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.766 D_fake: 0.625 \n",
      "(epoch: 71, iters: 1500, time: 0.075, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.748 D_fake: 0.645 \n",
      "(epoch: 71, iters: 1600, time: 0.071, data: 0.002) G_GAN: 0.752 G_L1: 2.124 D_real: 0.576 D_fake: 0.644 \n",
      "(epoch: 71, iters: 1700, time: 0.072, data: 0.003) G_GAN: 0.768 G_L1: 0.000 D_real: 0.770 D_fake: 0.627 \n",
      "(epoch: 71, iters: 1800, time: 0.072, data: 0.003) G_GAN: 0.748 G_L1: 0.000 D_real: 0.752 D_fake: 0.640 \n",
      "(epoch: 71, iters: 1900, time: 0.072, data: 0.002) G_GAN: 0.758 G_L1: 3.702 D_real: 0.541 D_fake: 0.648 \n",
      "(epoch: 71, iters: 2000, time: 0.072, data: 0.002) G_GAN: 0.762 G_L1: 0.000 D_real: 0.764 D_fake: 0.631 \n",
      "(epoch: 71, iters: 2100, time: 0.071, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.720 D_fake: 0.669 \n",
      "(epoch: 71, iters: 2200, time: 0.071, data: 0.002) G_GAN: 0.756 G_L1: 1.583 D_real: 0.574 D_fake: 0.668 \n",
      "End of epoch 71 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 72, iters: 20, time: 0.074, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.751 D_fake: 0.641 \n",
      "(epoch: 72, iters: 120, time: 0.072, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.748 D_fake: 0.639 \n",
      "(epoch: 72, iters: 220, time: 0.071, data: 0.002) G_GAN: 0.757 G_L1: 2.749 D_real: 0.558 D_fake: 0.642 \n",
      "(epoch: 72, iters: 320, time: 0.073, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.755 D_fake: 0.646 \n",
      "(epoch: 72, iters: 420, time: 0.072, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.749 D_fake: 0.647 \n",
      "(epoch: 72, iters: 520, time: 0.074, data: 0.002) G_GAN: 0.751 G_L1: 1.419 D_real: 0.592 D_fake: 0.648 \n",
      "(epoch: 72, iters: 620, time: 0.071, data: 0.004) G_GAN: 0.756 G_L1: 0.000 D_real: 0.759 D_fake: 0.633 \n",
      "(epoch: 72, iters: 720, time: 0.072, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.742 D_fake: 0.651 \n",
      "(epoch: 72, iters: 820, time: 0.074, data: 0.003) G_GAN: 0.752 G_L1: 1.824 D_real: 0.591 D_fake: 0.648 \n",
      "(epoch: 72, iters: 920, time: 0.073, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.728 D_fake: 0.662 \n",
      "(epoch: 72, iters: 1020, time: 0.075, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.740 D_fake: 0.650 \n",
      "(epoch: 72, iters: 1120, time: 0.071, data: 0.002) G_GAN: 0.750 G_L1: 1.957 D_real: 0.582 D_fake: 0.645 \n",
      "(epoch: 72, iters: 1220, time: 0.071, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.755 D_fake: 0.636 \n",
      "(epoch: 72, iters: 1320, time: 0.073, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.734 D_fake: 0.649 \n",
      "(epoch: 72, iters: 1420, time: 0.075, data: 0.002) G_GAN: 0.759 G_L1: 2.010 D_real: 0.583 D_fake: 0.646 \n",
      "(epoch: 72, iters: 1520, time: 0.071, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.755 D_fake: 0.640 \n",
      "(epoch: 72, iters: 1620, time: 0.071, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.745 D_fake: 0.645 \n",
      "(epoch: 72, iters: 1720, time: 0.073, data: 0.002) G_GAN: 0.754 G_L1: 3.150 D_real: 0.547 D_fake: 0.647 \n",
      "(epoch: 72, iters: 1820, time: 0.072, data: 0.002) G_GAN: 0.774 G_L1: 0.000 D_real: 0.776 D_fake: 0.623 \n",
      "(epoch: 72, iters: 1920, time: 0.072, data: 0.003) G_GAN: 0.739 G_L1: 0.000 D_real: 0.742 D_fake: 0.649 \n",
      "(epoch: 72, iters: 2020, time: 0.072, data: 0.002) G_GAN: 0.757 G_L1: 1.672 D_real: 0.598 D_fake: 0.638 \n",
      "(epoch: 72, iters: 2120, time: 0.072, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.765 D_fake: 0.621 \n",
      "(epoch: 72, iters: 2220, time: 0.072, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.716 D_fake: 0.676 \n",
      "End of epoch 72 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 73, iters: 40, time: 0.073, data: 0.002) G_GAN: 0.744 G_L1: 1.820 D_real: 0.580 D_fake: 0.642 \n",
      "(epoch: 73, iters: 140, time: 0.074, data: 0.004) G_GAN: 0.752 G_L1: 0.000 D_real: 0.752 D_fake: 0.640 \n",
      "(epoch: 73, iters: 240, time: 0.072, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.749 D_fake: 0.643 \n",
      "(epoch: 73, iters: 340, time: 0.072, data: 0.002) G_GAN: 0.746 G_L1: 1.290 D_real: 0.603 D_fake: 0.649 \n",
      "(epoch: 73, iters: 440, time: 0.071, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.748 D_fake: 0.644 \n",
      "(epoch: 73, iters: 540, time: 0.074, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.744 D_fake: 0.642 \n",
      "(epoch: 73, iters: 640, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 2.682 D_real: 0.558 D_fake: 0.648 \n",
      "(epoch: 73, iters: 740, time: 0.071, data: 0.003) G_GAN: 0.776 G_L1: 0.000 D_real: 0.788 D_fake: 0.612 \n",
      "(epoch: 73, iters: 840, time: 0.070, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.741 D_fake: 0.646 \n",
      "saving the latest model (epoch 73, total_steps 165000)\n",
      "(epoch: 73, iters: 940, time: 0.072, data: 0.002) G_GAN: 0.775 G_L1: 3.230 D_real: 0.551 D_fake: 0.642 \n",
      "(epoch: 73, iters: 1040, time: 0.071, data: 0.003) G_GAN: 0.762 G_L1: 0.000 D_real: 0.770 D_fake: 0.633 \n",
      "(epoch: 73, iters: 1140, time: 0.072, data: 0.003) G_GAN: 0.741 G_L1: 0.000 D_real: 0.751 D_fake: 0.643 \n",
      "(epoch: 73, iters: 1240, time: 0.070, data: 0.002) G_GAN: 0.767 G_L1: 2.399 D_real: 0.574 D_fake: 0.636 \n",
      "(epoch: 73, iters: 1340, time: 0.074, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.756 D_fake: 0.638 \n",
      "(epoch: 73, iters: 1440, time: 0.071, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.751 D_fake: 0.639 \n",
      "(epoch: 73, iters: 1540, time: 0.072, data: 0.002) G_GAN: 0.757 G_L1: 1.508 D_real: 0.594 D_fake: 0.639 \n",
      "(epoch: 73, iters: 1640, time: 0.072, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.764 D_fake: 0.630 \n",
      "(epoch: 73, iters: 1740, time: 0.073, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.752 D_fake: 0.637 \n",
      "(epoch: 73, iters: 1840, time: 0.072, data: 0.001) G_GAN: 0.755 G_L1: 0.842 D_real: 0.619 D_fake: 0.640 \n",
      "(epoch: 73, iters: 1940, time: 0.073, data: 0.003) G_GAN: 0.751 G_L1: 0.000 D_real: 0.761 D_fake: 0.638 \n",
      "(epoch: 73, iters: 2040, time: 0.072, data: 0.004) G_GAN: 0.746 G_L1: 0.000 D_real: 0.750 D_fake: 0.642 \n",
      "(epoch: 73, iters: 2140, time: 0.072, data: 0.002) G_GAN: 0.794 G_L1: 0.917 D_real: 0.662 D_fake: 0.597 \n",
      "(epoch: 73, iters: 2240, time: 0.074, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.750 D_fake: 0.645 \n",
      "End of epoch 73 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 74, iters: 60, time: 0.074, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.723 D_fake: 0.649 \n",
      "(epoch: 74, iters: 160, time: 0.072, data: 0.001) G_GAN: 0.791 G_L1: 2.187 D_real: 0.595 D_fake: 0.619 \n",
      "(epoch: 74, iters: 260, time: 0.072, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.780 D_fake: 0.625 \n",
      "(epoch: 74, iters: 360, time: 0.072, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.745 D_fake: 0.646 \n",
      "(epoch: 74, iters: 460, time: 0.072, data: 0.002) G_GAN: 0.756 G_L1: 2.055 D_real: 0.585 D_fake: 0.639 \n",
      "(epoch: 74, iters: 560, time: 0.072, data: 0.003) G_GAN: 0.760 G_L1: 0.000 D_real: 0.762 D_fake: 0.629 \n",
      "(epoch: 74, iters: 660, time: 0.071, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.738 D_fake: 0.653 \n",
      "(epoch: 74, iters: 760, time: 0.074, data: 0.003) G_GAN: 0.747 G_L1: 2.009 D_real: 0.575 D_fake: 0.648 \n",
      "(epoch: 74, iters: 860, time: 0.070, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.751 D_fake: 0.635 \n",
      "(epoch: 74, iters: 960, time: 0.072, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.758 D_fake: 0.645 \n",
      "(epoch: 74, iters: 1060, time: 0.071, data: 0.002) G_GAN: 0.748 G_L1: 0.699 D_real: 0.633 D_fake: 0.647 \n",
      "(epoch: 74, iters: 1160, time: 0.071, data: 0.002) G_GAN: 0.781 G_L1: 0.000 D_real: 0.798 D_fake: 0.608 \n",
      "(epoch: 74, iters: 1260, time: 0.072, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.736 D_fake: 0.624 \n",
      "(epoch: 74, iters: 1360, time: 0.072, data: 0.003) G_GAN: 0.745 G_L1: 2.029 D_real: 0.583 D_fake: 0.647 \n",
      "(epoch: 74, iters: 1460, time: 0.075, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.762 D_fake: 0.630 \n",
      "(epoch: 74, iters: 1560, time: 0.072, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.749 D_fake: 0.644 \n",
      "(epoch: 74, iters: 1660, time: 0.071, data: 0.002) G_GAN: 0.747 G_L1: 1.703 D_real: 0.588 D_fake: 0.648 \n",
      "(epoch: 74, iters: 1760, time: 0.071, data: 0.003) G_GAN: 0.756 G_L1: 0.000 D_real: 0.759 D_fake: 0.635 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 74, iters: 1860, time: 0.072, data: 0.003) G_GAN: 0.743 G_L1: 0.000 D_real: 0.755 D_fake: 0.641 \n",
      "(epoch: 74, iters: 1960, time: 0.071, data: 0.003) G_GAN: 0.752 G_L1: 2.015 D_real: 0.580 D_fake: 0.648 \n",
      "(epoch: 74, iters: 2060, time: 0.070, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.740 D_fake: 0.640 \n",
      "(epoch: 74, iters: 2160, time: 0.072, data: 0.003) G_GAN: 0.728 G_L1: 0.000 D_real: 0.732 D_fake: 0.658 \n",
      "(epoch: 74, iters: 2260, time: 0.073, data: 0.002) G_GAN: 0.812 G_L1: 2.749 D_real: 0.612 D_fake: 0.599 \n",
      "End of epoch 74 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 75, iters: 80, time: 0.073, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.775 D_fake: 0.628 \n",
      "(epoch: 75, iters: 180, time: 0.071, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.748 D_fake: 0.600 \n",
      "(epoch: 75, iters: 280, time: 0.071, data: 0.002) G_GAN: 0.737 G_L1: 1.026 D_real: 0.598 D_fake: 0.664 \n",
      "(epoch: 75, iters: 380, time: 0.073, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.756 D_fake: 0.642 \n",
      "(epoch: 75, iters: 480, time: 0.072, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.741 D_fake: 0.650 \n",
      "(epoch: 75, iters: 580, time: 0.072, data: 0.002) G_GAN: 0.753 G_L1: 3.541 D_real: 0.540 D_fake: 0.647 \n",
      "(epoch: 75, iters: 680, time: 0.073, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.753 D_fake: 0.631 \n",
      "(epoch: 75, iters: 780, time: 0.071, data: 0.003) G_GAN: 0.734 G_L1: 0.000 D_real: 0.740 D_fake: 0.648 \n",
      "(epoch: 75, iters: 880, time: 0.072, data: 0.003) G_GAN: 0.767 G_L1: 2.571 D_real: 0.318 D_fake: 1.926 \n",
      "(epoch: 75, iters: 980, time: 0.073, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.771 D_fake: 0.624 \n",
      "(epoch: 75, iters: 1080, time: 0.072, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.727 D_fake: 0.664 \n",
      "(epoch: 75, iters: 1180, time: 0.072, data: 0.002) G_GAN: 0.756 G_L1: 2.021 D_real: 0.594 D_fake: 0.639 \n",
      "(epoch: 75, iters: 1280, time: 0.073, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.777 D_fake: 0.629 \n",
      "saving the latest model (epoch 75, total_steps 170000)\n",
      "(epoch: 75, iters: 1380, time: 0.071, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.738 D_fake: 0.648 \n",
      "(epoch: 75, iters: 1480, time: 0.071, data: 0.002) G_GAN: 0.749 G_L1: 1.813 D_real: 0.582 D_fake: 0.647 \n",
      "(epoch: 75, iters: 1580, time: 0.071, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.766 D_fake: 0.631 \n",
      "(epoch: 75, iters: 1680, time: 0.073, data: 0.003) G_GAN: 0.746 G_L1: 0.000 D_real: 0.750 D_fake: 0.643 \n",
      "(epoch: 75, iters: 1780, time: 0.074, data: 0.002) G_GAN: 0.751 G_L1: 2.503 D_real: 0.567 D_fake: 0.641 \n",
      "(epoch: 75, iters: 1880, time: 0.072, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.752 D_fake: 0.641 \n",
      "(epoch: 75, iters: 1980, time: 0.073, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.754 D_fake: 0.641 \n",
      "(epoch: 75, iters: 2080, time: 0.074, data: 0.002) G_GAN: 0.739 G_L1: 2.297 D_real: 0.554 D_fake: 0.657 \n",
      "(epoch: 75, iters: 2180, time: 0.074, data: 0.002) G_GAN: 0.768 G_L1: 0.000 D_real: 0.768 D_fake: 0.636 \n",
      "(epoch: 75, iters: 2280, time: 0.074, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.736 D_fake: 0.649 \n",
      "saving the model at the end of epoch 75, iters 171000\n",
      "End of epoch 75 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 76, iters: 100, time: 0.074, data: 0.427) G_GAN: 0.748 G_L1: 2.485 D_real: 0.563 D_fake: 0.656 \n",
      "(epoch: 76, iters: 200, time: 0.072, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.753 D_fake: 0.637 \n",
      "(epoch: 76, iters: 300, time: 0.072, data: 0.003) G_GAN: 0.736 G_L1: 0.000 D_real: 0.740 D_fake: 0.651 \n",
      "(epoch: 76, iters: 400, time: 0.073, data: 0.002) G_GAN: 0.753 G_L1: 1.437 D_real: 0.600 D_fake: 0.648 \n",
      "(epoch: 76, iters: 500, time: 0.074, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.753 D_fake: 0.637 \n",
      "(epoch: 76, iters: 600, time: 0.072, data: 0.003) G_GAN: 0.755 G_L1: 0.000 D_real: 0.759 D_fake: 0.634 \n",
      "(epoch: 76, iters: 700, time: 0.073, data: 0.002) G_GAN: 0.766 G_L1: 1.919 D_real: 0.590 D_fake: 0.634 \n",
      "(epoch: 76, iters: 800, time: 0.071, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.757 D_fake: 0.636 \n",
      "(epoch: 76, iters: 900, time: 0.074, data: 0.002) G_GAN: 0.666 G_L1: 0.000 D_real: 0.678 D_fake: 0.711 \n",
      "(epoch: 76, iters: 1000, time: 0.072, data: 0.002) G_GAN: 0.754 G_L1: 1.678 D_real: 0.590 D_fake: 0.652 \n",
      "(epoch: 76, iters: 1100, time: 0.072, data: 0.002) G_GAN: 0.773 G_L1: 0.000 D_real: 0.805 D_fake: 0.632 \n",
      "(epoch: 76, iters: 1200, time: 0.071, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.759 D_fake: 0.630 \n",
      "(epoch: 76, iters: 1300, time: 0.072, data: 0.003) G_GAN: 0.737 G_L1: 1.744 D_real: 0.582 D_fake: 0.661 \n",
      "(epoch: 76, iters: 1400, time: 0.072, data: 0.002) G_GAN: 0.768 G_L1: 0.000 D_real: 0.771 D_fake: 0.626 \n",
      "(epoch: 76, iters: 1500, time: 0.073, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.741 D_fake: 0.649 \n",
      "(epoch: 76, iters: 1600, time: 0.074, data: 0.002) G_GAN: 0.747 G_L1: 2.124 D_real: 0.577 D_fake: 0.645 \n",
      "(epoch: 76, iters: 1700, time: 0.071, data: 0.002) G_GAN: 0.771 G_L1: 0.000 D_real: 0.776 D_fake: 0.625 \n",
      "(epoch: 76, iters: 1800, time: 0.072, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.749 D_fake: 0.643 \n",
      "(epoch: 76, iters: 1900, time: 0.074, data: 0.003) G_GAN: 0.758 G_L1: 3.702 D_real: 0.535 D_fake: 0.641 \n",
      "(epoch: 76, iters: 2000, time: 0.073, data: 0.003) G_GAN: 0.774 G_L1: 0.000 D_real: 0.776 D_fake: 0.613 \n",
      "(epoch: 76, iters: 2100, time: 0.075, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.736 D_fake: 0.637 \n",
      "(epoch: 76, iters: 2200, time: 0.072, data: 0.002) G_GAN: 0.830 G_L1: 1.583 D_real: 0.620 D_fake: 0.583 \n",
      "End of epoch 76 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 77, iters: 20, time: 0.074, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.770 D_fake: 0.627 \n",
      "(epoch: 77, iters: 120, time: 0.072, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.745 D_fake: 0.641 \n",
      "(epoch: 77, iters: 220, time: 0.073, data: 0.002) G_GAN: 0.759 G_L1: 2.749 D_real: 0.556 D_fake: 0.645 \n",
      "(epoch: 77, iters: 320, time: 0.073, data: 0.003) G_GAN: 0.755 G_L1: 0.000 D_real: 0.756 D_fake: 0.640 \n",
      "(epoch: 77, iters: 420, time: 0.073, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.743 D_fake: 0.649 \n",
      "(epoch: 77, iters: 520, time: 0.072, data: 0.002) G_GAN: 0.742 G_L1: 1.419 D_real: 0.586 D_fake: 0.654 \n",
      "(epoch: 77, iters: 620, time: 0.074, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.762 D_fake: 0.630 \n",
      "(epoch: 77, iters: 720, time: 0.073, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.743 D_fake: 0.652 \n",
      "(epoch: 77, iters: 820, time: 0.072, data: 0.002) G_GAN: 0.765 G_L1: 1.824 D_real: 0.597 D_fake: 0.638 \n",
      "(epoch: 77, iters: 920, time: 0.075, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.757 D_fake: 0.630 \n",
      "(epoch: 77, iters: 1020, time: 0.072, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.754 D_fake: 0.640 \n",
      "(epoch: 77, iters: 1120, time: 0.072, data: 0.002) G_GAN: 0.763 G_L1: 1.957 D_real: 0.583 D_fake: 0.634 \n",
      "(epoch: 77, iters: 1220, time: 0.071, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.755 D_fake: 0.633 \n",
      "(epoch: 77, iters: 1320, time: 0.071, data: 0.003) G_GAN: 0.732 G_L1: 0.000 D_real: 0.735 D_fake: 0.657 \n",
      "(epoch: 77, iters: 1420, time: 0.073, data: 0.002) G_GAN: 0.764 G_L1: 2.010 D_real: 0.586 D_fake: 0.639 \n",
      "(epoch: 77, iters: 1520, time: 0.074, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.751 D_fake: 0.646 \n",
      "(epoch: 77, iters: 1620, time: 0.074, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.759 D_fake: 0.640 \n",
      "(epoch: 77, iters: 1720, time: 0.073, data: 0.002) G_GAN: 0.761 G_L1: 3.150 D_real: 0.553 D_fake: 0.642 \n",
      "saving the latest model (epoch 77, total_steps 175000)\n",
      "(epoch: 77, iters: 1820, time: 0.072, data: 0.002) G_GAN: 0.770 G_L1: 0.000 D_real: 0.773 D_fake: 0.625 \n",
      "(epoch: 77, iters: 1920, time: 0.072, data: 0.003) G_GAN: 0.742 G_L1: 0.000 D_real: 0.746 D_fake: 0.645 \n",
      "(epoch: 77, iters: 2020, time: 0.073, data: 0.002) G_GAN: 0.760 G_L1: 1.672 D_real: 0.598 D_fake: 0.636 \n",
      "(epoch: 77, iters: 2120, time: 0.071, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.782 D_fake: 0.613 \n",
      "(epoch: 77, iters: 2220, time: 0.072, data: 0.002) G_GAN: 0.817 G_L1: 0.000 D_real: 0.806 D_fake: 0.502 \n",
      "End of epoch 77 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 78, iters: 40, time: 0.072, data: 0.002) G_GAN: 0.760 G_L1: 1.820 D_real: 0.589 D_fake: 0.650 \n",
      "(epoch: 78, iters: 140, time: 0.074, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.754 D_fake: 0.637 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 78, iters: 240, time: 0.072, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.740 D_fake: 0.647 \n",
      "(epoch: 78, iters: 340, time: 0.072, data: 0.002) G_GAN: 0.770 G_L1: 1.290 D_real: 0.617 D_fake: 0.624 \n",
      "(epoch: 78, iters: 440, time: 0.071, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.744 D_fake: 0.645 \n",
      "(epoch: 78, iters: 540, time: 0.074, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.731 D_fake: 0.651 \n",
      "(epoch: 78, iters: 640, time: 0.072, data: 0.002) G_GAN: 0.758 G_L1: 2.682 D_real: 0.560 D_fake: 0.644 \n",
      "(epoch: 78, iters: 740, time: 0.071, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.768 D_fake: 0.638 \n",
      "(epoch: 78, iters: 840, time: 0.071, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.741 D_fake: 0.648 \n",
      "(epoch: 78, iters: 940, time: 0.073, data: 0.002) G_GAN: 0.785 G_L1: 3.230 D_real: 0.570 D_fake: 0.628 \n",
      "(epoch: 78, iters: 1040, time: 0.076, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.754 D_fake: 0.640 \n",
      "(epoch: 78, iters: 1140, time: 0.071, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.758 D_fake: 0.637 \n",
      "(epoch: 78, iters: 1240, time: 0.074, data: 0.002) G_GAN: 0.757 G_L1: 2.399 D_real: 0.565 D_fake: 0.643 \n",
      "(epoch: 78, iters: 1340, time: 0.071, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.755 D_fake: 0.640 \n",
      "(epoch: 78, iters: 1440, time: 0.074, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.750 D_fake: 0.641 \n",
      "(epoch: 78, iters: 1540, time: 0.072, data: 0.003) G_GAN: 0.771 G_L1: 1.508 D_real: 0.602 D_fake: 0.633 \n",
      "(epoch: 78, iters: 1640, time: 0.072, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.756 D_fake: 0.637 \n",
      "(epoch: 78, iters: 1740, time: 0.072, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.746 D_fake: 0.645 \n",
      "(epoch: 78, iters: 1840, time: 0.073, data: 0.002) G_GAN: 0.759 G_L1: 0.842 D_real: 0.624 D_fake: 0.636 \n",
      "(epoch: 78, iters: 1940, time: 0.072, data: 0.002) G_GAN: 0.762 G_L1: 0.000 D_real: 0.771 D_fake: 0.631 \n",
      "(epoch: 78, iters: 2040, time: 0.072, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.751 D_fake: 0.637 \n",
      "(epoch: 78, iters: 2140, time: 0.072, data: 0.002) G_GAN: 0.817 G_L1: 0.917 D_real: 0.696 D_fake: 0.603 \n",
      "(epoch: 78, iters: 2240, time: 0.072, data: 0.002) G_GAN: 0.778 G_L1: 0.000 D_real: 0.774 D_fake: 0.591 \n",
      "End of epoch 78 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 79, iters: 60, time: 0.074, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.721 D_fake: 0.650 \n",
      "(epoch: 79, iters: 160, time: 0.074, data: 0.001) G_GAN: 0.765 G_L1: 2.187 D_real: 0.576 D_fake: 0.635 \n",
      "(epoch: 79, iters: 260, time: 0.071, data: 0.002) G_GAN: 0.780 G_L1: 0.000 D_real: 0.787 D_fake: 0.617 \n",
      "(epoch: 79, iters: 360, time: 0.071, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.748 D_fake: 0.648 \n",
      "(epoch: 79, iters: 460, time: 0.073, data: 0.002) G_GAN: 0.770 G_L1: 2.055 D_real: 0.590 D_fake: 0.635 \n",
      "(epoch: 79, iters: 560, time: 0.072, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.751 D_fake: 0.643 \n",
      "(epoch: 79, iters: 660, time: 0.072, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.756 D_fake: 0.634 \n",
      "(epoch: 79, iters: 760, time: 0.075, data: 0.002) G_GAN: 0.750 G_L1: 2.009 D_real: 0.576 D_fake: 0.652 \n",
      "(epoch: 79, iters: 860, time: 0.070, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.745 D_fake: 0.643 \n",
      "(epoch: 79, iters: 960, time: 0.073, data: 0.002) G_GAN: 0.769 G_L1: 0.000 D_real: 0.757 D_fake: 0.606 \n",
      "(epoch: 79, iters: 1060, time: 0.074, data: 0.002) G_GAN: 0.737 G_L1: 0.699 D_real: 0.620 D_fake: 0.654 \n",
      "(epoch: 79, iters: 1160, time: 0.072, data: 0.002) G_GAN: 0.770 G_L1: 0.000 D_real: 0.786 D_fake: 0.620 \n",
      "(epoch: 79, iters: 1260, time: 0.071, data: 0.003) G_GAN: 0.732 G_L1: 0.000 D_real: 0.740 D_fake: 0.632 \n",
      "(epoch: 79, iters: 1360, time: 0.071, data: 0.002) G_GAN: 0.742 G_L1: 2.029 D_real: 0.575 D_fake: 0.643 \n",
      "(epoch: 79, iters: 1460, time: 0.072, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.757 D_fake: 0.627 \n",
      "(epoch: 79, iters: 1560, time: 0.071, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.746 D_fake: 0.642 \n",
      "(epoch: 79, iters: 1660, time: 0.072, data: 0.002) G_GAN: 0.765 G_L1: 1.703 D_real: 0.588 D_fake: 0.636 \n",
      "(epoch: 79, iters: 1760, time: 0.073, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.772 D_fake: 0.625 \n",
      "(epoch: 79, iters: 1860, time: 0.075, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.746 D_fake: 0.636 \n",
      "(epoch: 79, iters: 1960, time: 0.071, data: 0.002) G_GAN: 0.768 G_L1: 2.015 D_real: 0.585 D_fake: 0.638 \n",
      "(epoch: 79, iters: 2060, time: 0.072, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.744 D_fake: 0.637 \n",
      "(epoch: 79, iters: 2160, time: 0.072, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.721 D_fake: 0.668 \n",
      "saving the latest model (epoch 79, total_steps 180000)\n",
      "(epoch: 79, iters: 2260, time: 0.071, data: 0.002) G_GAN: 0.821 G_L1: 2.749 D_real: 0.579 D_fake: 0.595 \n",
      "End of epoch 79 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 80, iters: 80, time: 0.072, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.758 D_fake: 0.645 \n",
      "(epoch: 80, iters: 180, time: 0.071, data: 0.003) G_GAN: 0.743 G_L1: 0.000 D_real: 0.747 D_fake: 0.645 \n",
      "(epoch: 80, iters: 280, time: 0.074, data: 0.003) G_GAN: 0.769 G_L1: 1.026 D_real: 0.620 D_fake: 0.636 \n",
      "(epoch: 80, iters: 380, time: 0.071, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.761 D_fake: 0.645 \n",
      "(epoch: 80, iters: 480, time: 0.075, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.742 D_fake: 0.650 \n",
      "(epoch: 80, iters: 580, time: 0.072, data: 0.002) G_GAN: 0.757 G_L1: 3.541 D_real: 0.536 D_fake: 0.658 \n",
      "(epoch: 80, iters: 680, time: 0.075, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.754 D_fake: 0.636 \n",
      "(epoch: 80, iters: 780, time: 0.072, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.735 D_fake: 0.659 \n",
      "(epoch: 80, iters: 880, time: 0.070, data: 0.002) G_GAN: 0.752 G_L1: 2.571 D_real: 0.549 D_fake: 0.656 \n",
      "(epoch: 80, iters: 980, time: 0.072, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.721 D_fake: 0.666 \n",
      "(epoch: 80, iters: 1080, time: 0.071, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.734 D_fake: 0.650 \n",
      "(epoch: 80, iters: 1180, time: 0.073, data: 0.002) G_GAN: 0.764 G_L1: 2.021 D_real: 0.590 D_fake: 0.637 \n",
      "(epoch: 80, iters: 1280, time: 0.073, data: 0.003) G_GAN: 0.772 G_L1: 0.000 D_real: 0.773 D_fake: 0.590 \n",
      "(epoch: 80, iters: 1380, time: 0.071, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.744 D_fake: 0.645 \n",
      "(epoch: 80, iters: 1480, time: 0.072, data: 0.002) G_GAN: 0.762 G_L1: 1.813 D_real: 0.586 D_fake: 0.644 \n",
      "(epoch: 80, iters: 1580, time: 0.074, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.760 D_fake: 0.634 \n",
      "(epoch: 80, iters: 1680, time: 0.076, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.762 D_fake: 0.635 \n",
      "(epoch: 80, iters: 1780, time: 0.071, data: 0.002) G_GAN: 0.761 G_L1: 2.503 D_real: 0.569 D_fake: 0.640 \n",
      "(epoch: 80, iters: 1880, time: 0.072, data: 0.002) G_GAN: 0.762 G_L1: 0.000 D_real: 0.766 D_fake: 0.631 \n",
      "(epoch: 80, iters: 1980, time: 0.073, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.754 D_fake: 0.645 \n",
      "(epoch: 80, iters: 2080, time: 0.074, data: 0.002) G_GAN: 0.772 G_L1: 2.297 D_real: 0.550 D_fake: 0.633 \n",
      "(epoch: 80, iters: 2180, time: 0.072, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.736 D_fake: 0.660 \n",
      "(epoch: 80, iters: 2280, time: 0.071, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.713 D_fake: 0.673 \n",
      "saving the model at the end of epoch 80, iters 182400\n",
      "End of epoch 80 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 81, iters: 100, time: 0.076, data: 0.426) G_GAN: 0.759 G_L1: 2.485 D_real: 0.567 D_fake: 0.642 \n",
      "(epoch: 81, iters: 200, time: 0.071, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.754 D_fake: 0.633 \n",
      "(epoch: 81, iters: 300, time: 0.075, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.740 D_fake: 0.652 \n",
      "(epoch: 81, iters: 400, time: 0.071, data: 0.003) G_GAN: 0.759 G_L1: 1.437 D_real: 0.598 D_fake: 0.646 \n",
      "(epoch: 81, iters: 500, time: 0.074, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.752 D_fake: 0.626 \n",
      "(epoch: 81, iters: 600, time: 0.073, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.755 D_fake: 0.638 \n",
      "(epoch: 81, iters: 700, time: 0.073, data: 0.002) G_GAN: 0.782 G_L1: 1.919 D_real: 0.592 D_fake: 0.638 \n",
      "(epoch: 81, iters: 800, time: 0.072, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.751 D_fake: 0.639 \n",
      "(epoch: 81, iters: 900, time: 0.070, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.727 D_fake: 0.593 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 81, iters: 1000, time: 0.073, data: 0.002) G_GAN: 0.762 G_L1: 1.678 D_real: 0.589 D_fake: 0.642 \n",
      "(epoch: 81, iters: 1100, time: 0.074, data: 0.002) G_GAN: 0.766 G_L1: 0.000 D_real: 0.777 D_fake: 0.627 \n",
      "(epoch: 81, iters: 1200, time: 0.072, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.747 D_fake: 0.640 \n",
      "(epoch: 81, iters: 1300, time: 0.075, data: 0.001) G_GAN: 0.785 G_L1: 1.744 D_real: 0.604 D_fake: 0.625 \n",
      "(epoch: 81, iters: 1400, time: 0.072, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.768 D_fake: 0.627 \n",
      "(epoch: 81, iters: 1500, time: 0.075, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.741 D_fake: 0.645 \n",
      "(epoch: 81, iters: 1600, time: 0.074, data: 0.002) G_GAN: 0.750 G_L1: 2.124 D_real: 0.578 D_fake: 0.646 \n",
      "(epoch: 81, iters: 1700, time: 0.074, data: 0.002) G_GAN: 0.776 G_L1: 0.000 D_real: 0.783 D_fake: 0.629 \n",
      "(epoch: 81, iters: 1800, time: 0.074, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.745 D_fake: 0.650 \n",
      "(epoch: 81, iters: 1900, time: 0.074, data: 0.002) G_GAN: 0.757 G_L1: 3.702 D_real: 0.532 D_fake: 0.656 \n",
      "(epoch: 81, iters: 2000, time: 0.074, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.757 D_fake: 0.636 \n",
      "(epoch: 81, iters: 2100, time: 0.075, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.736 D_fake: 0.636 \n",
      "(epoch: 81, iters: 2200, time: 0.071, data: 0.002) G_GAN: 0.853 G_L1: 1.583 D_real: 0.671 D_fake: 0.557 \n",
      "End of epoch 81 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 82, iters: 20, time: 0.074, data: 0.003) G_GAN: 0.750 G_L1: 0.000 D_real: 0.751 D_fake: 0.640 \n",
      "(epoch: 82, iters: 120, time: 0.074, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.735 D_fake: 0.657 \n",
      "(epoch: 82, iters: 220, time: 0.077, data: 0.002) G_GAN: 0.760 G_L1: 2.749 D_real: 0.557 D_fake: 0.645 \n",
      "(epoch: 82, iters: 320, time: 0.071, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.756 D_fake: 0.637 \n",
      "saving the latest model (epoch 82, total_steps 185000)\n",
      "(epoch: 82, iters: 420, time: 0.072, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.750 D_fake: 0.648 \n",
      "(epoch: 82, iters: 520, time: 0.071, data: 0.003) G_GAN: 0.799 G_L1: 1.419 D_real: 0.672 D_fake: 0.605 \n",
      "(epoch: 82, iters: 620, time: 0.074, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.755 D_fake: 0.647 \n",
      "(epoch: 82, iters: 720, time: 0.076, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.733 D_fake: 0.611 \n",
      "(epoch: 82, iters: 820, time: 0.071, data: 0.002) G_GAN: 0.758 G_L1: 1.824 D_real: 0.586 D_fake: 0.650 \n",
      "(epoch: 82, iters: 920, time: 0.075, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.759 D_fake: 0.613 \n",
      "(epoch: 82, iters: 1020, time: 0.073, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.746 D_fake: 0.647 \n",
      "(epoch: 82, iters: 1120, time: 0.073, data: 0.002) G_GAN: 0.727 G_L1: 1.957 D_real: 0.552 D_fake: 0.675 \n",
      "(epoch: 82, iters: 1220, time: 0.073, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.756 D_fake: 0.639 \n",
      "(epoch: 82, iters: 1320, time: 0.073, data: 0.003) G_GAN: 0.737 G_L1: 0.000 D_real: 0.739 D_fake: 0.654 \n",
      "(epoch: 82, iters: 1420, time: 0.078, data: 0.003) G_GAN: 0.772 G_L1: 2.010 D_real: 0.587 D_fake: 0.637 \n",
      "(epoch: 82, iters: 1520, time: 0.071, data: 0.003) G_GAN: 0.758 G_L1: 0.000 D_real: 0.761 D_fake: 0.638 \n",
      "(epoch: 82, iters: 1620, time: 0.071, data: 0.003) G_GAN: 0.742 G_L1: 0.000 D_real: 0.747 D_fake: 0.643 \n",
      "(epoch: 82, iters: 1720, time: 0.074, data: 0.002) G_GAN: 0.765 G_L1: 3.150 D_real: 0.549 D_fake: 0.637 \n",
      "(epoch: 82, iters: 1820, time: 0.072, data: 0.002) G_GAN: 0.775 G_L1: 0.000 D_real: 0.784 D_fake: 0.619 \n",
      "(epoch: 82, iters: 1920, time: 0.076, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.736 D_fake: 0.603 \n",
      "(epoch: 82, iters: 2020, time: 0.074, data: 0.002) G_GAN: 0.751 G_L1: 1.672 D_real: 0.589 D_fake: 0.649 \n",
      "(epoch: 82, iters: 2120, time: 0.075, data: 0.002) G_GAN: 0.768 G_L1: 0.000 D_real: 0.793 D_fake: 0.599 \n",
      "(epoch: 82, iters: 2220, time: 0.071, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.731 D_fake: 0.650 \n",
      "End of epoch 82 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 83, iters: 40, time: 0.082, data: 0.001) G_GAN: 0.748 G_L1: 1.820 D_real: 0.584 D_fake: 0.633 \n",
      "(epoch: 83, iters: 140, time: 0.078, data: 0.001) G_GAN: 0.756 G_L1: 0.000 D_real: 0.766 D_fake: 0.627 \n",
      "(epoch: 83, iters: 240, time: 0.073, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.752 D_fake: 0.656 \n",
      "(epoch: 83, iters: 340, time: 0.071, data: 0.002) G_GAN: 0.756 G_L1: 1.290 D_real: 0.598 D_fake: 0.641 \n",
      "(epoch: 83, iters: 440, time: 0.072, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.753 D_fake: 0.639 \n",
      "(epoch: 83, iters: 540, time: 0.071, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.737 D_fake: 0.644 \n",
      "(epoch: 83, iters: 640, time: 0.074, data: 0.003) G_GAN: 0.777 G_L1: 2.682 D_real: 0.562 D_fake: 0.627 \n",
      "(epoch: 83, iters: 740, time: 0.073, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.777 D_fake: 0.636 \n",
      "(epoch: 83, iters: 840, time: 0.075, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.752 D_fake: 0.632 \n",
      "(epoch: 83, iters: 940, time: 0.075, data: 0.003) G_GAN: 0.835 G_L1: 3.230 D_real: 0.574 D_fake: 0.602 \n",
      "(epoch: 83, iters: 1040, time: 0.072, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.739 D_fake: 0.654 \n",
      "(epoch: 83, iters: 1140, time: 0.072, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.724 D_fake: 0.659 \n",
      "(epoch: 83, iters: 1240, time: 0.072, data: 0.002) G_GAN: 0.830 G_L1: 2.399 D_real: 0.617 D_fake: 0.589 \n",
      "(epoch: 83, iters: 1340, time: 0.072, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.734 D_fake: 0.660 \n",
      "(epoch: 83, iters: 1440, time: 0.073, data: 0.003) G_GAN: 0.746 G_L1: 0.000 D_real: 0.749 D_fake: 0.644 \n",
      "(epoch: 83, iters: 1540, time: 0.073, data: 0.002) G_GAN: 0.764 G_L1: 1.508 D_real: 0.588 D_fake: 0.638 \n",
      "(epoch: 83, iters: 1640, time: 0.078, data: 0.003) G_GAN: 0.752 G_L1: 0.000 D_real: 0.754 D_fake: 0.636 \n",
      "(epoch: 83, iters: 1740, time: 0.076, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.755 D_fake: 0.640 \n",
      "(epoch: 83, iters: 1840, time: 0.077, data: 0.002) G_GAN: 0.768 G_L1: 0.842 D_real: 0.627 D_fake: 0.633 \n",
      "(epoch: 83, iters: 1940, time: 0.074, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.783 D_fake: 0.639 \n",
      "(epoch: 83, iters: 2040, time: 0.072, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.741 D_fake: 0.645 \n",
      "(epoch: 83, iters: 2140, time: 0.072, data: 0.002) G_GAN: 0.796 G_L1: 0.917 D_real: 0.646 D_fake: 0.643 \n",
      "(epoch: 83, iters: 2240, time: 0.075, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.744 D_fake: 0.642 \n",
      "End of epoch 83 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 84, iters: 60, time: 0.077, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.745 D_fake: 0.643 \n",
      "(epoch: 84, iters: 160, time: 0.071, data: 0.001) G_GAN: 0.786 G_L1: 2.187 D_real: 0.581 D_fake: 0.614 \n",
      "(epoch: 84, iters: 260, time: 0.074, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.645 \n",
      "(epoch: 84, iters: 360, time: 0.072, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.743 D_fake: 0.649 \n",
      "(epoch: 84, iters: 460, time: 0.072, data: 0.002) G_GAN: 0.770 G_L1: 2.055 D_real: 0.591 D_fake: 0.639 \n",
      "(epoch: 84, iters: 560, time: 0.073, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.646 \n",
      "(epoch: 84, iters: 660, time: 0.076, data: 0.003) G_GAN: 0.746 G_L1: 0.000 D_real: 0.754 D_fake: 0.646 \n",
      "(epoch: 84, iters: 760, time: 0.072, data: 0.002) G_GAN: 0.757 G_L1: 2.009 D_real: 0.573 D_fake: 0.640 \n",
      "saving the latest model (epoch 84, total_steps 190000)\n",
      "(epoch: 84, iters: 860, time: 0.071, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.738 D_fake: 0.642 \n",
      "(epoch: 84, iters: 960, time: 0.076, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.756 D_fake: 0.626 \n",
      "(epoch: 84, iters: 1060, time: 0.073, data: 0.003) G_GAN: 0.753 G_L1: 0.699 D_real: 0.629 D_fake: 0.647 \n",
      "(epoch: 84, iters: 1160, time: 0.070, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.754 D_fake: 0.639 \n",
      "(epoch: 84, iters: 1260, time: 0.073, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.738 D_fake: 0.646 \n",
      "(epoch: 84, iters: 1360, time: 0.072, data: 0.002) G_GAN: 0.753 G_L1: 2.029 D_real: 0.574 D_fake: 0.653 \n",
      "(epoch: 84, iters: 1460, time: 0.071, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.829 D_fake: 0.597 \n",
      "(epoch: 84, iters: 1560, time: 0.072, data: 0.003) G_GAN: 0.730 G_L1: 0.000 D_real: 0.735 D_fake: 0.650 \n",
      "(epoch: 84, iters: 1660, time: 0.071, data: 0.002) G_GAN: 0.769 G_L1: 1.703 D_real: 0.585 D_fake: 0.634 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 84, iters: 1760, time: 0.072, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.752 D_fake: 0.641 \n",
      "(epoch: 84, iters: 1860, time: 0.074, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.735 D_fake: 0.635 \n",
      "(epoch: 84, iters: 1960, time: 0.075, data: 0.002) G_GAN: 0.779 G_L1: 2.015 D_real: 0.590 D_fake: 0.644 \n",
      "(epoch: 84, iters: 2060, time: 0.074, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.754 D_fake: 0.635 \n",
      "(epoch: 84, iters: 2160, time: 0.079, data: 0.003) G_GAN: 0.725 G_L1: 0.000 D_real: 0.732 D_fake: 0.660 \n",
      "(epoch: 84, iters: 2260, time: 0.078, data: 0.003) G_GAN: 0.835 G_L1: 2.749 D_real: 0.644 D_fake: 0.589 \n",
      "End of epoch 84 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 85, iters: 80, time: 0.073, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.750 D_fake: 0.639 \n",
      "(epoch: 85, iters: 180, time: 0.076, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.737 D_fake: 0.645 \n",
      "(epoch: 85, iters: 280, time: 0.074, data: 0.002) G_GAN: 0.751 G_L1: 1.026 D_real: 0.607 D_fake: 0.645 \n",
      "(epoch: 85, iters: 380, time: 0.072, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.758 D_fake: 0.632 \n",
      "(epoch: 85, iters: 480, time: 0.072, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.745 D_fake: 0.629 \n",
      "(epoch: 85, iters: 580, time: 0.074, data: 0.001) G_GAN: 0.769 G_L1: 3.541 D_real: 0.540 D_fake: 0.638 \n",
      "(epoch: 85, iters: 680, time: 0.072, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.766 D_fake: 0.630 \n",
      "(epoch: 85, iters: 780, time: 0.072, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.739 D_fake: 0.653 \n",
      "(epoch: 85, iters: 880, time: 0.073, data: 0.002) G_GAN: 0.751 G_L1: 2.571 D_real: 0.547 D_fake: 0.641 \n",
      "(epoch: 85, iters: 980, time: 0.075, data: 0.004) G_GAN: 0.752 G_L1: 0.000 D_real: 0.760 D_fake: 0.632 \n",
      "(epoch: 85, iters: 1080, time: 0.071, data: 0.003) G_GAN: 0.718 G_L1: 0.000 D_real: 0.723 D_fake: 0.657 \n",
      "(epoch: 85, iters: 1180, time: 0.072, data: 0.002) G_GAN: 0.776 G_L1: 2.021 D_real: 0.588 D_fake: 0.634 \n",
      "(epoch: 85, iters: 1280, time: 0.074, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.753 D_fake: 0.642 \n",
      "(epoch: 85, iters: 1380, time: 0.073, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.740 D_fake: 0.648 \n",
      "(epoch: 85, iters: 1480, time: 0.075, data: 0.002) G_GAN: 0.774 G_L1: 1.813 D_real: 0.587 D_fake: 0.639 \n",
      "(epoch: 85, iters: 1580, time: 0.073, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.758 D_fake: 0.639 \n",
      "(epoch: 85, iters: 1680, time: 0.071, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.775 D_fake: 0.629 \n",
      "(epoch: 85, iters: 1780, time: 0.071, data: 0.003) G_GAN: 0.762 G_L1: 2.503 D_real: 0.560 D_fake: 0.647 \n",
      "(epoch: 85, iters: 1880, time: 0.074, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.771 D_fake: 0.633 \n",
      "(epoch: 85, iters: 1980, time: 0.074, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.749 D_fake: 0.634 \n",
      "(epoch: 85, iters: 2080, time: 0.074, data: 0.002) G_GAN: 0.767 G_L1: 2.297 D_real: 0.562 D_fake: 0.639 \n",
      "(epoch: 85, iters: 2180, time: 0.072, data: 0.002) G_GAN: 0.768 G_L1: 0.000 D_real: 0.760 D_fake: 0.616 \n",
      "(epoch: 85, iters: 2280, time: 0.073, data: 0.003) G_GAN: 0.704 G_L1: 0.000 D_real: 0.725 D_fake: 0.668 \n",
      "saving the model at the end of epoch 85, iters 193800\n",
      "End of epoch 85 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 86, iters: 100, time: 0.073, data: 0.427) G_GAN: 0.760 G_L1: 2.485 D_real: 0.559 D_fake: 0.649 \n",
      "(epoch: 86, iters: 200, time: 0.077, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.764 D_fake: 0.617 \n",
      "(epoch: 86, iters: 300, time: 0.074, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.735 D_fake: 0.658 \n",
      "(epoch: 86, iters: 400, time: 0.074, data: 0.002) G_GAN: 0.767 G_L1: 1.437 D_real: 0.597 D_fake: 0.646 \n",
      "(epoch: 86, iters: 500, time: 0.073, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.747 D_fake: 0.640 \n",
      "(epoch: 86, iters: 600, time: 0.072, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.755 D_fake: 0.642 \n",
      "(epoch: 86, iters: 700, time: 0.080, data: 0.002) G_GAN: 0.788 G_L1: 1.919 D_real: 0.585 D_fake: 0.623 \n",
      "(epoch: 86, iters: 800, time: 0.077, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.748 D_fake: 0.655 \n",
      "(epoch: 86, iters: 900, time: 0.075, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.744 D_fake: 0.593 \n",
      "(epoch: 86, iters: 1000, time: 0.073, data: 0.002) G_GAN: 0.765 G_L1: 1.678 D_real: 0.594 D_fake: 0.654 \n",
      "(epoch: 86, iters: 1100, time: 0.076, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.777 D_fake: 0.623 \n",
      "(epoch: 86, iters: 1200, time: 0.072, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.744 D_fake: 0.641 \n",
      "saving the latest model (epoch 86, total_steps 195000)\n",
      "(epoch: 86, iters: 1300, time: 0.072, data: 0.002) G_GAN: 0.717 G_L1: 1.744 D_real: 0.557 D_fake: 0.692 \n",
      "(epoch: 86, iters: 1400, time: 0.075, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.750 D_fake: 0.643 \n",
      "(epoch: 86, iters: 1500, time: 0.072, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.734 D_fake: 0.643 \n",
      "(epoch: 86, iters: 1600, time: 0.076, data: 0.002) G_GAN: 0.762 G_L1: 2.124 D_real: 0.572 D_fake: 0.646 \n",
      "(epoch: 86, iters: 1700, time: 0.072, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.773 D_fake: 0.639 \n",
      "(epoch: 86, iters: 1800, time: 0.073, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.747 D_fake: 0.653 \n",
      "(epoch: 86, iters: 1900, time: 0.075, data: 0.003) G_GAN: 0.777 G_L1: 3.702 D_real: 0.531 D_fake: 0.630 \n",
      "(epoch: 86, iters: 2000, time: 0.074, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.759 D_fake: 0.638 \n",
      "(epoch: 86, iters: 2100, time: 0.075, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.740 D_fake: 0.639 \n",
      "(epoch: 86, iters: 2200, time: 0.081, data: 0.003) G_GAN: 0.794 G_L1: 1.583 D_real: 0.585 D_fake: 0.626 \n",
      "End of epoch 86 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 87, iters: 20, time: 0.073, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.762 D_fake: 0.640 \n",
      "(epoch: 87, iters: 120, time: 0.072, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.738 D_fake: 0.660 \n",
      "(epoch: 87, iters: 220, time: 0.076, data: 0.002) G_GAN: 0.753 G_L1: 2.749 D_real: 0.555 D_fake: 0.650 \n",
      "(epoch: 87, iters: 320, time: 0.073, data: 0.003) G_GAN: 0.748 G_L1: 0.000 D_real: 0.749 D_fake: 0.627 \n",
      "(epoch: 87, iters: 420, time: 0.072, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.738 D_fake: 0.648 \n",
      "(epoch: 87, iters: 520, time: 0.078, data: 0.002) G_GAN: 0.772 G_L1: 1.419 D_real: 0.598 D_fake: 0.640 \n",
      "(epoch: 87, iters: 620, time: 0.071, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.769 D_fake: 0.641 \n",
      "(epoch: 87, iters: 720, time: 0.072, data: 0.003) G_GAN: 0.739 G_L1: 0.000 D_real: 0.744 D_fake: 0.636 \n",
      "(epoch: 87, iters: 820, time: 0.072, data: 0.002) G_GAN: 0.762 G_L1: 1.824 D_real: 0.576 D_fake: 0.647 \n",
      "(epoch: 87, iters: 920, time: 0.075, data: 0.002) G_GAN: 0.682 G_L1: 0.000 D_real: 0.691 D_fake: 0.670 \n",
      "(epoch: 87, iters: 1020, time: 0.072, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.735 D_fake: 0.659 \n",
      "(epoch: 87, iters: 1120, time: 0.076, data: 0.002) G_GAN: 0.748 G_L1: 1.957 D_real: 0.552 D_fake: 0.651 \n",
      "(epoch: 87, iters: 1220, time: 0.076, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.745 D_fake: 0.645 \n",
      "(epoch: 87, iters: 1320, time: 0.072, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.736 D_fake: 0.655 \n",
      "(epoch: 87, iters: 1420, time: 0.075, data: 0.002) G_GAN: 0.775 G_L1: 2.010 D_real: 0.591 D_fake: 0.628 \n",
      "(epoch: 87, iters: 1520, time: 0.074, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.750 D_fake: 0.634 \n",
      "(epoch: 87, iters: 1620, time: 0.078, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.743 D_fake: 0.641 \n",
      "(epoch: 87, iters: 1720, time: 0.072, data: 0.002) G_GAN: 0.789 G_L1: 3.150 D_real: 0.539 D_fake: 0.618 \n",
      "(epoch: 87, iters: 1820, time: 0.075, data: 0.002) G_GAN: 0.780 G_L1: 0.000 D_real: 0.793 D_fake: 0.612 \n",
      "(epoch: 87, iters: 1920, time: 0.074, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.735 D_fake: 0.632 \n",
      "(epoch: 87, iters: 2020, time: 0.072, data: 0.002) G_GAN: 0.765 G_L1: 1.672 D_real: 0.592 D_fake: 0.644 \n",
      "(epoch: 87, iters: 2120, time: 0.074, data: 0.003) G_GAN: 0.774 G_L1: 0.000 D_real: 0.780 D_fake: 0.631 \n",
      "(epoch: 87, iters: 2220, time: 0.072, data: 0.003) G_GAN: 0.727 G_L1: 0.000 D_real: 0.739 D_fake: 0.647 \n",
      "End of epoch 87 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 88, iters: 40, time: 0.073, data: 0.002) G_GAN: 0.767 G_L1: 1.820 D_real: 0.576 D_fake: 0.647 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 88, iters: 140, time: 0.072, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.743 D_fake: 0.634 \n",
      "(epoch: 88, iters: 240, time: 0.071, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.755 D_fake: 0.638 \n",
      "(epoch: 88, iters: 340, time: 0.076, data: 0.002) G_GAN: 0.757 G_L1: 1.290 D_real: 0.599 D_fake: 0.644 \n",
      "(epoch: 88, iters: 440, time: 0.070, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.738 D_fake: 0.640 \n",
      "(epoch: 88, iters: 540, time: 0.076, data: 0.001) G_GAN: 0.720 G_L1: 0.000 D_real: 0.725 D_fake: 0.667 \n",
      "(epoch: 88, iters: 640, time: 0.073, data: 0.002) G_GAN: 0.793 G_L1: 2.682 D_real: 0.559 D_fake: 0.632 \n",
      "(epoch: 88, iters: 740, time: 0.071, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.751 D_fake: 0.657 \n",
      "(epoch: 88, iters: 840, time: 0.074, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.741 D_fake: 0.652 \n",
      "(epoch: 88, iters: 940, time: 0.075, data: 0.002) G_GAN: 0.818 G_L1: 3.230 D_real: 0.564 D_fake: 0.629 \n",
      "(epoch: 88, iters: 1040, time: 0.072, data: 0.004) G_GAN: 0.752 G_L1: 0.000 D_real: 0.754 D_fake: 0.637 \n",
      "(epoch: 88, iters: 1140, time: 0.073, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.758 D_fake: 0.638 \n",
      "(epoch: 88, iters: 1240, time: 0.078, data: 0.002) G_GAN: 0.799 G_L1: 2.399 D_real: 0.566 D_fake: 0.623 \n",
      "(epoch: 88, iters: 1340, time: 0.071, data: 0.003) G_GAN: 0.754 G_L1: 0.000 D_real: 0.757 D_fake: 0.626 \n",
      "(epoch: 88, iters: 1440, time: 0.071, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.741 D_fake: 0.650 \n",
      "(epoch: 88, iters: 1540, time: 0.071, data: 0.002) G_GAN: 0.773 G_L1: 1.508 D_real: 0.584 D_fake: 0.634 \n",
      "(epoch: 88, iters: 1640, time: 0.072, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.767 D_fake: 0.631 \n",
      "saving the latest model (epoch 88, total_steps 200000)\n",
      "(epoch: 88, iters: 1740, time: 0.073, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.749 D_fake: 0.624 \n",
      "(epoch: 88, iters: 1840, time: 0.078, data: 0.002) G_GAN: 0.753 G_L1: 0.842 D_real: 0.605 D_fake: 0.647 \n",
      "(epoch: 88, iters: 1940, time: 0.075, data: 0.002) G_GAN: 0.766 G_L1: 0.000 D_real: 0.781 D_fake: 0.626 \n",
      "(epoch: 88, iters: 2040, time: 0.075, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.744 D_fake: 0.637 \n",
      "(epoch: 88, iters: 2140, time: 0.074, data: 0.002) G_GAN: 0.792 G_L1: 0.917 D_real: 0.683 D_fake: 0.634 \n",
      "(epoch: 88, iters: 2240, time: 0.073, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.733 D_fake: 0.636 \n",
      "End of epoch 88 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 89, iters: 60, time: 0.073, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.749 D_fake: 0.646 \n",
      "(epoch: 89, iters: 160, time: 0.074, data: 0.001) G_GAN: 0.853 G_L1: 2.187 D_real: 0.605 D_fake: 0.581 \n",
      "(epoch: 89, iters: 260, time: 0.075, data: 0.002) G_GAN: 0.783 G_L1: 0.000 D_real: 0.897 D_fake: 0.562 \n",
      "(epoch: 89, iters: 360, time: 0.072, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.751 D_fake: 0.648 \n",
      "(epoch: 89, iters: 460, time: 0.073, data: 0.002) G_GAN: 0.790 G_L1: 2.055 D_real: 0.597 D_fake: 0.624 \n",
      "(epoch: 89, iters: 560, time: 0.071, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.745 D_fake: 0.645 \n",
      "(epoch: 89, iters: 660, time: 0.073, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.755 D_fake: 0.644 \n",
      "(epoch: 89, iters: 760, time: 0.075, data: 0.003) G_GAN: 0.787 G_L1: 2.009 D_real: 0.594 D_fake: 0.647 \n",
      "(epoch: 89, iters: 860, time: 0.074, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.729 D_fake: 0.654 \n",
      "(epoch: 89, iters: 960, time: 0.074, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.741 D_fake: 0.647 \n",
      "(epoch: 89, iters: 1060, time: 0.079, data: 0.002) G_GAN: 0.741 G_L1: 0.699 D_real: 0.624 D_fake: 0.654 \n",
      "(epoch: 89, iters: 1160, time: 0.077, data: 0.002) G_GAN: 0.773 G_L1: 0.000 D_real: 0.806 D_fake: 0.610 \n",
      "(epoch: 89, iters: 1260, time: 0.071, data: 0.003) G_GAN: 0.725 G_L1: 0.000 D_real: 0.734 D_fake: 0.661 \n",
      "(epoch: 89, iters: 1360, time: 0.071, data: 0.003) G_GAN: 0.754 G_L1: 2.029 D_real: 0.575 D_fake: 0.665 \n",
      "(epoch: 89, iters: 1460, time: 0.071, data: 0.003) G_GAN: 0.770 G_L1: 0.000 D_real: 0.796 D_fake: 0.621 \n",
      "(epoch: 89, iters: 1560, time: 0.074, data: 0.003) G_GAN: 0.727 G_L1: 0.000 D_real: 0.732 D_fake: 0.640 \n",
      "(epoch: 89, iters: 1660, time: 0.072, data: 0.002) G_GAN: 0.772 G_L1: 1.703 D_real: 0.581 D_fake: 0.636 \n",
      "(epoch: 89, iters: 1760, time: 0.075, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.747 D_fake: 0.636 \n",
      "(epoch: 89, iters: 1860, time: 0.071, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.720 D_fake: 0.674 \n",
      "(epoch: 89, iters: 1960, time: 0.074, data: 0.002) G_GAN: 0.782 G_L1: 2.015 D_real: 0.576 D_fake: 0.622 \n",
      "(epoch: 89, iters: 2060, time: 0.074, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.755 D_fake: 0.639 \n",
      "(epoch: 89, iters: 2160, time: 0.072, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.762 D_fake: 0.627 \n",
      "(epoch: 89, iters: 2260, time: 0.075, data: 0.002) G_GAN: 0.869 G_L1: 2.749 D_real: 0.603 D_fake: 0.584 \n",
      "End of epoch 89 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 90, iters: 80, time: 0.075, data: 0.002) G_GAN: 0.762 G_L1: 0.000 D_real: 0.765 D_fake: 0.631 \n",
      "(epoch: 90, iters: 180, time: 0.072, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.730 D_fake: 0.650 \n",
      "(epoch: 90, iters: 280, time: 0.074, data: 0.002) G_GAN: 0.778 G_L1: 1.026 D_real: 0.601 D_fake: 0.637 \n",
      "(epoch: 90, iters: 380, time: 0.072, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.765 D_fake: 0.643 \n",
      "(epoch: 90, iters: 480, time: 0.073, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.741 D_fake: 0.645 \n",
      "(epoch: 90, iters: 580, time: 0.073, data: 0.002) G_GAN: 0.804 G_L1: 3.541 D_real: 0.536 D_fake: 0.631 \n",
      "(epoch: 90, iters: 680, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.752 D_fake: 0.635 \n",
      "(epoch: 90, iters: 780, time: 0.072, data: 0.003) G_GAN: 0.712 G_L1: 0.000 D_real: 0.721 D_fake: 0.664 \n",
      "(epoch: 90, iters: 880, time: 0.073, data: 0.002) G_GAN: 0.761 G_L1: 2.571 D_real: 0.553 D_fake: 0.619 \n",
      "(epoch: 90, iters: 980, time: 0.078, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.759 D_fake: 0.638 \n",
      "(epoch: 90, iters: 1080, time: 0.077, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.739 D_fake: 0.632 \n",
      "(epoch: 90, iters: 1180, time: 0.079, data: 0.002) G_GAN: 0.785 G_L1: 2.021 D_real: 0.587 D_fake: 0.627 \n",
      "(epoch: 90, iters: 1280, time: 0.072, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.777 D_fake: 0.600 \n",
      "(epoch: 90, iters: 1380, time: 0.072, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.745 D_fake: 0.640 \n",
      "(epoch: 90, iters: 1480, time: 0.074, data: 0.003) G_GAN: 0.799 G_L1: 1.813 D_real: 0.592 D_fake: 0.617 \n",
      "(epoch: 90, iters: 1580, time: 0.075, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.759 D_fake: 0.644 \n",
      "(epoch: 90, iters: 1680, time: 0.071, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.766 D_fake: 0.628 \n",
      "(epoch: 90, iters: 1780, time: 0.072, data: 0.002) G_GAN: 0.791 G_L1: 2.503 D_real: 0.561 D_fake: 0.620 \n",
      "(epoch: 90, iters: 1880, time: 0.076, data: 0.002) G_GAN: 0.773 G_L1: 0.000 D_real: 0.790 D_fake: 0.635 \n",
      "(epoch: 90, iters: 1980, time: 0.074, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.736 D_fake: 0.657 \n",
      "(epoch: 90, iters: 2080, time: 0.074, data: 0.003) G_GAN: 0.793 G_L1: 2.297 D_real: 0.564 D_fake: 0.629 \n",
      "saving the latest model (epoch 90, total_steps 205000)\n",
      "(epoch: 90, iters: 2180, time: 0.077, data: 0.002) G_GAN: 0.776 G_L1: 0.000 D_real: 0.806 D_fake: 0.603 \n",
      "(epoch: 90, iters: 2280, time: 0.072, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.701 D_fake: 0.681 \n",
      "saving the model at the end of epoch 90, iters 205200\n",
      "End of epoch 90 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 91, iters: 100, time: 0.074, data: 0.415) G_GAN: 0.786 G_L1: 2.485 D_real: 0.578 D_fake: 0.642 \n",
      "(epoch: 91, iters: 200, time: 0.071, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.749 D_fake: 0.650 \n",
      "(epoch: 91, iters: 300, time: 0.074, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.734 D_fake: 0.660 \n",
      "(epoch: 91, iters: 400, time: 0.076, data: 0.002) G_GAN: 0.789 G_L1: 1.437 D_real: 0.592 D_fake: 0.633 \n",
      "(epoch: 91, iters: 500, time: 0.072, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.745 D_fake: 0.647 \n",
      "(epoch: 91, iters: 600, time: 0.073, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.763 D_fake: 0.620 \n",
      "(epoch: 91, iters: 700, time: 0.073, data: 0.002) G_GAN: 0.853 G_L1: 1.919 D_real: 0.606 D_fake: 0.593 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 91, iters: 800, time: 0.072, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.747 D_fake: 0.639 \n",
      "(epoch: 91, iters: 900, time: 0.069, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.727 D_fake: 0.663 \n",
      "(epoch: 91, iters: 1000, time: 0.074, data: 0.002) G_GAN: 0.787 G_L1: 1.678 D_real: 0.594 D_fake: 0.649 \n",
      "(epoch: 91, iters: 1100, time: 0.072, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.780 D_fake: 0.622 \n",
      "(epoch: 91, iters: 1200, time: 0.073, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.744 D_fake: 0.645 \n",
      "(epoch: 91, iters: 1300, time: 0.072, data: 0.003) G_GAN: 0.822 G_L1: 1.744 D_real: 0.610 D_fake: 0.623 \n",
      "(epoch: 91, iters: 1400, time: 0.072, data: 0.002) G_GAN: 0.773 G_L1: 0.000 D_real: 0.782 D_fake: 0.619 \n",
      "(epoch: 91, iters: 1500, time: 0.074, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.735 D_fake: 0.652 \n",
      "(epoch: 91, iters: 1600, time: 0.071, data: 0.003) G_GAN: 0.765 G_L1: 2.124 D_real: 0.570 D_fake: 0.640 \n",
      "(epoch: 91, iters: 1700, time: 0.075, data: 0.002) G_GAN: 0.786 G_L1: 0.000 D_real: 0.795 D_fake: 0.614 \n",
      "(epoch: 91, iters: 1800, time: 0.070, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.730 D_fake: 0.630 \n",
      "(epoch: 91, iters: 1900, time: 0.077, data: 0.002) G_GAN: 0.751 G_L1: 3.702 D_real: 0.516 D_fake: 0.672 \n",
      "(epoch: 91, iters: 2000, time: 0.071, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.773 D_fake: 0.635 \n",
      "(epoch: 91, iters: 2100, time: 0.075, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.723 D_fake: 0.656 \n",
      "(epoch: 91, iters: 2200, time: 0.071, data: 0.001) G_GAN: 0.864 G_L1: 1.583 D_real: 0.619 D_fake: 0.642 \n",
      "End of epoch 91 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 92, iters: 20, time: 0.075, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.740 D_fake: 0.643 \n",
      "(epoch: 92, iters: 120, time: 0.071, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.737 D_fake: 0.642 \n",
      "(epoch: 92, iters: 220, time: 0.073, data: 0.002) G_GAN: 0.776 G_L1: 2.749 D_real: 0.555 D_fake: 0.646 \n",
      "(epoch: 92, iters: 320, time: 0.072, data: 0.003) G_GAN: 0.751 G_L1: 0.000 D_real: 0.754 D_fake: 0.623 \n",
      "(epoch: 92, iters: 420, time: 0.073, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.724 D_fake: 0.672 \n",
      "(epoch: 92, iters: 520, time: 0.072, data: 0.003) G_GAN: 0.817 G_L1: 1.419 D_real: 0.624 D_fake: 0.618 \n",
      "(epoch: 92, iters: 620, time: 0.071, data: 0.003) G_GAN: 0.757 G_L1: 0.000 D_real: 0.763 D_fake: 0.631 \n",
      "(epoch: 92, iters: 720, time: 0.074, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.723 D_fake: 0.664 \n",
      "(epoch: 92, iters: 820, time: 0.077, data: 0.002) G_GAN: 0.754 G_L1: 1.824 D_real: 0.574 D_fake: 0.651 \n",
      "(epoch: 92, iters: 920, time: 0.076, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.752 D_fake: 0.623 \n",
      "(epoch: 92, iters: 1020, time: 0.073, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.765 D_fake: 0.648 \n",
      "(epoch: 92, iters: 1120, time: 0.076, data: 0.002) G_GAN: 0.818 G_L1: 1.957 D_real: 0.585 D_fake: 0.631 \n",
      "(epoch: 92, iters: 1220, time: 0.072, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.745 D_fake: 0.650 \n",
      "(epoch: 92, iters: 1320, time: 0.078, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.754 D_fake: 0.633 \n",
      "(epoch: 92, iters: 1420, time: 0.074, data: 0.002) G_GAN: 0.777 G_L1: 2.010 D_real: 0.601 D_fake: 0.626 \n",
      "(epoch: 92, iters: 1520, time: 0.071, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.732 D_fake: 0.655 \n",
      "(epoch: 92, iters: 1620, time: 0.072, data: 0.003) G_GAN: 0.724 G_L1: 0.000 D_real: 0.726 D_fake: 0.659 \n",
      "(epoch: 92, iters: 1720, time: 0.074, data: 0.003) G_GAN: 0.788 G_L1: 3.150 D_real: 0.568 D_fake: 0.620 \n",
      "(epoch: 92, iters: 1820, time: 0.071, data: 0.003) G_GAN: 0.763 G_L1: 0.000 D_real: 0.764 D_fake: 0.633 \n",
      "(epoch: 92, iters: 1920, time: 0.071, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.746 D_fake: 0.637 \n",
      "(epoch: 92, iters: 2020, time: 0.073, data: 0.002) G_GAN: 0.753 G_L1: 1.672 D_real: 0.592 D_fake: 0.643 \n",
      "(epoch: 92, iters: 2120, time: 0.073, data: 0.003) G_GAN: 0.744 G_L1: 0.000 D_real: 0.748 D_fake: 0.637 \n",
      "(epoch: 92, iters: 2220, time: 0.073, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.755 D_fake: 0.619 \n",
      "End of epoch 92 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 93, iters: 40, time: 0.076, data: 0.002) G_GAN: 0.765 G_L1: 1.820 D_real: 0.584 D_fake: 0.640 \n",
      "(epoch: 93, iters: 140, time: 0.082, data: 0.004) G_GAN: 0.737 G_L1: 0.000 D_real: 0.736 D_fake: 0.647 \n",
      "(epoch: 93, iters: 240, time: 0.072, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.746 D_fake: 0.641 \n",
      "saving the latest model (epoch 93, total_steps 210000)\n",
      "(epoch: 93, iters: 340, time: 0.074, data: 0.002) G_GAN: 0.773 G_L1: 1.290 D_real: 0.609 D_fake: 0.624 \n",
      "(epoch: 93, iters: 440, time: 0.071, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.745 D_fake: 0.649 \n",
      "(epoch: 93, iters: 540, time: 0.073, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.735 D_fake: 0.644 \n",
      "(epoch: 93, iters: 640, time: 0.072, data: 0.002) G_GAN: 0.777 G_L1: 2.682 D_real: 0.568 D_fake: 0.630 \n",
      "(epoch: 93, iters: 740, time: 0.077, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.743 D_fake: 0.634 \n",
      "(epoch: 93, iters: 840, time: 0.072, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.747 D_fake: 0.647 \n",
      "(epoch: 93, iters: 940, time: 0.075, data: 0.002) G_GAN: 0.802 G_L1: 3.230 D_real: 0.567 D_fake: 0.634 \n",
      "(epoch: 93, iters: 1040, time: 0.073, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.752 D_fake: 0.629 \n",
      "(epoch: 93, iters: 1140, time: 0.075, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.746 D_fake: 0.651 \n",
      "(epoch: 93, iters: 1240, time: 0.071, data: 0.002) G_GAN: 0.808 G_L1: 2.399 D_real: 0.581 D_fake: 0.623 \n",
      "(epoch: 93, iters: 1340, time: 0.074, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.728 D_fake: 0.655 \n",
      "(epoch: 93, iters: 1440, time: 0.071, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.738 D_fake: 0.652 \n",
      "(epoch: 93, iters: 1540, time: 0.071, data: 0.001) G_GAN: 0.767 G_L1: 1.508 D_real: 0.587 D_fake: 0.647 \n",
      "(epoch: 93, iters: 1640, time: 0.073, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.646 \n",
      "(epoch: 93, iters: 1740, time: 0.076, data: 0.001) G_GAN: 0.743 G_L1: 0.000 D_real: 0.749 D_fake: 0.636 \n",
      "(epoch: 93, iters: 1840, time: 0.083, data: 0.002) G_GAN: 0.768 G_L1: 0.842 D_real: 0.615 D_fake: 0.638 \n",
      "(epoch: 93, iters: 1940, time: 0.075, data: 0.001) G_GAN: 0.770 G_L1: 0.000 D_real: 0.775 D_fake: 0.618 \n",
      "(epoch: 93, iters: 2040, time: 0.074, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.741 D_fake: 0.631 \n",
      "(epoch: 93, iters: 2140, time: 0.073, data: 0.002) G_GAN: 0.782 G_L1: 0.917 D_real: 0.625 D_fake: 0.628 \n",
      "(epoch: 93, iters: 2240, time: 0.074, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.731 D_fake: 0.646 \n",
      "End of epoch 93 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 94, iters: 60, time: 0.073, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.750 D_fake: 0.627 \n",
      "(epoch: 94, iters: 160, time: 0.074, data: 0.001) G_GAN: 0.865 G_L1: 2.187 D_real: 0.620 D_fake: 0.607 \n",
      "(epoch: 94, iters: 260, time: 0.077, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.746 D_fake: 0.650 \n",
      "(epoch: 94, iters: 360, time: 0.072, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.741 D_fake: 0.658 \n",
      "(epoch: 94, iters: 460, time: 0.075, data: 0.002) G_GAN: 0.778 G_L1: 2.055 D_real: 0.579 D_fake: 0.638 \n",
      "(epoch: 94, iters: 560, time: 0.073, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.743 D_fake: 0.638 \n",
      "(epoch: 94, iters: 660, time: 0.076, data: 0.003) G_GAN: 0.741 G_L1: 0.000 D_real: 0.753 D_fake: 0.633 \n",
      "(epoch: 94, iters: 760, time: 0.072, data: 0.002) G_GAN: 0.784 G_L1: 2.009 D_real: 0.576 D_fake: 0.645 \n",
      "(epoch: 94, iters: 860, time: 0.074, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.752 D_fake: 0.645 \n",
      "(epoch: 94, iters: 960, time: 0.073, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.738 D_fake: 0.669 \n",
      "(epoch: 94, iters: 1060, time: 0.073, data: 0.002) G_GAN: 0.756 G_L1: 0.699 D_real: 0.624 D_fake: 0.651 \n",
      "(epoch: 94, iters: 1160, time: 0.071, data: 0.002) G_GAN: 0.795 G_L1: 0.000 D_real: 0.829 D_fake: 0.590 \n",
      "(epoch: 94, iters: 1260, time: 0.069, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.719 D_fake: 0.675 \n",
      "(epoch: 94, iters: 1360, time: 0.073, data: 0.003) G_GAN: 0.756 G_L1: 2.029 D_real: 0.569 D_fake: 0.660 \n",
      "(epoch: 94, iters: 1460, time: 0.073, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.754 D_fake: 0.639 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 94, iters: 1560, time: 0.070, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.715 D_fake: 0.666 \n",
      "(epoch: 94, iters: 1660, time: 0.072, data: 0.002) G_GAN: 0.784 G_L1: 1.703 D_real: 0.589 D_fake: 0.649 \n",
      "(epoch: 94, iters: 1760, time: 0.073, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.747 D_fake: 0.637 \n",
      "(epoch: 94, iters: 1860, time: 0.072, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.718 D_fake: 0.675 \n",
      "(epoch: 94, iters: 1960, time: 0.076, data: 0.002) G_GAN: 0.792 G_L1: 2.015 D_real: 0.579 D_fake: 0.620 \n",
      "(epoch: 94, iters: 2060, time: 0.072, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.755 D_fake: 0.639 \n",
      "(epoch: 94, iters: 2160, time: 0.072, data: 0.001) G_GAN: 0.712 G_L1: 0.000 D_real: 0.720 D_fake: 0.668 \n",
      "(epoch: 94, iters: 2260, time: 0.077, data: 0.002) G_GAN: 0.868 G_L1: 2.749 D_real: 0.601 D_fake: 0.590 \n",
      "End of epoch 94 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 95, iters: 80, time: 0.075, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.754 D_fake: 0.641 \n",
      "(epoch: 95, iters: 180, time: 0.071, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.703 D_fake: 0.666 \n",
      "(epoch: 95, iters: 280, time: 0.080, data: 0.002) G_GAN: 0.784 G_L1: 1.026 D_real: 0.603 D_fake: 0.636 \n",
      "(epoch: 95, iters: 380, time: 0.075, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.761 D_fake: 0.645 \n",
      "(epoch: 95, iters: 480, time: 0.074, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.730 D_fake: 0.650 \n",
      "(epoch: 95, iters: 580, time: 0.071, data: 0.002) G_GAN: 0.801 G_L1: 3.541 D_real: 0.531 D_fake: 0.633 \n",
      "(epoch: 95, iters: 680, time: 0.079, data: 0.003) G_GAN: 0.746 G_L1: 0.000 D_real: 0.751 D_fake: 0.630 \n",
      "saving the latest model (epoch 95, total_steps 215000)\n",
      "(epoch: 95, iters: 780, time: 0.074, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.727 D_fake: 0.652 \n",
      "(epoch: 95, iters: 880, time: 0.073, data: 0.002) G_GAN: 0.818 G_L1: 2.571 D_real: 0.567 D_fake: 0.556 \n",
      "(epoch: 95, iters: 980, time: 0.076, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.722 D_fake: 0.682 \n",
      "(epoch: 95, iters: 1080, time: 0.071, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.712 D_fake: 0.678 \n",
      "(epoch: 95, iters: 1180, time: 0.075, data: 0.002) G_GAN: 0.785 G_L1: 2.021 D_real: 0.590 D_fake: 0.636 \n",
      "(epoch: 95, iters: 1280, time: 0.074, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.765 D_fake: 0.626 \n",
      "(epoch: 95, iters: 1380, time: 0.070, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.761 D_fake: 0.634 \n",
      "(epoch: 95, iters: 1480, time: 0.075, data: 0.002) G_GAN: 0.809 G_L1: 1.813 D_real: 0.590 D_fake: 0.615 \n",
      "(epoch: 95, iters: 1580, time: 0.072, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.751 D_fake: 0.631 \n",
      "(epoch: 95, iters: 1680, time: 0.072, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.755 D_fake: 0.637 \n",
      "(epoch: 95, iters: 1780, time: 0.076, data: 0.002) G_GAN: 0.781 G_L1: 2.503 D_real: 0.565 D_fake: 0.628 \n",
      "(epoch: 95, iters: 1880, time: 0.071, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.753 D_fake: 0.645 \n",
      "(epoch: 95, iters: 1980, time: 0.075, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.736 D_fake: 0.649 \n",
      "(epoch: 95, iters: 2080, time: 0.078, data: 0.002) G_GAN: 0.783 G_L1: 2.297 D_real: 0.560 D_fake: 0.630 \n",
      "(epoch: 95, iters: 2180, time: 0.076, data: 0.002) G_GAN: 0.766 G_L1: 0.000 D_real: 0.767 D_fake: 0.612 \n",
      "(epoch: 95, iters: 2280, time: 0.070, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.738 D_fake: 0.662 \n",
      "saving the model at the end of epoch 95, iters 216600\n",
      "End of epoch 95 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 96, iters: 100, time: 0.077, data: 0.420) G_GAN: 0.796 G_L1: 2.485 D_real: 0.604 D_fake: 0.647 \n",
      "(epoch: 96, iters: 200, time: 0.077, data: 0.004) G_GAN: 0.752 G_L1: 0.000 D_real: 0.756 D_fake: 0.641 \n",
      "(epoch: 96, iters: 300, time: 0.073, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.737 D_fake: 0.656 \n",
      "(epoch: 96, iters: 400, time: 0.073, data: 0.002) G_GAN: 0.789 G_L1: 1.437 D_real: 0.601 D_fake: 0.628 \n",
      "(epoch: 96, iters: 500, time: 0.072, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.743 D_fake: 0.647 \n",
      "(epoch: 96, iters: 600, time: 0.073, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.749 D_fake: 0.643 \n",
      "(epoch: 96, iters: 700, time: 0.072, data: 0.002) G_GAN: 0.823 G_L1: 1.919 D_real: 0.593 D_fake: 0.629 \n",
      "(epoch: 96, iters: 800, time: 0.076, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.734 D_fake: 0.618 \n",
      "(epoch: 96, iters: 900, time: 0.080, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.732 D_fake: 0.636 \n",
      "(epoch: 96, iters: 1000, time: 0.075, data: 0.002) G_GAN: 0.816 G_L1: 1.678 D_real: 0.602 D_fake: 0.613 \n",
      "(epoch: 96, iters: 1100, time: 0.080, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.748 D_fake: 0.647 \n",
      "(epoch: 96, iters: 1200, time: 0.076, data: 0.003) G_GAN: 0.731 G_L1: 0.000 D_real: 0.735 D_fake: 0.643 \n",
      "(epoch: 96, iters: 1300, time: 0.073, data: 0.002) G_GAN: 0.819 G_L1: 1.744 D_real: 0.619 D_fake: 0.615 \n",
      "(epoch: 96, iters: 1400, time: 0.071, data: 0.002) G_GAN: 0.787 G_L1: 0.000 D_real: 0.795 D_fake: 0.610 \n",
      "(epoch: 96, iters: 1500, time: 0.073, data: 0.003) G_GAN: 0.728 G_L1: 0.000 D_real: 0.733 D_fake: 0.652 \n",
      "(epoch: 96, iters: 1600, time: 0.073, data: 0.002) G_GAN: 0.779 G_L1: 2.124 D_real: 0.579 D_fake: 0.663 \n",
      "(epoch: 96, iters: 1700, time: 0.072, data: 0.002) G_GAN: 0.775 G_L1: 0.000 D_real: 0.781 D_fake: 0.632 \n",
      "(epoch: 96, iters: 1800, time: 0.074, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.745 D_fake: 0.628 \n",
      "(epoch: 96, iters: 1900, time: 0.076, data: 0.002) G_GAN: 0.799 G_L1: 3.702 D_real: 0.523 D_fake: 0.631 \n",
      "(epoch: 96, iters: 2000, time: 0.072, data: 0.003) G_GAN: 0.767 G_L1: 0.000 D_real: 0.773 D_fake: 0.629 \n",
      "(epoch: 96, iters: 2100, time: 0.076, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.723 D_fake: 0.642 \n",
      "(epoch: 96, iters: 2200, time: 0.074, data: 0.002) G_GAN: 0.774 G_L1: 1.583 D_real: 0.561 D_fake: 0.665 \n",
      "End of epoch 96 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 97, iters: 20, time: 0.077, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.742 D_fake: 0.637 \n",
      "(epoch: 97, iters: 120, time: 0.073, data: 0.003) G_GAN: 0.710 G_L1: 0.000 D_real: 0.718 D_fake: 0.667 \n",
      "(epoch: 97, iters: 220, time: 0.075, data: 0.002) G_GAN: 0.811 G_L1: 2.749 D_real: 0.558 D_fake: 0.614 \n",
      "(epoch: 97, iters: 320, time: 0.078, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.761 D_fake: 0.646 \n",
      "(epoch: 97, iters: 420, time: 0.073, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.743 D_fake: 0.636 \n",
      "(epoch: 97, iters: 520, time: 0.074, data: 0.002) G_GAN: 0.831 G_L1: 1.419 D_real: 0.650 D_fake: 0.636 \n",
      "(epoch: 97, iters: 620, time: 0.081, data: 0.004) G_GAN: 0.760 G_L1: 0.000 D_real: 0.767 D_fake: 0.622 \n",
      "(epoch: 97, iters: 720, time: 0.079, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.741 D_fake: 0.648 \n",
      "(epoch: 97, iters: 820, time: 0.079, data: 0.002) G_GAN: 0.784 G_L1: 1.824 D_real: 0.578 D_fake: 0.643 \n",
      "(epoch: 97, iters: 920, time: 0.072, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.739 D_fake: 0.643 \n",
      "(epoch: 97, iters: 1020, time: 0.073, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.750 D_fake: 0.648 \n",
      "(epoch: 97, iters: 1120, time: 0.072, data: 0.002) G_GAN: 0.807 G_L1: 1.957 D_real: 0.580 D_fake: 0.630 \n",
      "saving the latest model (epoch 97, total_steps 220000)\n",
      "(epoch: 97, iters: 1220, time: 0.073, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.748 D_fake: 0.637 \n",
      "(epoch: 97, iters: 1320, time: 0.072, data: 0.003) G_GAN: 0.717 G_L1: 0.000 D_real: 0.722 D_fake: 0.653 \n",
      "(epoch: 97, iters: 1420, time: 0.075, data: 0.003) G_GAN: 0.802 G_L1: 2.010 D_real: 0.575 D_fake: 0.626 \n",
      "(epoch: 97, iters: 1520, time: 0.071, data: 0.003) G_GAN: 0.741 G_L1: 0.000 D_real: 0.744 D_fake: 0.639 \n",
      "(epoch: 97, iters: 1620, time: 0.071, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.733 D_fake: 0.659 \n",
      "(epoch: 97, iters: 1720, time: 0.075, data: 0.002) G_GAN: 0.806 G_L1: 3.150 D_real: 0.535 D_fake: 0.634 \n",
      "(epoch: 97, iters: 1820, time: 0.072, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.766 D_fake: 0.636 \n",
      "(epoch: 97, iters: 1920, time: 0.072, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.723 D_fake: 0.631 \n",
      "(epoch: 97, iters: 2020, time: 0.071, data: 0.002) G_GAN: 0.793 G_L1: 1.672 D_real: 0.590 D_fake: 0.627 \n",
      "(epoch: 97, iters: 2120, time: 0.074, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.787 D_fake: 0.636 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 97, iters: 2220, time: 0.074, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.687 D_fake: 0.696 \n",
      "End of epoch 97 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 98, iters: 40, time: 0.073, data: 0.002) G_GAN: 0.786 G_L1: 1.820 D_real: 0.597 D_fake: 0.636 \n",
      "(epoch: 98, iters: 140, time: 0.071, data: 0.001) G_GAN: 0.771 G_L1: 0.000 D_real: 0.771 D_fake: 0.608 \n",
      "(epoch: 98, iters: 240, time: 0.073, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.743 D_fake: 0.649 \n",
      "(epoch: 98, iters: 340, time: 0.073, data: 0.002) G_GAN: 0.781 G_L1: 1.290 D_real: 0.603 D_fake: 0.628 \n",
      "(epoch: 98, iters: 440, time: 0.071, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.753 D_fake: 0.628 \n",
      "(epoch: 98, iters: 540, time: 0.074, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.712 D_fake: 0.678 \n",
      "(epoch: 98, iters: 640, time: 0.072, data: 0.002) G_GAN: 0.783 G_L1: 2.682 D_real: 0.567 D_fake: 0.646 \n",
      "(epoch: 98, iters: 740, time: 0.071, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.767 D_fake: 0.637 \n",
      "(epoch: 98, iters: 840, time: 0.074, data: 0.003) G_GAN: 0.738 G_L1: 0.000 D_real: 0.745 D_fake: 0.644 \n",
      "(epoch: 98, iters: 940, time: 0.075, data: 0.002) G_GAN: 0.844 G_L1: 3.230 D_real: 0.571 D_fake: 0.621 \n",
      "(epoch: 98, iters: 1040, time: 0.075, data: 0.003) G_GAN: 0.745 G_L1: 0.000 D_real: 0.750 D_fake: 0.653 \n",
      "(epoch: 98, iters: 1140, time: 0.071, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.760 D_fake: 0.627 \n",
      "(epoch: 98, iters: 1240, time: 0.071, data: 0.003) G_GAN: 0.873 G_L1: 2.399 D_real: 0.618 D_fake: 0.567 \n",
      "(epoch: 98, iters: 1340, time: 0.074, data: 0.003) G_GAN: 0.741 G_L1: 0.000 D_real: 0.749 D_fake: 0.625 \n",
      "(epoch: 98, iters: 1440, time: 0.072, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.740 D_fake: 0.657 \n",
      "(epoch: 98, iters: 1540, time: 0.072, data: 0.002) G_GAN: 0.787 G_L1: 1.508 D_real: 0.587 D_fake: 0.644 \n",
      "(epoch: 98, iters: 1640, time: 0.073, data: 0.003) G_GAN: 0.750 G_L1: 0.000 D_real: 0.756 D_fake: 0.618 \n",
      "(epoch: 98, iters: 1740, time: 0.074, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.751 D_fake: 0.646 \n",
      "(epoch: 98, iters: 1840, time: 0.072, data: 0.002) G_GAN: 0.790 G_L1: 0.842 D_real: 0.617 D_fake: 0.609 \n",
      "(epoch: 98, iters: 1940, time: 0.072, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.763 D_fake: 0.638 \n",
      "(epoch: 98, iters: 2040, time: 0.074, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.735 D_fake: 0.652 \n",
      "(epoch: 98, iters: 2140, time: 0.074, data: 0.003) G_GAN: 0.793 G_L1: 0.917 D_real: 0.605 D_fake: 0.639 \n",
      "(epoch: 98, iters: 2240, time: 0.072, data: 0.003) G_GAN: 0.751 G_L1: 0.000 D_real: 0.755 D_fake: 0.589 \n",
      "End of epoch 98 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 99, iters: 60, time: 0.072, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.735 D_fake: 0.660 \n",
      "(epoch: 99, iters: 160, time: 0.075, data: 0.001) G_GAN: 0.812 G_L1: 2.187 D_real: 0.581 D_fake: 0.641 \n",
      "(epoch: 99, iters: 260, time: 0.073, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.738 D_fake: 0.654 \n",
      "(epoch: 99, iters: 360, time: 0.072, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.734 D_fake: 0.658 \n",
      "(epoch: 99, iters: 460, time: 0.072, data: 0.002) G_GAN: 0.802 G_L1: 2.055 D_real: 0.580 D_fake: 0.633 \n",
      "(epoch: 99, iters: 560, time: 0.071, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.749 D_fake: 0.643 \n",
      "(epoch: 99, iters: 660, time: 0.072, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.747 D_fake: 0.626 \n",
      "(epoch: 99, iters: 760, time: 0.072, data: 0.003) G_GAN: 0.817 G_L1: 2.009 D_real: 0.589 D_fake: 0.617 \n",
      "(epoch: 99, iters: 860, time: 0.070, data: 0.002) G_GAN: 0.762 G_L1: 0.000 D_real: 0.761 D_fake: 0.630 \n",
      "(epoch: 99, iters: 960, time: 0.071, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.738 D_fake: 0.642 \n",
      "(epoch: 99, iters: 1060, time: 0.071, data: 0.003) G_GAN: 0.763 G_L1: 0.699 D_real: 0.616 D_fake: 0.659 \n",
      "(epoch: 99, iters: 1160, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.773 D_fake: 0.603 \n",
      "(epoch: 99, iters: 1260, time: 0.071, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.722 D_fake: 0.671 \n",
      "(epoch: 99, iters: 1360, time: 0.072, data: 0.002) G_GAN: 0.784 G_L1: 2.029 D_real: 0.579 D_fake: 0.631 \n",
      "(epoch: 99, iters: 1460, time: 0.070, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.822 D_fake: 0.615 \n",
      "(epoch: 99, iters: 1560, time: 0.074, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.726 D_fake: 0.654 \n",
      "saving the latest model (epoch 99, total_steps 225000)\n",
      "(epoch: 99, iters: 1660, time: 0.073, data: 0.002) G_GAN: 0.811 G_L1: 1.703 D_real: 0.587 D_fake: 0.627 \n",
      "(epoch: 99, iters: 1760, time: 0.074, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.754 D_fake: 0.654 \n",
      "(epoch: 99, iters: 1860, time: 0.071, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.715 D_fake: 0.671 \n",
      "(epoch: 99, iters: 1960, time: 0.072, data: 0.002) G_GAN: 0.813 G_L1: 2.015 D_real: 0.579 D_fake: 0.626 \n",
      "(epoch: 99, iters: 2060, time: 0.072, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.759 D_fake: 0.632 \n",
      "(epoch: 99, iters: 2160, time: 0.071, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.731 D_fake: 0.659 \n",
      "(epoch: 99, iters: 2260, time: 0.074, data: 0.002) G_GAN: 0.762 G_L1: 2.749 D_real: 0.530 D_fake: 0.686 \n",
      "End of epoch 99 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0016000\n",
      "(epoch: 100, iters: 80, time: 0.071, data: 0.003) G_GAN: 0.766 G_L1: 0.000 D_real: 0.771 D_fake: 0.618 \n",
      "(epoch: 100, iters: 180, time: 0.072, data: 0.001) G_GAN: 0.718 G_L1: 0.000 D_real: 0.726 D_fake: 0.631 \n",
      "(epoch: 100, iters: 280, time: 0.073, data: 0.002) G_GAN: 0.787 G_L1: 1.026 D_real: 0.597 D_fake: 0.650 \n",
      "(epoch: 100, iters: 380, time: 0.073, data: 0.002) G_GAN: 0.766 G_L1: 0.000 D_real: 0.776 D_fake: 0.642 \n",
      "(epoch: 100, iters: 480, time: 0.075, data: 0.003) G_GAN: 0.722 G_L1: 0.000 D_real: 0.731 D_fake: 0.632 \n",
      "(epoch: 100, iters: 580, time: 0.076, data: 0.002) G_GAN: 0.836 G_L1: 3.541 D_real: 0.531 D_fake: 0.616 \n",
      "(epoch: 100, iters: 680, time: 0.078, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.755 D_fake: 0.645 \n",
      "(epoch: 100, iters: 780, time: 0.080, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.679 D_fake: 0.720 \n",
      "(epoch: 100, iters: 880, time: 0.074, data: 0.002) G_GAN: 0.807 G_L1: 2.571 D_real: 0.556 D_fake: 0.639 \n",
      "(epoch: 100, iters: 980, time: 0.082, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.759 D_fake: 0.627 \n",
      "(epoch: 100, iters: 1080, time: 0.079, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.724 D_fake: 0.658 \n",
      "(epoch: 100, iters: 1180, time: 0.079, data: 0.002) G_GAN: 0.821 G_L1: 2.021 D_real: 0.585 D_fake: 0.627 \n",
      "(epoch: 100, iters: 1280, time: 0.082, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.766 D_fake: 0.654 \n",
      "(epoch: 100, iters: 1380, time: 0.082, data: 0.002) G_GAN: 0.679 G_L1: 0.000 D_real: 0.691 D_fake: 0.682 \n",
      "(epoch: 100, iters: 1480, time: 0.080, data: 0.002) G_GAN: 0.811 G_L1: 1.813 D_real: 0.586 D_fake: 0.645 \n",
      "(epoch: 100, iters: 1580, time: 0.080, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.752 D_fake: 0.626 \n",
      "(epoch: 100, iters: 1680, time: 0.078, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.775 D_fake: 0.645 \n",
      "(epoch: 100, iters: 1780, time: 0.077, data: 0.002) G_GAN: 0.808 G_L1: 2.503 D_real: 0.559 D_fake: 0.645 \n",
      "(epoch: 100, iters: 1880, time: 0.081, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.756 D_fake: 0.624 \n",
      "(epoch: 100, iters: 1980, time: 0.078, data: 0.003) G_GAN: 0.711 G_L1: 0.000 D_real: 0.726 D_fake: 0.627 \n",
      "(epoch: 100, iters: 2080, time: 0.078, data: 0.002) G_GAN: 0.801 G_L1: 2.297 D_real: 0.555 D_fake: 0.634 \n",
      "(epoch: 100, iters: 2180, time: 0.082, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.749 D_fake: 0.640 \n",
      "(epoch: 100, iters: 2280, time: 0.070, data: 0.003) G_GAN: 0.670 G_L1: 0.000 D_real: 0.683 D_fake: 0.684 \n",
      "saving the model at the end of epoch 100, iters 228000\n",
      "End of epoch 100 / 200 \t Time Taken: 119 sec\n",
      "learning rate = 0.0015842\n",
      "(epoch: 101, iters: 100, time: 0.076, data: 0.406) G_GAN: 0.804 G_L1: 2.485 D_real: 0.553 D_fake: 0.636 \n",
      "(epoch: 101, iters: 200, time: 0.073, data: 0.004) G_GAN: 0.717 G_L1: 0.000 D_real: 0.725 D_fake: 0.671 \n",
      "(epoch: 101, iters: 300, time: 0.071, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.730 D_fake: 0.667 \n",
      "(epoch: 101, iters: 400, time: 0.071, data: 0.002) G_GAN: 0.830 G_L1: 1.437 D_real: 0.587 D_fake: 0.631 \n",
      "(epoch: 101, iters: 500, time: 0.072, data: 0.003) G_GAN: 0.731 G_L1: 0.000 D_real: 0.735 D_fake: 0.659 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 101, iters: 600, time: 0.071, data: 0.003) G_GAN: 0.747 G_L1: 0.000 D_real: 0.760 D_fake: 0.619 \n",
      "(epoch: 101, iters: 700, time: 0.071, data: 0.002) G_GAN: 0.833 G_L1: 1.919 D_real: 0.565 D_fake: 0.625 \n",
      "(epoch: 101, iters: 800, time: 0.075, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.747 D_fake: 0.647 \n",
      "(epoch: 101, iters: 900, time: 0.071, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.677 D_fake: 0.682 \n",
      "(epoch: 101, iters: 1000, time: 0.071, data: 0.002) G_GAN: 0.792 G_L1: 1.678 D_real: 0.573 D_fake: 0.649 \n",
      "(epoch: 101, iters: 1100, time: 0.071, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.818 D_fake: 0.609 \n",
      "(epoch: 101, iters: 1200, time: 0.074, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.724 D_fake: 0.636 \n",
      "(epoch: 101, iters: 1300, time: 0.074, data: 0.002) G_GAN: 0.821 G_L1: 1.744 D_real: 0.613 D_fake: 0.622 \n",
      "(epoch: 101, iters: 1400, time: 0.074, data: 0.003) G_GAN: 0.796 G_L1: 0.000 D_real: 0.813 D_fake: 0.597 \n",
      "(epoch: 101, iters: 1500, time: 0.071, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.731 D_fake: 0.658 \n",
      "(epoch: 101, iters: 1600, time: 0.071, data: 0.002) G_GAN: 0.810 G_L1: 2.124 D_real: 0.578 D_fake: 0.615 \n",
      "(epoch: 101, iters: 1700, time: 0.073, data: 0.002) G_GAN: 0.773 G_L1: 0.000 D_real: 0.793 D_fake: 0.591 \n",
      "(epoch: 101, iters: 1800, time: 0.071, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.736 D_fake: 0.659 \n",
      "(epoch: 101, iters: 1900, time: 0.072, data: 0.002) G_GAN: 0.796 G_L1: 3.702 D_real: 0.524 D_fake: 0.609 \n",
      "(epoch: 101, iters: 2000, time: 0.074, data: 0.002) G_GAN: 0.780 G_L1: 0.000 D_real: 0.785 D_fake: 0.596 \n",
      "saving the latest model (epoch 101, total_steps 230000)\n",
      "(epoch: 101, iters: 2100, time: 0.074, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.723 D_fake: 0.659 \n",
      "(epoch: 101, iters: 2200, time: 0.072, data: 0.002) G_GAN: 0.817 G_L1: 1.583 D_real: 0.548 D_fake: 0.678 \n",
      "End of epoch 101 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0015683\n",
      "(epoch: 102, iters: 20, time: 0.073, data: 0.003) G_GAN: 0.720 G_L1: 0.000 D_real: 0.735 D_fake: 0.627 \n",
      "(epoch: 102, iters: 120, time: 0.072, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.748 D_fake: 0.655 \n",
      "(epoch: 102, iters: 220, time: 0.071, data: 0.001) G_GAN: 0.833 G_L1: 2.749 D_real: 0.548 D_fake: 0.642 \n",
      "(epoch: 102, iters: 320, time: 0.072, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.763 D_fake: 0.635 \n",
      "(epoch: 102, iters: 420, time: 0.073, data: 0.003) G_GAN: 0.726 G_L1: 0.000 D_real: 0.739 D_fake: 0.656 \n",
      "(epoch: 102, iters: 520, time: 0.075, data: 0.002) G_GAN: 0.839 G_L1: 1.419 D_real: 0.605 D_fake: 0.639 \n",
      "(epoch: 102, iters: 620, time: 0.072, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.765 D_fake: 0.638 \n",
      "(epoch: 102, iters: 720, time: 0.073, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.739 D_fake: 0.584 \n",
      "(epoch: 102, iters: 820, time: 0.072, data: 0.002) G_GAN: 0.800 G_L1: 1.824 D_real: 0.578 D_fake: 0.629 \n",
      "(epoch: 102, iters: 920, time: 0.074, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.721 D_fake: 0.675 \n",
      "(epoch: 102, iters: 1020, time: 0.076, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.740 D_fake: 0.623 \n",
      "(epoch: 102, iters: 1120, time: 0.074, data: 0.002) G_GAN: 0.803 G_L1: 1.957 D_real: 0.574 D_fake: 0.628 \n",
      "(epoch: 102, iters: 1220, time: 0.075, data: 0.003) G_GAN: 0.743 G_L1: 0.000 D_real: 0.750 D_fake: 0.633 \n",
      "(epoch: 102, iters: 1320, time: 0.072, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.746 D_fake: 0.638 \n",
      "(epoch: 102, iters: 1420, time: 0.075, data: 0.002) G_GAN: 0.821 G_L1: 2.010 D_real: 0.565 D_fake: 0.641 \n",
      "(epoch: 102, iters: 1520, time: 0.071, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.740 D_fake: 0.645 \n",
      "(epoch: 102, iters: 1620, time: 0.071, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.734 D_fake: 0.644 \n",
      "(epoch: 102, iters: 1720, time: 0.075, data: 0.002) G_GAN: 0.831 G_L1: 3.150 D_real: 0.524 D_fake: 0.674 \n",
      "(epoch: 102, iters: 1820, time: 0.075, data: 0.002) G_GAN: 0.766 G_L1: 0.000 D_real: 0.773 D_fake: 0.616 \n",
      "(epoch: 102, iters: 1920, time: 0.071, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.719 D_fake: 0.641 \n",
      "(epoch: 102, iters: 2020, time: 0.073, data: 0.003) G_GAN: 0.821 G_L1: 1.672 D_real: 0.589 D_fake: 0.614 \n",
      "(epoch: 102, iters: 2120, time: 0.072, data: 0.002) G_GAN: 0.771 G_L1: 0.000 D_real: 0.782 D_fake: 0.626 \n",
      "(epoch: 102, iters: 2220, time: 0.076, data: 0.002) G_GAN: 0.666 G_L1: 0.000 D_real: 0.669 D_fake: 0.669 \n",
      "End of epoch 102 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0015525\n",
      "(epoch: 103, iters: 40, time: 0.075, data: 0.002) G_GAN: 0.806 G_L1: 1.820 D_real: 0.580 D_fake: 0.635 \n",
      "(epoch: 103, iters: 140, time: 0.071, data: 0.003) G_GAN: 0.756 G_L1: 0.000 D_real: 0.763 D_fake: 0.630 \n",
      "(epoch: 103, iters: 240, time: 0.072, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.728 D_fake: 0.653 \n",
      "(epoch: 103, iters: 340, time: 0.072, data: 0.002) G_GAN: 0.787 G_L1: 1.290 D_real: 0.591 D_fake: 0.646 \n",
      "(epoch: 103, iters: 440, time: 0.072, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.740 D_fake: 0.630 \n",
      "(epoch: 103, iters: 540, time: 0.074, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.711 D_fake: 0.674 \n",
      "(epoch: 103, iters: 640, time: 0.073, data: 0.002) G_GAN: 0.846 G_L1: 2.682 D_real: 0.571 D_fake: 0.626 \n",
      "(epoch: 103, iters: 740, time: 0.072, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.750 D_fake: 0.633 \n",
      "(epoch: 103, iters: 840, time: 0.071, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.732 D_fake: 0.642 \n",
      "(epoch: 103, iters: 940, time: 0.071, data: 0.002) G_GAN: 0.890 G_L1: 3.230 D_real: 0.576 D_fake: 0.626 \n",
      "(epoch: 103, iters: 1040, time: 0.071, data: 0.003) G_GAN: 0.744 G_L1: 0.000 D_real: 0.751 D_fake: 0.632 \n",
      "(epoch: 103, iters: 1140, time: 0.072, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.737 D_fake: 0.644 \n",
      "(epoch: 103, iters: 1240, time: 0.071, data: 0.002) G_GAN: 0.938 G_L1: 2.399 D_real: 0.617 D_fake: 0.593 \n",
      "(epoch: 103, iters: 1340, time: 0.071, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.762 D_fake: 0.628 \n",
      "(epoch: 103, iters: 1440, time: 0.072, data: 0.003) G_GAN: 0.713 G_L1: 0.000 D_real: 0.725 D_fake: 0.667 \n",
      "(epoch: 103, iters: 1540, time: 0.075, data: 0.002) G_GAN: 0.825 G_L1: 1.508 D_real: 0.590 D_fake: 0.623 \n",
      "(epoch: 103, iters: 1640, time: 0.071, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.751 D_fake: 0.605 \n",
      "(epoch: 103, iters: 1740, time: 0.075, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.724 D_fake: 0.651 \n",
      "(epoch: 103, iters: 1840, time: 0.075, data: 0.002) G_GAN: 0.783 G_L1: 0.842 D_real: 0.603 D_fake: 0.650 \n",
      "(epoch: 103, iters: 1940, time: 0.071, data: 0.001) G_GAN: 0.767 G_L1: 0.000 D_real: 0.782 D_fake: 0.622 \n",
      "(epoch: 103, iters: 2040, time: 0.075, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.733 D_fake: 0.623 \n",
      "(epoch: 103, iters: 2140, time: 0.076, data: 0.002) G_GAN: 0.839 G_L1: 0.917 D_real: 0.628 D_fake: 0.610 \n",
      "(epoch: 103, iters: 2240, time: 0.074, data: 0.002) G_GAN: 0.776 G_L1: 0.000 D_real: 0.796 D_fake: 0.614 \n",
      "End of epoch 103 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0015366\n",
      "(epoch: 104, iters: 60, time: 0.073, data: 0.002) G_GAN: 0.644 G_L1: 0.000 D_real: 0.651 D_fake: 0.726 \n",
      "(epoch: 104, iters: 160, time: 0.072, data: 0.001) G_GAN: 0.866 G_L1: 2.187 D_real: 0.574 D_fake: 0.646 \n",
      "saving the latest model (epoch 104, total_steps 235000)\n",
      "(epoch: 104, iters: 260, time: 0.072, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.758 D_fake: 0.637 \n",
      "(epoch: 104, iters: 360, time: 0.074, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.704 D_fake: 0.682 \n",
      "(epoch: 104, iters: 460, time: 0.075, data: 0.002) G_GAN: 0.806 G_L1: 2.055 D_real: 0.571 D_fake: 0.640 \n",
      "(epoch: 104, iters: 560, time: 0.079, data: 0.005) G_GAN: 0.745 G_L1: 0.000 D_real: 0.752 D_fake: 0.622 \n",
      "(epoch: 104, iters: 660, time: 0.078, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.743 D_fake: 0.644 \n",
      "(epoch: 104, iters: 760, time: 0.082, data: 0.003) G_GAN: 0.833 G_L1: 2.009 D_real: 0.577 D_fake: 0.621 \n",
      "(epoch: 104, iters: 860, time: 0.082, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.760 D_fake: 0.545 \n",
      "(epoch: 104, iters: 960, time: 0.076, data: 0.002) G_GAN: 0.673 G_L1: 0.000 D_real: 0.671 D_fake: 0.735 \n",
      "(epoch: 104, iters: 1060, time: 0.083, data: 0.002) G_GAN: 0.764 G_L1: 0.699 D_real: 0.608 D_fake: 0.669 \n",
      "(epoch: 104, iters: 1160, time: 0.078, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.774 D_fake: 0.610 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 104, iters: 1260, time: 0.070, data: 0.002) G_GAN: 0.654 G_L1: 0.000 D_real: 0.663 D_fake: 0.694 \n",
      "(epoch: 104, iters: 1360, time: 0.071, data: 0.002) G_GAN: 0.805 G_L1: 2.029 D_real: 0.572 D_fake: 0.588 \n",
      "(epoch: 104, iters: 1460, time: 0.071, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.816 D_fake: 0.605 \n",
      "(epoch: 104, iters: 1560, time: 0.072, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.733 D_fake: 0.654 \n",
      "(epoch: 104, iters: 1660, time: 0.072, data: 0.002) G_GAN: 0.816 G_L1: 1.703 D_real: 0.585 D_fake: 0.618 \n",
      "(epoch: 104, iters: 1760, time: 0.071, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.733 D_fake: 0.651 \n",
      "(epoch: 104, iters: 1860, time: 0.071, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.711 D_fake: 0.667 \n",
      "(epoch: 104, iters: 1960, time: 0.073, data: 0.002) G_GAN: 0.829 G_L1: 2.015 D_real: 0.586 D_fake: 0.612 \n",
      "(epoch: 104, iters: 2060, time: 0.072, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.757 D_fake: 0.664 \n",
      "(epoch: 104, iters: 2160, time: 0.077, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.754 D_fake: 0.621 \n",
      "(epoch: 104, iters: 2260, time: 0.075, data: 0.002) G_GAN: 0.828 G_L1: 2.749 D_real: 0.543 D_fake: 0.649 \n",
      "End of epoch 104 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0015208\n",
      "(epoch: 105, iters: 80, time: 0.075, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.738 D_fake: 0.647 \n",
      "(epoch: 105, iters: 180, time: 0.077, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.720 D_fake: 0.670 \n",
      "(epoch: 105, iters: 280, time: 0.075, data: 0.002) G_GAN: 0.825 G_L1: 1.026 D_real: 0.594 D_fake: 0.645 \n",
      "(epoch: 105, iters: 380, time: 0.075, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.792 D_fake: 0.609 \n",
      "(epoch: 105, iters: 480, time: 0.074, data: 0.003) G_GAN: 0.717 G_L1: 0.000 D_real: 0.727 D_fake: 0.637 \n",
      "(epoch: 105, iters: 580, time: 0.074, data: 0.003) G_GAN: 0.875 G_L1: 3.541 D_real: 0.535 D_fake: 0.622 \n",
      "(epoch: 105, iters: 680, time: 0.073, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.740 D_fake: 0.600 \n",
      "(epoch: 105, iters: 780, time: 0.072, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.704 D_fake: 0.679 \n",
      "(epoch: 105, iters: 880, time: 0.070, data: 0.002) G_GAN: 0.751 G_L1: 2.571 D_real: 0.586 D_fake: 0.537 \n",
      "(epoch: 105, iters: 980, time: 0.073, data: 0.003) G_GAN: 0.774 G_L1: 0.000 D_real: 0.770 D_fake: 0.613 \n",
      "(epoch: 105, iters: 1080, time: 0.083, data: 0.002) G_GAN: 0.702 G_L1: 0.000 D_real: 0.710 D_fake: 0.653 \n",
      "(epoch: 105, iters: 1180, time: 0.077, data: 0.002) G_GAN: 0.795 G_L1: 2.021 D_real: 0.576 D_fake: 0.661 \n",
      "(epoch: 105, iters: 1280, time: 0.073, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.749 D_fake: 0.655 \n",
      "(epoch: 105, iters: 1380, time: 0.071, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.748 D_fake: 0.649 \n",
      "(epoch: 105, iters: 1480, time: 0.071, data: 0.002) G_GAN: 0.815 G_L1: 1.813 D_real: 0.573 D_fake: 0.626 \n",
      "(epoch: 105, iters: 1580, time: 0.072, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.742 D_fake: 0.640 \n",
      "(epoch: 105, iters: 1680, time: 0.071, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.757 D_fake: 0.640 \n",
      "(epoch: 105, iters: 1780, time: 0.073, data: 0.001) G_GAN: 0.797 G_L1: 2.503 D_real: 0.552 D_fake: 0.621 \n",
      "(epoch: 105, iters: 1880, time: 0.072, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.753 D_fake: 0.658 \n",
      "(epoch: 105, iters: 1980, time: 0.072, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.725 D_fake: 0.646 \n",
      "(epoch: 105, iters: 2080, time: 0.071, data: 0.002) G_GAN: 0.768 G_L1: 2.297 D_real: 0.532 D_fake: 0.632 \n",
      "(epoch: 105, iters: 2180, time: 0.071, data: 0.003) G_GAN: 0.739 G_L1: 0.000 D_real: 0.740 D_fake: 0.652 \n",
      "(epoch: 105, iters: 2280, time: 0.070, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.694 D_fake: 0.706 \n",
      "saving the model at the end of epoch 105, iters 239400\n",
      "End of epoch 105 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0015050\n",
      "(epoch: 106, iters: 100, time: 0.073, data: 0.408) G_GAN: 0.807 G_L1: 2.485 D_real: 0.562 D_fake: 0.673 \n",
      "(epoch: 106, iters: 200, time: 0.071, data: 0.003) G_GAN: 0.714 G_L1: 0.000 D_real: 0.725 D_fake: 0.656 \n",
      "(epoch: 106, iters: 300, time: 0.072, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.687 D_fake: 0.693 \n",
      "(epoch: 106, iters: 400, time: 0.073, data: 0.002) G_GAN: 0.808 G_L1: 1.437 D_real: 0.571 D_fake: 0.659 \n",
      "(epoch: 106, iters: 500, time: 0.075, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.749 D_fake: 0.630 \n",
      "(epoch: 106, iters: 600, time: 0.076, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.757 D_fake: 0.635 \n",
      "saving the latest model (epoch 106, total_steps 240000)\n",
      "(epoch: 106, iters: 700, time: 0.072, data: 0.002) G_GAN: 0.847 G_L1: 1.919 D_real: 0.562 D_fake: 0.611 \n",
      "(epoch: 106, iters: 800, time: 0.072, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.736 D_fake: 0.666 \n",
      "(epoch: 106, iters: 900, time: 0.073, data: 0.003) G_GAN: 0.702 G_L1: 0.000 D_real: 0.715 D_fake: 0.675 \n",
      "(epoch: 106, iters: 1000, time: 0.073, data: 0.002) G_GAN: 0.842 G_L1: 1.678 D_real: 0.590 D_fake: 0.604 \n",
      "(epoch: 106, iters: 1100, time: 0.071, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.795 D_fake: 0.600 \n",
      "(epoch: 106, iters: 1200, time: 0.071, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.720 D_fake: 0.607 \n",
      "(epoch: 106, iters: 1300, time: 0.072, data: 0.002) G_GAN: 0.834 G_L1: 1.744 D_real: 0.613 D_fake: 0.630 \n",
      "(epoch: 106, iters: 1400, time: 0.072, data: 0.002) G_GAN: 0.797 G_L1: 0.000 D_real: 0.818 D_fake: 0.579 \n",
      "(epoch: 106, iters: 1500, time: 0.072, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.727 D_fake: 0.661 \n",
      "(epoch: 106, iters: 1600, time: 0.072, data: 0.002) G_GAN: 0.839 G_L1: 2.124 D_real: 0.568 D_fake: 0.625 \n",
      "(epoch: 106, iters: 1700, time: 0.071, data: 0.002) G_GAN: 0.777 G_L1: 0.000 D_real: 0.792 D_fake: 0.609 \n",
      "(epoch: 106, iters: 1800, time: 0.072, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.727 D_fake: 0.671 \n",
      "(epoch: 106, iters: 1900, time: 0.075, data: 0.002) G_GAN: 0.822 G_L1: 3.702 D_real: 0.518 D_fake: 0.633 \n",
      "(epoch: 106, iters: 2000, time: 0.073, data: 0.003) G_GAN: 0.761 G_L1: 0.000 D_real: 0.770 D_fake: 0.626 \n",
      "(epoch: 106, iters: 2100, time: 0.075, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.708 D_fake: 0.679 \n",
      "(epoch: 106, iters: 2200, time: 0.071, data: 0.003) G_GAN: 0.861 G_L1: 1.583 D_real: 0.590 D_fake: 0.622 \n",
      "End of epoch 106 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0014891\n",
      "(epoch: 107, iters: 20, time: 0.073, data: 0.001) G_GAN: 0.751 G_L1: 0.000 D_real: 0.788 D_fake: 0.596 \n",
      "(epoch: 107, iters: 120, time: 0.074, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.739 D_fake: 0.643 \n",
      "(epoch: 107, iters: 220, time: 0.073, data: 0.002) G_GAN: 0.818 G_L1: 2.749 D_real: 0.515 D_fake: 0.676 \n",
      "(epoch: 107, iters: 320, time: 0.074, data: 0.003) G_GAN: 0.747 G_L1: 0.000 D_real: 0.752 D_fake: 0.654 \n",
      "(epoch: 107, iters: 420, time: 0.076, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.735 D_fake: 0.649 \n",
      "(epoch: 107, iters: 520, time: 0.074, data: 0.002) G_GAN: 0.850 G_L1: 1.419 D_real: 0.622 D_fake: 0.626 \n",
      "(epoch: 107, iters: 620, time: 0.071, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.741 D_fake: 0.660 \n",
      "(epoch: 107, iters: 720, time: 0.074, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.733 D_fake: 0.656 \n",
      "(epoch: 107, iters: 820, time: 0.072, data: 0.002) G_GAN: 0.835 G_L1: 1.824 D_real: 0.590 D_fake: 0.643 \n",
      "(epoch: 107, iters: 920, time: 0.070, data: 0.002) G_GAN: 0.673 G_L1: 0.000 D_real: 0.635 D_fake: 0.723 \n",
      "(epoch: 107, iters: 1020, time: 0.072, data: 0.002) G_GAN: 0.654 G_L1: 0.000 D_real: 0.667 D_fake: 0.645 \n",
      "(epoch: 107, iters: 1120, time: 0.070, data: 0.003) G_GAN: 0.821 G_L1: 1.957 D_real: 0.565 D_fake: 0.670 \n",
      "(epoch: 107, iters: 1220, time: 0.072, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.732 D_fake: 0.644 \n",
      "(epoch: 107, iters: 1320, time: 0.075, data: 0.003) G_GAN: 0.725 G_L1: 0.000 D_real: 0.733 D_fake: 0.661 \n",
      "(epoch: 107, iters: 1420, time: 0.076, data: 0.003) G_GAN: 0.816 G_L1: 2.010 D_real: 0.558 D_fake: 0.659 \n",
      "(epoch: 107, iters: 1520, time: 0.073, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.736 D_fake: 0.650 \n",
      "(epoch: 107, iters: 1620, time: 0.071, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.726 D_fake: 0.633 \n",
      "(epoch: 107, iters: 1720, time: 0.072, data: 0.002) G_GAN: 0.890 G_L1: 3.150 D_real: 0.532 D_fake: 0.654 \n",
      "(epoch: 107, iters: 1820, time: 0.073, data: 0.002) G_GAN: 0.776 G_L1: 0.000 D_real: 0.784 D_fake: 0.616 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 107, iters: 1920, time: 0.072, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.704 D_fake: 0.639 \n",
      "(epoch: 107, iters: 2020, time: 0.075, data: 0.003) G_GAN: 0.834 G_L1: 1.672 D_real: 0.595 D_fake: 0.613 \n",
      "(epoch: 107, iters: 2120, time: 0.071, data: 0.002) G_GAN: 0.667 G_L1: 0.000 D_real: 0.848 D_fake: 0.579 \n",
      "(epoch: 107, iters: 2220, time: 0.072, data: 0.002) G_GAN: 0.683 G_L1: 0.000 D_real: 0.592 D_fake: 0.831 \n",
      "End of epoch 107 / 200 \t Time Taken: 108 sec\n",
      "learning rate = 0.0014733\n",
      "(epoch: 108, iters: 40, time: 0.073, data: 0.002) G_GAN: 0.790 G_L1: 1.820 D_real: 0.563 D_fake: 0.626 \n",
      "(epoch: 108, iters: 140, time: 0.071, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.763 D_fake: 0.599 \n",
      "(epoch: 108, iters: 240, time: 0.072, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.717 D_fake: 0.661 \n",
      "(epoch: 108, iters: 340, time: 0.071, data: 0.002) G_GAN: 0.813 G_L1: 1.290 D_real: 0.583 D_fake: 0.648 \n",
      "(epoch: 108, iters: 440, time: 0.071, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.738 D_fake: 0.651 \n",
      "(epoch: 108, iters: 540, time: 0.071, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.717 D_fake: 0.653 \n",
      "(epoch: 108, iters: 640, time: 0.075, data: 0.002) G_GAN: 0.828 G_L1: 2.682 D_real: 0.561 D_fake: 0.633 \n",
      "(epoch: 108, iters: 740, time: 0.071, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.736 D_fake: 0.639 \n",
      "(epoch: 108, iters: 840, time: 0.073, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.722 D_fake: 0.658 \n",
      "(epoch: 108, iters: 940, time: 0.074, data: 0.003) G_GAN: 0.887 G_L1: 3.230 D_real: 0.560 D_fake: 0.611 \n",
      "(epoch: 108, iters: 1040, time: 0.072, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.751 D_fake: 0.640 \n",
      "saving the latest model (epoch 108, total_steps 245000)\n",
      "(epoch: 108, iters: 1140, time: 0.072, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.749 D_fake: 0.636 \n",
      "(epoch: 108, iters: 1240, time: 0.071, data: 0.002) G_GAN: 0.808 G_L1: 2.399 D_real: 0.792 D_fake: 0.542 \n",
      "(epoch: 108, iters: 1340, time: 0.074, data: 0.003) G_GAN: 0.773 G_L1: 0.000 D_real: 0.783 D_fake: 0.625 \n",
      "(epoch: 108, iters: 1440, time: 0.073, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.730 D_fake: 0.626 \n",
      "(epoch: 108, iters: 1540, time: 0.073, data: 0.002) G_GAN: 0.853 G_L1: 1.508 D_real: 0.613 D_fake: 0.646 \n",
      "(epoch: 108, iters: 1640, time: 0.072, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.757 D_fake: 0.631 \n",
      "(epoch: 108, iters: 1740, time: 0.072, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.734 D_fake: 0.628 \n",
      "(epoch: 108, iters: 1840, time: 0.072, data: 0.002) G_GAN: 0.792 G_L1: 0.842 D_real: 0.588 D_fake: 0.660 \n",
      "(epoch: 108, iters: 1940, time: 0.073, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.771 D_fake: 0.613 \n",
      "(epoch: 108, iters: 2040, time: 0.071, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.731 D_fake: 0.650 \n",
      "(epoch: 108, iters: 2140, time: 0.074, data: 0.003) G_GAN: 0.870 G_L1: 0.917 D_real: 0.630 D_fake: 0.604 \n",
      "(epoch: 108, iters: 2240, time: 0.077, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.759 D_fake: 0.559 \n",
      "End of epoch 108 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0014574\n",
      "(epoch: 109, iters: 60, time: 0.078, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.733 D_fake: 0.644 \n",
      "(epoch: 109, iters: 160, time: 0.073, data: 0.001) G_GAN: 0.878 G_L1: 2.187 D_real: 0.575 D_fake: 0.585 \n",
      "(epoch: 109, iters: 260, time: 0.074, data: 0.002) G_GAN: 0.773 G_L1: 0.000 D_real: 0.800 D_fake: 0.606 \n",
      "(epoch: 109, iters: 360, time: 0.073, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.721 D_fake: 0.661 \n",
      "(epoch: 109, iters: 460, time: 0.076, data: 0.002) G_GAN: 0.837 G_L1: 2.055 D_real: 0.569 D_fake: 0.631 \n",
      "(epoch: 109, iters: 560, time: 0.072, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.759 D_fake: 0.621 \n",
      "(epoch: 109, iters: 660, time: 0.072, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.739 D_fake: 0.639 \n",
      "(epoch: 109, iters: 760, time: 0.073, data: 0.002) G_GAN: 0.897 G_L1: 2.009 D_real: 0.611 D_fake: 0.590 \n",
      "(epoch: 109, iters: 860, time: 0.072, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.796 D_fake: 0.573 \n",
      "(epoch: 109, iters: 960, time: 0.074, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.700 D_fake: 0.590 \n",
      "(epoch: 109, iters: 1060, time: 0.071, data: 0.003) G_GAN: 0.781 G_L1: 0.699 D_real: 0.611 D_fake: 0.650 \n",
      "(epoch: 109, iters: 1160, time: 0.071, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.797 D_fake: 0.642 \n",
      "(epoch: 109, iters: 1260, time: 0.076, data: 0.003) G_GAN: 0.657 G_L1: 0.000 D_real: 0.666 D_fake: 0.729 \n",
      "(epoch: 109, iters: 1360, time: 0.076, data: 0.002) G_GAN: 0.790 G_L1: 2.029 D_real: 0.575 D_fake: 0.641 \n",
      "(epoch: 109, iters: 1460, time: 0.075, data: 0.002) G_GAN: 0.772 G_L1: 0.000 D_real: 0.803 D_fake: 0.610 \n",
      "(epoch: 109, iters: 1560, time: 0.075, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.728 D_fake: 0.655 \n",
      "(epoch: 109, iters: 1660, time: 0.074, data: 0.003) G_GAN: 0.816 G_L1: 1.703 D_real: 0.569 D_fake: 0.639 \n",
      "(epoch: 109, iters: 1760, time: 0.071, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.734 D_fake: 0.649 \n",
      "(epoch: 109, iters: 1860, time: 0.071, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.707 D_fake: 0.669 \n",
      "(epoch: 109, iters: 1960, time: 0.071, data: 0.002) G_GAN: 0.828 G_L1: 2.015 D_real: 0.568 D_fake: 0.628 \n",
      "(epoch: 109, iters: 2060, time: 0.071, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.748 D_fake: 0.625 \n",
      "(epoch: 109, iters: 2160, time: 0.073, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.714 D_fake: 0.655 \n",
      "(epoch: 109, iters: 2260, time: 0.071, data: 0.003) G_GAN: 0.900 G_L1: 2.749 D_real: 0.586 D_fake: 0.659 \n",
      "End of epoch 109 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0014416\n",
      "(epoch: 110, iters: 80, time: 0.072, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.749 D_fake: 0.620 \n",
      "(epoch: 110, iters: 180, time: 0.074, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.727 D_fake: 0.647 \n",
      "(epoch: 110, iters: 280, time: 0.072, data: 0.002) G_GAN: 0.844 G_L1: 1.026 D_real: 0.591 D_fake: 0.641 \n",
      "(epoch: 110, iters: 380, time: 0.073, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.777 D_fake: 0.639 \n",
      "(epoch: 110, iters: 480, time: 0.072, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.718 D_fake: 0.624 \n",
      "(epoch: 110, iters: 580, time: 0.072, data: 0.002) G_GAN: 0.890 G_L1: 3.541 D_real: 0.521 D_fake: 0.618 \n",
      "(epoch: 110, iters: 680, time: 0.074, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.736 D_fake: 0.652 \n",
      "(epoch: 110, iters: 780, time: 0.071, data: 0.002) G_GAN: 0.702 G_L1: 0.000 D_real: 0.709 D_fake: 0.686 \n",
      "(epoch: 110, iters: 880, time: 0.070, data: 0.002) G_GAN: 0.856 G_L1: 2.571 D_real: 0.546 D_fake: 0.581 \n",
      "(epoch: 110, iters: 980, time: 0.073, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.764 D_fake: 0.615 \n",
      "(epoch: 110, iters: 1080, time: 0.072, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.699 D_fake: 0.679 \n",
      "(epoch: 110, iters: 1180, time: 0.073, data: 0.002) G_GAN: 0.833 G_L1: 2.021 D_real: 0.570 D_fake: 0.615 \n",
      "(epoch: 110, iters: 1280, time: 0.073, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.773 D_fake: 0.638 \n",
      "(epoch: 110, iters: 1380, time: 0.070, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.724 D_fake: 0.645 \n",
      "(epoch: 110, iters: 1480, time: 0.073, data: 0.002) G_GAN: 0.874 G_L1: 1.813 D_real: 0.586 D_fake: 0.647 \n",
      "saving the latest model (epoch 110, total_steps 250000)\n",
      "(epoch: 110, iters: 1580, time: 0.072, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.753 D_fake: 0.655 \n",
      "(epoch: 110, iters: 1680, time: 0.070, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.728 D_fake: 0.668 \n",
      "(epoch: 110, iters: 1780, time: 0.071, data: 0.001) G_GAN: 0.859 G_L1: 2.503 D_real: 0.561 D_fake: 0.609 \n",
      "(epoch: 110, iters: 1880, time: 0.071, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.739 D_fake: 0.660 \n",
      "(epoch: 110, iters: 1980, time: 0.072, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.705 D_fake: 0.651 \n",
      "(epoch: 110, iters: 2080, time: 0.073, data: 0.003) G_GAN: 0.806 G_L1: 2.297 D_real: 0.539 D_fake: 0.649 \n",
      "(epoch: 110, iters: 2180, time: 0.072, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.815 D_fake: 0.591 \n",
      "(epoch: 110, iters: 2280, time: 0.071, data: 0.003) G_GAN: 0.647 G_L1: 0.000 D_real: 0.606 D_fake: 0.755 \n",
      "saving the model at the end of epoch 110, iters 250800\n",
      "End of epoch 110 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0014257\n",
      "(epoch: 111, iters: 100, time: 0.073, data: 0.396) G_GAN: 0.780 G_L1: 2.485 D_real: 0.547 D_fake: 0.675 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 111, iters: 200, time: 0.070, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.739 D_fake: 0.660 \n",
      "(epoch: 111, iters: 300, time: 0.072, data: 0.003) G_GAN: 0.721 G_L1: 0.000 D_real: 0.728 D_fake: 0.661 \n",
      "(epoch: 111, iters: 400, time: 0.072, data: 0.003) G_GAN: 0.853 G_L1: 1.437 D_real: 0.589 D_fake: 0.636 \n",
      "(epoch: 111, iters: 500, time: 0.074, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.755 D_fake: 0.617 \n",
      "(epoch: 111, iters: 600, time: 0.075, data: 0.003) G_GAN: 0.736 G_L1: 0.000 D_real: 0.746 D_fake: 0.649 \n",
      "(epoch: 111, iters: 700, time: 0.075, data: 0.002) G_GAN: 0.913 G_L1: 1.919 D_real: 0.579 D_fake: 0.568 \n",
      "(epoch: 111, iters: 800, time: 0.072, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.761 D_fake: 0.642 \n",
      "(epoch: 111, iters: 900, time: 0.070, data: 0.001) G_GAN: 0.669 G_L1: 0.000 D_real: 0.702 D_fake: 0.675 \n",
      "(epoch: 111, iters: 1000, time: 0.072, data: 0.002) G_GAN: 0.821 G_L1: 1.678 D_real: 0.587 D_fake: 0.625 \n",
      "(epoch: 111, iters: 1100, time: 0.073, data: 0.003) G_GAN: 0.788 G_L1: 0.000 D_real: 0.816 D_fake: 0.585 \n",
      "(epoch: 111, iters: 1200, time: 0.074, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.735 D_fake: 0.656 \n",
      "(epoch: 111, iters: 1300, time: 0.073, data: 0.002) G_GAN: 0.879 G_L1: 1.744 D_real: 0.633 D_fake: 0.596 \n",
      "(epoch: 111, iters: 1400, time: 0.073, data: 0.002) G_GAN: 0.801 G_L1: 0.000 D_real: 0.822 D_fake: 0.582 \n",
      "(epoch: 111, iters: 1500, time: 0.073, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.723 D_fake: 0.664 \n",
      "(epoch: 111, iters: 1600, time: 0.074, data: 0.002) G_GAN: 0.852 G_L1: 2.124 D_real: 0.566 D_fake: 0.624 \n",
      "(epoch: 111, iters: 1700, time: 0.073, data: 0.002) G_GAN: 0.782 G_L1: 0.000 D_real: 0.788 D_fake: 0.601 \n",
      "(epoch: 111, iters: 1800, time: 0.072, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.731 D_fake: 0.634 \n",
      "(epoch: 111, iters: 1900, time: 0.073, data: 0.003) G_GAN: 0.824 G_L1: 3.702 D_real: 0.531 D_fake: 0.653 \n",
      "(epoch: 111, iters: 2000, time: 0.071, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.777 D_fake: 0.614 \n",
      "(epoch: 111, iters: 2100, time: 0.071, data: 0.003) G_GAN: 0.676 G_L1: 0.000 D_real: 0.686 D_fake: 0.675 \n",
      "(epoch: 111, iters: 2200, time: 0.074, data: 0.002) G_GAN: 0.827 G_L1: 1.583 D_real: 0.590 D_fake: 0.607 \n",
      "End of epoch 111 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0014099\n",
      "(epoch: 112, iters: 20, time: 0.076, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.742 D_fake: 0.608 \n",
      "(epoch: 112, iters: 120, time: 0.072, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.749 D_fake: 0.636 \n",
      "(epoch: 112, iters: 220, time: 0.074, data: 0.002) G_GAN: 0.846 G_L1: 2.749 D_real: 0.529 D_fake: 0.638 \n",
      "(epoch: 112, iters: 320, time: 0.071, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.753 D_fake: 0.666 \n",
      "(epoch: 112, iters: 420, time: 0.071, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.737 D_fake: 0.655 \n",
      "(epoch: 112, iters: 520, time: 0.074, data: 0.002) G_GAN: 0.820 G_L1: 1.419 D_real: 0.605 D_fake: 0.631 \n",
      "(epoch: 112, iters: 620, time: 0.073, data: 0.003) G_GAN: 0.754 G_L1: 0.000 D_real: 0.769 D_fake: 0.630 \n",
      "(epoch: 112, iters: 720, time: 0.072, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.711 D_fake: 0.670 \n",
      "(epoch: 112, iters: 820, time: 0.073, data: 0.003) G_GAN: 0.831 G_L1: 1.824 D_real: 0.593 D_fake: 0.643 \n",
      "(epoch: 112, iters: 920, time: 0.074, data: 0.003) G_GAN: 0.703 G_L1: 0.000 D_real: 0.720 D_fake: 0.644 \n",
      "(epoch: 112, iters: 1020, time: 0.072, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.736 D_fake: 0.621 \n",
      "(epoch: 112, iters: 1120, time: 0.072, data: 0.002) G_GAN: 0.900 G_L1: 1.957 D_real: 0.587 D_fake: 0.587 \n",
      "(epoch: 112, iters: 1220, time: 0.076, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.756 D_fake: 0.649 \n",
      "(epoch: 112, iters: 1320, time: 0.072, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.716 D_fake: 0.653 \n",
      "(epoch: 112, iters: 1420, time: 0.073, data: 0.003) G_GAN: 0.838 G_L1: 2.010 D_real: 0.537 D_fake: 0.650 \n",
      "(epoch: 112, iters: 1520, time: 0.072, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.730 D_fake: 0.640 \n",
      "(epoch: 112, iters: 1620, time: 0.070, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.732 D_fake: 0.641 \n",
      "(epoch: 112, iters: 1720, time: 0.072, data: 0.002) G_GAN: 0.909 G_L1: 3.150 D_real: 0.536 D_fake: 0.626 \n",
      "(epoch: 112, iters: 1820, time: 0.076, data: 0.003) G_GAN: 0.780 G_L1: 0.000 D_real: 0.796 D_fake: 0.610 \n",
      "(epoch: 112, iters: 1920, time: 0.073, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.723 D_fake: 0.671 \n",
      "saving the latest model (epoch 112, total_steps 255000)\n",
      "(epoch: 112, iters: 2020, time: 0.073, data: 0.002) G_GAN: 0.828 G_L1: 1.672 D_real: 0.597 D_fake: 0.644 \n",
      "(epoch: 112, iters: 2120, time: 0.073, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.779 D_fake: 0.631 \n",
      "(epoch: 112, iters: 2220, time: 0.072, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.710 D_fake: 0.666 \n",
      "End of epoch 112 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0013941\n",
      "(epoch: 113, iters: 40, time: 0.090, data: 0.002) G_GAN: 0.849 G_L1: 1.820 D_real: 0.560 D_fake: 0.633 \n",
      "(epoch: 113, iters: 140, time: 0.072, data: 0.003) G_GAN: 0.745 G_L1: 0.000 D_real: 0.754 D_fake: 0.636 \n",
      "(epoch: 113, iters: 240, time: 0.075, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.706 D_fake: 0.671 \n",
      "(epoch: 113, iters: 340, time: 0.071, data: 0.002) G_GAN: 0.762 G_L1: 1.290 D_real: 0.575 D_fake: 0.654 \n",
      "(epoch: 113, iters: 440, time: 0.072, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.752 D_fake: 0.627 \n",
      "(epoch: 113, iters: 540, time: 0.073, data: 0.003) G_GAN: 0.675 G_L1: 0.000 D_real: 0.688 D_fake: 0.685 \n",
      "(epoch: 113, iters: 640, time: 0.074, data: 0.002) G_GAN: 0.839 G_L1: 2.682 D_real: 0.568 D_fake: 0.633 \n",
      "(epoch: 113, iters: 740, time: 0.077, data: 0.003) G_GAN: 0.716 G_L1: 0.000 D_real: 0.727 D_fake: 0.664 \n",
      "(epoch: 113, iters: 840, time: 0.071, data: 0.002) G_GAN: 0.671 G_L1: 0.000 D_real: 0.686 D_fake: 0.686 \n",
      "(epoch: 113, iters: 940, time: 0.074, data: 0.002) G_GAN: 0.998 G_L1: 3.230 D_real: 0.571 D_fake: 0.577 \n",
      "(epoch: 113, iters: 1040, time: 0.076, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.752 D_fake: 0.653 \n",
      "(epoch: 113, iters: 1140, time: 0.073, data: 0.003) G_GAN: 0.737 G_L1: 0.000 D_real: 0.745 D_fake: 0.643 \n",
      "(epoch: 113, iters: 1240, time: 0.070, data: 0.003) G_GAN: 1.052 G_L1: 2.399 D_real: 0.645 D_fake: 0.578 \n",
      "(epoch: 113, iters: 1340, time: 0.071, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.791 D_fake: 0.608 \n",
      "(epoch: 113, iters: 1440, time: 0.073, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.739 D_fake: 0.633 \n",
      "(epoch: 113, iters: 1540, time: 0.071, data: 0.002) G_GAN: 0.886 G_L1: 1.508 D_real: 0.595 D_fake: 0.599 \n",
      "(epoch: 113, iters: 1640, time: 0.072, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.764 D_fake: 0.622 \n",
      "(epoch: 113, iters: 1740, time: 0.072, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.737 D_fake: 0.643 \n",
      "(epoch: 113, iters: 1840, time: 0.074, data: 0.003) G_GAN: 0.847 G_L1: 0.842 D_real: 0.626 D_fake: 0.618 \n",
      "(epoch: 113, iters: 1940, time: 0.080, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.755 D_fake: 0.632 \n",
      "(epoch: 113, iters: 2040, time: 0.076, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.716 D_fake: 0.640 \n",
      "(epoch: 113, iters: 2140, time: 0.076, data: 0.002) G_GAN: 0.875 G_L1: 0.917 D_real: 0.626 D_fake: 0.617 \n",
      "(epoch: 113, iters: 2240, time: 0.076, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.797 D_fake: 0.558 \n",
      "End of epoch 113 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0013782\n",
      "(epoch: 114, iters: 60, time: 0.075, data: 0.003) G_GAN: 0.675 G_L1: 0.000 D_real: 0.683 D_fake: 0.719 \n",
      "(epoch: 114, iters: 160, time: 0.072, data: 0.001) G_GAN: 0.901 G_L1: 2.187 D_real: 0.580 D_fake: 0.604 \n",
      "(epoch: 114, iters: 260, time: 0.074, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.781 D_fake: 0.627 \n",
      "(epoch: 114, iters: 360, time: 0.072, data: 0.002) G_GAN: 0.678 G_L1: 0.000 D_real: 0.686 D_fake: 0.702 \n",
      "(epoch: 114, iters: 460, time: 0.074, data: 0.002) G_GAN: 0.853 G_L1: 2.055 D_real: 0.574 D_fake: 0.644 \n",
      "(epoch: 114, iters: 560, time: 0.074, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.757 D_fake: 0.630 \n",
      "(epoch: 114, iters: 660, time: 0.075, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.750 D_fake: 0.620 \n",
      "(epoch: 114, iters: 760, time: 0.071, data: 0.003) G_GAN: 0.831 G_L1: 2.009 D_real: 0.533 D_fake: 0.660 \n",
      "(epoch: 114, iters: 860, time: 0.073, data: 0.002) G_GAN: 0.766 G_L1: 0.000 D_real: 0.773 D_fake: 0.622 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 114, iters: 960, time: 0.072, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.724 D_fake: 0.637 \n",
      "(epoch: 114, iters: 1060, time: 0.075, data: 0.002) G_GAN: 0.769 G_L1: 0.699 D_real: 0.608 D_fake: 0.663 \n",
      "(epoch: 114, iters: 1160, time: 0.071, data: 0.003) G_GAN: 0.700 G_L1: 0.000 D_real: 0.832 D_fake: 0.646 \n",
      "(epoch: 114, iters: 1260, time: 0.070, data: 0.002) G_GAN: 0.680 G_L1: 0.000 D_real: 0.689 D_fake: 0.707 \n",
      "(epoch: 114, iters: 1360, time: 0.072, data: 0.002) G_GAN: 0.826 G_L1: 2.029 D_real: 0.573 D_fake: 0.630 \n",
      "(epoch: 114, iters: 1460, time: 0.073, data: 0.002) G_GAN: 0.762 G_L1: 0.000 D_real: 0.781 D_fake: 0.602 \n",
      "(epoch: 114, iters: 1560, time: 0.071, data: 0.004) G_GAN: 0.706 G_L1: 0.000 D_real: 0.720 D_fake: 0.647 \n",
      "(epoch: 114, iters: 1660, time: 0.074, data: 0.002) G_GAN: 0.851 G_L1: 1.703 D_real: 0.580 D_fake: 0.624 \n",
      "(epoch: 114, iters: 1760, time: 0.075, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.726 D_fake: 0.650 \n",
      "(epoch: 114, iters: 1860, time: 0.074, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.717 D_fake: 0.665 \n",
      "(epoch: 114, iters: 1960, time: 0.072, data: 0.002) G_GAN: 0.844 G_L1: 2.015 D_real: 0.584 D_fake: 0.612 \n",
      "(epoch: 114, iters: 2060, time: 0.071, data: 0.003) G_GAN: 0.714 G_L1: 0.000 D_real: 0.732 D_fake: 0.681 \n",
      "(epoch: 114, iters: 2160, time: 0.073, data: 0.003) G_GAN: 0.715 G_L1: 0.000 D_real: 0.722 D_fake: 0.672 \n",
      "(epoch: 114, iters: 2260, time: 0.071, data: 0.002) G_GAN: 0.865 G_L1: 2.749 D_real: 0.550 D_fake: 0.623 \n",
      "End of epoch 114 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0013624\n",
      "(epoch: 115, iters: 80, time: 0.074, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.770 D_fake: 0.616 \n",
      "saving the latest model (epoch 115, total_steps 260000)\n",
      "(epoch: 115, iters: 180, time: 0.074, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.729 D_fake: 0.650 \n",
      "(epoch: 115, iters: 280, time: 0.071, data: 0.002) G_GAN: 0.870 G_L1: 1.026 D_real: 0.604 D_fake: 0.624 \n",
      "(epoch: 115, iters: 380, time: 0.073, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.774 D_fake: 0.654 \n",
      "(epoch: 115, iters: 480, time: 0.074, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.721 D_fake: 0.673 \n",
      "(epoch: 115, iters: 580, time: 0.074, data: 0.002) G_GAN: 0.910 G_L1: 3.541 D_real: 0.526 D_fake: 0.649 \n",
      "(epoch: 115, iters: 680, time: 0.073, data: 0.003) G_GAN: 0.729 G_L1: 0.000 D_real: 0.736 D_fake: 0.640 \n",
      "(epoch: 115, iters: 780, time: 0.071, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.697 D_fake: 0.685 \n",
      "(epoch: 115, iters: 880, time: 0.071, data: 0.002) G_GAN: 0.892 G_L1: 2.571 D_real: 0.545 D_fake: 0.621 \n",
      "(epoch: 115, iters: 980, time: 0.072, data: 0.003) G_GAN: 0.767 G_L1: 0.000 D_real: 0.767 D_fake: 0.629 \n",
      "(epoch: 115, iters: 1080, time: 0.072, data: 0.003) G_GAN: 0.660 G_L1: 0.000 D_real: 0.679 D_fake: 0.682 \n",
      "(epoch: 115, iters: 1180, time: 0.071, data: 0.002) G_GAN: 0.817 G_L1: 2.021 D_real: 0.564 D_fake: 0.633 \n",
      "(epoch: 115, iters: 1280, time: 0.071, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.723 D_fake: 0.663 \n",
      "(epoch: 115, iters: 1380, time: 0.073, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.721 D_fake: 0.661 \n",
      "(epoch: 115, iters: 1480, time: 0.071, data: 0.002) G_GAN: 0.871 G_L1: 1.813 D_real: 0.574 D_fake: 0.624 \n",
      "(epoch: 115, iters: 1580, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.757 D_fake: 0.636 \n",
      "(epoch: 115, iters: 1680, time: 0.074, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.718 D_fake: 0.634 \n",
      "(epoch: 115, iters: 1780, time: 0.072, data: 0.003) G_GAN: 0.846 G_L1: 2.503 D_real: 0.559 D_fake: 0.651 \n",
      "(epoch: 115, iters: 1880, time: 0.071, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.743 D_fake: 0.669 \n",
      "(epoch: 115, iters: 1980, time: 0.073, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.712 D_fake: 0.633 \n",
      "(epoch: 115, iters: 2080, time: 0.071, data: 0.002) G_GAN: 0.803 G_L1: 2.297 D_real: 0.545 D_fake: 0.639 \n",
      "(epoch: 115, iters: 2180, time: 0.073, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.752 D_fake: 0.646 \n",
      "(epoch: 115, iters: 2280, time: 0.075, data: 0.002) G_GAN: 0.640 G_L1: 0.000 D_real: 0.612 D_fake: 0.802 \n",
      "saving the model at the end of epoch 115, iters 262200\n",
      "End of epoch 115 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0013465\n",
      "(epoch: 116, iters: 100, time: 0.080, data: 0.437) G_GAN: 0.863 G_L1: 2.485 D_real: 0.560 D_fake: 0.634 \n",
      "(epoch: 116, iters: 200, time: 0.074, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.712 D_fake: 0.661 \n",
      "(epoch: 116, iters: 300, time: 0.075, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.752 D_fake: 0.637 \n",
      "(epoch: 116, iters: 400, time: 0.072, data: 0.002) G_GAN: 0.881 G_L1: 1.437 D_real: 0.574 D_fake: 0.625 \n",
      "(epoch: 116, iters: 500, time: 0.076, data: 0.003) G_GAN: 0.734 G_L1: 0.000 D_real: 0.740 D_fake: 0.620 \n",
      "(epoch: 116, iters: 600, time: 0.074, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.754 D_fake: 0.663 \n",
      "(epoch: 116, iters: 700, time: 0.076, data: 0.002) G_GAN: 0.886 G_L1: 1.919 D_real: 0.561 D_fake: 0.653 \n",
      "(epoch: 116, iters: 800, time: 0.075, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.764 D_fake: 0.612 \n",
      "(epoch: 116, iters: 900, time: 0.072, data: 0.003) G_GAN: 0.636 G_L1: 0.000 D_real: 0.617 D_fake: 0.676 \n",
      "(epoch: 116, iters: 1000, time: 0.072, data: 0.002) G_GAN: 0.829 G_L1: 1.678 D_real: 0.585 D_fake: 0.653 \n",
      "(epoch: 116, iters: 1100, time: 0.075, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.914 D_fake: 0.585 \n",
      "(epoch: 116, iters: 1200, time: 0.072, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.762 D_fake: 0.619 \n",
      "(epoch: 116, iters: 1300, time: 0.072, data: 0.002) G_GAN: 0.850 G_L1: 1.744 D_real: 0.635 D_fake: 0.619 \n",
      "(epoch: 116, iters: 1400, time: 0.075, data: 0.002) G_GAN: 0.782 G_L1: 0.000 D_real: 0.800 D_fake: 0.608 \n",
      "(epoch: 116, iters: 1500, time: 0.072, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.722 D_fake: 0.681 \n",
      "(epoch: 116, iters: 1600, time: 0.073, data: 0.001) G_GAN: 0.882 G_L1: 2.124 D_real: 0.575 D_fake: 0.644 \n",
      "(epoch: 116, iters: 1700, time: 0.075, data: 0.002) G_GAN: 0.784 G_L1: 0.000 D_real: 0.798 D_fake: 0.612 \n",
      "(epoch: 116, iters: 1800, time: 0.071, data: 0.003) G_GAN: 0.718 G_L1: 0.000 D_real: 0.728 D_fake: 0.647 \n",
      "(epoch: 116, iters: 1900, time: 0.071, data: 0.002) G_GAN: 0.808 G_L1: 3.702 D_real: 0.523 D_fake: 0.628 \n",
      "(epoch: 116, iters: 2000, time: 0.073, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.775 D_fake: 0.622 \n",
      "(epoch: 116, iters: 2100, time: 0.072, data: 0.003) G_GAN: 0.722 G_L1: 0.000 D_real: 0.727 D_fake: 0.656 \n",
      "(epoch: 116, iters: 2200, time: 0.072, data: 0.002) G_GAN: 0.862 G_L1: 1.583 D_real: 0.582 D_fake: 0.646 \n",
      "End of epoch 116 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0013307\n",
      "(epoch: 117, iters: 20, time: 0.077, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.793 D_fake: 0.601 \n",
      "(epoch: 117, iters: 120, time: 0.077, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.725 D_fake: 0.628 \n",
      "(epoch: 117, iters: 220, time: 0.073, data: 0.003) G_GAN: 0.879 G_L1: 2.749 D_real: 0.545 D_fake: 0.604 \n",
      "(epoch: 117, iters: 320, time: 0.073, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.737 D_fake: 0.646 \n",
      "(epoch: 117, iters: 420, time: 0.075, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.745 D_fake: 0.651 \n",
      "(epoch: 117, iters: 520, time: 0.072, data: 0.002) G_GAN: 0.883 G_L1: 1.419 D_real: 0.628 D_fake: 0.655 \n",
      "saving the latest model (epoch 117, total_steps 265000)\n",
      "(epoch: 117, iters: 620, time: 0.072, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.756 D_fake: 0.662 \n",
      "(epoch: 117, iters: 720, time: 0.074, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.702 D_fake: 0.643 \n",
      "(epoch: 117, iters: 820, time: 0.076, data: 0.002) G_GAN: 0.829 G_L1: 1.824 D_real: 0.587 D_fake: 0.619 \n",
      "(epoch: 117, iters: 920, time: 0.072, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.738 D_fake: 0.621 \n",
      "(epoch: 117, iters: 1020, time: 0.075, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.728 D_fake: 0.648 \n",
      "(epoch: 117, iters: 1120, time: 0.071, data: 0.002) G_GAN: 0.832 G_L1: 1.957 D_real: 0.532 D_fake: 0.657 \n",
      "(epoch: 117, iters: 1220, time: 0.072, data: 0.003) G_GAN: 0.747 G_L1: 0.000 D_real: 0.751 D_fake: 0.653 \n",
      "(epoch: 117, iters: 1320, time: 0.074, data: 0.003) G_GAN: 0.734 G_L1: 0.000 D_real: 0.739 D_fake: 0.654 \n",
      "(epoch: 117, iters: 1420, time: 0.073, data: 0.002) G_GAN: 0.851 G_L1: 2.010 D_real: 0.554 D_fake: 0.641 \n",
      "(epoch: 117, iters: 1520, time: 0.072, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.728 D_fake: 0.646 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 117, iters: 1620, time: 0.072, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.728 D_fake: 0.661 \n",
      "(epoch: 117, iters: 1720, time: 0.072, data: 0.002) G_GAN: 0.940 G_L1: 3.150 D_real: 0.531 D_fake: 0.605 \n",
      "(epoch: 117, iters: 1820, time: 0.074, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.766 D_fake: 0.612 \n",
      "(epoch: 117, iters: 1920, time: 0.071, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.730 D_fake: 0.641 \n",
      "(epoch: 117, iters: 2020, time: 0.073, data: 0.002) G_GAN: 0.878 G_L1: 1.672 D_real: 0.607 D_fake: 0.620 \n",
      "(epoch: 117, iters: 2120, time: 0.075, data: 0.003) G_GAN: 0.765 G_L1: 0.000 D_real: 0.779 D_fake: 0.601 \n",
      "(epoch: 117, iters: 2220, time: 0.074, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.716 D_fake: 0.669 \n",
      "End of epoch 117 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0013149\n",
      "(epoch: 118, iters: 40, time: 0.076, data: 0.002) G_GAN: 0.852 G_L1: 1.820 D_real: 0.548 D_fake: 0.637 \n",
      "(epoch: 118, iters: 140, time: 0.071, data: 0.008) G_GAN: 0.736 G_L1: 0.000 D_real: 0.743 D_fake: 0.651 \n",
      "(epoch: 118, iters: 240, time: 0.072, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.719 D_fake: 0.657 \n",
      "(epoch: 118, iters: 340, time: 0.072, data: 0.003) G_GAN: 0.797 G_L1: 1.290 D_real: 0.585 D_fake: 0.639 \n",
      "(epoch: 118, iters: 440, time: 0.071, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.730 D_fake: 0.629 \n",
      "(epoch: 118, iters: 540, time: 0.070, data: 0.003) G_GAN: 0.683 G_L1: 0.000 D_real: 0.694 D_fake: 0.674 \n",
      "(epoch: 118, iters: 640, time: 0.074, data: 0.003) G_GAN: 0.834 G_L1: 2.682 D_real: 0.552 D_fake: 0.658 \n",
      "(epoch: 118, iters: 740, time: 0.074, data: 0.003) G_GAN: 0.722 G_L1: 0.000 D_real: 0.728 D_fake: 0.652 \n",
      "(epoch: 118, iters: 840, time: 0.074, data: 0.003) G_GAN: 0.703 G_L1: 0.000 D_real: 0.706 D_fake: 0.685 \n",
      "(epoch: 118, iters: 940, time: 0.075, data: 0.002) G_GAN: 1.013 G_L1: 3.230 D_real: 0.562 D_fake: 0.574 \n",
      "(epoch: 118, iters: 1040, time: 0.072, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.758 D_fake: 0.646 \n",
      "(epoch: 118, iters: 1140, time: 0.071, data: 0.003) G_GAN: 0.727 G_L1: 0.000 D_real: 0.723 D_fake: 0.624 \n",
      "(epoch: 118, iters: 1240, time: 0.072, data: 0.002) G_GAN: 1.094 G_L1: 2.399 D_real: 0.684 D_fake: 0.532 \n",
      "(epoch: 118, iters: 1340, time: 0.074, data: 0.002) G_GAN: 0.774 G_L1: 0.000 D_real: 0.778 D_fake: 0.642 \n",
      "(epoch: 118, iters: 1440, time: 0.075, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.741 D_fake: 0.642 \n",
      "(epoch: 118, iters: 1540, time: 0.075, data: 0.002) G_GAN: 0.912 G_L1: 1.508 D_real: 0.591 D_fake: 0.598 \n",
      "(epoch: 118, iters: 1640, time: 0.074, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.750 D_fake: 0.632 \n",
      "(epoch: 118, iters: 1740, time: 0.072, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.738 D_fake: 0.672 \n",
      "(epoch: 118, iters: 1840, time: 0.073, data: 0.002) G_GAN: 0.895 G_L1: 0.842 D_real: 0.624 D_fake: 0.603 \n",
      "(epoch: 118, iters: 1940, time: 0.070, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.746 D_fake: 0.641 \n",
      "(epoch: 118, iters: 2040, time: 0.075, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.723 D_fake: 0.663 \n",
      "(epoch: 118, iters: 2140, time: 0.075, data: 0.003) G_GAN: 0.892 G_L1: 0.917 D_real: 0.625 D_fake: 0.603 \n",
      "(epoch: 118, iters: 2240, time: 0.072, data: 0.002) G_GAN: 0.789 G_L1: 0.000 D_real: 0.852 D_fake: 0.544 \n",
      "End of epoch 118 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0012990\n",
      "(epoch: 119, iters: 60, time: 0.073, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.721 D_fake: 0.663 \n",
      "(epoch: 119, iters: 160, time: 0.076, data: 0.002) G_GAN: 0.889 G_L1: 2.187 D_real: 0.567 D_fake: 0.622 \n",
      "(epoch: 119, iters: 260, time: 0.071, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.733 D_fake: 0.659 \n",
      "(epoch: 119, iters: 360, time: 0.072, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.729 D_fake: 0.660 \n",
      "(epoch: 119, iters: 460, time: 0.077, data: 0.002) G_GAN: 0.877 G_L1: 2.055 D_real: 0.572 D_fake: 0.631 \n",
      "(epoch: 119, iters: 560, time: 0.071, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.729 D_fake: 0.641 \n",
      "(epoch: 119, iters: 660, time: 0.074, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.734 D_fake: 0.669 \n",
      "(epoch: 119, iters: 760, time: 0.073, data: 0.002) G_GAN: 0.922 G_L1: 2.009 D_real: 0.585 D_fake: 0.595 \n",
      "(epoch: 119, iters: 860, time: 0.072, data: 0.002) G_GAN: 0.762 G_L1: 0.000 D_real: 0.774 D_fake: 0.647 \n",
      "(epoch: 119, iters: 960, time: 0.072, data: 0.003) G_GAN: 0.705 G_L1: 0.000 D_real: 0.717 D_fake: 0.669 \n",
      "saving the latest model (epoch 119, total_steps 270000)\n",
      "(epoch: 119, iters: 1060, time: 0.071, data: 0.002) G_GAN: 0.837 G_L1: 0.699 D_real: 0.628 D_fake: 0.622 \n",
      "(epoch: 119, iters: 1160, time: 0.072, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.759 D_fake: 0.639 \n",
      "(epoch: 119, iters: 1260, time: 0.075, data: 0.002) G_GAN: 0.680 G_L1: 0.000 D_real: 0.682 D_fake: 0.676 \n",
      "(epoch: 119, iters: 1360, time: 0.073, data: 0.002) G_GAN: 0.848 G_L1: 2.029 D_real: 0.634 D_fake: 0.574 \n",
      "(epoch: 119, iters: 1460, time: 0.075, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.774 D_fake: 0.610 \n",
      "(epoch: 119, iters: 1560, time: 0.073, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.704 D_fake: 0.678 \n",
      "(epoch: 119, iters: 1660, time: 0.072, data: 0.002) G_GAN: 0.845 G_L1: 1.703 D_real: 0.565 D_fake: 0.613 \n",
      "(epoch: 119, iters: 1760, time: 0.076, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.733 D_fake: 0.648 \n",
      "(epoch: 119, iters: 1860, time: 0.077, data: 0.003) G_GAN: 0.713 G_L1: 0.000 D_real: 0.726 D_fake: 0.667 \n",
      "(epoch: 119, iters: 1960, time: 0.075, data: 0.002) G_GAN: 0.851 G_L1: 2.015 D_real: 0.579 D_fake: 0.599 \n",
      "(epoch: 119, iters: 2060, time: 0.071, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.752 D_fake: 0.649 \n",
      "(epoch: 119, iters: 2160, time: 0.076, data: 0.002) G_GAN: 0.686 G_L1: 0.000 D_real: 0.728 D_fake: 0.598 \n",
      "(epoch: 119, iters: 2260, time: 0.071, data: 0.002) G_GAN: 0.937 G_L1: 2.749 D_real: 0.571 D_fake: 0.601 \n",
      "End of epoch 119 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0012832\n",
      "(epoch: 120, iters: 80, time: 0.077, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.741 D_fake: 0.635 \n",
      "(epoch: 120, iters: 180, time: 0.074, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.717 D_fake: 0.674 \n",
      "(epoch: 120, iters: 280, time: 0.074, data: 0.002) G_GAN: 0.878 G_L1: 1.026 D_real: 0.597 D_fake: 0.621 \n",
      "(epoch: 120, iters: 380, time: 0.073, data: 0.004) G_GAN: 0.772 G_L1: 0.000 D_real: 0.808 D_fake: 0.602 \n",
      "(epoch: 120, iters: 480, time: 0.077, data: 0.003) G_GAN: 0.702 G_L1: 0.000 D_real: 0.714 D_fake: 0.647 \n",
      "(epoch: 120, iters: 580, time: 0.076, data: 0.002) G_GAN: 0.940 G_L1: 3.541 D_real: 0.517 D_fake: 0.627 \n",
      "(epoch: 120, iters: 680, time: 0.074, data: 0.003) G_GAN: 0.708 G_L1: 0.000 D_real: 0.718 D_fake: 0.629 \n",
      "(epoch: 120, iters: 780, time: 0.074, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.714 D_fake: 0.677 \n",
      "(epoch: 120, iters: 880, time: 0.071, data: 0.002) G_GAN: 0.910 G_L1: 2.571 D_real: 0.553 D_fake: 0.607 \n",
      "(epoch: 120, iters: 980, time: 0.075, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.730 D_fake: 0.673 \n",
      "(epoch: 120, iters: 1080, time: 0.071, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.698 D_fake: 0.669 \n",
      "(epoch: 120, iters: 1180, time: 0.071, data: 0.002) G_GAN: 0.929 G_L1: 2.021 D_real: 0.664 D_fake: 0.542 \n",
      "(epoch: 120, iters: 1280, time: 0.072, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.751 D_fake: 0.654 \n",
      "(epoch: 120, iters: 1380, time: 0.071, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.729 D_fake: 0.637 \n",
      "(epoch: 120, iters: 1480, time: 0.074, data: 0.002) G_GAN: 0.925 G_L1: 1.813 D_real: 0.588 D_fake: 0.633 \n",
      "(epoch: 120, iters: 1580, time: 0.074, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.740 D_fake: 0.632 \n",
      "(epoch: 120, iters: 1680, time: 0.076, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.729 D_fake: 0.671 \n",
      "(epoch: 120, iters: 1780, time: 0.072, data: 0.002) G_GAN: 0.866 G_L1: 2.503 D_real: 0.557 D_fake: 0.637 \n",
      "(epoch: 120, iters: 1880, time: 0.074, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.735 D_fake: 0.664 \n",
      "(epoch: 120, iters: 1980, time: 0.074, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.704 D_fake: 0.657 \n",
      "(epoch: 120, iters: 2080, time: 0.072, data: 0.002) G_GAN: 0.884 G_L1: 2.297 D_real: 0.538 D_fake: 0.623 \n",
      "(epoch: 120, iters: 2180, time: 0.074, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.741 D_fake: 0.622 \n",
      "(epoch: 120, iters: 2280, time: 0.073, data: 0.003) G_GAN: 0.663 G_L1: 0.000 D_real: 0.665 D_fake: 0.690 \n",
      "saving the model at the end of epoch 120, iters 273600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 120 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0012673\n",
      "(epoch: 121, iters: 100, time: 0.076, data: 0.436) G_GAN: 0.916 G_L1: 2.485 D_real: 0.550 D_fake: 0.626 \n",
      "(epoch: 121, iters: 200, time: 0.072, data: 0.001) G_GAN: 0.699 G_L1: 0.000 D_real: 0.720 D_fake: 0.625 \n",
      "(epoch: 121, iters: 300, time: 0.072, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.742 D_fake: 0.661 \n",
      "(epoch: 121, iters: 400, time: 0.076, data: 0.002) G_GAN: 0.966 G_L1: 1.437 D_real: 0.586 D_fake: 0.588 \n",
      "(epoch: 121, iters: 500, time: 0.075, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.741 D_fake: 0.590 \n",
      "(epoch: 121, iters: 600, time: 0.077, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.741 D_fake: 0.646 \n",
      "(epoch: 121, iters: 700, time: 0.074, data: 0.002) G_GAN: 0.911 G_L1: 1.919 D_real: 0.564 D_fake: 0.600 \n",
      "(epoch: 121, iters: 800, time: 0.071, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.770 D_fake: 0.624 \n",
      "(epoch: 121, iters: 900, time: 0.073, data: 0.002) G_GAN: 0.682 G_L1: 0.000 D_real: 0.723 D_fake: 0.690 \n",
      "(epoch: 121, iters: 1000, time: 0.079, data: 0.002) G_GAN: 0.858 G_L1: 1.678 D_real: 0.583 D_fake: 0.638 \n",
      "(epoch: 121, iters: 1100, time: 0.071, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.768 D_fake: 0.633 \n",
      "(epoch: 121, iters: 1200, time: 0.075, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.736 D_fake: 0.647 \n",
      "(epoch: 121, iters: 1300, time: 0.072, data: 0.003) G_GAN: 0.873 G_L1: 1.744 D_real: 0.619 D_fake: 0.621 \n",
      "(epoch: 121, iters: 1400, time: 0.076, data: 0.002) G_GAN: 0.788 G_L1: 0.000 D_real: 0.839 D_fake: 0.595 \n",
      "saving the latest model (epoch 121, total_steps 275000)\n",
      "(epoch: 121, iters: 1500, time: 0.075, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.704 D_fake: 0.690 \n",
      "(epoch: 121, iters: 1600, time: 0.074, data: 0.003) G_GAN: 0.945 G_L1: 2.124 D_real: 0.559 D_fake: 0.610 \n",
      "(epoch: 121, iters: 1700, time: 0.076, data: 0.003) G_GAN: 0.760 G_L1: 0.000 D_real: 0.770 D_fake: 0.610 \n",
      "(epoch: 121, iters: 1800, time: 0.072, data: 0.003) G_GAN: 0.694 G_L1: 0.000 D_real: 0.712 D_fake: 0.661 \n",
      "(epoch: 121, iters: 1900, time: 0.073, data: 0.002) G_GAN: 0.863 G_L1: 3.702 D_real: 0.515 D_fake: 0.644 \n",
      "(epoch: 121, iters: 2000, time: 0.071, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.786 D_fake: 0.634 \n",
      "(epoch: 121, iters: 2100, time: 0.077, data: 0.002) G_GAN: 0.656 G_L1: 0.000 D_real: 0.698 D_fake: 0.670 \n",
      "(epoch: 121, iters: 2200, time: 0.075, data: 0.002) G_GAN: 0.881 G_L1: 1.583 D_real: 0.574 D_fake: 0.604 \n",
      "End of epoch 121 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0012515\n",
      "(epoch: 122, iters: 20, time: 0.074, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.785 D_fake: 0.634 \n",
      "(epoch: 122, iters: 120, time: 0.074, data: 0.003) G_GAN: 0.715 G_L1: 0.000 D_real: 0.724 D_fake: 0.650 \n",
      "(epoch: 122, iters: 220, time: 0.071, data: 0.002) G_GAN: 0.938 G_L1: 2.749 D_real: 0.535 D_fake: 0.623 \n",
      "(epoch: 122, iters: 320, time: 0.077, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.759 D_fake: 0.617 \n",
      "(epoch: 122, iters: 420, time: 0.074, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.744 D_fake: 0.652 \n",
      "(epoch: 122, iters: 520, time: 0.072, data: 0.002) G_GAN: 0.907 G_L1: 1.419 D_real: 0.629 D_fake: 0.598 \n",
      "(epoch: 122, iters: 620, time: 0.074, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.767 D_fake: 0.641 \n",
      "(epoch: 122, iters: 720, time: 0.072, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.700 D_fake: 0.650 \n",
      "(epoch: 122, iters: 820, time: 0.073, data: 0.003) G_GAN: 0.889 G_L1: 1.824 D_real: 0.575 D_fake: 0.614 \n",
      "(epoch: 122, iters: 920, time: 0.072, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.746 D_fake: 0.600 \n",
      "(epoch: 122, iters: 1020, time: 0.072, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.698 D_fake: 0.698 \n",
      "(epoch: 122, iters: 1120, time: 0.074, data: 0.002) G_GAN: 0.908 G_L1: 1.957 D_real: 0.578 D_fake: 0.558 \n",
      "(epoch: 122, iters: 1220, time: 0.073, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.726 D_fake: 0.648 \n",
      "(epoch: 122, iters: 1320, time: 0.072, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.741 D_fake: 0.647 \n",
      "(epoch: 122, iters: 1420, time: 0.075, data: 0.002) G_GAN: 0.827 G_L1: 2.010 D_real: 0.585 D_fake: 0.611 \n",
      "(epoch: 122, iters: 1520, time: 0.074, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.732 D_fake: 0.691 \n",
      "(epoch: 122, iters: 1620, time: 0.073, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.735 D_fake: 0.643 \n",
      "(epoch: 122, iters: 1720, time: 0.072, data: 0.002) G_GAN: 0.901 G_L1: 3.150 D_real: 0.540 D_fake: 0.599 \n",
      "(epoch: 122, iters: 1820, time: 0.072, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.765 D_fake: 0.609 \n",
      "(epoch: 122, iters: 1920, time: 0.072, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.727 D_fake: 0.652 \n",
      "(epoch: 122, iters: 2020, time: 0.072, data: 0.002) G_GAN: 0.846 G_L1: 1.672 D_real: 0.586 D_fake: 0.677 \n",
      "(epoch: 122, iters: 2120, time: 0.071, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.768 D_fake: 0.611 \n",
      "(epoch: 122, iters: 2220, time: 0.072, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.728 D_fake: 0.601 \n",
      "End of epoch 122 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0012356\n",
      "(epoch: 123, iters: 40, time: 0.075, data: 0.002) G_GAN: 0.884 G_L1: 1.820 D_real: 0.556 D_fake: 0.614 \n",
      "(epoch: 123, iters: 140, time: 0.073, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.760 D_fake: 0.618 \n",
      "(epoch: 123, iters: 240, time: 0.072, data: 0.003) G_GAN: 0.714 G_L1: 0.000 D_real: 0.724 D_fake: 0.661 \n",
      "(epoch: 123, iters: 340, time: 0.071, data: 0.002) G_GAN: 0.806 G_L1: 1.290 D_real: 0.567 D_fake: 0.641 \n",
      "(epoch: 123, iters: 440, time: 0.072, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.730 D_fake: 0.650 \n",
      "(epoch: 123, iters: 540, time: 0.072, data: 0.003) G_GAN: 0.688 G_L1: 0.000 D_real: 0.711 D_fake: 0.654 \n",
      "(epoch: 123, iters: 640, time: 0.072, data: 0.002) G_GAN: 0.870 G_L1: 2.682 D_real: 0.558 D_fake: 0.628 \n",
      "(epoch: 123, iters: 740, time: 0.072, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.737 D_fake: 0.656 \n",
      "(epoch: 123, iters: 840, time: 0.073, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.702 D_fake: 0.674 \n",
      "(epoch: 123, iters: 940, time: 0.077, data: 0.002) G_GAN: 0.985 G_L1: 3.230 D_real: 0.545 D_fake: 0.594 \n",
      "(epoch: 123, iters: 1040, time: 0.073, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.728 D_fake: 0.679 \n",
      "(epoch: 123, iters: 1140, time: 0.076, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.716 D_fake: 0.683 \n",
      "(epoch: 123, iters: 1240, time: 0.074, data: 0.002) G_GAN: 1.089 G_L1: 2.399 D_real: 0.624 D_fake: 0.561 \n",
      "(epoch: 123, iters: 1340, time: 0.073, data: 0.003) G_GAN: 0.764 G_L1: 0.000 D_real: 0.772 D_fake: 0.632 \n",
      "(epoch: 123, iters: 1440, time: 0.073, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.725 D_fake: 0.665 \n",
      "(epoch: 123, iters: 1540, time: 0.071, data: 0.002) G_GAN: 0.905 G_L1: 1.508 D_real: 0.592 D_fake: 0.620 \n",
      "(epoch: 123, iters: 1640, time: 0.072, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.745 D_fake: 0.635 \n",
      "(epoch: 123, iters: 1740, time: 0.074, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.743 D_fake: 0.630 \n",
      "(epoch: 123, iters: 1840, time: 0.073, data: 0.003) G_GAN: 0.902 G_L1: 0.842 D_real: 0.612 D_fake: 0.645 \n",
      "saving the latest model (epoch 123, total_steps 280000)\n",
      "(epoch: 123, iters: 1940, time: 0.073, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.746 D_fake: 0.658 \n",
      "(epoch: 123, iters: 2040, time: 0.073, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.717 D_fake: 0.675 \n",
      "(epoch: 123, iters: 2140, time: 0.072, data: 0.002) G_GAN: 0.956 G_L1: 0.917 D_real: 0.631 D_fake: 0.628 \n",
      "(epoch: 123, iters: 2240, time: 0.076, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.760 D_fake: 0.640 \n",
      "End of epoch 123 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0012198\n",
      "(epoch: 124, iters: 60, time: 0.074, data: 0.002) G_GAN: 0.682 G_L1: 0.000 D_real: 0.696 D_fake: 0.639 \n",
      "(epoch: 124, iters: 160, time: 0.074, data: 0.002) G_GAN: 0.913 G_L1: 2.187 D_real: 0.558 D_fake: 0.633 \n",
      "(epoch: 124, iters: 260, time: 0.072, data: 0.002) G_GAN: 0.552 G_L1: 0.000 D_real: 0.931 D_fake: 0.531 \n",
      "(epoch: 124, iters: 360, time: 0.075, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.727 D_fake: 0.665 \n",
      "(epoch: 124, iters: 460, time: 0.071, data: 0.002) G_GAN: 0.883 G_L1: 2.055 D_real: 0.565 D_fake: 0.654 \n",
      "(epoch: 124, iters: 560, time: 0.074, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.725 D_fake: 0.635 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 124, iters: 660, time: 0.072, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.721 D_fake: 0.628 \n",
      "(epoch: 124, iters: 760, time: 0.074, data: 0.002) G_GAN: 0.889 G_L1: 2.009 D_real: 0.570 D_fake: 0.630 \n",
      "(epoch: 124, iters: 860, time: 0.071, data: 0.003) G_GAN: 0.518 G_L1: 0.000 D_real: 0.667 D_fake: 0.644 \n",
      "(epoch: 124, iters: 960, time: 0.075, data: 0.003) G_GAN: 0.674 G_L1: 0.000 D_real: 0.702 D_fake: 0.571 \n",
      "(epoch: 124, iters: 1060, time: 0.072, data: 0.002) G_GAN: 0.794 G_L1: 0.699 D_real: 0.607 D_fake: 0.660 \n",
      "(epoch: 124, iters: 1160, time: 0.072, data: 0.002) G_GAN: 0.772 G_L1: 0.000 D_real: 0.788 D_fake: 0.644 \n",
      "(epoch: 124, iters: 1260, time: 0.070, data: 0.002) G_GAN: 0.688 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 124, iters: 1360, time: 0.072, data: 0.002) G_GAN: 0.790 G_L1: 2.029 D_real: 0.558 D_fake: 0.660 \n",
      "(epoch: 124, iters: 1460, time: 0.072, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.815 D_fake: 0.586 \n",
      "(epoch: 124, iters: 1560, time: 0.072, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.711 D_fake: 0.671 \n",
      "(epoch: 124, iters: 1660, time: 0.072, data: 0.002) G_GAN: 0.868 G_L1: 1.703 D_real: 0.569 D_fake: 0.598 \n",
      "(epoch: 124, iters: 1760, time: 0.071, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.735 D_fake: 0.652 \n",
      "(epoch: 124, iters: 1860, time: 0.074, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.710 D_fake: 0.621 \n",
      "(epoch: 124, iters: 1960, time: 0.072, data: 0.002) G_GAN: 0.852 G_L1: 2.015 D_real: 0.577 D_fake: 0.609 \n",
      "(epoch: 124, iters: 2060, time: 0.075, data: 0.003) G_GAN: 0.737 G_L1: 0.000 D_real: 0.749 D_fake: 0.640 \n",
      "(epoch: 124, iters: 2160, time: 0.078, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.717 D_fake: 0.668 \n",
      "(epoch: 124, iters: 2260, time: 0.077, data: 0.002) G_GAN: 0.983 G_L1: 2.749 D_real: 0.560 D_fake: 0.612 \n",
      "End of epoch 124 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0012040\n",
      "(epoch: 125, iters: 80, time: 0.078, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.762 D_fake: 0.647 \n",
      "(epoch: 125, iters: 180, time: 0.072, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.717 D_fake: 0.676 \n",
      "(epoch: 125, iters: 280, time: 0.072, data: 0.002) G_GAN: 0.924 G_L1: 1.026 D_real: 0.589 D_fake: 0.601 \n",
      "(epoch: 125, iters: 380, time: 0.072, data: 0.002) G_GAN: 0.790 G_L1: 0.000 D_real: 0.811 D_fake: 0.595 \n",
      "(epoch: 125, iters: 480, time: 0.076, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.717 D_fake: 0.613 \n",
      "(epoch: 125, iters: 580, time: 0.076, data: 0.002) G_GAN: 0.984 G_L1: 3.541 D_real: 0.524 D_fake: 0.609 \n",
      "(epoch: 125, iters: 680, time: 0.071, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.737 D_fake: 0.663 \n",
      "(epoch: 125, iters: 780, time: 0.075, data: 0.003) G_GAN: 0.697 G_L1: 0.000 D_real: 0.710 D_fake: 0.672 \n",
      "(epoch: 125, iters: 880, time: 0.072, data: 0.003) G_GAN: 0.897 G_L1: 2.571 D_real: 0.525 D_fake: 0.641 \n",
      "(epoch: 125, iters: 980, time: 0.072, data: 0.003) G_GAN: 0.734 G_L1: 0.000 D_real: 0.739 D_fake: 0.672 \n",
      "(epoch: 125, iters: 1080, time: 0.071, data: 0.003) G_GAN: 0.680 G_L1: 0.000 D_real: 0.696 D_fake: 0.677 \n",
      "(epoch: 125, iters: 1180, time: 0.077, data: 0.001) G_GAN: 0.981 G_L1: 2.021 D_real: 0.607 D_fake: 0.569 \n",
      "(epoch: 125, iters: 1280, time: 0.078, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.635 \n",
      "(epoch: 125, iters: 1380, time: 0.073, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.728 D_fake: 0.663 \n",
      "(epoch: 125, iters: 1480, time: 0.074, data: 0.002) G_GAN: 0.923 G_L1: 1.813 D_real: 0.572 D_fake: 0.610 \n",
      "(epoch: 125, iters: 1580, time: 0.072, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.755 D_fake: 0.646 \n",
      "(epoch: 125, iters: 1680, time: 0.075, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.720 D_fake: 0.649 \n",
      "(epoch: 125, iters: 1780, time: 0.072, data: 0.002) G_GAN: 0.866 G_L1: 2.503 D_real: 0.552 D_fake: 0.605 \n",
      "(epoch: 125, iters: 1880, time: 0.073, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.749 D_fake: 0.648 \n",
      "(epoch: 125, iters: 1980, time: 0.073, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.705 D_fake: 0.629 \n",
      "(epoch: 125, iters: 2080, time: 0.073, data: 0.002) G_GAN: 0.837 G_L1: 2.297 D_real: 0.527 D_fake: 0.637 \n",
      "(epoch: 125, iters: 2180, time: 0.077, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.744 D_fake: 0.642 \n",
      "(epoch: 125, iters: 2280, time: 0.071, data: 0.002) G_GAN: 0.679 G_L1: 0.000 D_real: 0.671 D_fake: 0.649 \n",
      "saving the latest model (epoch 125, total_steps 285000)\n",
      "saving the model at the end of epoch 125, iters 285000\n",
      "End of epoch 125 / 200 \t Time Taken: 113 sec\n",
      "learning rate = 0.0011881\n",
      "(epoch: 126, iters: 100, time: 0.077, data: 0.429) G_GAN: 0.911 G_L1: 2.485 D_real: 0.555 D_fake: 0.600 \n",
      "(epoch: 126, iters: 200, time: 0.073, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.723 D_fake: 0.629 \n",
      "(epoch: 126, iters: 300, time: 0.073, data: 0.003) G_GAN: 0.712 G_L1: 0.000 D_real: 0.726 D_fake: 0.667 \n",
      "(epoch: 126, iters: 400, time: 0.075, data: 0.002) G_GAN: 1.018 G_L1: 1.437 D_real: 0.546 D_fake: 0.661 \n",
      "(epoch: 126, iters: 500, time: 0.073, data: 0.002) G_GAN: 0.586 G_L1: 0.000 D_real: 0.637 D_fake: 0.624 \n",
      "(epoch: 126, iters: 600, time: 0.073, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.745 D_fake: 0.652 \n",
      "(epoch: 126, iters: 700, time: 0.076, data: 0.002) G_GAN: 0.928 G_L1: 1.919 D_real: 0.558 D_fake: 0.622 \n",
      "(epoch: 126, iters: 800, time: 0.071, data: 0.003) G_GAN: 0.732 G_L1: 0.000 D_real: 0.738 D_fake: 0.624 \n",
      "(epoch: 126, iters: 900, time: 0.073, data: 0.003) G_GAN: 0.730 G_L1: 0.000 D_real: 0.746 D_fake: 0.589 \n",
      "(epoch: 126, iters: 1000, time: 0.080, data: 0.002) G_GAN: 0.881 G_L1: 1.678 D_real: 0.583 D_fake: 0.625 \n",
      "(epoch: 126, iters: 1100, time: 0.074, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.783 D_fake: 0.617 \n",
      "(epoch: 126, iters: 1200, time: 0.077, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.728 D_fake: 0.615 \n",
      "(epoch: 126, iters: 1300, time: 0.075, data: 0.002) G_GAN: 0.871 G_L1: 1.744 D_real: 0.606 D_fake: 0.613 \n",
      "(epoch: 126, iters: 1400, time: 0.074, data: 0.002) G_GAN: 0.793 G_L1: 0.000 D_real: 0.813 D_fake: 0.601 \n",
      "(epoch: 126, iters: 1500, time: 0.073, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.739 D_fake: 0.658 \n",
      "(epoch: 126, iters: 1600, time: 0.074, data: 0.002) G_GAN: 0.948 G_L1: 2.124 D_real: 0.571 D_fake: 0.612 \n",
      "(epoch: 126, iters: 1700, time: 0.075, data: 0.001) G_GAN: 0.769 G_L1: 0.000 D_real: 0.775 D_fake: 0.620 \n",
      "(epoch: 126, iters: 1800, time: 0.074, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.729 D_fake: 0.657 \n",
      "(epoch: 126, iters: 1900, time: 0.073, data: 0.003) G_GAN: 0.884 G_L1: 3.702 D_real: 0.524 D_fake: 0.668 \n",
      "(epoch: 126, iters: 2000, time: 0.075, data: 0.003) G_GAN: 0.756 G_L1: 0.000 D_real: 0.775 D_fake: 0.614 \n",
      "(epoch: 126, iters: 2100, time: 0.073, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.718 D_fake: 0.631 \n",
      "(epoch: 126, iters: 2200, time: 0.078, data: 0.002) G_GAN: 0.899 G_L1: 1.583 D_real: 0.588 D_fake: 0.609 \n",
      "End of epoch 126 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0011723\n",
      "(epoch: 127, iters: 20, time: 0.073, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.764 D_fake: 0.606 \n",
      "(epoch: 127, iters: 120, time: 0.073, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.739 D_fake: 0.620 \n",
      "(epoch: 127, iters: 220, time: 0.073, data: 0.002) G_GAN: 0.946 G_L1: 2.749 D_real: 0.548 D_fake: 0.637 \n",
      "(epoch: 127, iters: 320, time: 0.072, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.746 D_fake: 0.626 \n",
      "(epoch: 127, iters: 420, time: 0.073, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.730 D_fake: 0.653 \n",
      "(epoch: 127, iters: 520, time: 0.074, data: 0.002) G_GAN: 0.888 G_L1: 1.419 D_real: 0.628 D_fake: 0.637 \n",
      "(epoch: 127, iters: 620, time: 0.073, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.746 D_fake: 0.656 \n",
      "(epoch: 127, iters: 720, time: 0.078, data: 0.003) G_GAN: 0.726 G_L1: 0.000 D_real: 0.736 D_fake: 0.623 \n",
      "(epoch: 127, iters: 820, time: 0.075, data: 0.002) G_GAN: 0.914 G_L1: 1.824 D_real: 0.617 D_fake: 0.582 \n",
      "(epoch: 127, iters: 920, time: 0.072, data: 0.003) G_GAN: 0.655 G_L1: 0.000 D_real: 0.705 D_fake: 0.612 \n",
      "(epoch: 127, iters: 1020, time: 0.074, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.720 D_fake: 0.672 \n",
      "(epoch: 127, iters: 1120, time: 0.071, data: 0.002) G_GAN: 0.833 G_L1: 1.957 D_real: 0.537 D_fake: 0.665 \n",
      "(epoch: 127, iters: 1220, time: 0.071, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.722 D_fake: 0.616 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 127, iters: 1320, time: 0.073, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.706 D_fake: 0.656 \n",
      "(epoch: 127, iters: 1420, time: 0.074, data: 0.002) G_GAN: 0.919 G_L1: 2.010 D_real: 0.572 D_fake: 0.631 \n",
      "(epoch: 127, iters: 1520, time: 0.074, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.738 D_fake: 0.646 \n",
      "(epoch: 127, iters: 1620, time: 0.070, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.703 D_fake: 0.694 \n",
      "(epoch: 127, iters: 1720, time: 0.072, data: 0.003) G_GAN: 1.014 G_L1: 3.150 D_real: 0.527 D_fake: 0.576 \n",
      "(epoch: 127, iters: 1820, time: 0.075, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.767 D_fake: 0.629 \n",
      "(epoch: 127, iters: 1920, time: 0.071, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.715 D_fake: 0.673 \n",
      "(epoch: 127, iters: 2020, time: 0.071, data: 0.002) G_GAN: 0.960 G_L1: 1.672 D_real: 0.613 D_fake: 0.607 \n",
      "(epoch: 127, iters: 2120, time: 0.075, data: 0.002) G_GAN: 0.680 G_L1: 0.000 D_real: 0.803 D_fake: 0.533 \n",
      "(epoch: 127, iters: 2220, time: 0.074, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.722 D_fake: 0.666 \n",
      "End of epoch 127 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0011564\n",
      "(epoch: 128, iters: 40, time: 0.073, data: 0.002) G_GAN: 0.951 G_L1: 1.820 D_real: 0.562 D_fake: 0.598 \n",
      "(epoch: 128, iters: 140, time: 0.072, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.732 D_fake: 0.622 \n",
      "(epoch: 128, iters: 240, time: 0.072, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.697 D_fake: 0.694 \n",
      "(epoch: 128, iters: 340, time: 0.072, data: 0.002) G_GAN: 0.798 G_L1: 1.290 D_real: 0.581 D_fake: 0.637 \n",
      "(epoch: 128, iters: 440, time: 0.073, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.724 D_fake: 0.619 \n",
      "saving the latest model (epoch 128, total_steps 290000)\n",
      "(epoch: 128, iters: 540, time: 0.074, data: 0.002) G_GAN: 0.679 G_L1: 0.000 D_real: 0.692 D_fake: 0.680 \n",
      "(epoch: 128, iters: 640, time: 0.074, data: 0.002) G_GAN: 0.873 G_L1: 2.682 D_real: 0.548 D_fake: 0.636 \n",
      "(epoch: 128, iters: 740, time: 0.075, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.734 D_fake: 0.648 \n",
      "(epoch: 128, iters: 840, time: 0.071, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.715 D_fake: 0.641 \n",
      "(epoch: 128, iters: 940, time: 0.074, data: 0.002) G_GAN: 1.062 G_L1: 3.230 D_real: 0.561 D_fake: 0.568 \n",
      "(epoch: 128, iters: 1040, time: 0.072, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.746 D_fake: 0.655 \n",
      "(epoch: 128, iters: 1140, time: 0.072, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.724 D_fake: 0.678 \n",
      "(epoch: 128, iters: 1240, time: 0.072, data: 0.002) G_GAN: 1.161 G_L1: 2.399 D_real: 0.632 D_fake: 0.475 \n",
      "(epoch: 128, iters: 1340, time: 0.074, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.796 D_fake: 0.585 \n",
      "(epoch: 128, iters: 1440, time: 0.073, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.733 D_fake: 0.659 \n",
      "(epoch: 128, iters: 1540, time: 0.071, data: 0.003) G_GAN: 0.984 G_L1: 1.508 D_real: 0.603 D_fake: 0.562 \n",
      "(epoch: 128, iters: 1640, time: 0.072, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.776 D_fake: 0.620 \n",
      "(epoch: 128, iters: 1740, time: 0.072, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.730 D_fake: 0.655 \n",
      "(epoch: 128, iters: 1840, time: 0.076, data: 0.002) G_GAN: 0.903 G_L1: 0.842 D_real: 0.609 D_fake: 0.628 \n",
      "(epoch: 128, iters: 1940, time: 0.073, data: 0.003) G_GAN: 0.702 G_L1: 0.000 D_real: 0.729 D_fake: 0.682 \n",
      "(epoch: 128, iters: 2040, time: 0.071, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.702 D_fake: 0.674 \n",
      "(epoch: 128, iters: 2140, time: 0.075, data: 0.002) G_GAN: 0.917 G_L1: 0.917 D_real: 0.618 D_fake: 0.632 \n",
      "(epoch: 128, iters: 2240, time: 0.078, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.772 D_fake: 0.619 \n",
      "End of epoch 128 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0011406\n",
      "(epoch: 129, iters: 60, time: 0.079, data: 0.002) G_GAN: 0.659 G_L1: 0.000 D_real: 0.646 D_fake: 0.758 \n",
      "(epoch: 129, iters: 160, time: 0.071, data: 0.001) G_GAN: 0.938 G_L1: 2.187 D_real: 0.576 D_fake: 0.581 \n",
      "(epoch: 129, iters: 260, time: 0.072, data: 0.001) G_GAN: 0.782 G_L1: 0.000 D_real: 0.825 D_fake: 0.585 \n",
      "(epoch: 129, iters: 360, time: 0.075, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.718 D_fake: 0.651 \n",
      "(epoch: 129, iters: 460, time: 0.073, data: 0.002) G_GAN: 0.916 G_L1: 2.055 D_real: 0.581 D_fake: 0.629 \n",
      "(epoch: 129, iters: 560, time: 0.077, data: 0.003) G_GAN: 0.749 G_L1: 0.000 D_real: 0.766 D_fake: 0.625 \n",
      "(epoch: 129, iters: 660, time: 0.071, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.731 D_fake: 0.658 \n",
      "(epoch: 129, iters: 760, time: 0.072, data: 0.002) G_GAN: 0.921 G_L1: 2.009 D_real: 0.577 D_fake: 0.622 \n",
      "(epoch: 129, iters: 860, time: 0.071, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.792 D_fake: 0.558 \n",
      "(epoch: 129, iters: 960, time: 0.074, data: 0.003) G_GAN: 0.546 G_L1: 0.000 D_real: 0.686 D_fake: 0.608 \n",
      "(epoch: 129, iters: 1060, time: 0.071, data: 0.002) G_GAN: 0.739 G_L1: 0.699 D_real: 0.611 D_fake: 0.656 \n",
      "(epoch: 129, iters: 1160, time: 0.071, data: 0.003) G_GAN: 0.722 G_L1: 0.000 D_real: 0.768 D_fake: 0.637 \n",
      "(epoch: 129, iters: 1260, time: 0.073, data: 0.003) G_GAN: 0.675 G_L1: 0.000 D_real: 0.688 D_fake: 0.680 \n",
      "(epoch: 129, iters: 1360, time: 0.072, data: 0.002) G_GAN: 0.790 G_L1: 2.029 D_real: 0.559 D_fake: 0.641 \n",
      "(epoch: 129, iters: 1460, time: 0.073, data: 0.002) G_GAN: 0.769 G_L1: 0.000 D_real: 0.803 D_fake: 0.580 \n",
      "(epoch: 129, iters: 1560, time: 0.071, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.729 D_fake: 0.606 \n",
      "(epoch: 129, iters: 1660, time: 0.073, data: 0.002) G_GAN: 0.883 G_L1: 1.703 D_real: 0.590 D_fake: 0.623 \n",
      "(epoch: 129, iters: 1760, time: 0.073, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.746 D_fake: 0.651 \n",
      "(epoch: 129, iters: 1860, time: 0.071, data: 0.002) G_GAN: 0.702 G_L1: 0.000 D_real: 0.716 D_fake: 0.650 \n",
      "(epoch: 129, iters: 1960, time: 0.077, data: 0.002) G_GAN: 0.848 G_L1: 2.015 D_real: 0.575 D_fake: 0.596 \n",
      "(epoch: 129, iters: 2060, time: 0.071, data: 0.003) G_GAN: 0.741 G_L1: 0.000 D_real: 0.747 D_fake: 0.648 \n",
      "(epoch: 129, iters: 2160, time: 0.072, data: 0.003) G_GAN: 0.713 G_L1: 0.000 D_real: 0.723 D_fake: 0.652 \n",
      "(epoch: 129, iters: 2260, time: 0.071, data: 0.002) G_GAN: 0.990 G_L1: 2.749 D_real: 0.559 D_fake: 0.572 \n",
      "End of epoch 129 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0011248\n",
      "(epoch: 130, iters: 80, time: 0.074, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.756 D_fake: 0.658 \n",
      "(epoch: 130, iters: 180, time: 0.076, data: 0.003) G_GAN: 0.698 G_L1: 0.000 D_real: 0.708 D_fake: 0.647 \n",
      "(epoch: 130, iters: 280, time: 0.073, data: 0.002) G_GAN: 0.930 G_L1: 1.026 D_real: 0.604 D_fake: 0.598 \n",
      "(epoch: 130, iters: 380, time: 0.075, data: 0.002) G_GAN: 0.778 G_L1: 0.000 D_real: 0.792 D_fake: 0.622 \n",
      "(epoch: 130, iters: 480, time: 0.074, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.725 D_fake: 0.654 \n",
      "(epoch: 130, iters: 580, time: 0.076, data: 0.002) G_GAN: 0.952 G_L1: 3.541 D_real: 0.518 D_fake: 0.615 \n",
      "(epoch: 130, iters: 680, time: 0.076, data: 0.003) G_GAN: 0.716 G_L1: 0.000 D_real: 0.726 D_fake: 0.658 \n",
      "(epoch: 130, iters: 780, time: 0.071, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.707 D_fake: 0.648 \n",
      "(epoch: 130, iters: 880, time: 0.073, data: 0.003) G_GAN: 0.919 G_L1: 2.571 D_real: 0.548 D_fake: 0.604 \n",
      "saving the latest model (epoch 130, total_steps 295000)\n",
      "(epoch: 130, iters: 980, time: 0.072, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.728 D_fake: 0.668 \n",
      "(epoch: 130, iters: 1080, time: 0.075, data: 0.002) G_GAN: 0.671 G_L1: 0.000 D_real: 0.684 D_fake: 0.666 \n",
      "(epoch: 130, iters: 1180, time: 0.072, data: 0.002) G_GAN: 0.920 G_L1: 2.021 D_real: 0.581 D_fake: 0.637 \n",
      "(epoch: 130, iters: 1280, time: 0.073, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.717 D_fake: 0.675 \n",
      "(epoch: 130, iters: 1380, time: 0.074, data: 0.001) G_GAN: 0.678 G_L1: 0.000 D_real: 0.709 D_fake: 0.646 \n",
      "(epoch: 130, iters: 1480, time: 0.074, data: 0.003) G_GAN: 0.927 G_L1: 1.813 D_real: 0.579 D_fake: 0.630 \n",
      "(epoch: 130, iters: 1580, time: 0.073, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.741 D_fake: 0.639 \n",
      "(epoch: 130, iters: 1680, time: 0.072, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.708 D_fake: 0.659 \n",
      "(epoch: 130, iters: 1780, time: 0.072, data: 0.002) G_GAN: 0.843 G_L1: 2.503 D_real: 0.543 D_fake: 0.628 \n",
      "(epoch: 130, iters: 1880, time: 0.073, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.745 D_fake: 0.642 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 130, iters: 1980, time: 0.073, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.712 D_fake: 0.623 \n",
      "(epoch: 130, iters: 2080, time: 0.072, data: 0.002) G_GAN: 0.857 G_L1: 2.297 D_real: 0.524 D_fake: 0.633 \n",
      "(epoch: 130, iters: 2180, time: 0.075, data: 0.003) G_GAN: 0.737 G_L1: 0.000 D_real: 0.733 D_fake: 0.640 \n",
      "(epoch: 130, iters: 2280, time: 0.072, data: 0.004) G_GAN: 0.658 G_L1: 0.000 D_real: 0.672 D_fake: 0.767 \n",
      "saving the model at the end of epoch 130, iters 296400\n",
      "End of epoch 130 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0011089\n",
      "(epoch: 131, iters: 100, time: 0.073, data: 0.406) G_GAN: 0.914 G_L1: 2.485 D_real: 0.547 D_fake: 0.649 \n",
      "(epoch: 131, iters: 200, time: 0.078, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.710 D_fake: 0.673 \n",
      "(epoch: 131, iters: 300, time: 0.071, data: 0.003) G_GAN: 0.735 G_L1: 0.000 D_real: 0.748 D_fake: 0.641 \n",
      "(epoch: 131, iters: 400, time: 0.074, data: 0.003) G_GAN: 1.009 G_L1: 1.437 D_real: 0.567 D_fake: 0.594 \n",
      "(epoch: 131, iters: 500, time: 0.074, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.746 D_fake: 0.614 \n",
      "(epoch: 131, iters: 600, time: 0.074, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.749 D_fake: 0.642 \n",
      "(epoch: 131, iters: 700, time: 0.076, data: 0.001) G_GAN: 0.926 G_L1: 1.919 D_real: 0.557 D_fake: 0.622 \n",
      "(epoch: 131, iters: 800, time: 0.072, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.749 D_fake: 0.647 \n",
      "(epoch: 131, iters: 900, time: 0.071, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.727 D_fake: 0.652 \n",
      "(epoch: 131, iters: 1000, time: 0.073, data: 0.002) G_GAN: 0.896 G_L1: 1.678 D_real: 0.571 D_fake: 0.632 \n",
      "(epoch: 131, iters: 1100, time: 0.074, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.790 D_fake: 0.614 \n",
      "(epoch: 131, iters: 1200, time: 0.073, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.716 D_fake: 0.665 \n",
      "(epoch: 131, iters: 1300, time: 0.072, data: 0.002) G_GAN: 0.907 G_L1: 1.744 D_real: 0.599 D_fake: 0.612 \n",
      "(epoch: 131, iters: 1400, time: 0.073, data: 0.002) G_GAN: 0.799 G_L1: 0.000 D_real: 0.825 D_fake: 0.588 \n",
      "(epoch: 131, iters: 1500, time: 0.072, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.716 D_fake: 0.657 \n",
      "(epoch: 131, iters: 1600, time: 0.073, data: 0.002) G_GAN: 0.994 G_L1: 2.124 D_real: 0.569 D_fake: 0.610 \n",
      "(epoch: 131, iters: 1700, time: 0.076, data: 0.002) G_GAN: 0.768 G_L1: 0.000 D_real: 0.772 D_fake: 0.626 \n",
      "(epoch: 131, iters: 1800, time: 0.074, data: 0.003) G_GAN: 0.729 G_L1: 0.000 D_real: 0.742 D_fake: 0.638 \n",
      "(epoch: 131, iters: 1900, time: 0.074, data: 0.002) G_GAN: 0.894 G_L1: 3.702 D_real: 0.532 D_fake: 0.596 \n",
      "(epoch: 131, iters: 2000, time: 0.072, data: 0.003) G_GAN: 0.754 G_L1: 0.000 D_real: 0.777 D_fake: 0.567 \n",
      "(epoch: 131, iters: 2100, time: 0.072, data: 0.003) G_GAN: 0.695 G_L1: 0.000 D_real: 0.709 D_fake: 0.663 \n",
      "(epoch: 131, iters: 2200, time: 0.073, data: 0.003) G_GAN: 0.901 G_L1: 1.583 D_real: 0.575 D_fake: 0.651 \n",
      "End of epoch 131 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0010931\n",
      "(epoch: 132, iters: 20, time: 0.073, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.758 D_fake: 0.662 \n",
      "(epoch: 132, iters: 120, time: 0.073, data: 0.001) G_GAN: 0.724 G_L1: 0.000 D_real: 0.728 D_fake: 0.642 \n",
      "(epoch: 132, iters: 220, time: 0.073, data: 0.002) G_GAN: 0.974 G_L1: 2.749 D_real: 0.531 D_fake: 0.642 \n",
      "(epoch: 132, iters: 320, time: 0.074, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.727 D_fake: 0.654 \n",
      "(epoch: 132, iters: 420, time: 0.071, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.722 D_fake: 0.668 \n",
      "(epoch: 132, iters: 520, time: 0.073, data: 0.002) G_GAN: 0.929 G_L1: 1.419 D_real: 0.605 D_fake: 0.564 \n",
      "(epoch: 132, iters: 620, time: 0.075, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.753 D_fake: 0.626 \n",
      "(epoch: 132, iters: 720, time: 0.076, data: 0.002) G_GAN: 0.702 G_L1: 0.000 D_real: 0.708 D_fake: 0.667 \n",
      "(epoch: 132, iters: 820, time: 0.075, data: 0.003) G_GAN: 0.900 G_L1: 1.824 D_real: 0.608 D_fake: 0.681 \n",
      "(epoch: 132, iters: 920, time: 0.076, data: 0.002) G_GAN: 0.643 G_L1: 0.000 D_real: 0.636 D_fake: 0.647 \n",
      "(epoch: 132, iters: 1020, time: 0.079, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.737 D_fake: 0.640 \n",
      "(epoch: 132, iters: 1120, time: 0.071, data: 0.002) G_GAN: 0.900 G_L1: 1.957 D_real: 0.571 D_fake: 0.638 \n",
      "(epoch: 132, iters: 1220, time: 0.072, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.744 D_fake: 0.640 \n",
      "(epoch: 132, iters: 1320, time: 0.077, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.727 D_fake: 0.653 \n",
      "saving the latest model (epoch 132, total_steps 300000)\n",
      "(epoch: 132, iters: 1420, time: 0.072, data: 0.003) G_GAN: 0.939 G_L1: 2.010 D_real: 0.549 D_fake: 0.634 \n",
      "(epoch: 132, iters: 1520, time: 0.078, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.729 D_fake: 0.648 \n",
      "(epoch: 132, iters: 1620, time: 0.071, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.736 D_fake: 0.655 \n",
      "(epoch: 132, iters: 1720, time: 0.072, data: 0.002) G_GAN: 0.987 G_L1: 3.150 D_real: 0.525 D_fake: 0.651 \n",
      "(epoch: 132, iters: 1820, time: 0.075, data: 0.002) G_GAN: 0.778 G_L1: 0.000 D_real: 0.787 D_fake: 0.613 \n",
      "(epoch: 132, iters: 1920, time: 0.071, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.725 D_fake: 0.661 \n",
      "(epoch: 132, iters: 2020, time: 0.072, data: 0.002) G_GAN: 0.939 G_L1: 1.672 D_real: 0.598 D_fake: 0.615 \n",
      "(epoch: 132, iters: 2120, time: 0.074, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.772 D_fake: 0.640 \n",
      "(epoch: 132, iters: 2220, time: 0.077, data: 0.003) G_GAN: 0.689 G_L1: 0.000 D_real: 0.699 D_fake: 0.642 \n",
      "End of epoch 132 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0010772\n",
      "(epoch: 133, iters: 40, time: 0.072, data: 0.002) G_GAN: 0.914 G_L1: 1.820 D_real: 0.551 D_fake: 0.639 \n",
      "(epoch: 133, iters: 140, time: 0.073, data: 0.003) G_GAN: 0.740 G_L1: 0.000 D_real: 0.747 D_fake: 0.616 \n",
      "(epoch: 133, iters: 240, time: 0.073, data: 0.002) G_GAN: 0.677 G_L1: 0.000 D_real: 0.691 D_fake: 0.668 \n",
      "(epoch: 133, iters: 340, time: 0.075, data: 0.003) G_GAN: 0.828 G_L1: 1.290 D_real: 0.584 D_fake: 0.633 \n",
      "(epoch: 133, iters: 440, time: 0.072, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.732 D_fake: 0.640 \n",
      "(epoch: 133, iters: 540, time: 0.075, data: 0.003) G_GAN: 0.664 G_L1: 0.000 D_real: 0.686 D_fake: 0.643 \n",
      "(epoch: 133, iters: 640, time: 0.072, data: 0.002) G_GAN: 0.865 G_L1: 2.682 D_real: 0.545 D_fake: 0.611 \n",
      "(epoch: 133, iters: 740, time: 0.071, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.720 D_fake: 0.672 \n",
      "(epoch: 133, iters: 840, time: 0.071, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.715 D_fake: 0.646 \n",
      "(epoch: 133, iters: 940, time: 0.072, data: 0.002) G_GAN: 1.095 G_L1: 3.230 D_real: 0.535 D_fake: 0.600 \n",
      "(epoch: 133, iters: 1040, time: 0.073, data: 0.003) G_GAN: 0.744 G_L1: 0.000 D_real: 0.756 D_fake: 0.636 \n",
      "(epoch: 133, iters: 1140, time: 0.072, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.745 D_fake: 0.662 \n",
      "(epoch: 133, iters: 1240, time: 0.074, data: 0.002) G_GAN: 1.111 G_L1: 2.399 D_real: 0.591 D_fake: 0.614 \n",
      "(epoch: 133, iters: 1340, time: 0.071, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.785 D_fake: 0.604 \n",
      "(epoch: 133, iters: 1440, time: 0.072, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.728 D_fake: 0.632 \n",
      "(epoch: 133, iters: 1540, time: 0.073, data: 0.002) G_GAN: 0.955 G_L1: 1.508 D_real: 0.586 D_fake: 0.606 \n",
      "(epoch: 133, iters: 1640, time: 0.072, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.760 D_fake: 0.637 \n",
      "(epoch: 133, iters: 1740, time: 0.075, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.743 D_fake: 0.655 \n",
      "(epoch: 133, iters: 1840, time: 0.075, data: 0.002) G_GAN: 0.910 G_L1: 0.842 D_real: 0.618 D_fake: 0.620 \n",
      "(epoch: 133, iters: 1940, time: 0.074, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.756 D_fake: 0.632 \n",
      "(epoch: 133, iters: 2040, time: 0.075, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.716 D_fake: 0.676 \n",
      "(epoch: 133, iters: 2140, time: 0.074, data: 0.002) G_GAN: 0.941 G_L1: 0.917 D_real: 0.674 D_fake: 0.566 \n",
      "(epoch: 133, iters: 2240, time: 0.075, data: 0.003) G_GAN: 0.742 G_L1: 0.000 D_real: 0.756 D_fake: 0.610 \n",
      "End of epoch 133 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0010614\n",
      "(epoch: 134, iters: 60, time: 0.074, data: 0.002) G_GAN: 0.661 G_L1: 0.000 D_real: 0.688 D_fake: 0.721 \n",
      "(epoch: 134, iters: 160, time: 0.072, data: 0.001) G_GAN: 0.951 G_L1: 2.187 D_real: 0.579 D_fake: 0.617 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 134, iters: 260, time: 0.073, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.756 D_fake: 0.646 \n",
      "(epoch: 134, iters: 360, time: 0.072, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.712 D_fake: 0.689 \n",
      "(epoch: 134, iters: 460, time: 0.074, data: 0.002) G_GAN: 0.915 G_L1: 2.055 D_real: 0.577 D_fake: 0.603 \n",
      "(epoch: 134, iters: 560, time: 0.071, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.726 D_fake: 0.658 \n",
      "(epoch: 134, iters: 660, time: 0.072, data: 0.003) G_GAN: 0.722 G_L1: 0.000 D_real: 0.736 D_fake: 0.644 \n",
      "(epoch: 134, iters: 760, time: 0.072, data: 0.003) G_GAN: 0.976 G_L1: 2.009 D_real: 0.583 D_fake: 0.624 \n",
      "(epoch: 134, iters: 860, time: 0.071, data: 0.003) G_GAN: 0.766 G_L1: 0.000 D_real: 0.783 D_fake: 0.624 \n",
      "(epoch: 134, iters: 960, time: 0.074, data: 0.003) G_GAN: 0.707 G_L1: 0.000 D_real: 0.729 D_fake: 0.668 \n",
      "(epoch: 134, iters: 1060, time: 0.073, data: 0.003) G_GAN: 0.848 G_L1: 0.699 D_real: 0.609 D_fake: 0.649 \n",
      "(epoch: 134, iters: 1160, time: 0.074, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.730 D_fake: 0.638 \n",
      "(epoch: 134, iters: 1260, time: 0.071, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.707 D_fake: 0.695 \n",
      "(epoch: 134, iters: 1360, time: 0.077, data: 0.002) G_GAN: 0.818 G_L1: 2.029 D_real: 0.564 D_fake: 0.625 \n",
      "(epoch: 134, iters: 1460, time: 0.073, data: 0.003) G_GAN: 0.777 G_L1: 0.000 D_real: 0.801 D_fake: 0.612 \n",
      "(epoch: 134, iters: 1560, time: 0.071, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.728 D_fake: 0.649 \n",
      "(epoch: 134, iters: 1660, time: 0.075, data: 0.002) G_GAN: 0.872 G_L1: 1.703 D_real: 0.554 D_fake: 0.616 \n",
      "(epoch: 134, iters: 1760, time: 0.075, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.740 D_fake: 0.637 \n",
      "saving the latest model (epoch 134, total_steps 305000)\n",
      "(epoch: 134, iters: 1860, time: 0.071, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.716 D_fake: 0.691 \n",
      "(epoch: 134, iters: 1960, time: 0.072, data: 0.002) G_GAN: 0.896 G_L1: 2.015 D_real: 0.589 D_fake: 0.614 \n",
      "(epoch: 134, iters: 2060, time: 0.074, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.731 D_fake: 0.649 \n",
      "(epoch: 134, iters: 2160, time: 0.071, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.726 D_fake: 0.667 \n",
      "(epoch: 134, iters: 2260, time: 0.071, data: 0.002) G_GAN: 1.008 G_L1: 2.749 D_real: 0.589 D_fake: 0.590 \n",
      "End of epoch 134 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0010455\n",
      "(epoch: 135, iters: 80, time: 0.073, data: 0.003) G_GAN: 0.702 G_L1: 0.000 D_real: 0.725 D_fake: 0.669 \n",
      "(epoch: 135, iters: 180, time: 0.073, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.710 D_fake: 0.680 \n",
      "(epoch: 135, iters: 280, time: 0.073, data: 0.002) G_GAN: 0.924 G_L1: 1.026 D_real: 0.600 D_fake: 0.605 \n",
      "(epoch: 135, iters: 380, time: 0.077, data: 0.002) G_GAN: 0.781 G_L1: 0.000 D_real: 0.802 D_fake: 0.605 \n",
      "(epoch: 135, iters: 480, time: 0.076, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.728 D_fake: 0.656 \n",
      "(epoch: 135, iters: 580, time: 0.075, data: 0.002) G_GAN: 1.011 G_L1: 3.541 D_real: 0.516 D_fake: 0.614 \n",
      "(epoch: 135, iters: 680, time: 0.072, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.713 D_fake: 0.632 \n",
      "(epoch: 135, iters: 780, time: 0.075, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.703 D_fake: 0.652 \n",
      "(epoch: 135, iters: 880, time: 0.072, data: 0.003) G_GAN: 1.002 G_L1: 2.571 D_real: 0.544 D_fake: 0.614 \n",
      "(epoch: 135, iters: 980, time: 0.071, data: 0.003) G_GAN: 0.718 G_L1: 0.000 D_real: 0.713 D_fake: 0.668 \n",
      "(epoch: 135, iters: 1080, time: 0.071, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.709 D_fake: 0.663 \n",
      "(epoch: 135, iters: 1180, time: 0.077, data: 0.002) G_GAN: 0.927 G_L1: 2.021 D_real: 0.564 D_fake: 0.590 \n",
      "(epoch: 135, iters: 1280, time: 0.076, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.790 D_fake: 0.600 \n",
      "(epoch: 135, iters: 1380, time: 0.073, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.718 D_fake: 0.663 \n",
      "(epoch: 135, iters: 1480, time: 0.071, data: 0.002) G_GAN: 0.878 G_L1: 1.813 D_real: 0.567 D_fake: 0.637 \n",
      "(epoch: 135, iters: 1580, time: 0.075, data: 0.003) G_GAN: 0.741 G_L1: 0.000 D_real: 0.746 D_fake: 0.659 \n",
      "(epoch: 135, iters: 1680, time: 0.073, data: 0.003) G_GAN: 0.728 G_L1: 0.000 D_real: 0.736 D_fake: 0.647 \n",
      "(epoch: 135, iters: 1780, time: 0.074, data: 0.002) G_GAN: 0.866 G_L1: 2.503 D_real: 0.547 D_fake: 0.633 \n",
      "(epoch: 135, iters: 1880, time: 0.073, data: 0.003) G_GAN: 0.729 G_L1: 0.000 D_real: 0.735 D_fake: 0.662 \n",
      "(epoch: 135, iters: 1980, time: 0.072, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.707 D_fake: 0.658 \n",
      "(epoch: 135, iters: 2080, time: 0.071, data: 0.002) G_GAN: 0.854 G_L1: 2.297 D_real: 0.507 D_fake: 0.653 \n",
      "(epoch: 135, iters: 2180, time: 0.072, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.764 D_fake: 0.565 \n",
      "(epoch: 135, iters: 2280, time: 0.072, data: 0.002) G_GAN: 0.597 G_L1: 0.000 D_real: 0.602 D_fake: 0.703 \n",
      "saving the model at the end of epoch 135, iters 307800\n",
      "End of epoch 135 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0010297\n",
      "(epoch: 136, iters: 100, time: 0.078, data: 0.421) G_GAN: 0.953 G_L1: 2.485 D_real: 0.550 D_fake: 0.641 \n",
      "(epoch: 136, iters: 200, time: 0.072, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.716 D_fake: 0.638 \n",
      "(epoch: 136, iters: 300, time: 0.073, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.752 D_fake: 0.647 \n",
      "(epoch: 136, iters: 400, time: 0.072, data: 0.002) G_GAN: 1.045 G_L1: 1.437 D_real: 0.578 D_fake: 0.584 \n",
      "(epoch: 136, iters: 500, time: 0.072, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.731 D_fake: 0.640 \n",
      "(epoch: 136, iters: 600, time: 0.071, data: 0.003) G_GAN: 0.718 G_L1: 0.000 D_real: 0.733 D_fake: 0.674 \n",
      "(epoch: 136, iters: 700, time: 0.075, data: 0.003) G_GAN: 1.025 G_L1: 1.919 D_real: 0.580 D_fake: 0.562 \n",
      "(epoch: 136, iters: 800, time: 0.072, data: 0.003) G_GAN: 0.709 G_L1: 0.000 D_real: 0.750 D_fake: 0.631 \n",
      "(epoch: 136, iters: 900, time: 0.072, data: 0.003) G_GAN: 0.697 G_L1: 0.000 D_real: 0.699 D_fake: 0.685 \n",
      "(epoch: 136, iters: 1000, time: 0.075, data: 0.002) G_GAN: 0.874 G_L1: 1.678 D_real: 0.561 D_fake: 0.695 \n",
      "(epoch: 136, iters: 1100, time: 0.073, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.964 D_fake: 0.562 \n",
      "(epoch: 136, iters: 1200, time: 0.074, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.738 D_fake: 0.648 \n",
      "(epoch: 136, iters: 1300, time: 0.073, data: 0.002) G_GAN: 0.898 G_L1: 1.744 D_real: 0.625 D_fake: 0.629 \n",
      "(epoch: 136, iters: 1400, time: 0.071, data: 0.003) G_GAN: 0.787 G_L1: 0.000 D_real: 0.834 D_fake: 0.611 \n",
      "(epoch: 136, iters: 1500, time: 0.077, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.725 D_fake: 0.651 \n",
      "(epoch: 136, iters: 1600, time: 0.073, data: 0.002) G_GAN: 0.962 G_L1: 2.124 D_real: 0.576 D_fake: 0.606 \n",
      "(epoch: 136, iters: 1700, time: 0.075, data: 0.002) G_GAN: 0.773 G_L1: 0.000 D_real: 0.776 D_fake: 0.610 \n",
      "(epoch: 136, iters: 1800, time: 0.071, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.714 D_fake: 0.651 \n",
      "(epoch: 136, iters: 1900, time: 0.072, data: 0.003) G_GAN: 0.886 G_L1: 3.702 D_real: 0.516 D_fake: 0.616 \n",
      "(epoch: 136, iters: 2000, time: 0.072, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.769 D_fake: 0.615 \n",
      "(epoch: 136, iters: 2100, time: 0.072, data: 0.002) G_GAN: 0.673 G_L1: 0.000 D_real: 0.686 D_fake: 0.665 \n",
      "(epoch: 136, iters: 2200, time: 0.073, data: 0.002) G_GAN: 0.887 G_L1: 1.583 D_real: 0.586 D_fake: 0.579 \n",
      "saving the latest model (epoch 136, total_steps 310000)\n",
      "End of epoch 136 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0010139\n",
      "(epoch: 137, iters: 20, time: 0.077, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.746 D_fake: 0.643 \n",
      "(epoch: 137, iters: 120, time: 0.072, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.729 D_fake: 0.646 \n",
      "(epoch: 137, iters: 220, time: 0.072, data: 0.002) G_GAN: 0.988 G_L1: 2.749 D_real: 0.520 D_fake: 0.630 \n",
      "(epoch: 137, iters: 320, time: 0.074, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.731 D_fake: 0.661 \n",
      "(epoch: 137, iters: 420, time: 0.074, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.725 D_fake: 0.675 \n",
      "(epoch: 137, iters: 520, time: 0.075, data: 0.002) G_GAN: 0.934 G_L1: 1.419 D_real: 0.599 D_fake: 0.604 \n",
      "(epoch: 137, iters: 620, time: 0.074, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.758 D_fake: 0.642 \n",
      "(epoch: 137, iters: 720, time: 0.073, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.726 D_fake: 0.627 \n",
      "(epoch: 137, iters: 820, time: 0.072, data: 0.002) G_GAN: 0.905 G_L1: 1.824 D_real: 0.575 D_fake: 0.628 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 137, iters: 920, time: 0.078, data: 0.002) G_GAN: 0.680 G_L1: 0.000 D_real: 0.672 D_fake: 0.724 \n",
      "(epoch: 137, iters: 1020, time: 0.074, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.693 D_fake: 0.664 \n",
      "(epoch: 137, iters: 1120, time: 0.076, data: 0.002) G_GAN: 0.882 G_L1: 1.957 D_real: 0.548 D_fake: 0.697 \n",
      "(epoch: 137, iters: 1220, time: 0.075, data: 0.003) G_GAN: 0.730 G_L1: 0.000 D_real: 0.736 D_fake: 0.640 \n",
      "(epoch: 137, iters: 1320, time: 0.077, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.716 D_fake: 0.634 \n",
      "(epoch: 137, iters: 1420, time: 0.072, data: 0.002) G_GAN: 0.950 G_L1: 2.010 D_real: 0.558 D_fake: 0.593 \n",
      "(epoch: 137, iters: 1520, time: 0.072, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.743 D_fake: 0.640 \n",
      "(epoch: 137, iters: 1620, time: 0.077, data: 0.003) G_GAN: 0.709 G_L1: 0.000 D_real: 0.727 D_fake: 0.634 \n",
      "(epoch: 137, iters: 1720, time: 0.073, data: 0.002) G_GAN: 1.032 G_L1: 3.150 D_real: 0.525 D_fake: 0.615 \n",
      "(epoch: 137, iters: 1820, time: 0.074, data: 0.002) G_GAN: 0.787 G_L1: 0.000 D_real: 0.796 D_fake: 0.615 \n",
      "(epoch: 137, iters: 1920, time: 0.073, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.724 D_fake: 0.615 \n",
      "(epoch: 137, iters: 2020, time: 0.073, data: 0.002) G_GAN: 0.974 G_L1: 1.672 D_real: 0.592 D_fake: 0.626 \n",
      "(epoch: 137, iters: 2120, time: 0.074, data: 0.002) G_GAN: 0.641 G_L1: 0.000 D_real: 0.865 D_fake: 0.521 \n",
      "(epoch: 137, iters: 2220, time: 0.071, data: 0.002) G_GAN: 0.638 G_L1: 0.000 D_real: 0.680 D_fake: 0.622 \n",
      "End of epoch 137 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0009980\n",
      "(epoch: 138, iters: 40, time: 0.075, data: 0.002) G_GAN: 0.952 G_L1: 1.820 D_real: 0.547 D_fake: 0.593 \n",
      "(epoch: 138, iters: 140, time: 0.071, data: 0.001) G_GAN: 0.763 G_L1: 0.000 D_real: 0.781 D_fake: 0.618 \n",
      "(epoch: 138, iters: 240, time: 0.074, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.702 D_fake: 0.693 \n",
      "(epoch: 138, iters: 340, time: 0.072, data: 0.002) G_GAN: 0.829 G_L1: 1.290 D_real: 0.569 D_fake: 0.622 \n",
      "(epoch: 138, iters: 440, time: 0.072, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.734 D_fake: 0.648 \n",
      "(epoch: 138, iters: 540, time: 0.071, data: 0.003) G_GAN: 0.647 G_L1: 0.000 D_real: 0.668 D_fake: 0.687 \n",
      "(epoch: 138, iters: 640, time: 0.072, data: 0.002) G_GAN: 0.878 G_L1: 2.682 D_real: 0.553 D_fake: 0.653 \n",
      "(epoch: 138, iters: 740, time: 0.072, data: 0.003) G_GAN: 0.719 G_L1: 0.000 D_real: 0.743 D_fake: 0.618 \n",
      "(epoch: 138, iters: 840, time: 0.079, data: 0.002) G_GAN: 0.676 G_L1: 0.000 D_real: 0.685 D_fake: 0.674 \n",
      "(epoch: 138, iters: 940, time: 0.077, data: 0.002) G_GAN: 1.085 G_L1: 3.230 D_real: 0.535 D_fake: 0.634 \n",
      "(epoch: 138, iters: 1040, time: 0.077, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.765 D_fake: 0.640 \n",
      "(epoch: 138, iters: 1140, time: 0.072, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.729 D_fake: 0.627 \n",
      "(epoch: 138, iters: 1240, time: 0.072, data: 0.002) G_GAN: 1.153 G_L1: 2.399 D_real: 0.620 D_fake: 0.618 \n",
      "(epoch: 138, iters: 1340, time: 0.077, data: 0.002) G_GAN: 0.785 G_L1: 0.000 D_real: 0.806 D_fake: 0.606 \n",
      "(epoch: 138, iters: 1440, time: 0.078, data: 0.003) G_GAN: 0.713 G_L1: 0.000 D_real: 0.724 D_fake: 0.655 \n",
      "(epoch: 138, iters: 1540, time: 0.077, data: 0.002) G_GAN: 0.994 G_L1: 1.508 D_real: 0.585 D_fake: 0.603 \n",
      "(epoch: 138, iters: 1640, time: 0.075, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.748 D_fake: 0.651 \n",
      "(epoch: 138, iters: 1740, time: 0.074, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.741 D_fake: 0.653 \n",
      "(epoch: 138, iters: 1840, time: 0.077, data: 0.004) G_GAN: 0.938 G_L1: 0.842 D_real: 0.604 D_fake: 0.640 \n",
      "(epoch: 138, iters: 1940, time: 0.072, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.730 D_fake: 0.637 \n",
      "(epoch: 138, iters: 2040, time: 0.077, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.731 D_fake: 0.622 \n",
      "(epoch: 138, iters: 2140, time: 0.077, data: 0.002) G_GAN: 0.929 G_L1: 0.917 D_real: 0.608 D_fake: 0.612 \n",
      "(epoch: 138, iters: 2240, time: 0.077, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.752 D_fake: 0.638 \n",
      "End of epoch 138 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0009822\n",
      "(epoch: 139, iters: 60, time: 0.075, data: 0.002) G_GAN: 0.669 G_L1: 0.000 D_real: 0.681 D_fake: 0.720 \n",
      "(epoch: 139, iters: 160, time: 0.076, data: 0.001) G_GAN: 0.987 G_L1: 2.187 D_real: 0.560 D_fake: 0.618 \n",
      "(epoch: 139, iters: 260, time: 0.075, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.745 D_fake: 0.624 \n",
      "(epoch: 139, iters: 360, time: 0.075, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.717 D_fake: 0.674 \n",
      "saving the latest model (epoch 139, total_steps 315000)\n",
      "(epoch: 139, iters: 460, time: 0.072, data: 0.002) G_GAN: 0.956 G_L1: 2.055 D_real: 0.576 D_fake: 0.574 \n",
      "(epoch: 139, iters: 560, time: 0.072, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.729 D_fake: 0.668 \n",
      "(epoch: 139, iters: 660, time: 0.073, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.745 D_fake: 0.564 \n",
      "(epoch: 139, iters: 760, time: 0.074, data: 0.003) G_GAN: 0.962 G_L1: 2.009 D_real: 0.543 D_fake: 0.634 \n",
      "(epoch: 139, iters: 860, time: 0.071, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.775 D_fake: 0.579 \n",
      "(epoch: 139, iters: 960, time: 0.072, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.719 D_fake: 0.689 \n",
      "(epoch: 139, iters: 1060, time: 0.076, data: 0.002) G_GAN: 0.847 G_L1: 0.699 D_real: 0.619 D_fake: 0.644 \n",
      "(epoch: 139, iters: 1160, time: 0.071, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.759 D_fake: 0.619 \n",
      "(epoch: 139, iters: 1260, time: 0.074, data: 0.002) G_GAN: 0.657 G_L1: 0.000 D_real: 0.671 D_fake: 0.719 \n",
      "(epoch: 139, iters: 1360, time: 0.071, data: 0.002) G_GAN: 0.795 G_L1: 2.029 D_real: 0.538 D_fake: 0.635 \n",
      "(epoch: 139, iters: 1460, time: 0.072, data: 0.002) G_GAN: 0.785 G_L1: 0.000 D_real: 0.830 D_fake: 0.592 \n",
      "(epoch: 139, iters: 1560, time: 0.074, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.730 D_fake: 0.634 \n",
      "(epoch: 139, iters: 1660, time: 0.071, data: 0.002) G_GAN: 0.906 G_L1: 1.703 D_real: 0.573 D_fake: 0.611 \n",
      "(epoch: 139, iters: 1760, time: 0.071, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.741 D_fake: 0.609 \n",
      "(epoch: 139, iters: 1860, time: 0.071, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.734 D_fake: 0.652 \n",
      "(epoch: 139, iters: 1960, time: 0.074, data: 0.002) G_GAN: 0.888 G_L1: 2.015 D_real: 0.565 D_fake: 0.589 \n",
      "(epoch: 139, iters: 2060, time: 0.071, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.733 D_fake: 0.658 \n",
      "(epoch: 139, iters: 2160, time: 0.074, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.703 D_fake: 0.684 \n",
      "(epoch: 139, iters: 2260, time: 0.074, data: 0.002) G_GAN: 1.018 G_L1: 2.749 D_real: 0.548 D_fake: 0.601 \n",
      "End of epoch 139 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0009663\n",
      "(epoch: 140, iters: 80, time: 0.073, data: 0.003) G_GAN: 0.754 G_L1: 0.000 D_real: 0.784 D_fake: 0.650 \n",
      "(epoch: 140, iters: 180, time: 0.077, data: 0.003) G_GAN: 0.686 G_L1: 0.000 D_real: 0.699 D_fake: 0.665 \n",
      "(epoch: 140, iters: 280, time: 0.072, data: 0.002) G_GAN: 0.972 G_L1: 1.026 D_real: 0.596 D_fake: 0.631 \n",
      "(epoch: 140, iters: 380, time: 0.076, data: 0.002) G_GAN: 0.771 G_L1: 0.000 D_real: 0.795 D_fake: 0.624 \n",
      "(epoch: 140, iters: 480, time: 0.072, data: 0.002) G_GAN: 0.676 G_L1: 0.000 D_real: 0.694 D_fake: 0.682 \n",
      "(epoch: 140, iters: 580, time: 0.075, data: 0.002) G_GAN: 1.053 G_L1: 3.541 D_real: 0.533 D_fake: 0.609 \n",
      "(epoch: 140, iters: 680, time: 0.075, data: 0.003) G_GAN: 0.707 G_L1: 0.000 D_real: 0.714 D_fake: 0.687 \n",
      "(epoch: 140, iters: 780, time: 0.072, data: 0.002) G_GAN: 0.662 G_L1: 0.000 D_real: 0.684 D_fake: 0.678 \n",
      "(epoch: 140, iters: 880, time: 0.073, data: 0.002) G_GAN: 0.982 G_L1: 2.571 D_real: 0.508 D_fake: 0.661 \n",
      "(epoch: 140, iters: 980, time: 0.073, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.758 D_fake: 0.650 \n",
      "(epoch: 140, iters: 1080, time: 0.071, data: 0.002) G_GAN: 0.684 G_L1: 0.000 D_real: 0.697 D_fake: 0.649 \n",
      "(epoch: 140, iters: 1180, time: 0.073, data: 0.002) G_GAN: 1.021 G_L1: 2.021 D_real: 0.563 D_fake: 0.598 \n",
      "(epoch: 140, iters: 1280, time: 0.075, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.730 D_fake: 0.674 \n",
      "(epoch: 140, iters: 1380, time: 0.071, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.723 D_fake: 0.643 \n",
      "(epoch: 140, iters: 1480, time: 0.073, data: 0.002) G_GAN: 0.968 G_L1: 1.813 D_real: 0.563 D_fake: 0.624 \n",
      "(epoch: 140, iters: 1580, time: 0.075, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.755 D_fake: 0.615 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 140, iters: 1680, time: 0.072, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.715 D_fake: 0.652 \n",
      "(epoch: 140, iters: 1780, time: 0.075, data: 0.002) G_GAN: 0.862 G_L1: 2.503 D_real: 0.554 D_fake: 0.626 \n",
      "(epoch: 140, iters: 1880, time: 0.073, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.763 D_fake: 0.619 \n",
      "(epoch: 140, iters: 1980, time: 0.072, data: 0.002) G_GAN: 0.688 G_L1: 0.000 D_real: 0.700 D_fake: 0.644 \n",
      "(epoch: 140, iters: 2080, time: 0.073, data: 0.002) G_GAN: 0.875 G_L1: 2.297 D_real: 0.532 D_fake: 0.634 \n",
      "(epoch: 140, iters: 2180, time: 0.075, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.760 D_fake: 0.626 \n",
      "(epoch: 140, iters: 2280, time: 0.070, data: 0.002) G_GAN: 0.667 G_L1: 0.000 D_real: 0.679 D_fake: 0.663 \n",
      "saving the model at the end of epoch 140, iters 319200\n",
      "End of epoch 140 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0009505\n",
      "(epoch: 141, iters: 100, time: 0.074, data: 0.415) G_GAN: 0.981 G_L1: 2.485 D_real: 0.541 D_fake: 0.628 \n",
      "(epoch: 141, iters: 200, time: 0.071, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.709 D_fake: 0.656 \n",
      "(epoch: 141, iters: 300, time: 0.072, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.727 D_fake: 0.664 \n",
      "(epoch: 141, iters: 400, time: 0.078, data: 0.002) G_GAN: 1.029 G_L1: 1.437 D_real: 0.596 D_fake: 0.576 \n",
      "(epoch: 141, iters: 500, time: 0.071, data: 0.003) G_GAN: 0.725 G_L1: 0.000 D_real: 0.735 D_fake: 0.629 \n",
      "(epoch: 141, iters: 600, time: 0.073, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.763 D_fake: 0.645 \n",
      "(epoch: 141, iters: 700, time: 0.073, data: 0.002) G_GAN: 1.032 G_L1: 1.919 D_real: 0.541 D_fake: 0.661 \n",
      "(epoch: 141, iters: 800, time: 0.075, data: 0.003) G_GAN: 0.723 G_L1: 0.000 D_real: 0.723 D_fake: 0.654 \n",
      "saving the latest model (epoch 141, total_steps 320000)\n",
      "(epoch: 141, iters: 900, time: 0.073, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.749 D_fake: 0.621 \n",
      "(epoch: 141, iters: 1000, time: 0.072, data: 0.002) G_GAN: 0.955 G_L1: 1.678 D_real: 0.576 D_fake: 0.653 \n",
      "(epoch: 141, iters: 1100, time: 0.073, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.811 D_fake: 0.601 \n",
      "(epoch: 141, iters: 1200, time: 0.074, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.729 D_fake: 0.664 \n",
      "(epoch: 141, iters: 1300, time: 0.075, data: 0.002) G_GAN: 0.952 G_L1: 1.744 D_real: 0.616 D_fake: 0.573 \n",
      "(epoch: 141, iters: 1400, time: 0.074, data: 0.002) G_GAN: 0.796 G_L1: 0.000 D_real: 0.816 D_fake: 0.580 \n",
      "(epoch: 141, iters: 1500, time: 0.072, data: 0.003) G_GAN: 0.699 G_L1: 0.000 D_real: 0.718 D_fake: 0.602 \n",
      "(epoch: 141, iters: 1600, time: 0.072, data: 0.003) G_GAN: 1.011 G_L1: 2.124 D_real: 0.557 D_fake: 0.607 \n",
      "(epoch: 141, iters: 1700, time: 0.077, data: 0.002) G_GAN: 0.777 G_L1: 0.000 D_real: 0.785 D_fake: 0.622 \n",
      "(epoch: 141, iters: 1800, time: 0.074, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.732 D_fake: 0.663 \n",
      "(epoch: 141, iters: 1900, time: 0.073, data: 0.003) G_GAN: 0.856 G_L1: 3.702 D_real: 0.500 D_fake: 0.624 \n",
      "(epoch: 141, iters: 2000, time: 0.074, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.765 D_fake: 0.644 \n",
      "(epoch: 141, iters: 2100, time: 0.076, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.717 D_fake: 0.659 \n",
      "(epoch: 141, iters: 2200, time: 0.076, data: 0.002) G_GAN: 0.904 G_L1: 1.583 D_real: 0.572 D_fake: 0.595 \n",
      "End of epoch 141 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0009347\n",
      "(epoch: 142, iters: 20, time: 0.073, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.732 D_fake: 0.616 \n",
      "(epoch: 142, iters: 120, time: 0.077, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.744 D_fake: 0.627 \n",
      "(epoch: 142, iters: 220, time: 0.072, data: 0.002) G_GAN: 1.044 G_L1: 2.749 D_real: 0.533 D_fake: 0.591 \n",
      "(epoch: 142, iters: 320, time: 0.074, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.741 D_fake: 0.615 \n",
      "(epoch: 142, iters: 420, time: 0.074, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.729 D_fake: 0.641 \n",
      "(epoch: 142, iters: 520, time: 0.074, data: 0.002) G_GAN: 0.977 G_L1: 1.419 D_real: 0.646 D_fake: 0.662 \n",
      "(epoch: 142, iters: 620, time: 0.071, data: 0.003) G_GAN: 0.726 G_L1: 0.000 D_real: 0.740 D_fake: 0.651 \n",
      "(epoch: 142, iters: 720, time: 0.076, data: 0.003) G_GAN: 0.739 G_L1: 0.000 D_real: 0.752 D_fake: 0.625 \n",
      "(epoch: 142, iters: 820, time: 0.074, data: 0.003) G_GAN: 0.867 G_L1: 1.824 D_real: 0.547 D_fake: 0.626 \n",
      "(epoch: 142, iters: 920, time: 0.072, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.724 D_fake: 0.637 \n",
      "(epoch: 142, iters: 1020, time: 0.072, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.712 D_fake: 0.630 \n",
      "(epoch: 142, iters: 1120, time: 0.078, data: 0.002) G_GAN: 0.900 G_L1: 1.957 D_real: 0.565 D_fake: 0.631 \n",
      "(epoch: 142, iters: 1220, time: 0.074, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.750 D_fake: 0.604 \n",
      "(epoch: 142, iters: 1320, time: 0.073, data: 0.003) G_GAN: 0.703 G_L1: 0.000 D_real: 0.724 D_fake: 0.636 \n",
      "(epoch: 142, iters: 1420, time: 0.071, data: 0.002) G_GAN: 0.956 G_L1: 2.010 D_real: 0.558 D_fake: 0.614 \n",
      "(epoch: 142, iters: 1520, time: 0.073, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.735 D_fake: 0.637 \n",
      "(epoch: 142, iters: 1620, time: 0.071, data: 0.003) G_GAN: 0.749 G_L1: 0.000 D_real: 0.762 D_fake: 0.622 \n",
      "(epoch: 142, iters: 1720, time: 0.075, data: 0.003) G_GAN: 1.125 G_L1: 3.150 D_real: 0.532 D_fake: 0.585 \n",
      "(epoch: 142, iters: 1820, time: 0.077, data: 0.002) G_GAN: 0.778 G_L1: 0.000 D_real: 0.791 D_fake: 0.609 \n",
      "(epoch: 142, iters: 1920, time: 0.076, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.725 D_fake: 0.670 \n",
      "(epoch: 142, iters: 2020, time: 0.079, data: 0.002) G_GAN: 0.968 G_L1: 1.672 D_real: 0.605 D_fake: 0.585 \n",
      "(epoch: 142, iters: 2120, time: 0.072, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.756 D_fake: 0.615 \n",
      "(epoch: 142, iters: 2220, time: 0.072, data: 0.002) G_GAN: 0.677 G_L1: 0.000 D_real: 0.650 D_fake: 0.734 \n",
      "End of epoch 142 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0009188\n",
      "(epoch: 143, iters: 40, time: 0.074, data: 0.002) G_GAN: 0.972 G_L1: 1.820 D_real: 0.547 D_fake: 0.588 \n",
      "(epoch: 143, iters: 140, time: 0.073, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.736 D_fake: 0.611 \n",
      "(epoch: 143, iters: 240, time: 0.075, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.718 D_fake: 0.655 \n",
      "(epoch: 143, iters: 340, time: 0.076, data: 0.002) G_GAN: 0.848 G_L1: 1.290 D_real: 0.589 D_fake: 0.619 \n",
      "(epoch: 143, iters: 440, time: 0.075, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.704 D_fake: 0.671 \n",
      "(epoch: 143, iters: 540, time: 0.071, data: 0.003) G_GAN: 0.669 G_L1: 0.000 D_real: 0.686 D_fake: 0.667 \n",
      "(epoch: 143, iters: 640, time: 0.073, data: 0.002) G_GAN: 0.807 G_L1: 2.682 D_real: 0.558 D_fake: 0.619 \n",
      "(epoch: 143, iters: 740, time: 0.072, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.736 D_fake: 0.659 \n",
      "(epoch: 143, iters: 840, time: 0.074, data: 0.003) G_GAN: 0.705 G_L1: 0.000 D_real: 0.710 D_fake: 0.691 \n",
      "(epoch: 143, iters: 940, time: 0.072, data: 0.002) G_GAN: 0.944 G_L1: 3.230 D_real: 0.562 D_fake: 0.606 \n",
      "(epoch: 143, iters: 1040, time: 0.072, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.756 D_fake: 0.645 \n",
      "(epoch: 143, iters: 1140, time: 0.075, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.743 D_fake: 0.657 \n",
      "(epoch: 143, iters: 1240, time: 0.071, data: 0.002) G_GAN: 1.023 G_L1: 2.399 D_real: 0.610 D_fake: 0.595 \n",
      "saving the latest model (epoch 143, total_steps 325000)\n",
      "(epoch: 143, iters: 1340, time: 0.072, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.757 D_fake: 0.650 \n",
      "(epoch: 143, iters: 1440, time: 0.073, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.720 D_fake: 0.648 \n",
      "(epoch: 143, iters: 1540, time: 0.073, data: 0.002) G_GAN: 0.938 G_L1: 1.508 D_real: 0.585 D_fake: 0.611 \n",
      "(epoch: 143, iters: 1640, time: 0.073, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.729 D_fake: 0.643 \n",
      "(epoch: 143, iters: 1740, time: 0.073, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.740 D_fake: 0.620 \n",
      "(epoch: 143, iters: 1840, time: 0.073, data: 0.002) G_GAN: 0.934 G_L1: 0.842 D_real: 0.617 D_fake: 0.629 \n",
      "(epoch: 143, iters: 1940, time: 0.076, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.739 D_fake: 0.657 \n",
      "(epoch: 143, iters: 2040, time: 0.075, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.707 D_fake: 0.669 \n",
      "(epoch: 143, iters: 2140, time: 0.073, data: 0.002) G_GAN: 0.974 G_L1: 0.917 D_real: 0.679 D_fake: 0.546 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 143, iters: 2240, time: 0.073, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.718 D_fake: 0.638 \n",
      "End of epoch 143 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0009030\n",
      "(epoch: 144, iters: 60, time: 0.074, data: 0.002) G_GAN: 0.676 G_L1: 0.000 D_real: 0.680 D_fake: 0.692 \n",
      "(epoch: 144, iters: 160, time: 0.076, data: 0.001) G_GAN: 0.980 G_L1: 2.187 D_real: 0.584 D_fake: 0.603 \n",
      "(epoch: 144, iters: 260, time: 0.073, data: 0.003) G_GAN: 0.718 G_L1: 0.000 D_real: 0.728 D_fake: 0.667 \n",
      "(epoch: 144, iters: 360, time: 0.076, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.731 D_fake: 0.658 \n",
      "(epoch: 144, iters: 460, time: 0.073, data: 0.002) G_GAN: 0.932 G_L1: 2.055 D_real: 0.582 D_fake: 0.576 \n",
      "(epoch: 144, iters: 560, time: 0.075, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.739 D_fake: 0.621 \n",
      "(epoch: 144, iters: 660, time: 0.074, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.746 D_fake: 0.666 \n",
      "(epoch: 144, iters: 760, time: 0.076, data: 0.003) G_GAN: 1.024 G_L1: 2.009 D_real: 0.583 D_fake: 0.647 \n",
      "(epoch: 144, iters: 860, time: 0.079, data: 0.002) G_GAN: 0.772 G_L1: 0.000 D_real: 0.794 D_fake: 0.587 \n",
      "(epoch: 144, iters: 960, time: 0.078, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.747 D_fake: 0.649 \n",
      "(epoch: 144, iters: 1060, time: 0.078, data: 0.002) G_GAN: 0.850 G_L1: 0.699 D_real: 0.611 D_fake: 0.633 \n",
      "(epoch: 144, iters: 1160, time: 0.071, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.746 D_fake: 0.601 \n",
      "(epoch: 144, iters: 1260, time: 0.070, data: 0.002) G_GAN: 0.667 G_L1: 0.000 D_real: 0.664 D_fake: 0.687 \n",
      "(epoch: 144, iters: 1360, time: 0.072, data: 0.003) G_GAN: 0.816 G_L1: 2.029 D_real: 0.550 D_fake: 0.644 \n",
      "(epoch: 144, iters: 1460, time: 0.072, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.764 D_fake: 0.641 \n",
      "(epoch: 144, iters: 1560, time: 0.074, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.716 D_fake: 0.628 \n",
      "(epoch: 144, iters: 1660, time: 0.072, data: 0.002) G_GAN: 0.912 G_L1: 1.703 D_real: 0.584 D_fake: 0.627 \n",
      "(epoch: 144, iters: 1760, time: 0.072, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.741 D_fake: 0.641 \n",
      "(epoch: 144, iters: 1860, time: 0.075, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.724 D_fake: 0.654 \n",
      "(epoch: 144, iters: 1960, time: 0.076, data: 0.002) G_GAN: 0.918 G_L1: 2.015 D_real: 0.568 D_fake: 0.594 \n",
      "(epoch: 144, iters: 2060, time: 0.071, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.735 D_fake: 0.622 \n",
      "(epoch: 144, iters: 2160, time: 0.072, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.711 D_fake: 0.668 \n",
      "(epoch: 144, iters: 2260, time: 0.070, data: 0.002) G_GAN: 1.071 G_L1: 2.749 D_real: 0.545 D_fake: 0.588 \n",
      "End of epoch 144 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0008871\n",
      "(epoch: 145, iters: 80, time: 0.078, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.784 D_fake: 0.609 \n",
      "(epoch: 145, iters: 180, time: 0.074, data: 0.003) G_GAN: 0.691 G_L1: 0.000 D_real: 0.690 D_fake: 0.700 \n",
      "(epoch: 145, iters: 280, time: 0.072, data: 0.003) G_GAN: 0.903 G_L1: 1.026 D_real: 0.587 D_fake: 0.651 \n",
      "(epoch: 145, iters: 380, time: 0.073, data: 0.003) G_GAN: 0.755 G_L1: 0.000 D_real: 0.778 D_fake: 0.598 \n",
      "(epoch: 145, iters: 480, time: 0.071, data: 0.003) G_GAN: 0.717 G_L1: 0.000 D_real: 0.723 D_fake: 0.618 \n",
      "(epoch: 145, iters: 580, time: 0.071, data: 0.002) G_GAN: 1.018 G_L1: 3.541 D_real: 0.517 D_fake: 0.609 \n",
      "(epoch: 145, iters: 680, time: 0.071, data: 0.002) G_GAN: 0.678 G_L1: 0.000 D_real: 0.696 D_fake: 0.611 \n",
      "(epoch: 145, iters: 780, time: 0.071, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.704 D_fake: 0.683 \n",
      "(epoch: 145, iters: 880, time: 0.071, data: 0.002) G_GAN: 1.011 G_L1: 2.571 D_real: 0.534 D_fake: 0.603 \n",
      "(epoch: 145, iters: 980, time: 0.071, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.727 D_fake: 0.633 \n",
      "(epoch: 145, iters: 1080, time: 0.072, data: 0.002) G_GAN: 0.674 G_L1: 0.000 D_real: 0.692 D_fake: 0.675 \n",
      "(epoch: 145, iters: 1180, time: 0.072, data: 0.002) G_GAN: 0.985 G_L1: 2.021 D_real: 0.559 D_fake: 0.650 \n",
      "(epoch: 145, iters: 1280, time: 0.076, data: 0.003) G_GAN: 0.753 G_L1: 0.000 D_real: 0.755 D_fake: 0.621 \n",
      "(epoch: 145, iters: 1380, time: 0.074, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.735 D_fake: 0.644 \n",
      "(epoch: 145, iters: 1480, time: 0.076, data: 0.002) G_GAN: 1.014 G_L1: 1.813 D_real: 0.581 D_fake: 0.608 \n",
      "(epoch: 145, iters: 1580, time: 0.076, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.748 D_fake: 0.635 \n",
      "(epoch: 145, iters: 1680, time: 0.073, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.717 D_fake: 0.631 \n",
      "saving the latest model (epoch 145, total_steps 330000)\n",
      "(epoch: 145, iters: 1780, time: 0.073, data: 0.002) G_GAN: 0.898 G_L1: 2.503 D_real: 0.554 D_fake: 0.616 \n",
      "(epoch: 145, iters: 1880, time: 0.075, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.733 D_fake: 0.641 \n",
      "(epoch: 145, iters: 1980, time: 0.072, data: 0.003) G_GAN: 0.670 G_L1: 0.000 D_real: 0.682 D_fake: 0.675 \n",
      "(epoch: 145, iters: 2080, time: 0.072, data: 0.002) G_GAN: 0.931 G_L1: 2.297 D_real: 0.540 D_fake: 0.609 \n",
      "(epoch: 145, iters: 2180, time: 0.072, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.756 D_fake: 0.625 \n",
      "(epoch: 145, iters: 2280, time: 0.073, data: 0.002) G_GAN: 0.654 G_L1: 0.000 D_real: 0.653 D_fake: 0.747 \n",
      "saving the model at the end of epoch 145, iters 330600\n",
      "End of epoch 145 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0008713\n",
      "(epoch: 146, iters: 100, time: 0.073, data: 0.420) G_GAN: 1.019 G_L1: 2.485 D_real: 0.547 D_fake: 0.602 \n",
      "(epoch: 146, iters: 200, time: 0.074, data: 0.002) G_GAN: 0.682 G_L1: 0.000 D_real: 0.685 D_fake: 0.713 \n",
      "(epoch: 146, iters: 300, time: 0.072, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.736 D_fake: 0.653 \n",
      "(epoch: 146, iters: 400, time: 0.072, data: 0.002) G_GAN: 1.090 G_L1: 1.437 D_real: 0.550 D_fake: 0.651 \n",
      "(epoch: 146, iters: 500, time: 0.075, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.753 D_fake: 0.643 \n",
      "(epoch: 146, iters: 600, time: 0.072, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.763 D_fake: 0.639 \n",
      "(epoch: 146, iters: 700, time: 0.073, data: 0.002) G_GAN: 1.042 G_L1: 1.919 D_real: 0.584 D_fake: 0.643 \n",
      "(epoch: 146, iters: 800, time: 0.075, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.754 D_fake: 0.649 \n",
      "(epoch: 146, iters: 900, time: 0.070, data: 0.003) G_GAN: 0.691 G_L1: 0.000 D_real: 0.731 D_fake: 0.615 \n",
      "(epoch: 146, iters: 1000, time: 0.071, data: 0.002) G_GAN: 0.953 G_L1: 1.678 D_real: 0.582 D_fake: 0.626 \n",
      "(epoch: 146, iters: 1100, time: 0.075, data: 0.003) G_GAN: 0.714 G_L1: 0.000 D_real: 0.820 D_fake: 0.592 \n",
      "(epoch: 146, iters: 1200, time: 0.078, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.758 D_fake: 0.646 \n",
      "(epoch: 146, iters: 1300, time: 0.079, data: 0.002) G_GAN: 0.924 G_L1: 1.744 D_real: 0.607 D_fake: 0.577 \n",
      "(epoch: 146, iters: 1400, time: 0.076, data: 0.002) G_GAN: 0.802 G_L1: 0.000 D_real: 0.812 D_fake: 0.599 \n",
      "(epoch: 146, iters: 1500, time: 0.075, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.708 D_fake: 0.679 \n",
      "(epoch: 146, iters: 1600, time: 0.073, data: 0.002) G_GAN: 1.004 G_L1: 2.124 D_real: 0.561 D_fake: 0.607 \n",
      "(epoch: 146, iters: 1700, time: 0.073, data: 0.003) G_GAN: 0.777 G_L1: 0.000 D_real: 0.787 D_fake: 0.605 \n",
      "(epoch: 146, iters: 1800, time: 0.073, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.728 D_fake: 0.661 \n",
      "(epoch: 146, iters: 1900, time: 0.073, data: 0.003) G_GAN: 0.883 G_L1: 3.702 D_real: 0.519 D_fake: 0.630 \n",
      "(epoch: 146, iters: 2000, time: 0.073, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.753 D_fake: 0.626 \n",
      "(epoch: 146, iters: 2100, time: 0.075, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.704 D_fake: 0.657 \n",
      "(epoch: 146, iters: 2200, time: 0.073, data: 0.002) G_GAN: 0.928 G_L1: 1.583 D_real: 0.569 D_fake: 0.609 \n",
      "End of epoch 146 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0008554\n",
      "(epoch: 147, iters: 20, time: 0.076, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.740 D_fake: 0.642 \n",
      "(epoch: 147, iters: 120, time: 0.074, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.733 D_fake: 0.622 \n",
      "(epoch: 147, iters: 220, time: 0.075, data: 0.001) G_GAN: 1.015 G_L1: 2.749 D_real: 0.522 D_fake: 0.622 \n",
      "(epoch: 147, iters: 320, time: 0.076, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.739 D_fake: 0.655 \n",
      "(epoch: 147, iters: 420, time: 0.072, data: 0.001) G_GAN: 0.715 G_L1: 0.000 D_real: 0.729 D_fake: 0.639 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 147, iters: 520, time: 0.074, data: 0.002) G_GAN: 0.956 G_L1: 1.419 D_real: 0.590 D_fake: 0.624 \n",
      "(epoch: 147, iters: 620, time: 0.076, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.755 D_fake: 0.642 \n",
      "(epoch: 147, iters: 720, time: 0.072, data: 0.003) G_GAN: 0.719 G_L1: 0.000 D_real: 0.732 D_fake: 0.672 \n",
      "(epoch: 147, iters: 820, time: 0.076, data: 0.002) G_GAN: 0.939 G_L1: 1.824 D_real: 0.573 D_fake: 0.608 \n",
      "(epoch: 147, iters: 920, time: 0.071, data: 0.003) G_GAN: 0.678 G_L1: 0.000 D_real: 0.667 D_fake: 0.692 \n",
      "(epoch: 147, iters: 1020, time: 0.072, data: 0.002) G_GAN: 0.683 G_L1: 0.000 D_real: 0.708 D_fake: 0.585 \n",
      "(epoch: 147, iters: 1120, time: 0.074, data: 0.003) G_GAN: 0.906 G_L1: 1.957 D_real: 0.539 D_fake: 0.647 \n",
      "(epoch: 147, iters: 1220, time: 0.074, data: 0.003) G_GAN: 0.731 G_L1: 0.000 D_real: 0.734 D_fake: 0.652 \n",
      "(epoch: 147, iters: 1320, time: 0.071, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.729 D_fake: 0.624 \n",
      "(epoch: 147, iters: 1420, time: 0.074, data: 0.002) G_GAN: 0.978 G_L1: 2.010 D_real: 0.569 D_fake: 0.594 \n",
      "(epoch: 147, iters: 1520, time: 0.072, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.734 D_fake: 0.635 \n",
      "(epoch: 147, iters: 1620, time: 0.073, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.747 D_fake: 0.640 \n",
      "(epoch: 147, iters: 1720, time: 0.074, data: 0.002) G_GAN: 1.093 G_L1: 3.150 D_real: 0.520 D_fake: 0.594 \n",
      "(epoch: 147, iters: 1820, time: 0.073, data: 0.003) G_GAN: 0.769 G_L1: 0.000 D_real: 0.791 D_fake: 0.597 \n",
      "(epoch: 147, iters: 1920, time: 0.072, data: 0.003) G_GAN: 0.718 G_L1: 0.000 D_real: 0.726 D_fake: 0.674 \n",
      "(epoch: 147, iters: 2020, time: 0.072, data: 0.002) G_GAN: 0.994 G_L1: 1.672 D_real: 0.597 D_fake: 0.596 \n",
      "(epoch: 147, iters: 2120, time: 0.074, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.734 D_fake: 0.622 \n",
      "saving the latest model (epoch 147, total_steps 335000)\n",
      "(epoch: 147, iters: 2220, time: 0.072, data: 0.002) G_GAN: 0.645 G_L1: 0.000 D_real: 0.679 D_fake: 0.621 \n",
      "End of epoch 147 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0008396\n",
      "(epoch: 148, iters: 40, time: 0.073, data: 0.002) G_GAN: 0.966 G_L1: 1.820 D_real: 0.557 D_fake: 0.667 \n",
      "(epoch: 148, iters: 140, time: 0.075, data: 0.001) G_GAN: 0.736 G_L1: 0.000 D_real: 0.742 D_fake: 0.658 \n",
      "(epoch: 148, iters: 240, time: 0.075, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.720 D_fake: 0.648 \n",
      "(epoch: 148, iters: 340, time: 0.074, data: 0.003) G_GAN: 0.813 G_L1: 1.290 D_real: 0.562 D_fake: 0.633 \n",
      "(epoch: 148, iters: 440, time: 0.072, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.715 D_fake: 0.676 \n",
      "(epoch: 148, iters: 540, time: 0.072, data: 0.002) G_GAN: 0.664 G_L1: 0.000 D_real: 0.675 D_fake: 0.673 \n",
      "(epoch: 148, iters: 640, time: 0.074, data: 0.001) G_GAN: 0.930 G_L1: 2.682 D_real: 0.564 D_fake: 0.609 \n",
      "(epoch: 148, iters: 740, time: 0.072, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.730 D_fake: 0.664 \n",
      "(epoch: 148, iters: 840, time: 0.071, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.705 D_fake: 0.657 \n",
      "(epoch: 148, iters: 940, time: 0.073, data: 0.002) G_GAN: 1.066 G_L1: 3.230 D_real: 0.540 D_fake: 0.581 \n",
      "(epoch: 148, iters: 1040, time: 0.072, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.771 D_fake: 0.644 \n",
      "(epoch: 148, iters: 1140, time: 0.075, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.714 D_fake: 0.654 \n",
      "(epoch: 148, iters: 1240, time: 0.071, data: 0.002) G_GAN: 1.243 G_L1: 2.399 D_real: 0.609 D_fake: 0.643 \n",
      "(epoch: 148, iters: 1340, time: 0.072, data: 0.002) G_GAN: 0.783 G_L1: 0.000 D_real: 0.804 D_fake: 0.581 \n",
      "(epoch: 148, iters: 1440, time: 0.074, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.719 D_fake: 0.647 \n",
      "(epoch: 148, iters: 1540, time: 0.072, data: 0.002) G_GAN: 1.035 G_L1: 1.508 D_real: 0.588 D_fake: 0.582 \n",
      "(epoch: 148, iters: 1640, time: 0.076, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.749 D_fake: 0.634 \n",
      "(epoch: 148, iters: 1740, time: 0.072, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.741 D_fake: 0.629 \n",
      "(epoch: 148, iters: 1840, time: 0.076, data: 0.002) G_GAN: 0.993 G_L1: 0.842 D_real: 0.604 D_fake: 0.636 \n",
      "(epoch: 148, iters: 1940, time: 0.071, data: 0.004) G_GAN: 0.737 G_L1: 0.000 D_real: 0.755 D_fake: 0.644 \n",
      "(epoch: 148, iters: 2040, time: 0.073, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.721 D_fake: 0.672 \n",
      "(epoch: 148, iters: 2140, time: 0.073, data: 0.002) G_GAN: 0.969 G_L1: 0.917 D_real: 0.616 D_fake: 0.579 \n",
      "(epoch: 148, iters: 2240, time: 0.073, data: 0.003) G_GAN: 0.748 G_L1: 0.000 D_real: 0.758 D_fake: 0.593 \n",
      "End of epoch 148 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0008238\n",
      "(epoch: 149, iters: 60, time: 0.073, data: 0.002) G_GAN: 0.630 G_L1: 0.000 D_real: 0.661 D_fake: 0.666 \n",
      "(epoch: 149, iters: 160, time: 0.073, data: 0.001) G_GAN: 1.026 G_L1: 2.187 D_real: 0.560 D_fake: 0.586 \n",
      "(epoch: 149, iters: 260, time: 0.072, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.785 D_fake: 0.652 \n",
      "(epoch: 149, iters: 360, time: 0.072, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.732 D_fake: 0.621 \n",
      "(epoch: 149, iters: 460, time: 0.072, data: 0.002) G_GAN: 0.977 G_L1: 2.055 D_real: 0.579 D_fake: 0.568 \n",
      "(epoch: 149, iters: 560, time: 0.076, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.704 D_fake: 0.631 \n",
      "(epoch: 149, iters: 660, time: 0.073, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.745 D_fake: 0.645 \n",
      "(epoch: 149, iters: 760, time: 0.071, data: 0.003) G_GAN: 1.038 G_L1: 2.009 D_real: 0.574 D_fake: 0.581 \n",
      "(epoch: 149, iters: 860, time: 0.072, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.767 D_fake: 0.631 \n",
      "(epoch: 149, iters: 960, time: 0.071, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.740 D_fake: 0.576 \n",
      "(epoch: 149, iters: 1060, time: 0.075, data: 0.002) G_GAN: 0.844 G_L1: 0.699 D_real: 0.603 D_fake: 0.649 \n",
      "(epoch: 149, iters: 1160, time: 0.073, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.760 D_fake: 0.619 \n",
      "(epoch: 149, iters: 1260, time: 0.072, data: 0.004) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.714 \n",
      "(epoch: 149, iters: 1360, time: 0.073, data: 0.002) G_GAN: 0.816 G_L1: 2.029 D_real: 0.557 D_fake: 0.634 \n",
      "(epoch: 149, iters: 1460, time: 0.078, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.758 D_fake: 0.633 \n",
      "(epoch: 149, iters: 1560, time: 0.074, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.708 D_fake: 0.662 \n",
      "(epoch: 149, iters: 1660, time: 0.073, data: 0.003) G_GAN: 0.897 G_L1: 1.703 D_real: 0.571 D_fake: 0.607 \n",
      "(epoch: 149, iters: 1760, time: 0.073, data: 0.003) G_GAN: 0.745 G_L1: 0.000 D_real: 0.747 D_fake: 0.647 \n",
      "(epoch: 149, iters: 1860, time: 0.072, data: 0.003) G_GAN: 0.730 G_L1: 0.000 D_real: 0.744 D_fake: 0.674 \n",
      "(epoch: 149, iters: 1960, time: 0.073, data: 0.002) G_GAN: 0.906 G_L1: 2.015 D_real: 0.570 D_fake: 0.601 \n",
      "(epoch: 149, iters: 2060, time: 0.074, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.767 D_fake: 0.654 \n",
      "(epoch: 149, iters: 2160, time: 0.075, data: 0.001) G_GAN: 0.704 G_L1: 0.000 D_real: 0.712 D_fake: 0.673 \n",
      "(epoch: 149, iters: 2260, time: 0.071, data: 0.002) G_GAN: 1.053 G_L1: 2.749 D_real: 0.545 D_fake: 0.628 \n",
      "End of epoch 149 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0008079\n",
      "(epoch: 150, iters: 80, time: 0.074, data: 0.003) G_GAN: 0.739 G_L1: 0.000 D_real: 0.766 D_fake: 0.627 \n",
      "(epoch: 150, iters: 180, time: 0.072, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.719 D_fake: 0.629 \n",
      "(epoch: 150, iters: 280, time: 0.072, data: 0.002) G_GAN: 0.892 G_L1: 1.026 D_real: 0.584 D_fake: 0.643 \n",
      "saving the latest model (epoch 150, total_steps 340000)\n",
      "(epoch: 150, iters: 380, time: 0.074, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.793 D_fake: 0.614 \n",
      "(epoch: 150, iters: 480, time: 0.073, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.739 D_fake: 0.621 \n",
      "(epoch: 150, iters: 580, time: 0.072, data: 0.002) G_GAN: 1.120 G_L1: 3.541 D_real: 0.513 D_fake: 0.614 \n",
      "(epoch: 150, iters: 680, time: 0.071, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.711 D_fake: 0.626 \n",
      "(epoch: 150, iters: 780, time: 0.071, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.707 D_fake: 0.666 \n",
      "(epoch: 150, iters: 880, time: 0.071, data: 0.002) G_GAN: 1.084 G_L1: 2.571 D_real: 0.547 D_fake: 0.615 \n",
      "(epoch: 150, iters: 980, time: 0.075, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.755 D_fake: 0.650 \n",
      "(epoch: 150, iters: 1080, time: 0.071, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.694 D_fake: 0.680 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 150, iters: 1180, time: 0.072, data: 0.002) G_GAN: 0.959 G_L1: 2.021 D_real: 0.544 D_fake: 0.636 \n",
      "(epoch: 150, iters: 1280, time: 0.075, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.741 D_fake: 0.628 \n",
      "(epoch: 150, iters: 1380, time: 0.071, data: 0.002) G_GAN: 0.688 G_L1: 0.000 D_real: 0.694 D_fake: 0.668 \n",
      "(epoch: 150, iters: 1480, time: 0.072, data: 0.003) G_GAN: 1.055 G_L1: 1.813 D_real: 0.577 D_fake: 0.618 \n",
      "(epoch: 150, iters: 1580, time: 0.073, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.745 D_fake: 0.635 \n",
      "(epoch: 150, iters: 1680, time: 0.072, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.709 D_fake: 0.691 \n",
      "(epoch: 150, iters: 1780, time: 0.076, data: 0.002) G_GAN: 0.889 G_L1: 2.503 D_real: 0.536 D_fake: 0.635 \n",
      "(epoch: 150, iters: 1880, time: 0.074, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.753 D_fake: 0.606 \n",
      "(epoch: 150, iters: 1980, time: 0.076, data: 0.002) G_GAN: 0.671 G_L1: 0.000 D_real: 0.683 D_fake: 0.661 \n",
      "(epoch: 150, iters: 2080, time: 0.072, data: 0.003) G_GAN: 0.782 G_L1: 2.297 D_real: 0.499 D_fake: 0.669 \n",
      "(epoch: 150, iters: 2180, time: 0.072, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.745 D_fake: 0.581 \n",
      "(epoch: 150, iters: 2280, time: 0.070, data: 0.002) G_GAN: 0.651 G_L1: 0.000 D_real: 0.662 D_fake: 0.728 \n",
      "saving the model at the end of epoch 150, iters 342000\n",
      "End of epoch 150 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0007921\n",
      "(epoch: 151, iters: 100, time: 0.073, data: 0.413) G_GAN: 1.019 G_L1: 2.485 D_real: 0.544 D_fake: 0.594 \n",
      "(epoch: 151, iters: 200, time: 0.072, data: 0.002) G_GAN: 0.662 G_L1: 0.000 D_real: 0.690 D_fake: 0.648 \n",
      "(epoch: 151, iters: 300, time: 0.073, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.744 D_fake: 0.665 \n",
      "(epoch: 151, iters: 400, time: 0.074, data: 0.002) G_GAN: 1.086 G_L1: 1.437 D_real: 0.554 D_fake: 0.646 \n",
      "(epoch: 151, iters: 500, time: 0.073, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.744 D_fake: 0.631 \n",
      "(epoch: 151, iters: 600, time: 0.072, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.747 D_fake: 0.616 \n",
      "(epoch: 151, iters: 700, time: 0.073, data: 0.003) G_GAN: 1.041 G_L1: 1.919 D_real: 0.558 D_fake: 0.589 \n",
      "(epoch: 151, iters: 800, time: 0.073, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.752 D_fake: 0.623 \n",
      "(epoch: 151, iters: 900, time: 0.073, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.732 D_fake: 0.637 \n",
      "(epoch: 151, iters: 1000, time: 0.075, data: 0.002) G_GAN: 0.995 G_L1: 1.678 D_real: 0.565 D_fake: 0.592 \n",
      "(epoch: 151, iters: 1100, time: 0.075, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.747 D_fake: 0.646 \n",
      "(epoch: 151, iters: 1200, time: 0.075, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.726 D_fake: 0.674 \n",
      "(epoch: 151, iters: 1300, time: 0.075, data: 0.002) G_GAN: 0.959 G_L1: 1.744 D_real: 0.601 D_fake: 0.594 \n",
      "(epoch: 151, iters: 1400, time: 0.072, data: 0.002) G_GAN: 0.792 G_L1: 0.000 D_real: 0.864 D_fake: 0.563 \n",
      "(epoch: 151, iters: 1500, time: 0.074, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.723 D_fake: 0.669 \n",
      "(epoch: 151, iters: 1600, time: 0.073, data: 0.003) G_GAN: 1.068 G_L1: 2.124 D_real: 0.552 D_fake: 0.574 \n",
      "(epoch: 151, iters: 1700, time: 0.071, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.771 D_fake: 0.607 \n",
      "(epoch: 151, iters: 1800, time: 0.073, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.730 D_fake: 0.664 \n",
      "(epoch: 151, iters: 1900, time: 0.072, data: 0.003) G_GAN: 0.921 G_L1: 3.702 D_real: 0.499 D_fake: 0.619 \n",
      "(epoch: 151, iters: 2000, time: 0.073, data: 0.003) G_GAN: 0.766 G_L1: 0.000 D_real: 0.781 D_fake: 0.604 \n",
      "(epoch: 151, iters: 2100, time: 0.073, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.714 D_fake: 0.650 \n",
      "(epoch: 151, iters: 2200, time: 0.075, data: 0.002) G_GAN: 0.945 G_L1: 1.583 D_real: 0.567 D_fake: 0.648 \n",
      "End of epoch 151 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0007762\n",
      "(epoch: 152, iters: 20, time: 0.076, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.795 D_fake: 0.620 \n",
      "(epoch: 152, iters: 120, time: 0.072, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.740 D_fake: 0.636 \n",
      "(epoch: 152, iters: 220, time: 0.072, data: 0.003) G_GAN: 1.059 G_L1: 2.749 D_real: 0.507 D_fake: 0.646 \n",
      "(epoch: 152, iters: 320, time: 0.072, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.746 D_fake: 0.633 \n",
      "(epoch: 152, iters: 420, time: 0.073, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.732 D_fake: 0.673 \n",
      "(epoch: 152, iters: 520, time: 0.072, data: 0.003) G_GAN: 0.937 G_L1: 1.419 D_real: 0.576 D_fake: 0.645 \n",
      "(epoch: 152, iters: 620, time: 0.071, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.742 D_fake: 0.627 \n",
      "(epoch: 152, iters: 720, time: 0.073, data: 0.003) G_GAN: 0.732 G_L1: 0.000 D_real: 0.751 D_fake: 0.647 \n",
      "saving the latest model (epoch 152, total_steps 345000)\n",
      "(epoch: 152, iters: 820, time: 0.074, data: 0.002) G_GAN: 0.962 G_L1: 1.824 D_real: 0.560 D_fake: 0.627 \n",
      "(epoch: 152, iters: 920, time: 0.071, data: 0.002) G_GAN: 0.682 G_L1: 0.000 D_real: 0.705 D_fake: 0.673 \n",
      "(epoch: 152, iters: 1020, time: 0.072, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.705 D_fake: 0.655 \n",
      "(epoch: 152, iters: 1120, time: 0.072, data: 0.002) G_GAN: 0.891 G_L1: 1.957 D_real: 0.555 D_fake: 0.625 \n",
      "(epoch: 152, iters: 1220, time: 0.076, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.752 D_fake: 0.643 \n",
      "(epoch: 152, iters: 1320, time: 0.073, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.736 D_fake: 0.621 \n",
      "(epoch: 152, iters: 1420, time: 0.072, data: 0.002) G_GAN: 0.970 G_L1: 2.010 D_real: 0.535 D_fake: 0.601 \n",
      "(epoch: 152, iters: 1520, time: 0.073, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.764 D_fake: 0.606 \n",
      "(epoch: 152, iters: 1620, time: 0.074, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.750 D_fake: 0.657 \n",
      "(epoch: 152, iters: 1720, time: 0.077, data: 0.003) G_GAN: 1.169 G_L1: 3.150 D_real: 0.539 D_fake: 0.591 \n",
      "(epoch: 152, iters: 1820, time: 0.072, data: 0.003) G_GAN: 0.792 G_L1: 0.000 D_real: 0.837 D_fake: 0.613 \n",
      "(epoch: 152, iters: 1920, time: 0.071, data: 0.003) G_GAN: 0.718 G_L1: 0.000 D_real: 0.728 D_fake: 0.645 \n",
      "(epoch: 152, iters: 2020, time: 0.072, data: 0.002) G_GAN: 0.994 G_L1: 1.672 D_real: 0.575 D_fake: 0.601 \n",
      "(epoch: 152, iters: 2120, time: 0.072, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.758 D_fake: 0.624 \n",
      "(epoch: 152, iters: 2220, time: 0.074, data: 0.002) G_GAN: 0.679 G_L1: 0.000 D_real: 0.701 D_fake: 0.664 \n",
      "End of epoch 152 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0007604\n",
      "(epoch: 153, iters: 40, time: 0.072, data: 0.002) G_GAN: 1.005 G_L1: 1.820 D_real: 0.543 D_fake: 0.642 \n",
      "(epoch: 153, iters: 140, time: 0.071, data: 0.001) G_GAN: 0.736 G_L1: 0.000 D_real: 0.742 D_fake: 0.637 \n",
      "(epoch: 153, iters: 240, time: 0.072, data: 0.001) G_GAN: 0.682 G_L1: 0.000 D_real: 0.689 D_fake: 0.641 \n",
      "(epoch: 153, iters: 340, time: 0.073, data: 0.002) G_GAN: 0.841 G_L1: 1.290 D_real: 0.564 D_fake: 0.640 \n",
      "(epoch: 153, iters: 440, time: 0.072, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.731 D_fake: 0.636 \n",
      "(epoch: 153, iters: 540, time: 0.071, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.701 D_fake: 0.668 \n",
      "(epoch: 153, iters: 640, time: 0.072, data: 0.003) G_GAN: 0.964 G_L1: 2.682 D_real: 0.542 D_fake: 0.607 \n",
      "(epoch: 153, iters: 740, time: 0.073, data: 0.003) G_GAN: 0.726 G_L1: 0.000 D_real: 0.731 D_fake: 0.644 \n",
      "(epoch: 153, iters: 840, time: 0.072, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.700 D_fake: 0.603 \n",
      "(epoch: 153, iters: 940, time: 0.075, data: 0.002) G_GAN: 1.084 G_L1: 3.230 D_real: 0.526 D_fake: 0.579 \n",
      "(epoch: 153, iters: 1040, time: 0.074, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.757 D_fake: 0.634 \n",
      "(epoch: 153, iters: 1140, time: 0.075, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.703 D_fake: 0.774 \n",
      "(epoch: 153, iters: 1240, time: 0.072, data: 0.002) G_GAN: 1.196 G_L1: 2.399 D_real: 0.574 D_fake: 0.604 \n",
      "(epoch: 153, iters: 1340, time: 0.071, data: 0.002) G_GAN: 0.762 G_L1: 0.000 D_real: 0.793 D_fake: 0.631 \n",
      "(epoch: 153, iters: 1440, time: 0.074, data: 0.004) G_GAN: 0.729 G_L1: 0.000 D_real: 0.740 D_fake: 0.620 \n",
      "(epoch: 153, iters: 1540, time: 0.072, data: 0.002) G_GAN: 1.041 G_L1: 1.508 D_real: 0.578 D_fake: 0.597 \n",
      "(epoch: 153, iters: 1640, time: 0.073, data: 0.003) G_GAN: 0.734 G_L1: 0.000 D_real: 0.747 D_fake: 0.633 \n",
      "(epoch: 153, iters: 1740, time: 0.073, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.744 D_fake: 0.614 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 153, iters: 1840, time: 0.071, data: 0.002) G_GAN: 1.025 G_L1: 0.842 D_real: 0.612 D_fake: 0.614 \n",
      "(epoch: 153, iters: 1940, time: 0.073, data: 0.003) G_GAN: 0.725 G_L1: 0.000 D_real: 0.735 D_fake: 0.600 \n",
      "(epoch: 153, iters: 2040, time: 0.074, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.716 D_fake: 0.652 \n",
      "(epoch: 153, iters: 2140, time: 0.073, data: 0.002) G_GAN: 0.983 G_L1: 0.917 D_real: 0.601 D_fake: 0.631 \n",
      "(epoch: 153, iters: 2240, time: 0.071, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.734 D_fake: 0.640 \n",
      "End of epoch 153 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0007446\n",
      "(epoch: 154, iters: 60, time: 0.072, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.703 D_fake: 0.669 \n",
      "(epoch: 154, iters: 160, time: 0.072, data: 0.002) G_GAN: 1.019 G_L1: 2.187 D_real: 0.545 D_fake: 0.601 \n",
      "(epoch: 154, iters: 260, time: 0.072, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.744 D_fake: 0.647 \n",
      "(epoch: 154, iters: 360, time: 0.073, data: 0.003) G_GAN: 0.717 G_L1: 0.000 D_real: 0.730 D_fake: 0.669 \n",
      "(epoch: 154, iters: 460, time: 0.075, data: 0.004) G_GAN: 0.972 G_L1: 2.055 D_real: 0.569 D_fake: 0.602 \n",
      "(epoch: 154, iters: 560, time: 0.072, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.759 D_fake: 0.609 \n",
      "(epoch: 154, iters: 660, time: 0.075, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.715 D_fake: 0.635 \n",
      "(epoch: 154, iters: 760, time: 0.072, data: 0.002) G_GAN: 1.040 G_L1: 2.009 D_real: 0.542 D_fake: 0.603 \n",
      "(epoch: 154, iters: 860, time: 0.072, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.820 D_fake: 0.555 \n",
      "(epoch: 154, iters: 960, time: 0.072, data: 0.003) G_GAN: 0.678 G_L1: 0.000 D_real: 0.737 D_fake: 0.561 \n",
      "(epoch: 154, iters: 1060, time: 0.076, data: 0.003) G_GAN: 0.857 G_L1: 0.699 D_real: 0.611 D_fake: 0.615 \n",
      "(epoch: 154, iters: 1160, time: 0.072, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.782 D_fake: 0.648 \n",
      "saving the latest model (epoch 154, total_steps 350000)\n",
      "(epoch: 154, iters: 1260, time: 0.073, data: 0.002) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.683 \n",
      "(epoch: 154, iters: 1360, time: 0.072, data: 0.002) G_GAN: 0.815 G_L1: 2.029 D_real: 0.552 D_fake: 0.629 \n",
      "(epoch: 154, iters: 1460, time: 0.074, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.780 D_fake: 0.627 \n",
      "(epoch: 154, iters: 1560, time: 0.072, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.701 D_fake: 0.672 \n",
      "(epoch: 154, iters: 1660, time: 0.075, data: 0.003) G_GAN: 0.909 G_L1: 1.703 D_real: 0.582 D_fake: 0.636 \n",
      "(epoch: 154, iters: 1760, time: 0.071, data: 0.003) G_GAN: 0.730 G_L1: 0.000 D_real: 0.736 D_fake: 0.642 \n",
      "(epoch: 154, iters: 1860, time: 0.071, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.721 D_fake: 0.669 \n",
      "(epoch: 154, iters: 1960, time: 0.073, data: 0.002) G_GAN: 0.924 G_L1: 2.015 D_real: 0.580 D_fake: 0.586 \n",
      "(epoch: 154, iters: 2060, time: 0.072, data: 0.003) G_GAN: 0.725 G_L1: 0.000 D_real: 0.732 D_fake: 0.669 \n",
      "(epoch: 154, iters: 2160, time: 0.075, data: 0.003) G_GAN: 0.702 G_L1: 0.000 D_real: 0.728 D_fake: 0.620 \n",
      "(epoch: 154, iters: 2260, time: 0.075, data: 0.002) G_GAN: 1.037 G_L1: 2.749 D_real: 0.565 D_fake: 0.634 \n",
      "End of epoch 154 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0007287\n",
      "(epoch: 155, iters: 80, time: 0.073, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.735 D_fake: 0.672 \n",
      "(epoch: 155, iters: 180, time: 0.073, data: 0.003) G_GAN: 0.673 G_L1: 0.000 D_real: 0.691 D_fake: 0.658 \n",
      "(epoch: 155, iters: 280, time: 0.074, data: 0.002) G_GAN: 0.943 G_L1: 1.026 D_real: 0.572 D_fake: 0.633 \n",
      "(epoch: 155, iters: 380, time: 0.072, data: 0.002) G_GAN: 0.787 G_L1: 0.000 D_real: 0.806 D_fake: 0.632 \n",
      "(epoch: 155, iters: 480, time: 0.076, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.729 D_fake: 0.659 \n",
      "(epoch: 155, iters: 580, time: 0.071, data: 0.002) G_GAN: 1.062 G_L1: 3.541 D_real: 0.505 D_fake: 0.599 \n",
      "(epoch: 155, iters: 680, time: 0.075, data: 0.002) G_GAN: 0.702 G_L1: 0.000 D_real: 0.706 D_fake: 0.655 \n",
      "(epoch: 155, iters: 780, time: 0.071, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.715 D_fake: 0.675 \n",
      "(epoch: 155, iters: 880, time: 0.071, data: 0.002) G_GAN: 0.986 G_L1: 2.571 D_real: 0.533 D_fake: 0.675 \n",
      "(epoch: 155, iters: 980, time: 0.074, data: 0.003) G_GAN: 0.731 G_L1: 0.000 D_real: 0.757 D_fake: 0.606 \n",
      "(epoch: 155, iters: 1080, time: 0.072, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.697 D_fake: 0.674 \n",
      "(epoch: 155, iters: 1180, time: 0.072, data: 0.003) G_GAN: 0.951 G_L1: 2.021 D_real: 0.528 D_fake: 0.618 \n",
      "(epoch: 155, iters: 1280, time: 0.075, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.740 D_fake: 0.661 \n",
      "(epoch: 155, iters: 1380, time: 0.073, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.696 D_fake: 0.685 \n",
      "(epoch: 155, iters: 1480, time: 0.075, data: 0.002) G_GAN: 1.094 G_L1: 1.813 D_real: 0.579 D_fake: 0.590 \n",
      "(epoch: 155, iters: 1580, time: 0.076, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.740 D_fake: 0.652 \n",
      "(epoch: 155, iters: 1680, time: 0.078, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.701 D_fake: 0.649 \n",
      "(epoch: 155, iters: 1780, time: 0.072, data: 0.003) G_GAN: 0.909 G_L1: 2.503 D_real: 0.551 D_fake: 0.617 \n",
      "(epoch: 155, iters: 1880, time: 0.076, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.737 D_fake: 0.669 \n",
      "(epoch: 155, iters: 1980, time: 0.076, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.690 D_fake: 0.657 \n",
      "(epoch: 155, iters: 2080, time: 0.072, data: 0.003) G_GAN: 0.878 G_L1: 2.297 D_real: 0.534 D_fake: 0.622 \n",
      "(epoch: 155, iters: 2180, time: 0.071, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.753 D_fake: 0.606 \n",
      "(epoch: 155, iters: 2280, time: 0.070, data: 0.002) G_GAN: 0.642 G_L1: 0.000 D_real: 0.658 D_fake: 0.649 \n",
      "saving the model at the end of epoch 155, iters 353400\n",
      "End of epoch 155 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0007129\n",
      "(epoch: 156, iters: 100, time: 0.074, data: 0.428) G_GAN: 1.016 G_L1: 2.485 D_real: 0.553 D_fake: 0.645 \n",
      "(epoch: 156, iters: 200, time: 0.073, data: 0.003) G_GAN: 0.697 G_L1: 0.000 D_real: 0.711 D_fake: 0.667 \n",
      "(epoch: 156, iters: 300, time: 0.073, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.734 D_fake: 0.656 \n",
      "(epoch: 156, iters: 400, time: 0.072, data: 0.002) G_GAN: 1.084 G_L1: 1.437 D_real: 0.564 D_fake: 0.613 \n",
      "(epoch: 156, iters: 500, time: 0.077, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.744 D_fake: 0.629 \n",
      "(epoch: 156, iters: 600, time: 0.073, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.748 D_fake: 0.633 \n",
      "(epoch: 156, iters: 700, time: 0.073, data: 0.003) G_GAN: 1.009 G_L1: 1.919 D_real: 0.539 D_fake: 0.623 \n",
      "(epoch: 156, iters: 800, time: 0.074, data: 0.003) G_GAN: 0.729 G_L1: 0.000 D_real: 0.737 D_fake: 0.630 \n",
      "(epoch: 156, iters: 900, time: 0.071, data: 0.002) G_GAN: 0.677 G_L1: 0.000 D_real: 0.709 D_fake: 0.645 \n",
      "(epoch: 156, iters: 1000, time: 0.072, data: 0.002) G_GAN: 0.959 G_L1: 1.678 D_real: 0.564 D_fake: 0.589 \n",
      "(epoch: 156, iters: 1100, time: 0.073, data: 0.002) G_GAN: 0.682 G_L1: 0.000 D_real: 0.745 D_fake: 0.609 \n",
      "(epoch: 156, iters: 1200, time: 0.074, data: 0.004) G_GAN: 0.727 G_L1: 0.000 D_real: 0.734 D_fake: 0.668 \n",
      "(epoch: 156, iters: 1300, time: 0.074, data: 0.002) G_GAN: 0.986 G_L1: 1.744 D_real: 0.617 D_fake: 0.569 \n",
      "(epoch: 156, iters: 1400, time: 0.072, data: 0.002) G_GAN: 0.815 G_L1: 0.000 D_real: 0.841 D_fake: 0.601 \n",
      "(epoch: 156, iters: 1500, time: 0.073, data: 0.003) G_GAN: 0.721 G_L1: 0.000 D_real: 0.724 D_fake: 0.670 \n",
      "(epoch: 156, iters: 1600, time: 0.071, data: 0.002) G_GAN: 0.999 G_L1: 2.124 D_real: 0.548 D_fake: 0.601 \n",
      "saving the latest model (epoch 156, total_steps 355000)\n",
      "(epoch: 156, iters: 1700, time: 0.075, data: 0.002) G_GAN: 0.762 G_L1: 0.000 D_real: 0.777 D_fake: 0.599 \n",
      "(epoch: 156, iters: 1800, time: 0.075, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.734 D_fake: 0.627 \n",
      "(epoch: 156, iters: 1900, time: 0.072, data: 0.002) G_GAN: 0.940 G_L1: 3.702 D_real: 0.515 D_fake: 0.594 \n",
      "(epoch: 156, iters: 2000, time: 0.073, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.730 D_fake: 0.657 \n",
      "(epoch: 156, iters: 2100, time: 0.076, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.716 D_fake: 0.650 \n",
      "(epoch: 156, iters: 2200, time: 0.074, data: 0.002) G_GAN: 0.956 G_L1: 1.583 D_real: 0.596 D_fake: 0.650 \n",
      "End of epoch 156 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0006970\n",
      "(epoch: 157, iters: 20, time: 0.075, data: 0.003) G_GAN: 0.671 G_L1: 0.000 D_real: 0.682 D_fake: 0.664 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 157, iters: 120, time: 0.074, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.732 D_fake: 0.647 \n",
      "(epoch: 157, iters: 220, time: 0.073, data: 0.002) G_GAN: 1.020 G_L1: 2.749 D_real: 0.526 D_fake: 0.605 \n",
      "(epoch: 157, iters: 320, time: 0.074, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.740 D_fake: 0.595 \n",
      "(epoch: 157, iters: 420, time: 0.075, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.743 D_fake: 0.652 \n",
      "(epoch: 157, iters: 520, time: 0.072, data: 0.002) G_GAN: 0.998 G_L1: 1.419 D_real: 0.583 D_fake: 0.588 \n",
      "(epoch: 157, iters: 620, time: 0.071, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.759 D_fake: 0.628 \n",
      "(epoch: 157, iters: 720, time: 0.072, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.745 D_fake: 0.589 \n",
      "(epoch: 157, iters: 820, time: 0.071, data: 0.003) G_GAN: 0.932 G_L1: 1.824 D_real: 0.554 D_fake: 0.646 \n",
      "(epoch: 157, iters: 920, time: 0.073, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.705 D_fake: 0.673 \n",
      "(epoch: 157, iters: 1020, time: 0.075, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.695 D_fake: 0.658 \n",
      "(epoch: 157, iters: 1120, time: 0.072, data: 0.002) G_GAN: 0.843 G_L1: 1.957 D_real: 0.535 D_fake: 0.647 \n",
      "(epoch: 157, iters: 1220, time: 0.072, data: 0.003) G_GAN: 0.720 G_L1: 0.000 D_real: 0.725 D_fake: 0.644 \n",
      "(epoch: 157, iters: 1320, time: 0.077, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.748 D_fake: 0.599 \n",
      "(epoch: 157, iters: 1420, time: 0.073, data: 0.002) G_GAN: 1.029 G_L1: 2.010 D_real: 0.556 D_fake: 0.589 \n",
      "(epoch: 157, iters: 1520, time: 0.075, data: 0.003) G_GAN: 0.729 G_L1: 0.000 D_real: 0.729 D_fake: 0.656 \n",
      "(epoch: 157, iters: 1620, time: 0.072, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.753 D_fake: 0.635 \n",
      "(epoch: 157, iters: 1720, time: 0.072, data: 0.002) G_GAN: 1.181 G_L1: 3.150 D_real: 0.518 D_fake: 0.600 \n",
      "(epoch: 157, iters: 1820, time: 0.076, data: 0.003) G_GAN: 0.764 G_L1: 0.000 D_real: 0.768 D_fake: 0.631 \n",
      "(epoch: 157, iters: 1920, time: 0.073, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.734 D_fake: 0.644 \n",
      "(epoch: 157, iters: 2020, time: 0.074, data: 0.002) G_GAN: 0.991 G_L1: 1.672 D_real: 0.590 D_fake: 0.587 \n",
      "(epoch: 157, iters: 2120, time: 0.073, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.751 D_fake: 0.628 \n",
      "(epoch: 157, iters: 2220, time: 0.074, data: 0.002) G_GAN: 0.659 G_L1: 0.000 D_real: 0.655 D_fake: 0.745 \n",
      "End of epoch 157 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0006812\n",
      "(epoch: 158, iters: 40, time: 0.073, data: 0.002) G_GAN: 0.978 G_L1: 1.820 D_real: 0.549 D_fake: 0.603 \n",
      "(epoch: 158, iters: 140, time: 0.073, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.728 D_fake: 0.617 \n",
      "(epoch: 158, iters: 240, time: 0.075, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.703 D_fake: 0.669 \n",
      "(epoch: 158, iters: 340, time: 0.074, data: 0.002) G_GAN: 0.844 G_L1: 1.290 D_real: 0.573 D_fake: 0.641 \n",
      "(epoch: 158, iters: 440, time: 0.075, data: 0.003) G_GAN: 0.709 G_L1: 0.000 D_real: 0.711 D_fake: 0.664 \n",
      "(epoch: 158, iters: 540, time: 0.074, data: 0.002) G_GAN: 0.678 G_L1: 0.000 D_real: 0.684 D_fake: 0.683 \n",
      "(epoch: 158, iters: 640, time: 0.074, data: 0.003) G_GAN: 0.937 G_L1: 2.682 D_real: 0.541 D_fake: 0.589 \n",
      "(epoch: 158, iters: 740, time: 0.074, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.739 D_fake: 0.631 \n",
      "(epoch: 158, iters: 840, time: 0.073, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.703 D_fake: 0.665 \n",
      "(epoch: 158, iters: 940, time: 0.073, data: 0.002) G_GAN: 1.109 G_L1: 3.230 D_real: 0.536 D_fake: 0.573 \n",
      "(epoch: 158, iters: 1040, time: 0.076, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.770 D_fake: 0.618 \n",
      "(epoch: 158, iters: 1140, time: 0.074, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.737 D_fake: 0.656 \n",
      "(epoch: 158, iters: 1240, time: 0.076, data: 0.003) G_GAN: 1.249 G_L1: 2.399 D_real: 0.587 D_fake: 0.545 \n",
      "(epoch: 158, iters: 1340, time: 0.074, data: 0.002) G_GAN: 0.780 G_L1: 0.000 D_real: 0.793 D_fake: 0.619 \n",
      "(epoch: 158, iters: 1440, time: 0.072, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.719 D_fake: 0.630 \n",
      "(epoch: 158, iters: 1540, time: 0.074, data: 0.002) G_GAN: 1.095 G_L1: 1.508 D_real: 0.568 D_fake: 0.597 \n",
      "(epoch: 158, iters: 1640, time: 0.074, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.749 D_fake: 0.633 \n",
      "(epoch: 158, iters: 1740, time: 0.072, data: 0.003) G_GAN: 0.728 G_L1: 0.000 D_real: 0.738 D_fake: 0.648 \n",
      "(epoch: 158, iters: 1840, time: 0.076, data: 0.003) G_GAN: 1.067 G_L1: 0.842 D_real: 0.624 D_fake: 0.604 \n",
      "(epoch: 158, iters: 1940, time: 0.075, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.765 D_fake: 0.601 \n",
      "(epoch: 158, iters: 2040, time: 0.075, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.723 D_fake: 0.591 \n",
      "saving the latest model (epoch 158, total_steps 360000)\n",
      "(epoch: 158, iters: 2140, time: 0.072, data: 0.002) G_GAN: 1.014 G_L1: 0.917 D_real: 0.688 D_fake: 0.629 \n",
      "(epoch: 158, iters: 2240, time: 0.073, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.735 D_fake: 0.643 \n",
      "End of epoch 158 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0006653\n",
      "(epoch: 159, iters: 60, time: 0.074, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.701 D_fake: 0.644 \n",
      "(epoch: 159, iters: 160, time: 0.072, data: 0.001) G_GAN: 1.030 G_L1: 2.187 D_real: 0.553 D_fake: 0.595 \n",
      "(epoch: 159, iters: 260, time: 0.073, data: 0.003) G_GAN: 0.734 G_L1: 0.000 D_real: 0.744 D_fake: 0.633 \n",
      "(epoch: 159, iters: 360, time: 0.073, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.714 D_fake: 0.671 \n",
      "(epoch: 159, iters: 460, time: 0.077, data: 0.002) G_GAN: 0.970 G_L1: 2.055 D_real: 0.566 D_fake: 0.641 \n",
      "(epoch: 159, iters: 560, time: 0.071, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.722 D_fake: 0.631 \n",
      "(epoch: 159, iters: 660, time: 0.076, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.754 D_fake: 0.612 \n",
      "(epoch: 159, iters: 760, time: 0.075, data: 0.002) G_GAN: 1.147 G_L1: 2.009 D_real: 0.573 D_fake: 0.582 \n",
      "(epoch: 159, iters: 860, time: 0.071, data: 0.003) G_GAN: 0.728 G_L1: 0.000 D_real: 0.745 D_fake: 0.609 \n",
      "(epoch: 159, iters: 960, time: 0.074, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.772 D_fake: 0.625 \n",
      "(epoch: 159, iters: 1060, time: 0.071, data: 0.003) G_GAN: 0.931 G_L1: 0.699 D_real: 0.636 D_fake: 0.625 \n",
      "(epoch: 159, iters: 1160, time: 0.072, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.764 D_fake: 0.662 \n",
      "(epoch: 159, iters: 1260, time: 0.072, data: 0.003) G_GAN: 0.691 G_L1: 0.000 D_real: 0.705 D_fake: 0.637 \n",
      "(epoch: 159, iters: 1360, time: 0.074, data: 0.002) G_GAN: 0.884 G_L1: 2.029 D_real: 0.567 D_fake: 0.605 \n",
      "(epoch: 159, iters: 1460, time: 0.072, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.781 D_fake: 0.613 \n",
      "(epoch: 159, iters: 1560, time: 0.070, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.705 D_fake: 0.666 \n",
      "(epoch: 159, iters: 1660, time: 0.071, data: 0.002) G_GAN: 0.916 G_L1: 1.703 D_real: 0.567 D_fake: 0.625 \n",
      "(epoch: 159, iters: 1760, time: 0.072, data: 0.003) G_GAN: 0.734 G_L1: 0.000 D_real: 0.731 D_fake: 0.645 \n",
      "(epoch: 159, iters: 1860, time: 0.072, data: 0.003) G_GAN: 0.697 G_L1: 0.000 D_real: 0.706 D_fake: 0.675 \n",
      "(epoch: 159, iters: 1960, time: 0.073, data: 0.002) G_GAN: 0.912 G_L1: 2.015 D_real: 0.556 D_fake: 0.573 \n",
      "(epoch: 159, iters: 2060, time: 0.074, data: 0.003) G_GAN: 0.728 G_L1: 0.000 D_real: 0.741 D_fake: 0.640 \n",
      "(epoch: 159, iters: 2160, time: 0.072, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.705 D_fake: 0.655 \n",
      "(epoch: 159, iters: 2260, time: 0.071, data: 0.002) G_GAN: 1.084 G_L1: 2.749 D_real: 0.645 D_fake: 0.459 \n",
      "End of epoch 159 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0006495\n",
      "(epoch: 160, iters: 80, time: 0.077, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.743 D_fake: 0.628 \n",
      "(epoch: 160, iters: 180, time: 0.073, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.721 D_fake: 0.623 \n",
      "(epoch: 160, iters: 280, time: 0.074, data: 0.002) G_GAN: 0.947 G_L1: 1.026 D_real: 0.569 D_fake: 0.618 \n",
      "(epoch: 160, iters: 380, time: 0.071, data: 0.002) G_GAN: 0.773 G_L1: 0.000 D_real: 0.790 D_fake: 0.597 \n",
      "(epoch: 160, iters: 480, time: 0.072, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.729 D_fake: 0.659 \n",
      "(epoch: 160, iters: 580, time: 0.072, data: 0.003) G_GAN: 1.090 G_L1: 3.541 D_real: 0.498 D_fake: 0.584 \n",
      "(epoch: 160, iters: 680, time: 0.071, data: 0.003) G_GAN: 0.704 G_L1: 0.000 D_real: 0.709 D_fake: 0.663 \n",
      "(epoch: 160, iters: 780, time: 0.071, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.721 D_fake: 0.662 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 160, iters: 880, time: 0.071, data: 0.002) G_GAN: 1.058 G_L1: 2.571 D_real: 0.531 D_fake: 0.597 \n",
      "(epoch: 160, iters: 980, time: 0.071, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.736 D_fake: 0.649 \n",
      "(epoch: 160, iters: 1080, time: 0.073, data: 0.002) G_GAN: 0.683 G_L1: 0.000 D_real: 0.700 D_fake: 0.634 \n",
      "(epoch: 160, iters: 1180, time: 0.076, data: 0.002) G_GAN: 0.978 G_L1: 2.021 D_real: 0.522 D_fake: 0.654 \n",
      "(epoch: 160, iters: 1280, time: 0.073, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.742 D_fake: 0.648 \n",
      "(epoch: 160, iters: 1380, time: 0.072, data: 0.002) G_GAN: 0.671 G_L1: 0.000 D_real: 0.689 D_fake: 0.682 \n",
      "(epoch: 160, iters: 1480, time: 0.076, data: 0.002) G_GAN: 1.039 G_L1: 1.813 D_real: 0.547 D_fake: 0.597 \n",
      "(epoch: 160, iters: 1580, time: 0.075, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.737 D_fake: 0.641 \n",
      "(epoch: 160, iters: 1680, time: 0.071, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.709 D_fake: 0.635 \n",
      "(epoch: 160, iters: 1780, time: 0.074, data: 0.002) G_GAN: 0.913 G_L1: 2.503 D_real: 0.539 D_fake: 0.586 \n",
      "(epoch: 160, iters: 1880, time: 0.074, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.726 D_fake: 0.624 \n",
      "(epoch: 160, iters: 1980, time: 0.075, data: 0.003) G_GAN: 0.682 G_L1: 0.000 D_real: 0.692 D_fake: 0.677 \n",
      "(epoch: 160, iters: 2080, time: 0.073, data: 0.003) G_GAN: 0.926 G_L1: 2.297 D_real: 0.514 D_fake: 0.605 \n",
      "(epoch: 160, iters: 2180, time: 0.073, data: 0.003) G_GAN: 0.731 G_L1: 0.000 D_real: 0.731 D_fake: 0.632 \n",
      "(epoch: 160, iters: 2280, time: 0.070, data: 0.002) G_GAN: 0.679 G_L1: 0.000 D_real: 0.679 D_fake: 0.717 \n",
      "saving the model at the end of epoch 160, iters 364800\n",
      "End of epoch 160 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0006337\n",
      "(epoch: 161, iters: 100, time: 0.073, data: 0.428) G_GAN: 0.991 G_L1: 2.485 D_real: 0.538 D_fake: 0.614 \n",
      "(epoch: 161, iters: 200, time: 0.070, data: 0.002) G_GAN: 0.668 G_L1: 0.000 D_real: 0.686 D_fake: 0.668 \n",
      "saving the latest model (epoch 161, total_steps 365000)\n",
      "(epoch: 161, iters: 300, time: 0.075, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.742 D_fake: 0.675 \n",
      "(epoch: 161, iters: 400, time: 0.073, data: 0.003) G_GAN: 1.135 G_L1: 1.437 D_real: 0.552 D_fake: 0.614 \n",
      "(epoch: 161, iters: 500, time: 0.072, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.750 D_fake: 0.554 \n",
      "(epoch: 161, iters: 600, time: 0.072, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.730 D_fake: 0.681 \n",
      "(epoch: 161, iters: 700, time: 0.072, data: 0.003) G_GAN: 1.027 G_L1: 1.919 D_real: 0.543 D_fake: 0.652 \n",
      "(epoch: 161, iters: 800, time: 0.074, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.759 D_fake: 0.645 \n",
      "(epoch: 161, iters: 900, time: 0.074, data: 0.002) G_GAN: 0.583 G_L1: 0.000 D_real: 0.678 D_fake: 0.519 \n",
      "(epoch: 161, iters: 1000, time: 0.072, data: 0.002) G_GAN: 0.996 G_L1: 1.678 D_real: 0.604 D_fake: 0.606 \n",
      "(epoch: 161, iters: 1100, time: 0.073, data: 0.003) G_GAN: 0.371 G_L1: 0.000 D_real: 0.705 D_fake: 0.629 \n",
      "(epoch: 161, iters: 1200, time: 0.072, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.736 D_fake: 0.632 \n",
      "(epoch: 161, iters: 1300, time: 0.075, data: 0.003) G_GAN: 0.841 G_L1: 1.744 D_real: 0.588 D_fake: 0.605 \n",
      "(epoch: 161, iters: 1400, time: 0.072, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.754 D_fake: 0.631 \n",
      "(epoch: 161, iters: 1500, time: 0.072, data: 0.003) G_GAN: 0.726 G_L1: 0.000 D_real: 0.731 D_fake: 0.632 \n",
      "(epoch: 161, iters: 1600, time: 0.078, data: 0.002) G_GAN: 0.915 G_L1: 2.124 D_real: 0.551 D_fake: 0.623 \n",
      "(epoch: 161, iters: 1700, time: 0.074, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.741 D_fake: 0.654 \n",
      "(epoch: 161, iters: 1800, time: 0.072, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.728 D_fake: 0.658 \n",
      "(epoch: 161, iters: 1900, time: 0.076, data: 0.002) G_GAN: 0.881 G_L1: 3.702 D_real: 0.508 D_fake: 0.617 \n",
      "(epoch: 161, iters: 2000, time: 0.071, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.759 D_fake: 0.655 \n",
      "(epoch: 161, iters: 2100, time: 0.074, data: 0.002) G_GAN: 0.688 G_L1: 0.000 D_real: 0.697 D_fake: 0.673 \n",
      "(epoch: 161, iters: 2200, time: 0.075, data: 0.002) G_GAN: 0.886 G_L1: 1.583 D_real: 0.578 D_fake: 0.584 \n",
      "End of epoch 161 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0006178\n",
      "(epoch: 162, iters: 20, time: 0.075, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.714 D_fake: 0.660 \n",
      "(epoch: 162, iters: 120, time: 0.073, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.729 D_fake: 0.643 \n",
      "(epoch: 162, iters: 220, time: 0.073, data: 0.003) G_GAN: 1.034 G_L1: 2.749 D_real: 0.506 D_fake: 0.663 \n",
      "(epoch: 162, iters: 320, time: 0.073, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.738 D_fake: 0.616 \n",
      "(epoch: 162, iters: 420, time: 0.075, data: 0.003) G_GAN: 0.734 G_L1: 0.000 D_real: 0.743 D_fake: 0.649 \n",
      "(epoch: 162, iters: 520, time: 0.074, data: 0.002) G_GAN: 0.923 G_L1: 1.419 D_real: 0.596 D_fake: 0.587 \n",
      "(epoch: 162, iters: 620, time: 0.072, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.751 D_fake: 0.649 \n",
      "(epoch: 162, iters: 720, time: 0.075, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.707 D_fake: 0.677 \n",
      "(epoch: 162, iters: 820, time: 0.072, data: 0.002) G_GAN: 0.968 G_L1: 1.824 D_real: 0.569 D_fake: 0.620 \n",
      "(epoch: 162, iters: 920, time: 0.075, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.757 D_fake: 0.642 \n",
      "(epoch: 162, iters: 1020, time: 0.075, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.714 D_fake: 0.635 \n",
      "(epoch: 162, iters: 1120, time: 0.072, data: 0.003) G_GAN: 0.878 G_L1: 1.957 D_real: 0.526 D_fake: 0.627 \n",
      "(epoch: 162, iters: 1220, time: 0.075, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.755 D_fake: 0.576 \n",
      "(epoch: 162, iters: 1320, time: 0.071, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.693 D_fake: 0.669 \n",
      "(epoch: 162, iters: 1420, time: 0.072, data: 0.003) G_GAN: 1.029 G_L1: 2.010 D_real: 0.569 D_fake: 0.637 \n",
      "(epoch: 162, iters: 1520, time: 0.072, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.722 D_fake: 0.657 \n",
      "(epoch: 162, iters: 1620, time: 0.074, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.725 D_fake: 0.678 \n",
      "(epoch: 162, iters: 1720, time: 0.076, data: 0.002) G_GAN: 1.182 G_L1: 3.150 D_real: 0.537 D_fake: 0.591 \n",
      "(epoch: 162, iters: 1820, time: 0.075, data: 0.002) G_GAN: 0.799 G_L1: 0.000 D_real: 0.861 D_fake: 0.570 \n",
      "(epoch: 162, iters: 1920, time: 0.076, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.735 D_fake: 0.632 \n",
      "(epoch: 162, iters: 2020, time: 0.071, data: 0.002) G_GAN: 0.976 G_L1: 1.672 D_real: 0.570 D_fake: 0.660 \n",
      "(epoch: 162, iters: 2120, time: 0.071, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.762 D_fake: 0.614 \n",
      "(epoch: 162, iters: 2220, time: 0.072, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.736 D_fake: 0.572 \n",
      "End of epoch 162 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0006020\n",
      "(epoch: 163, iters: 40, time: 0.074, data: 0.002) G_GAN: 1.024 G_L1: 1.820 D_real: 0.564 D_fake: 0.590 \n",
      "(epoch: 163, iters: 140, time: 0.075, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.752 D_fake: 0.582 \n",
      "(epoch: 163, iters: 240, time: 0.077, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.700 D_fake: 0.693 \n",
      "(epoch: 163, iters: 340, time: 0.076, data: 0.002) G_GAN: 0.844 G_L1: 1.290 D_real: 0.556 D_fake: 0.639 \n",
      "(epoch: 163, iters: 440, time: 0.072, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.721 D_fake: 0.649 \n",
      "(epoch: 163, iters: 540, time: 0.072, data: 0.002) G_GAN: 0.662 G_L1: 0.000 D_real: 0.663 D_fake: 0.718 \n",
      "(epoch: 163, iters: 640, time: 0.073, data: 0.002) G_GAN: 0.940 G_L1: 2.682 D_real: 0.540 D_fake: 0.615 \n",
      "saving the latest model (epoch 163, total_steps 370000)\n",
      "(epoch: 163, iters: 740, time: 0.072, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.757 D_fake: 0.629 \n",
      "(epoch: 163, iters: 840, time: 0.074, data: 0.003) G_GAN: 0.683 G_L1: 0.000 D_real: 0.686 D_fake: 0.685 \n",
      "(epoch: 163, iters: 940, time: 0.073, data: 0.002) G_GAN: 1.055 G_L1: 3.230 D_real: 0.548 D_fake: 0.582 \n",
      "(epoch: 163, iters: 1040, time: 0.076, data: 0.003) G_GAN: 0.717 G_L1: 0.000 D_real: 0.744 D_fake: 0.684 \n",
      "(epoch: 163, iters: 1140, time: 0.076, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.732 D_fake: 0.608 \n",
      "(epoch: 163, iters: 1240, time: 0.075, data: 0.003) G_GAN: 1.228 G_L1: 2.399 D_real: 0.597 D_fake: 0.610 \n",
      "(epoch: 163, iters: 1340, time: 0.078, data: 0.003) G_GAN: 0.753 G_L1: 0.000 D_real: 0.765 D_fake: 0.667 \n",
      "(epoch: 163, iters: 1440, time: 0.071, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.739 D_fake: 0.629 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 163, iters: 1540, time: 0.072, data: 0.002) G_GAN: 1.059 G_L1: 1.508 D_real: 0.560 D_fake: 0.582 \n",
      "(epoch: 163, iters: 1640, time: 0.072, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.744 D_fake: 0.649 \n",
      "(epoch: 163, iters: 1740, time: 0.072, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.740 D_fake: 0.646 \n",
      "(epoch: 163, iters: 1840, time: 0.075, data: 0.003) G_GAN: 1.067 G_L1: 0.842 D_real: 0.627 D_fake: 0.618 \n",
      "(epoch: 163, iters: 1940, time: 0.077, data: 0.003) G_GAN: 0.747 G_L1: 0.000 D_real: 0.757 D_fake: 0.615 \n",
      "(epoch: 163, iters: 2040, time: 0.072, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.711 D_fake: 0.652 \n",
      "(epoch: 163, iters: 2140, time: 0.072, data: 0.002) G_GAN: 1.068 G_L1: 0.917 D_real: 0.667 D_fake: 0.591 \n",
      "(epoch: 163, iters: 2240, time: 0.072, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.746 D_fake: 0.625 \n",
      "End of epoch 163 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0005861\n",
      "(epoch: 164, iters: 60, time: 0.076, data: 0.002) G_GAN: 0.660 G_L1: 0.000 D_real: 0.673 D_fake: 0.648 \n",
      "(epoch: 164, iters: 160, time: 0.075, data: 0.001) G_GAN: 1.022 G_L1: 2.187 D_real: 0.578 D_fake: 0.591 \n",
      "(epoch: 164, iters: 260, time: 0.074, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.741 D_fake: 0.605 \n",
      "(epoch: 164, iters: 360, time: 0.074, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.729 D_fake: 0.648 \n",
      "(epoch: 164, iters: 460, time: 0.072, data: 0.002) G_GAN: 0.991 G_L1: 2.055 D_real: 0.574 D_fake: 0.655 \n",
      "(epoch: 164, iters: 560, time: 0.071, data: 0.003) G_GAN: 0.706 G_L1: 0.000 D_real: 0.713 D_fake: 0.671 \n",
      "(epoch: 164, iters: 660, time: 0.073, data: 0.003) G_GAN: 0.720 G_L1: 0.000 D_real: 0.731 D_fake: 0.610 \n",
      "(epoch: 164, iters: 760, time: 0.076, data: 0.002) G_GAN: 1.125 G_L1: 2.009 D_real: 0.568 D_fake: 0.569 \n",
      "(epoch: 164, iters: 860, time: 0.074, data: 0.002) G_GAN: 0.770 G_L1: 0.000 D_real: 0.783 D_fake: 0.631 \n",
      "(epoch: 164, iters: 960, time: 0.071, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.742 D_fake: 0.637 \n",
      "(epoch: 164, iters: 1060, time: 0.073, data: 0.002) G_GAN: 0.872 G_L1: 0.699 D_real: 0.582 D_fake: 0.648 \n",
      "(epoch: 164, iters: 1160, time: 0.072, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.759 D_fake: 0.614 \n",
      "(epoch: 164, iters: 1260, time: 0.071, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.698 D_fake: 0.678 \n",
      "(epoch: 164, iters: 1360, time: 0.075, data: 0.004) G_GAN: 0.842 G_L1: 2.029 D_real: 0.536 D_fake: 0.687 \n",
      "(epoch: 164, iters: 1460, time: 0.071, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.775 D_fake: 0.622 \n",
      "(epoch: 164, iters: 1560, time: 0.073, data: 0.004) G_GAN: 0.689 G_L1: 0.000 D_real: 0.701 D_fake: 0.689 \n",
      "(epoch: 164, iters: 1660, time: 0.072, data: 0.003) G_GAN: 0.904 G_L1: 1.703 D_real: 0.573 D_fake: 0.609 \n",
      "(epoch: 164, iters: 1760, time: 0.072, data: 0.003) G_GAN: 0.734 G_L1: 0.000 D_real: 0.736 D_fake: 0.640 \n",
      "(epoch: 164, iters: 1860, time: 0.073, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.741 D_fake: 0.664 \n",
      "(epoch: 164, iters: 1960, time: 0.073, data: 0.003) G_GAN: 0.920 G_L1: 2.015 D_real: 0.552 D_fake: 0.615 \n",
      "(epoch: 164, iters: 2060, time: 0.071, data: 0.003) G_GAN: 0.737 G_L1: 0.000 D_real: 0.742 D_fake: 0.653 \n",
      "(epoch: 164, iters: 2160, time: 0.074, data: 0.003) G_GAN: 0.712 G_L1: 0.000 D_real: 0.730 D_fake: 0.635 \n",
      "(epoch: 164, iters: 2260, time: 0.074, data: 0.003) G_GAN: 0.865 G_L1: 2.749 D_real: 0.537 D_fake: 0.667 \n",
      "End of epoch 164 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0005703\n",
      "(epoch: 165, iters: 80, time: 0.072, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.777 D_fake: 0.650 \n",
      "(epoch: 165, iters: 180, time: 0.075, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.725 D_fake: 0.665 \n",
      "(epoch: 165, iters: 280, time: 0.072, data: 0.003) G_GAN: 0.919 G_L1: 1.026 D_real: 0.568 D_fake: 0.644 \n",
      "(epoch: 165, iters: 380, time: 0.075, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.764 D_fake: 0.644 \n",
      "(epoch: 165, iters: 480, time: 0.075, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.727 D_fake: 0.648 \n",
      "(epoch: 165, iters: 580, time: 0.075, data: 0.002) G_GAN: 1.074 G_L1: 3.541 D_real: 0.518 D_fake: 0.589 \n",
      "(epoch: 165, iters: 680, time: 0.076, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.723 D_fake: 0.642 \n",
      "(epoch: 165, iters: 780, time: 0.075, data: 0.003) G_GAN: 0.696 G_L1: 0.000 D_real: 0.695 D_fake: 0.709 \n",
      "(epoch: 165, iters: 880, time: 0.075, data: 0.003) G_GAN: 0.981 G_L1: 2.571 D_real: 0.530 D_fake: 0.624 \n",
      "(epoch: 165, iters: 980, time: 0.072, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.749 D_fake: 0.624 \n",
      "(epoch: 165, iters: 1080, time: 0.071, data: 0.003) G_GAN: 0.675 G_L1: 0.000 D_real: 0.684 D_fake: 0.686 \n",
      "saving the latest model (epoch 165, total_steps 375000)\n",
      "(epoch: 165, iters: 1180, time: 0.077, data: 0.002) G_GAN: 0.983 G_L1: 2.021 D_real: 0.531 D_fake: 0.629 \n",
      "(epoch: 165, iters: 1280, time: 0.074, data: 0.003) G_GAN: 0.744 G_L1: 0.000 D_real: 0.742 D_fake: 0.628 \n",
      "(epoch: 165, iters: 1380, time: 0.074, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.723 D_fake: 0.652 \n",
      "(epoch: 165, iters: 1480, time: 0.073, data: 0.002) G_GAN: 1.090 G_L1: 1.813 D_real: 0.585 D_fake: 0.596 \n",
      "(epoch: 165, iters: 1580, time: 0.074, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.733 D_fake: 0.655 \n",
      "(epoch: 165, iters: 1680, time: 0.072, data: 0.003) G_GAN: 0.702 G_L1: 0.000 D_real: 0.707 D_fake: 0.700 \n",
      "(epoch: 165, iters: 1780, time: 0.072, data: 0.002) G_GAN: 0.898 G_L1: 2.503 D_real: 0.543 D_fake: 0.596 \n",
      "(epoch: 165, iters: 1880, time: 0.072, data: 0.003) G_GAN: 0.738 G_L1: 0.000 D_real: 0.740 D_fake: 0.644 \n",
      "(epoch: 165, iters: 1980, time: 0.073, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 2080, time: 0.076, data: 0.002) G_GAN: 0.917 G_L1: 2.297 D_real: 0.511 D_fake: 0.621 \n",
      "(epoch: 165, iters: 2180, time: 0.075, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.735 D_fake: 0.646 \n",
      "(epoch: 165, iters: 2280, time: 0.074, data: 0.003) G_GAN: 0.618 G_L1: 0.000 D_real: 0.660 D_fake: 0.712 \n",
      "saving the model at the end of epoch 165, iters 376200\n",
      "End of epoch 165 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0005545\n",
      "(epoch: 166, iters: 100, time: 0.078, data: 0.425) G_GAN: 1.036 G_L1: 2.485 D_real: 0.523 D_fake: 0.640 \n",
      "(epoch: 166, iters: 200, time: 0.075, data: 0.003) G_GAN: 0.700 G_L1: 0.000 D_real: 0.724 D_fake: 0.662 \n",
      "(epoch: 166, iters: 300, time: 0.072, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.739 D_fake: 0.635 \n",
      "(epoch: 166, iters: 400, time: 0.075, data: 0.002) G_GAN: 1.129 G_L1: 1.437 D_real: 0.553 D_fake: 0.644 \n",
      "(epoch: 166, iters: 500, time: 0.074, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.746 D_fake: 0.618 \n",
      "(epoch: 166, iters: 600, time: 0.073, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.740 D_fake: 0.629 \n",
      "(epoch: 166, iters: 700, time: 0.075, data: 0.003) G_GAN: 1.059 G_L1: 1.919 D_real: 0.552 D_fake: 0.589 \n",
      "(epoch: 166, iters: 800, time: 0.072, data: 0.003) G_GAN: 0.719 G_L1: 0.000 D_real: 0.741 D_fake: 0.644 \n",
      "(epoch: 166, iters: 900, time: 0.071, data: 0.003) G_GAN: 0.719 G_L1: 0.000 D_real: 0.731 D_fake: 0.648 \n",
      "(epoch: 166, iters: 1000, time: 0.072, data: 0.001) G_GAN: 1.007 G_L1: 1.678 D_real: 0.564 D_fake: 0.616 \n",
      "(epoch: 166, iters: 1100, time: 0.072, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.805 D_fake: 0.633 \n",
      "(epoch: 166, iters: 1200, time: 0.072, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.752 D_fake: 0.617 \n",
      "(epoch: 166, iters: 1300, time: 0.075, data: 0.002) G_GAN: 0.955 G_L1: 1.744 D_real: 0.595 D_fake: 0.574 \n",
      "(epoch: 166, iters: 1400, time: 0.072, data: 0.002) G_GAN: 0.800 G_L1: 0.000 D_real: 0.829 D_fake: 0.587 \n",
      "(epoch: 166, iters: 1500, time: 0.072, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.739 D_fake: 0.641 \n",
      "(epoch: 166, iters: 1600, time: 0.073, data: 0.003) G_GAN: 1.087 G_L1: 2.124 D_real: 0.547 D_fake: 0.589 \n",
      "(epoch: 166, iters: 1700, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.759 D_fake: 0.594 \n",
      "(epoch: 166, iters: 1800, time: 0.071, data: 0.003) G_GAN: 0.728 G_L1: 0.000 D_real: 0.735 D_fake: 0.675 \n",
      "(epoch: 166, iters: 1900, time: 0.073, data: 0.002) G_GAN: 0.896 G_L1: 3.702 D_real: 0.512 D_fake: 0.612 \n",
      "(epoch: 166, iters: 2000, time: 0.072, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.754 D_fake: 0.619 \n",
      "(epoch: 166, iters: 2100, time: 0.072, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.716 D_fake: 0.669 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 166, iters: 2200, time: 0.071, data: 0.002) G_GAN: 0.930 G_L1: 1.583 D_real: 0.593 D_fake: 0.574 \n",
      "End of epoch 166 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0005386\n",
      "(epoch: 167, iters: 20, time: 0.073, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.724 D_fake: 0.665 \n",
      "(epoch: 167, iters: 120, time: 0.072, data: 0.003) G_GAN: 0.731 G_L1: 0.000 D_real: 0.732 D_fake: 0.665 \n",
      "(epoch: 167, iters: 220, time: 0.073, data: 0.002) G_GAN: 1.106 G_L1: 2.749 D_real: 0.519 D_fake: 0.587 \n",
      "(epoch: 167, iters: 320, time: 0.073, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.732 D_fake: 0.636 \n",
      "(epoch: 167, iters: 420, time: 0.074, data: 0.003) G_GAN: 0.734 G_L1: 0.000 D_real: 0.752 D_fake: 0.660 \n",
      "(epoch: 167, iters: 520, time: 0.071, data: 0.003) G_GAN: 0.980 G_L1: 1.419 D_real: 0.604 D_fake: 0.600 \n",
      "(epoch: 167, iters: 620, time: 0.072, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.756 D_fake: 0.653 \n",
      "(epoch: 167, iters: 720, time: 0.072, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.723 D_fake: 0.639 \n",
      "(epoch: 167, iters: 820, time: 0.072, data: 0.002) G_GAN: 1.014 G_L1: 1.824 D_real: 0.582 D_fake: 0.592 \n",
      "(epoch: 167, iters: 920, time: 0.071, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.715 D_fake: 0.670 \n",
      "(epoch: 167, iters: 1020, time: 0.076, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.725 D_fake: 0.670 \n",
      "(epoch: 167, iters: 1120, time: 0.074, data: 0.002) G_GAN: 0.875 G_L1: 1.957 D_real: 0.508 D_fake: 0.632 \n",
      "(epoch: 167, iters: 1220, time: 0.078, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.736 D_fake: 0.647 \n",
      "(epoch: 167, iters: 1320, time: 0.073, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.713 D_fake: 0.655 \n",
      "(epoch: 167, iters: 1420, time: 0.073, data: 0.002) G_GAN: 1.081 G_L1: 2.010 D_real: 0.546 D_fake: 0.651 \n",
      "(epoch: 167, iters: 1520, time: 0.074, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.729 D_fake: 0.638 \n",
      "saving the latest model (epoch 167, total_steps 380000)\n",
      "(epoch: 167, iters: 1620, time: 0.072, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.752 D_fake: 0.656 \n",
      "(epoch: 167, iters: 1720, time: 0.073, data: 0.002) G_GAN: 1.207 G_L1: 3.150 D_real: 0.519 D_fake: 0.621 \n",
      "(epoch: 167, iters: 1820, time: 0.077, data: 0.002) G_GAN: 0.762 G_L1: 0.000 D_real: 0.770 D_fake: 0.585 \n",
      "(epoch: 167, iters: 1920, time: 0.072, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.735 D_fake: 0.652 \n",
      "(epoch: 167, iters: 2020, time: 0.074, data: 0.002) G_GAN: 1.074 G_L1: 1.672 D_real: 0.606 D_fake: 0.614 \n",
      "(epoch: 167, iters: 2120, time: 0.075, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.754 D_fake: 0.629 \n",
      "(epoch: 167, iters: 2220, time: 0.072, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.727 D_fake: 0.651 \n",
      "End of epoch 167 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0005228\n",
      "(epoch: 168, iters: 40, time: 0.073, data: 0.003) G_GAN: 0.971 G_L1: 1.820 D_real: 0.544 D_fake: 0.629 \n",
      "(epoch: 168, iters: 140, time: 0.073, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.732 D_fake: 0.623 \n",
      "(epoch: 168, iters: 240, time: 0.074, data: 0.003) G_GAN: 0.677 G_L1: 0.000 D_real: 0.681 D_fake: 0.686 \n",
      "(epoch: 168, iters: 340, time: 0.072, data: 0.002) G_GAN: 0.851 G_L1: 1.290 D_real: 0.583 D_fake: 0.627 \n",
      "(epoch: 168, iters: 440, time: 0.075, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.716 D_fake: 0.650 \n",
      "(epoch: 168, iters: 540, time: 0.073, data: 0.002) G_GAN: 0.682 G_L1: 0.000 D_real: 0.684 D_fake: 0.706 \n",
      "(epoch: 168, iters: 640, time: 0.076, data: 0.003) G_GAN: 0.978 G_L1: 2.682 D_real: 0.550 D_fake: 0.637 \n",
      "(epoch: 168, iters: 740, time: 0.072, data: 0.003) G_GAN: 0.712 G_L1: 0.000 D_real: 0.738 D_fake: 0.639 \n",
      "(epoch: 168, iters: 840, time: 0.071, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.687 D_fake: 0.704 \n",
      "(epoch: 168, iters: 940, time: 0.076, data: 0.002) G_GAN: 1.218 G_L1: 3.230 D_real: 0.535 D_fake: 0.630 \n",
      "(epoch: 168, iters: 1040, time: 0.071, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.745 D_fake: 0.670 \n",
      "(epoch: 168, iters: 1140, time: 0.075, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.719 D_fake: 0.659 \n",
      "(epoch: 168, iters: 1240, time: 0.075, data: 0.002) G_GAN: 1.290 G_L1: 2.399 D_real: 0.587 D_fake: 0.570 \n",
      "(epoch: 168, iters: 1340, time: 0.073, data: 0.002) G_GAN: 0.777 G_L1: 0.000 D_real: 0.791 D_fake: 0.660 \n",
      "(epoch: 168, iters: 1440, time: 0.071, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.730 D_fake: 0.604 \n",
      "(epoch: 168, iters: 1540, time: 0.074, data: 0.003) G_GAN: 1.075 G_L1: 1.508 D_real: 0.560 D_fake: 0.595 \n",
      "(epoch: 168, iters: 1640, time: 0.073, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.768 D_fake: 0.630 \n",
      "(epoch: 168, iters: 1740, time: 0.074, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.744 D_fake: 0.626 \n",
      "(epoch: 168, iters: 1840, time: 0.074, data: 0.003) G_GAN: 1.096 G_L1: 0.842 D_real: 0.636 D_fake: 0.583 \n",
      "(epoch: 168, iters: 1940, time: 0.071, data: 0.003) G_GAN: 0.741 G_L1: 0.000 D_real: 0.759 D_fake: 0.608 \n",
      "(epoch: 168, iters: 2040, time: 0.072, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.719 D_fake: 0.654 \n",
      "(epoch: 168, iters: 2140, time: 0.072, data: 0.003) G_GAN: 1.080 G_L1: 0.917 D_real: 0.670 D_fake: 0.626 \n",
      "(epoch: 168, iters: 2240, time: 0.076, data: 0.002) G_GAN: 0.702 G_L1: 0.000 D_real: 0.711 D_fake: 0.582 \n",
      "End of epoch 168 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0005069\n",
      "(epoch: 169, iters: 60, time: 0.075, data: 0.002) G_GAN: 0.688 G_L1: 0.000 D_real: 0.692 D_fake: 0.702 \n",
      "(epoch: 169, iters: 160, time: 0.073, data: 0.003) G_GAN: 1.001 G_L1: 2.187 D_real: 0.551 D_fake: 0.594 \n",
      "(epoch: 169, iters: 260, time: 0.075, data: 0.003) G_GAN: 0.752 G_L1: 0.000 D_real: 0.771 D_fake: 0.600 \n",
      "(epoch: 169, iters: 360, time: 0.071, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.716 D_fake: 0.647 \n",
      "(epoch: 169, iters: 460, time: 0.073, data: 0.002) G_GAN: 1.014 G_L1: 2.055 D_real: 0.578 D_fake: 0.596 \n",
      "(epoch: 169, iters: 560, time: 0.076, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.721 D_fake: 0.648 \n",
      "(epoch: 169, iters: 660, time: 0.072, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.733 D_fake: 0.650 \n",
      "(epoch: 169, iters: 760, time: 0.072, data: 0.002) G_GAN: 1.127 G_L1: 2.009 D_real: 0.533 D_fake: 0.596 \n",
      "(epoch: 169, iters: 860, time: 0.072, data: 0.003) G_GAN: 0.757 G_L1: 0.000 D_real: 0.772 D_fake: 0.608 \n",
      "(epoch: 169, iters: 960, time: 0.072, data: 0.003) G_GAN: 0.720 G_L1: 0.000 D_real: 0.734 D_fake: 0.623 \n",
      "(epoch: 169, iters: 1060, time: 0.075, data: 0.002) G_GAN: 0.889 G_L1: 0.699 D_real: 0.612 D_fake: 0.622 \n",
      "(epoch: 169, iters: 1160, time: 0.072, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.731 D_fake: 0.639 \n",
      "(epoch: 169, iters: 1260, time: 0.071, data: 0.002) G_GAN: 0.655 G_L1: 0.000 D_real: 0.660 D_fake: 0.747 \n",
      "(epoch: 169, iters: 1360, time: 0.072, data: 0.002) G_GAN: 0.867 G_L1: 2.029 D_real: 0.543 D_fake: 0.601 \n",
      "(epoch: 169, iters: 1460, time: 0.074, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.777 D_fake: 0.612 \n",
      "(epoch: 169, iters: 1560, time: 0.071, data: 0.003) G_GAN: 0.697 G_L1: 0.000 D_real: 0.709 D_fake: 0.626 \n",
      "(epoch: 169, iters: 1660, time: 0.074, data: 0.002) G_GAN: 0.904 G_L1: 1.703 D_real: 0.592 D_fake: 0.589 \n",
      "(epoch: 169, iters: 1760, time: 0.072, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.722 D_fake: 0.615 \n",
      "(epoch: 169, iters: 1860, time: 0.071, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.729 D_fake: 0.685 \n",
      "(epoch: 169, iters: 1960, time: 0.072, data: 0.002) G_GAN: 0.914 G_L1: 2.015 D_real: 0.557 D_fake: 0.636 \n",
      "saving the latest model (epoch 169, total_steps 385000)\n",
      "(epoch: 169, iters: 2060, time: 0.071, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.731 D_fake: 0.675 \n",
      "(epoch: 169, iters: 2160, time: 0.071, data: 0.003) G_GAN: 0.703 G_L1: 0.000 D_real: 0.705 D_fake: 0.690 \n",
      "(epoch: 169, iters: 2260, time: 0.074, data: 0.002) G_GAN: 1.131 G_L1: 2.749 D_real: 0.588 D_fake: 0.569 \n",
      "End of epoch 169 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0004911\n",
      "(epoch: 170, iters: 80, time: 0.072, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.742 D_fake: 0.610 \n",
      "(epoch: 170, iters: 180, time: 0.072, data: 0.003) G_GAN: 0.732 G_L1: 0.000 D_real: 0.735 D_fake: 0.656 \n",
      "(epoch: 170, iters: 280, time: 0.071, data: 0.003) G_GAN: 0.975 G_L1: 1.026 D_real: 0.600 D_fake: 0.616 \n",
      "(epoch: 170, iters: 380, time: 0.071, data: 0.003) G_GAN: 0.758 G_L1: 0.000 D_real: 0.762 D_fake: 0.681 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 170, iters: 480, time: 0.078, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.732 D_fake: 0.610 \n",
      "(epoch: 170, iters: 580, time: 0.076, data: 0.002) G_GAN: 1.061 G_L1: 3.541 D_real: 0.503 D_fake: 0.590 \n",
      "(epoch: 170, iters: 680, time: 0.074, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.705 D_fake: 0.628 \n",
      "(epoch: 170, iters: 780, time: 0.073, data: 0.003) G_GAN: 0.723 G_L1: 0.000 D_real: 0.728 D_fake: 0.665 \n",
      "(epoch: 170, iters: 880, time: 0.071, data: 0.003) G_GAN: 1.055 G_L1: 2.571 D_real: 0.536 D_fake: 0.621 \n",
      "(epoch: 170, iters: 980, time: 0.074, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.769 D_fake: 0.598 \n",
      "(epoch: 170, iters: 1080, time: 0.073, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.707 D_fake: 0.653 \n",
      "(epoch: 170, iters: 1180, time: 0.075, data: 0.002) G_GAN: 0.980 G_L1: 2.021 D_real: 0.570 D_fake: 0.582 \n",
      "(epoch: 170, iters: 1280, time: 0.071, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.737 D_fake: 0.634 \n",
      "(epoch: 170, iters: 1380, time: 0.074, data: 0.003) G_GAN: 0.695 G_L1: 0.000 D_real: 0.701 D_fake: 0.672 \n",
      "(epoch: 170, iters: 1480, time: 0.071, data: 0.002) G_GAN: 1.096 G_L1: 1.813 D_real: 0.588 D_fake: 0.590 \n",
      "(epoch: 170, iters: 1580, time: 0.072, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.739 D_fake: 0.658 \n",
      "(epoch: 170, iters: 1680, time: 0.073, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.730 D_fake: 0.665 \n",
      "(epoch: 170, iters: 1780, time: 0.073, data: 0.002) G_GAN: 0.897 G_L1: 2.503 D_real: 0.541 D_fake: 0.627 \n",
      "(epoch: 170, iters: 1880, time: 0.071, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.736 D_fake: 0.650 \n",
      "(epoch: 170, iters: 1980, time: 0.074, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.704 D_fake: 0.636 \n",
      "(epoch: 170, iters: 2080, time: 0.074, data: 0.003) G_GAN: 0.895 G_L1: 2.297 D_real: 0.518 D_fake: 0.632 \n",
      "(epoch: 170, iters: 2180, time: 0.073, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.745 D_fake: 0.641 \n",
      "(epoch: 170, iters: 2280, time: 0.072, data: 0.003) G_GAN: 0.677 G_L1: 0.000 D_real: 0.688 D_fake: 0.704 \n",
      "saving the model at the end of epoch 170, iters 387600\n",
      "End of epoch 170 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0004752\n",
      "(epoch: 171, iters: 100, time: 0.072, data: 0.430) G_GAN: 0.994 G_L1: 2.485 D_real: 0.558 D_fake: 0.591 \n",
      "(epoch: 171, iters: 200, time: 0.071, data: 0.003) G_GAN: 0.721 G_L1: 0.000 D_real: 0.735 D_fake: 0.640 \n",
      "(epoch: 171, iters: 300, time: 0.076, data: 0.003) G_GAN: 0.715 G_L1: 0.000 D_real: 0.720 D_fake: 0.673 \n",
      "(epoch: 171, iters: 400, time: 0.074, data: 0.002) G_GAN: 1.047 G_L1: 1.437 D_real: 0.567 D_fake: 0.609 \n",
      "(epoch: 171, iters: 500, time: 0.072, data: 0.003) G_GAN: 0.726 G_L1: 0.000 D_real: 0.729 D_fake: 0.645 \n",
      "(epoch: 171, iters: 600, time: 0.074, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.738 D_fake: 0.586 \n",
      "(epoch: 171, iters: 700, time: 0.072, data: 0.002) G_GAN: 1.023 G_L1: 1.919 D_real: 0.552 D_fake: 0.610 \n",
      "(epoch: 171, iters: 800, time: 0.073, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.731 D_fake: 0.673 \n",
      "(epoch: 171, iters: 900, time: 0.072, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.766 D_fake: 0.659 \n",
      "(epoch: 171, iters: 1000, time: 0.074, data: 0.002) G_GAN: 0.956 G_L1: 1.678 D_real: 0.571 D_fake: 0.626 \n",
      "(epoch: 171, iters: 1100, time: 0.072, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.731 D_fake: 0.646 \n",
      "(epoch: 171, iters: 1200, time: 0.073, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.719 D_fake: 0.651 \n",
      "(epoch: 171, iters: 1300, time: 0.074, data: 0.002) G_GAN: 0.929 G_L1: 1.744 D_real: 0.589 D_fake: 0.592 \n",
      "(epoch: 171, iters: 1400, time: 0.072, data: 0.002) G_GAN: 0.797 G_L1: 0.000 D_real: 0.818 D_fake: 0.604 \n",
      "(epoch: 171, iters: 1500, time: 0.071, data: 0.003) G_GAN: 0.731 G_L1: 0.000 D_real: 0.742 D_fake: 0.647 \n",
      "(epoch: 171, iters: 1600, time: 0.072, data: 0.002) G_GAN: 1.059 G_L1: 2.124 D_real: 0.559 D_fake: 0.598 \n",
      "(epoch: 171, iters: 1700, time: 0.075, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.753 D_fake: 0.656 \n",
      "(epoch: 171, iters: 1800, time: 0.071, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.736 D_fake: 0.654 \n",
      "(epoch: 171, iters: 1900, time: 0.073, data: 0.002) G_GAN: 0.867 G_L1: 3.702 D_real: 0.511 D_fake: 0.595 \n",
      "(epoch: 171, iters: 2000, time: 0.075, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.762 D_fake: 0.650 \n",
      "(epoch: 171, iters: 2100, time: 0.071, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.709 D_fake: 0.664 \n",
      "(epoch: 171, iters: 2200, time: 0.071, data: 0.003) G_GAN: 0.969 G_L1: 1.583 D_real: 0.583 D_fake: 0.574 \n",
      "End of epoch 171 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0004594\n",
      "(epoch: 172, iters: 20, time: 0.076, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.736 D_fake: 0.629 \n",
      "(epoch: 172, iters: 120, time: 0.073, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.728 D_fake: 0.658 \n",
      "saving the latest model (epoch 172, total_steps 390000)\n",
      "(epoch: 172, iters: 220, time: 0.075, data: 0.002) G_GAN: 1.081 G_L1: 2.749 D_real: 0.525 D_fake: 0.600 \n",
      "(epoch: 172, iters: 320, time: 0.071, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.739 D_fake: 0.630 \n",
      "(epoch: 172, iters: 420, time: 0.076, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.741 D_fake: 0.642 \n",
      "(epoch: 172, iters: 520, time: 0.073, data: 0.002) G_GAN: 1.035 G_L1: 1.419 D_real: 0.591 D_fake: 0.568 \n",
      "(epoch: 172, iters: 620, time: 0.071, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.761 D_fake: 0.656 \n",
      "(epoch: 172, iters: 720, time: 0.073, data: 0.003) G_GAN: 0.718 G_L1: 0.000 D_real: 0.720 D_fake: 0.650 \n",
      "(epoch: 172, iters: 820, time: 0.072, data: 0.002) G_GAN: 0.950 G_L1: 1.824 D_real: 0.557 D_fake: 0.608 \n",
      "(epoch: 172, iters: 920, time: 0.072, data: 0.002) G_GAN: 0.671 G_L1: 0.000 D_real: 0.674 D_fake: 0.659 \n",
      "(epoch: 172, iters: 1020, time: 0.071, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.691 D_fake: 0.669 \n",
      "(epoch: 172, iters: 1120, time: 0.072, data: 0.001) G_GAN: 0.883 G_L1: 1.957 D_real: 0.527 D_fake: 0.728 \n",
      "(epoch: 172, iters: 1220, time: 0.071, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.728 D_fake: 0.657 \n",
      "(epoch: 172, iters: 1320, time: 0.074, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.711 D_fake: 0.657 \n",
      "(epoch: 172, iters: 1420, time: 0.075, data: 0.002) G_GAN: 1.044 G_L1: 2.010 D_real: 0.557 D_fake: 0.659 \n",
      "(epoch: 172, iters: 1520, time: 0.074, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.735 D_fake: 0.669 \n",
      "(epoch: 172, iters: 1620, time: 0.075, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.751 D_fake: 0.609 \n",
      "(epoch: 172, iters: 1720, time: 0.074, data: 0.002) G_GAN: 1.115 G_L1: 3.150 D_real: 0.530 D_fake: 0.594 \n",
      "(epoch: 172, iters: 1820, time: 0.077, data: 0.003) G_GAN: 0.766 G_L1: 0.000 D_real: 0.850 D_fake: 0.629 \n",
      "(epoch: 172, iters: 1920, time: 0.078, data: 0.003) G_GAN: 0.710 G_L1: 0.000 D_real: 0.716 D_fake: 0.661 \n",
      "(epoch: 172, iters: 2020, time: 0.072, data: 0.002) G_GAN: 1.051 G_L1: 1.672 D_real: 0.596 D_fake: 0.668 \n",
      "(epoch: 172, iters: 2120, time: 0.075, data: 0.003) G_GAN: 0.735 G_L1: 0.000 D_real: 0.738 D_fake: 0.657 \n",
      "(epoch: 172, iters: 2220, time: 0.072, data: 0.003) G_GAN: 0.700 G_L1: 0.000 D_real: 0.708 D_fake: 0.689 \n",
      "End of epoch 172 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0004436\n",
      "(epoch: 173, iters: 40, time: 0.076, data: 0.003) G_GAN: 1.026 G_L1: 1.820 D_real: 0.558 D_fake: 0.620 \n",
      "(epoch: 173, iters: 140, time: 0.071, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.746 D_fake: 0.627 \n",
      "(epoch: 173, iters: 240, time: 0.076, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.694 D_fake: 0.682 \n",
      "(epoch: 173, iters: 340, time: 0.075, data: 0.002) G_GAN: 0.859 G_L1: 1.290 D_real: 0.582 D_fake: 0.626 \n",
      "(epoch: 173, iters: 440, time: 0.072, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.705 D_fake: 0.660 \n",
      "(epoch: 173, iters: 540, time: 0.075, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.713 D_fake: 0.653 \n",
      "(epoch: 173, iters: 640, time: 0.071, data: 0.002) G_GAN: 0.953 G_L1: 2.682 D_real: 0.539 D_fake: 0.598 \n",
      "(epoch: 173, iters: 740, time: 0.074, data: 0.003) G_GAN: 0.728 G_L1: 0.000 D_real: 0.739 D_fake: 0.615 \n",
      "(epoch: 173, iters: 840, time: 0.071, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.714 D_fake: 0.681 \n",
      "(epoch: 173, iters: 940, time: 0.071, data: 0.002) G_GAN: 1.126 G_L1: 3.230 D_real: 0.534 D_fake: 0.580 \n",
      "(epoch: 173, iters: 1040, time: 0.072, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.741 D_fake: 0.609 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 173, iters: 1140, time: 0.072, data: 0.003) G_GAN: 0.688 G_L1: 0.000 D_real: 0.693 D_fake: 0.706 \n",
      "(epoch: 173, iters: 1240, time: 0.072, data: 0.003) G_GAN: 1.284 G_L1: 2.399 D_real: 0.592 D_fake: 0.584 \n",
      "(epoch: 173, iters: 1340, time: 0.073, data: 0.003) G_GAN: 0.781 G_L1: 0.000 D_real: 0.800 D_fake: 0.619 \n",
      "(epoch: 173, iters: 1440, time: 0.072, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.725 D_fake: 0.676 \n",
      "(epoch: 173, iters: 1540, time: 0.071, data: 0.002) G_GAN: 1.074 G_L1: 1.508 D_real: 0.584 D_fake: 0.565 \n",
      "(epoch: 173, iters: 1640, time: 0.072, data: 0.003) G_GAN: 0.747 G_L1: 0.000 D_real: 0.755 D_fake: 0.591 \n",
      "(epoch: 173, iters: 1740, time: 0.073, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.732 D_fake: 0.652 \n",
      "(epoch: 173, iters: 1840, time: 0.074, data: 0.003) G_GAN: 1.069 G_L1: 0.842 D_real: 0.648 D_fake: 0.604 \n",
      "(epoch: 173, iters: 1940, time: 0.074, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.741 D_fake: 0.601 \n",
      "(epoch: 173, iters: 2040, time: 0.076, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.728 D_fake: 0.583 \n",
      "(epoch: 173, iters: 2140, time: 0.074, data: 0.002) G_GAN: 1.013 G_L1: 0.917 D_real: 0.634 D_fake: 0.614 \n",
      "(epoch: 173, iters: 2240, time: 0.072, data: 0.002) G_GAN: 0.688 G_L1: 0.000 D_real: 0.703 D_fake: 0.619 \n",
      "End of epoch 173 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0004277\n",
      "(epoch: 174, iters: 60, time: 0.072, data: 0.002) G_GAN: 0.670 G_L1: 0.000 D_real: 0.666 D_fake: 0.723 \n",
      "(epoch: 174, iters: 160, time: 0.075, data: 0.002) G_GAN: 1.073 G_L1: 2.187 D_real: 0.573 D_fake: 0.643 \n",
      "(epoch: 174, iters: 260, time: 0.072, data: 0.002) G_GAN: 0.557 G_L1: 0.000 D_real: 0.840 D_fake: 0.601 \n",
      "(epoch: 174, iters: 360, time: 0.074, data: 0.004) G_GAN: 0.713 G_L1: 0.000 D_real: 0.715 D_fake: 0.657 \n",
      "(epoch: 174, iters: 460, time: 0.075, data: 0.002) G_GAN: 0.955 G_L1: 2.055 D_real: 0.556 D_fake: 0.607 \n",
      "(epoch: 174, iters: 560, time: 0.073, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.765 D_fake: 0.616 \n",
      "saving the latest model (epoch 174, total_steps 395000)\n",
      "(epoch: 174, iters: 660, time: 0.074, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.728 D_fake: 0.667 \n",
      "(epoch: 174, iters: 760, time: 0.075, data: 0.002) G_GAN: 1.088 G_L1: 2.009 D_real: 0.553 D_fake: 0.587 \n",
      "(epoch: 174, iters: 860, time: 0.073, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.763 D_fake: 0.583 \n",
      "(epoch: 174, iters: 960, time: 0.075, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.732 D_fake: 0.630 \n",
      "(epoch: 174, iters: 1060, time: 0.072, data: 0.002) G_GAN: 0.928 G_L1: 0.699 D_real: 0.622 D_fake: 0.609 \n",
      "(epoch: 174, iters: 1160, time: 0.074, data: 0.003) G_GAN: 0.722 G_L1: 0.000 D_real: 0.738 D_fake: 0.634 \n",
      "(epoch: 174, iters: 1260, time: 0.072, data: 0.002) G_GAN: 0.684 G_L1: 0.000 D_real: 0.702 D_fake: 0.704 \n",
      "(epoch: 174, iters: 1360, time: 0.072, data: 0.002) G_GAN: 0.812 G_L1: 2.029 D_real: 0.524 D_fake: 0.680 \n",
      "(epoch: 174, iters: 1460, time: 0.071, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.767 D_fake: 0.633 \n",
      "(epoch: 174, iters: 1560, time: 0.072, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.717 D_fake: 0.653 \n",
      "(epoch: 174, iters: 1660, time: 0.075, data: 0.003) G_GAN: 0.917 G_L1: 1.703 D_real: 0.576 D_fake: 0.640 \n",
      "(epoch: 174, iters: 1760, time: 0.072, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.729 D_fake: 0.634 \n",
      "(epoch: 174, iters: 1860, time: 0.074, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.725 D_fake: 0.655 \n",
      "(epoch: 174, iters: 1960, time: 0.071, data: 0.002) G_GAN: 0.914 G_L1: 2.015 D_real: 0.556 D_fake: 0.602 \n",
      "(epoch: 174, iters: 2060, time: 0.070, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.730 D_fake: 0.685 \n",
      "(epoch: 174, iters: 2160, time: 0.072, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.709 D_fake: 0.649 \n",
      "(epoch: 174, iters: 2260, time: 0.074, data: 0.003) G_GAN: 1.067 G_L1: 2.749 D_real: 0.534 D_fake: 0.637 \n",
      "End of epoch 174 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0004119\n",
      "(epoch: 175, iters: 80, time: 0.073, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.730 D_fake: 0.648 \n",
      "(epoch: 175, iters: 180, time: 0.072, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.739 D_fake: 0.653 \n",
      "(epoch: 175, iters: 280, time: 0.074, data: 0.003) G_GAN: 0.968 G_L1: 1.026 D_real: 0.569 D_fake: 0.646 \n",
      "(epoch: 175, iters: 380, time: 0.072, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.751 D_fake: 0.649 \n",
      "(epoch: 175, iters: 480, time: 0.075, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.721 D_fake: 0.667 \n",
      "(epoch: 175, iters: 580, time: 0.073, data: 0.002) G_GAN: 1.118 G_L1: 3.541 D_real: 0.503 D_fake: 0.645 \n",
      "(epoch: 175, iters: 680, time: 0.073, data: 0.003) G_GAN: 0.707 G_L1: 0.000 D_real: 0.707 D_fake: 0.686 \n",
      "(epoch: 175, iters: 780, time: 0.072, data: 0.003) G_GAN: 0.694 G_L1: 0.000 D_real: 0.705 D_fake: 0.635 \n",
      "(epoch: 175, iters: 880, time: 0.075, data: 0.002) G_GAN: 1.151 G_L1: 2.571 D_real: 0.544 D_fake: 0.657 \n",
      "(epoch: 175, iters: 980, time: 0.072, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.762 D_fake: 0.608 \n",
      "(epoch: 175, iters: 1080, time: 0.071, data: 0.003) G_GAN: 0.686 G_L1: 0.000 D_real: 0.692 D_fake: 0.671 \n",
      "(epoch: 175, iters: 1180, time: 0.075, data: 0.002) G_GAN: 1.029 G_L1: 2.021 D_real: 0.542 D_fake: 0.597 \n",
      "(epoch: 175, iters: 1280, time: 0.072, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.735 D_fake: 0.636 \n",
      "(epoch: 175, iters: 1380, time: 0.071, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.714 D_fake: 0.648 \n",
      "(epoch: 175, iters: 1480, time: 0.074, data: 0.003) G_GAN: 1.116 G_L1: 1.813 D_real: 0.581 D_fake: 0.597 \n",
      "(epoch: 175, iters: 1580, time: 0.075, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.739 D_fake: 0.656 \n",
      "(epoch: 175, iters: 1680, time: 0.072, data: 0.003) G_GAN: 0.689 G_L1: 0.000 D_real: 0.701 D_fake: 0.623 \n",
      "(epoch: 175, iters: 1780, time: 0.073, data: 0.002) G_GAN: 0.920 G_L1: 2.503 D_real: 0.552 D_fake: 0.598 \n",
      "(epoch: 175, iters: 1880, time: 0.075, data: 0.004) G_GAN: 0.731 G_L1: 0.000 D_real: 0.736 D_fake: 0.637 \n",
      "(epoch: 175, iters: 1980, time: 0.074, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.696 D_fake: 0.655 \n",
      "(epoch: 175, iters: 2080, time: 0.074, data: 0.002) G_GAN: 0.947 G_L1: 2.297 D_real: 0.503 D_fake: 0.634 \n",
      "(epoch: 175, iters: 2180, time: 0.072, data: 0.002) G_GAN: 0.794 G_L1: 0.000 D_real: 0.807 D_fake: 0.537 \n",
      "(epoch: 175, iters: 2280, time: 0.072, data: 0.002) G_GAN: 0.678 G_L1: 0.000 D_real: 0.678 D_fake: 0.715 \n",
      "saving the model at the end of epoch 175, iters 399000\n",
      "End of epoch 175 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0003960\n",
      "(epoch: 176, iters: 100, time: 0.073, data: 0.407) G_GAN: 1.023 G_L1: 2.485 D_real: 0.530 D_fake: 0.625 \n",
      "(epoch: 176, iters: 200, time: 0.071, data: 0.003) G_GAN: 0.702 G_L1: 0.000 D_real: 0.712 D_fake: 0.676 \n",
      "(epoch: 176, iters: 300, time: 0.071, data: 0.004) G_GAN: 0.747 G_L1: 0.000 D_real: 0.752 D_fake: 0.625 \n",
      "(epoch: 176, iters: 400, time: 0.071, data: 0.002) G_GAN: 1.157 G_L1: 1.437 D_real: 0.566 D_fake: 0.623 \n",
      "(epoch: 176, iters: 500, time: 0.071, data: 0.003) G_GAN: 0.732 G_L1: 0.000 D_real: 0.734 D_fake: 0.618 \n",
      "(epoch: 176, iters: 600, time: 0.071, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.740 D_fake: 0.612 \n",
      "(epoch: 176, iters: 700, time: 0.074, data: 0.002) G_GAN: 1.082 G_L1: 1.919 D_real: 0.534 D_fake: 0.597 \n",
      "(epoch: 176, iters: 800, time: 0.076, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.717 D_fake: 0.667 \n",
      "(epoch: 176, iters: 900, time: 0.071, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.741 D_fake: 0.661 \n",
      "(epoch: 176, iters: 1000, time: 0.074, data: 0.002) G_GAN: 1.108 G_L1: 1.678 D_real: 0.583 D_fake: 0.573 \n",
      "saving the latest model (epoch 176, total_steps 400000)\n",
      "(epoch: 176, iters: 1100, time: 0.072, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.725 D_fake: 0.619 \n",
      "(epoch: 176, iters: 1200, time: 0.074, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.748 D_fake: 0.650 \n",
      "(epoch: 176, iters: 1300, time: 0.072, data: 0.002) G_GAN: 0.955 G_L1: 1.744 D_real: 0.603 D_fake: 0.611 \n",
      "(epoch: 176, iters: 1400, time: 0.071, data: 0.002) G_GAN: 0.781 G_L1: 0.000 D_real: 0.789 D_fake: 0.595 \n",
      "(epoch: 176, iters: 1500, time: 0.076, data: 0.001) G_GAN: 0.709 G_L1: 0.000 D_real: 0.716 D_fake: 0.679 \n",
      "(epoch: 176, iters: 1600, time: 0.073, data: 0.002) G_GAN: 1.070 G_L1: 2.124 D_real: 0.537 D_fake: 0.646 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 176, iters: 1700, time: 0.075, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.761 D_fake: 0.611 \n",
      "(epoch: 176, iters: 1800, time: 0.073, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.735 D_fake: 0.627 \n",
      "(epoch: 176, iters: 1900, time: 0.075, data: 0.002) G_GAN: 0.916 G_L1: 3.702 D_real: 0.508 D_fake: 0.583 \n",
      "(epoch: 176, iters: 2000, time: 0.074, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.745 D_fake: 0.632 \n",
      "(epoch: 176, iters: 2100, time: 0.072, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.709 D_fake: 0.689 \n",
      "(epoch: 176, iters: 2200, time: 0.074, data: 0.003) G_GAN: 0.911 G_L1: 1.583 D_real: 0.577 D_fake: 0.573 \n",
      "End of epoch 176 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0003802\n",
      "(epoch: 177, iters: 20, time: 0.073, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.726 D_fake: 0.659 \n",
      "(epoch: 177, iters: 120, time: 0.072, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.751 D_fake: 0.564 \n",
      "(epoch: 177, iters: 220, time: 0.072, data: 0.002) G_GAN: 1.096 G_L1: 2.749 D_real: 0.498 D_fake: 0.608 \n",
      "(epoch: 177, iters: 320, time: 0.071, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.719 D_fake: 0.639 \n",
      "(epoch: 177, iters: 420, time: 0.073, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.739 D_fake: 0.671 \n",
      "(epoch: 177, iters: 520, time: 0.071, data: 0.002) G_GAN: 0.973 G_L1: 1.419 D_real: 0.575 D_fake: 0.618 \n",
      "(epoch: 177, iters: 620, time: 0.070, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.773 D_fake: 0.657 \n",
      "(epoch: 177, iters: 720, time: 0.076, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.726 D_fake: 0.670 \n",
      "(epoch: 177, iters: 820, time: 0.074, data: 0.002) G_GAN: 1.024 G_L1: 1.824 D_real: 0.575 D_fake: 0.584 \n",
      "(epoch: 177, iters: 920, time: 0.072, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.738 D_fake: 0.643 \n",
      "(epoch: 177, iters: 1020, time: 0.071, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.699 D_fake: 0.699 \n",
      "(epoch: 177, iters: 1120, time: 0.073, data: 0.002) G_GAN: 0.930 G_L1: 1.957 D_real: 0.525 D_fake: 0.659 \n",
      "(epoch: 177, iters: 1220, time: 0.073, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.734 D_fake: 0.685 \n",
      "(epoch: 177, iters: 1320, time: 0.071, data: 0.003) G_GAN: 0.706 G_L1: 0.000 D_real: 0.711 D_fake: 0.669 \n",
      "(epoch: 177, iters: 1420, time: 0.074, data: 0.002) G_GAN: 1.144 G_L1: 2.010 D_real: 0.563 D_fake: 0.564 \n",
      "(epoch: 177, iters: 1520, time: 0.071, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.726 D_fake: 0.645 \n",
      "(epoch: 177, iters: 1620, time: 0.073, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.763 D_fake: 0.623 \n",
      "(epoch: 177, iters: 1720, time: 0.075, data: 0.002) G_GAN: 1.191 G_L1: 3.150 D_real: 0.526 D_fake: 0.565 \n",
      "(epoch: 177, iters: 1820, time: 0.073, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.800 D_fake: 0.632 \n",
      "(epoch: 177, iters: 1920, time: 0.074, data: 0.004) G_GAN: 0.718 G_L1: 0.000 D_real: 0.722 D_fake: 0.646 \n",
      "(epoch: 177, iters: 2020, time: 0.072, data: 0.003) G_GAN: 1.063 G_L1: 1.672 D_real: 0.592 D_fake: 0.610 \n",
      "(epoch: 177, iters: 2120, time: 0.071, data: 0.003) G_GAN: 0.761 G_L1: 0.000 D_real: 0.772 D_fake: 0.628 \n",
      "(epoch: 177, iters: 2220, time: 0.074, data: 0.004) G_GAN: 0.684 G_L1: 0.000 D_real: 0.696 D_fake: 0.649 \n",
      "End of epoch 177 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0003644\n",
      "(epoch: 178, iters: 40, time: 0.075, data: 0.002) G_GAN: 1.056 G_L1: 1.820 D_real: 0.556 D_fake: 0.590 \n",
      "(epoch: 178, iters: 140, time: 0.071, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.749 D_fake: 0.632 \n",
      "(epoch: 178, iters: 240, time: 0.075, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.710 D_fake: 0.647 \n",
      "(epoch: 178, iters: 340, time: 0.071, data: 0.003) G_GAN: 0.919 G_L1: 1.290 D_real: 0.604 D_fake: 0.582 \n",
      "(epoch: 178, iters: 440, time: 0.072, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.706 D_fake: 0.658 \n",
      "(epoch: 178, iters: 540, time: 0.071, data: 0.003) G_GAN: 0.669 G_L1: 0.000 D_real: 0.677 D_fake: 0.683 \n",
      "(epoch: 178, iters: 640, time: 0.072, data: 0.003) G_GAN: 0.977 G_L1: 2.682 D_real: 0.532 D_fake: 0.640 \n",
      "(epoch: 178, iters: 740, time: 0.071, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.735 D_fake: 0.666 \n",
      "(epoch: 178, iters: 840, time: 0.072, data: 0.002) G_GAN: 0.679 G_L1: 0.000 D_real: 0.680 D_fake: 0.693 \n",
      "(epoch: 178, iters: 940, time: 0.072, data: 0.002) G_GAN: 1.119 G_L1: 3.230 D_real: 0.544 D_fake: 0.574 \n",
      "(epoch: 178, iters: 1040, time: 0.072, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.759 D_fake: 0.648 \n",
      "(epoch: 178, iters: 1140, time: 0.074, data: 0.003) G_GAN: 0.705 G_L1: 0.000 D_real: 0.712 D_fake: 0.662 \n",
      "(epoch: 178, iters: 1240, time: 0.074, data: 0.002) G_GAN: 1.321 G_L1: 2.399 D_real: 0.549 D_fake: 0.579 \n",
      "(epoch: 178, iters: 1340, time: 0.072, data: 0.002) G_GAN: 0.789 G_L1: 0.000 D_real: 0.805 D_fake: 0.588 \n",
      "(epoch: 178, iters: 1440, time: 0.073, data: 0.003) G_GAN: 0.731 G_L1: 0.000 D_real: 0.739 D_fake: 0.657 \n",
      "saving the latest model (epoch 178, total_steps 405000)\n",
      "(epoch: 178, iters: 1540, time: 0.074, data: 0.002) G_GAN: 1.150 G_L1: 1.508 D_real: 0.562 D_fake: 0.572 \n",
      "(epoch: 178, iters: 1640, time: 0.072, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.753 D_fake: 0.637 \n",
      "(epoch: 178, iters: 1740, time: 0.075, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.738 D_fake: 0.656 \n",
      "(epoch: 178, iters: 1840, time: 0.075, data: 0.002) G_GAN: 1.149 G_L1: 0.842 D_real: 0.648 D_fake: 0.612 \n",
      "(epoch: 178, iters: 1940, time: 0.071, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.754 D_fake: 0.625 \n",
      "(epoch: 178, iters: 2040, time: 0.073, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.708 D_fake: 0.636 \n",
      "(epoch: 178, iters: 2140, time: 0.072, data: 0.002) G_GAN: 1.066 G_L1: 0.917 D_real: 0.631 D_fake: 0.552 \n",
      "(epoch: 178, iters: 2240, time: 0.072, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.726 D_fake: 0.671 \n",
      "End of epoch 178 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0003485\n",
      "(epoch: 179, iters: 60, time: 0.076, data: 0.003) G_GAN: 0.695 G_L1: 0.000 D_real: 0.700 D_fake: 0.690 \n",
      "(epoch: 179, iters: 160, time: 0.073, data: 0.001) G_GAN: 1.043 G_L1: 2.187 D_real: 0.555 D_fake: 0.582 \n",
      "(epoch: 179, iters: 260, time: 0.072, data: 0.003) G_GAN: 0.726 G_L1: 0.000 D_real: 0.732 D_fake: 0.666 \n",
      "(epoch: 179, iters: 360, time: 0.074, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.697 D_fake: 0.666 \n",
      "(epoch: 179, iters: 460, time: 0.072, data: 0.003) G_GAN: 1.040 G_L1: 2.055 D_real: 0.584 D_fake: 0.569 \n",
      "(epoch: 179, iters: 560, time: 0.075, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.716 D_fake: 0.635 \n",
      "(epoch: 179, iters: 660, time: 0.075, data: 0.003) G_GAN: 0.710 G_L1: 0.000 D_real: 0.715 D_fake: 0.658 \n",
      "(epoch: 179, iters: 760, time: 0.072, data: 0.002) G_GAN: 1.129 G_L1: 2.009 D_real: 0.551 D_fake: 0.643 \n",
      "(epoch: 179, iters: 860, time: 0.071, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.762 D_fake: 0.584 \n",
      "(epoch: 179, iters: 960, time: 0.071, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.727 D_fake: 0.635 \n",
      "(epoch: 179, iters: 1060, time: 0.074, data: 0.003) G_GAN: 0.885 G_L1: 0.699 D_real: 0.616 D_fake: 0.644 \n",
      "(epoch: 179, iters: 1160, time: 0.072, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.750 D_fake: 0.606 \n",
      "(epoch: 179, iters: 1260, time: 0.071, data: 0.003) G_GAN: 0.679 G_L1: 0.000 D_real: 0.684 D_fake: 0.696 \n",
      "(epoch: 179, iters: 1360, time: 0.074, data: 0.003) G_GAN: 0.832 G_L1: 2.029 D_real: 0.545 D_fake: 0.604 \n",
      "(epoch: 179, iters: 1460, time: 0.073, data: 0.002) G_GAN: 0.774 G_L1: 0.000 D_real: 0.791 D_fake: 0.633 \n",
      "(epoch: 179, iters: 1560, time: 0.071, data: 0.003) G_GAN: 0.707 G_L1: 0.000 D_real: 0.719 D_fake: 0.649 \n",
      "(epoch: 179, iters: 1660, time: 0.072, data: 0.002) G_GAN: 0.953 G_L1: 1.703 D_real: 0.588 D_fake: 0.561 \n",
      "(epoch: 179, iters: 1760, time: 0.076, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.729 D_fake: 0.668 \n",
      "(epoch: 179, iters: 1860, time: 0.072, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.757 D_fake: 0.667 \n",
      "(epoch: 179, iters: 1960, time: 0.075, data: 0.002) G_GAN: 0.922 G_L1: 2.015 D_real: 0.559 D_fake: 0.645 \n",
      "(epoch: 179, iters: 2060, time: 0.074, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.734 D_fake: 0.622 \n",
      "(epoch: 179, iters: 2160, time: 0.074, data: 0.003) G_GAN: 0.712 G_L1: 0.000 D_real: 0.721 D_fake: 0.644 \n",
      "(epoch: 179, iters: 2260, time: 0.075, data: 0.002) G_GAN: 1.099 G_L1: 2.749 D_real: 0.547 D_fake: 0.552 \n",
      "End of epoch 179 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0003327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 180, iters: 80, time: 0.072, data: 0.003) G_GAN: 0.733 G_L1: 0.000 D_real: 0.744 D_fake: 0.659 \n",
      "(epoch: 180, iters: 180, time: 0.071, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.726 D_fake: 0.647 \n",
      "(epoch: 180, iters: 280, time: 0.075, data: 0.002) G_GAN: 1.046 G_L1: 1.026 D_real: 0.599 D_fake: 0.638 \n",
      "(epoch: 180, iters: 380, time: 0.073, data: 0.003) G_GAN: 0.753 G_L1: 0.000 D_real: 0.759 D_fake: 0.676 \n",
      "(epoch: 180, iters: 480, time: 0.073, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.734 D_fake: 0.625 \n",
      "(epoch: 180, iters: 580, time: 0.071, data: 0.002) G_GAN: 1.126 G_L1: 3.541 D_real: 0.522 D_fake: 0.615 \n",
      "(epoch: 180, iters: 680, time: 0.072, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.718 D_fake: 0.649 \n",
      "(epoch: 180, iters: 780, time: 0.074, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.737 D_fake: 0.668 \n",
      "(epoch: 180, iters: 880, time: 0.071, data: 0.003) G_GAN: 1.108 G_L1: 2.571 D_real: 0.529 D_fake: 0.563 \n",
      "(epoch: 180, iters: 980, time: 0.072, data: 0.003) G_GAN: 0.732 G_L1: 0.000 D_real: 0.740 D_fake: 0.668 \n",
      "(epoch: 180, iters: 1080, time: 0.072, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.690 D_fake: 0.663 \n",
      "(epoch: 180, iters: 1180, time: 0.073, data: 0.003) G_GAN: 1.087 G_L1: 2.021 D_real: 0.556 D_fake: 0.604 \n",
      "(epoch: 180, iters: 1280, time: 0.076, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.729 D_fake: 0.653 \n",
      "(epoch: 180, iters: 1380, time: 0.073, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.698 D_fake: 0.662 \n",
      "(epoch: 180, iters: 1480, time: 0.075, data: 0.002) G_GAN: 1.181 G_L1: 1.813 D_real: 0.585 D_fake: 0.558 \n",
      "(epoch: 180, iters: 1580, time: 0.071, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.735 D_fake: 0.638 \n",
      "(epoch: 180, iters: 1680, time: 0.071, data: 0.004) G_GAN: 0.714 G_L1: 0.000 D_real: 0.721 D_fake: 0.648 \n",
      "(epoch: 180, iters: 1780, time: 0.073, data: 0.002) G_GAN: 0.894 G_L1: 2.503 D_real: 0.539 D_fake: 0.574 \n",
      "(epoch: 180, iters: 1880, time: 0.073, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.733 D_fake: 0.679 \n",
      "saving the latest model (epoch 180, total_steps 410000)\n",
      "(epoch: 180, iters: 1980, time: 0.074, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 180, iters: 2080, time: 0.073, data: 0.003) G_GAN: 1.027 G_L1: 2.297 D_real: 0.529 D_fake: 0.613 \n",
      "(epoch: 180, iters: 2180, time: 0.078, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.750 D_fake: 0.630 \n",
      "(epoch: 180, iters: 2280, time: 0.073, data: 0.003) G_GAN: 0.665 G_L1: 0.000 D_real: 0.671 D_fake: 0.713 \n",
      "saving the model at the end of epoch 180, iters 410400\n",
      "End of epoch 180 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0003168\n",
      "(epoch: 181, iters: 100, time: 0.076, data: 0.447) G_GAN: 1.109 G_L1: 2.485 D_real: 0.542 D_fake: 0.627 \n",
      "(epoch: 181, iters: 200, time: 0.074, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.715 D_fake: 0.600 \n",
      "(epoch: 181, iters: 300, time: 0.072, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.749 D_fake: 0.668 \n",
      "(epoch: 181, iters: 400, time: 0.076, data: 0.002) G_GAN: 1.204 G_L1: 1.437 D_real: 0.548 D_fake: 0.664 \n",
      "(epoch: 181, iters: 500, time: 0.073, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.742 D_fake: 0.615 \n",
      "(epoch: 181, iters: 600, time: 0.072, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.722 D_fake: 0.679 \n",
      "(epoch: 181, iters: 700, time: 0.074, data: 0.003) G_GAN: 1.092 G_L1: 1.919 D_real: 0.551 D_fake: 0.596 \n",
      "(epoch: 181, iters: 800, time: 0.073, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.746 D_fake: 0.634 \n",
      "(epoch: 181, iters: 900, time: 0.073, data: 0.003) G_GAN: 0.661 G_L1: 0.000 D_real: 0.685 D_fake: 0.572 \n",
      "(epoch: 181, iters: 1000, time: 0.072, data: 0.002) G_GAN: 1.087 G_L1: 1.678 D_real: 0.587 D_fake: 0.592 \n",
      "(epoch: 181, iters: 1100, time: 0.074, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.737 D_fake: 0.639 \n",
      "(epoch: 181, iters: 1200, time: 0.073, data: 0.003) G_GAN: 0.719 G_L1: 0.000 D_real: 0.728 D_fake: 0.607 \n",
      "(epoch: 181, iters: 1300, time: 0.073, data: 0.003) G_GAN: 1.042 G_L1: 1.744 D_real: 0.603 D_fake: 0.572 \n",
      "(epoch: 181, iters: 1400, time: 0.073, data: 0.002) G_GAN: 0.797 G_L1: 0.000 D_real: 0.804 D_fake: 0.619 \n",
      "(epoch: 181, iters: 1500, time: 0.073, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.716 D_fake: 0.676 \n",
      "(epoch: 181, iters: 1600, time: 0.073, data: 0.003) G_GAN: 1.071 G_L1: 2.124 D_real: 0.540 D_fake: 0.592 \n",
      "(epoch: 181, iters: 1700, time: 0.074, data: 0.003) G_GAN: 0.738 G_L1: 0.000 D_real: 0.737 D_fake: 0.637 \n",
      "(epoch: 181, iters: 1800, time: 0.075, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.720 D_fake: 0.646 \n",
      "(epoch: 181, iters: 1900, time: 0.072, data: 0.002) G_GAN: 0.898 G_L1: 3.702 D_real: 0.504 D_fake: 0.594 \n",
      "(epoch: 181, iters: 2000, time: 0.072, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.745 D_fake: 0.632 \n",
      "(epoch: 181, iters: 2100, time: 0.071, data: 0.003) G_GAN: 0.694 G_L1: 0.000 D_real: 0.706 D_fake: 0.636 \n",
      "(epoch: 181, iters: 2200, time: 0.071, data: 0.002) G_GAN: 0.932 G_L1: 1.583 D_real: 0.579 D_fake: 0.591 \n",
      "End of epoch 181 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0003010\n",
      "(epoch: 182, iters: 20, time: 0.073, data: 0.003) G_GAN: 0.689 G_L1: 0.000 D_real: 0.691 D_fake: 0.637 \n",
      "(epoch: 182, iters: 120, time: 0.071, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.727 D_fake: 0.627 \n",
      "(epoch: 182, iters: 220, time: 0.071, data: 0.003) G_GAN: 1.096 G_L1: 2.749 D_real: 0.500 D_fake: 0.654 \n",
      "(epoch: 182, iters: 320, time: 0.073, data: 0.003) G_GAN: 0.726 G_L1: 0.000 D_real: 0.731 D_fake: 0.664 \n",
      "(epoch: 182, iters: 420, time: 0.075, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.735 D_fake: 0.652 \n",
      "(epoch: 182, iters: 520, time: 0.073, data: 0.002) G_GAN: 1.058 G_L1: 1.419 D_real: 0.599 D_fake: 0.561 \n",
      "(epoch: 182, iters: 620, time: 0.074, data: 0.003) G_GAN: 0.756 G_L1: 0.000 D_real: 0.768 D_fake: 0.593 \n",
      "(epoch: 182, iters: 720, time: 0.077, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.712 D_fake: 0.684 \n",
      "(epoch: 182, iters: 820, time: 0.071, data: 0.002) G_GAN: 0.952 G_L1: 1.824 D_real: 0.544 D_fake: 0.645 \n",
      "(epoch: 182, iters: 920, time: 0.071, data: 0.002) G_GAN: 0.648 G_L1: 0.000 D_real: 0.654 D_fake: 0.681 \n",
      "(epoch: 182, iters: 1020, time: 0.073, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.708 D_fake: 0.679 \n",
      "(epoch: 182, iters: 1120, time: 0.075, data: 0.002) G_GAN: 0.934 G_L1: 1.957 D_real: 0.544 D_fake: 0.628 \n",
      "(epoch: 182, iters: 1220, time: 0.074, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.724 D_fake: 0.679 \n",
      "(epoch: 182, iters: 1320, time: 0.072, data: 0.003) G_GAN: 0.695 G_L1: 0.000 D_real: 0.702 D_fake: 0.658 \n",
      "(epoch: 182, iters: 1420, time: 0.074, data: 0.003) G_GAN: 1.135 G_L1: 2.010 D_real: 0.558 D_fake: 0.588 \n",
      "(epoch: 182, iters: 1520, time: 0.077, data: 0.003) G_GAN: 0.715 G_L1: 0.000 D_real: 0.722 D_fake: 0.615 \n",
      "(epoch: 182, iters: 1620, time: 0.071, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.757 D_fake: 0.645 \n",
      "(epoch: 182, iters: 1720, time: 0.074, data: 0.002) G_GAN: 1.143 G_L1: 3.150 D_real: 0.526 D_fake: 0.609 \n",
      "(epoch: 182, iters: 1820, time: 0.074, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.770 D_fake: 0.619 \n",
      "(epoch: 182, iters: 1920, time: 0.074, data: 0.004) G_GAN: 0.723 G_L1: 0.000 D_real: 0.730 D_fake: 0.630 \n",
      "(epoch: 182, iters: 2020, time: 0.077, data: 0.002) G_GAN: 1.066 G_L1: 1.672 D_real: 0.586 D_fake: 0.625 \n",
      "(epoch: 182, iters: 2120, time: 0.072, data: 0.003) G_GAN: 0.743 G_L1: 0.000 D_real: 0.746 D_fake: 0.649 \n",
      "(epoch: 182, iters: 2220, time: 0.073, data: 0.001) G_GAN: 0.719 G_L1: 0.000 D_real: 0.724 D_fake: 0.577 \n",
      "End of epoch 182 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0002851\n",
      "(epoch: 183, iters: 40, time: 0.072, data: 0.002) G_GAN: 1.058 G_L1: 1.820 D_real: 0.546 D_fake: 0.605 \n",
      "saving the latest model (epoch 183, total_steps 415000)\n",
      "(epoch: 183, iters: 140, time: 0.079, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.745 D_fake: 0.647 \n",
      "(epoch: 183, iters: 240, time: 0.077, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.689 D_fake: 0.676 \n",
      "(epoch: 183, iters: 340, time: 0.080, data: 0.002) G_GAN: 0.879 G_L1: 1.290 D_real: 0.584 D_fake: 0.608 \n",
      "(epoch: 183, iters: 440, time: 0.076, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.720 D_fake: 0.624 \n",
      "(epoch: 183, iters: 540, time: 0.074, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.709 D_fake: 0.676 \n",
      "(epoch: 183, iters: 640, time: 0.071, data: 0.002) G_GAN: 0.982 G_L1: 2.682 D_real: 0.525 D_fake: 0.634 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 183, iters: 740, time: 0.074, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.741 D_fake: 0.662 \n",
      "(epoch: 183, iters: 840, time: 0.072, data: 0.002) G_GAN: 0.682 G_L1: 0.000 D_real: 0.690 D_fake: 0.692 \n",
      "(epoch: 183, iters: 940, time: 0.072, data: 0.003) G_GAN: 1.251 G_L1: 3.230 D_real: 0.557 D_fake: 0.547 \n",
      "(epoch: 183, iters: 1040, time: 0.072, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.753 D_fake: 0.658 \n",
      "(epoch: 183, iters: 1140, time: 0.072, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.725 D_fake: 0.696 \n",
      "(epoch: 183, iters: 1240, time: 0.071, data: 0.002) G_GAN: 1.353 G_L1: 2.399 D_real: 0.565 D_fake: 0.630 \n",
      "(epoch: 183, iters: 1340, time: 0.070, data: 0.002) G_GAN: 0.795 G_L1: 0.000 D_real: 0.801 D_fake: 0.654 \n",
      "(epoch: 183, iters: 1440, time: 0.072, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.743 D_fake: 0.630 \n",
      "(epoch: 183, iters: 1540, time: 0.071, data: 0.002) G_GAN: 1.141 G_L1: 1.508 D_real: 0.563 D_fake: 0.569 \n",
      "(epoch: 183, iters: 1640, time: 0.075, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.752 D_fake: 0.601 \n",
      "(epoch: 183, iters: 1740, time: 0.073, data: 0.003) G_GAN: 0.743 G_L1: 0.000 D_real: 0.753 D_fake: 0.604 \n",
      "(epoch: 183, iters: 1840, time: 0.072, data: 0.002) G_GAN: 1.151 G_L1: 0.842 D_real: 0.644 D_fake: 0.592 \n",
      "(epoch: 183, iters: 1940, time: 0.074, data: 0.003) G_GAN: 0.732 G_L1: 0.000 D_real: 0.738 D_fake: 0.614 \n",
      "(epoch: 183, iters: 2040, time: 0.073, data: 0.003) G_GAN: 0.716 G_L1: 0.000 D_real: 0.714 D_fake: 0.660 \n",
      "(epoch: 183, iters: 2140, time: 0.072, data: 0.002) G_GAN: 1.124 G_L1: 0.917 D_real: 0.666 D_fake: 0.573 \n",
      "(epoch: 183, iters: 2240, time: 0.076, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.717 D_fake: 0.683 \n",
      "End of epoch 183 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0002693\n",
      "(epoch: 184, iters: 60, time: 0.074, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.702 D_fake: 0.642 \n",
      "(epoch: 184, iters: 160, time: 0.078, data: 0.001) G_GAN: 1.027 G_L1: 2.187 D_real: 0.576 D_fake: 0.584 \n",
      "(epoch: 184, iters: 260, time: 0.075, data: 0.002) G_GAN: 0.702 G_L1: 0.000 D_real: 0.704 D_fake: 0.664 \n",
      "(epoch: 184, iters: 360, time: 0.074, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.711 D_fake: 0.681 \n",
      "(epoch: 184, iters: 460, time: 0.072, data: 0.002) G_GAN: 0.993 G_L1: 2.055 D_real: 0.564 D_fake: 0.581 \n",
      "(epoch: 184, iters: 560, time: 0.074, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.711 D_fake: 0.646 \n",
      "(epoch: 184, iters: 660, time: 0.072, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.721 D_fake: 0.630 \n",
      "(epoch: 184, iters: 760, time: 0.074, data: 0.002) G_GAN: 1.189 G_L1: 2.009 D_real: 0.567 D_fake: 0.586 \n",
      "(epoch: 184, iters: 860, time: 0.074, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.751 D_fake: 0.640 \n",
      "(epoch: 184, iters: 960, time: 0.077, data: 0.003) G_GAN: 0.734 G_L1: 0.000 D_real: 0.742 D_fake: 0.633 \n",
      "(epoch: 184, iters: 1060, time: 0.073, data: 0.002) G_GAN: 0.925 G_L1: 0.699 D_real: 0.611 D_fake: 0.628 \n",
      "(epoch: 184, iters: 1160, time: 0.076, data: 0.003) G_GAN: 0.747 G_L1: 0.000 D_real: 0.757 D_fake: 0.624 \n",
      "(epoch: 184, iters: 1260, time: 0.071, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.694 D_fake: 0.661 \n",
      "(epoch: 184, iters: 1360, time: 0.072, data: 0.001) G_GAN: 0.835 G_L1: 2.029 D_real: 0.528 D_fake: 0.655 \n",
      "(epoch: 184, iters: 1460, time: 0.074, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.754 D_fake: 0.634 \n",
      "(epoch: 184, iters: 1560, time: 0.075, data: 0.003) G_GAN: 0.717 G_L1: 0.000 D_real: 0.726 D_fake: 0.661 \n",
      "(epoch: 184, iters: 1660, time: 0.071, data: 0.002) G_GAN: 0.917 G_L1: 1.703 D_real: 0.567 D_fake: 0.581 \n",
      "(epoch: 184, iters: 1760, time: 0.074, data: 0.003) G_GAN: 0.725 G_L1: 0.000 D_real: 0.728 D_fake: 0.638 \n",
      "(epoch: 184, iters: 1860, time: 0.071, data: 0.003) G_GAN: 0.743 G_L1: 0.000 D_real: 0.752 D_fake: 0.628 \n",
      "(epoch: 184, iters: 1960, time: 0.072, data: 0.002) G_GAN: 0.902 G_L1: 2.015 D_real: 0.557 D_fake: 0.598 \n",
      "(epoch: 184, iters: 2060, time: 0.073, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.737 D_fake: 0.638 \n",
      "(epoch: 184, iters: 2160, time: 0.078, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.728 D_fake: 0.611 \n",
      "(epoch: 184, iters: 2260, time: 0.071, data: 0.002) G_GAN: 1.082 G_L1: 2.749 D_real: 0.554 D_fake: 0.554 \n",
      "End of epoch 184 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0002535\n",
      "(epoch: 185, iters: 80, time: 0.073, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.730 D_fake: 0.670 \n",
      "(epoch: 185, iters: 180, time: 0.076, data: 0.003) G_GAN: 0.741 G_L1: 0.000 D_real: 0.743 D_fake: 0.574 \n",
      "(epoch: 185, iters: 280, time: 0.075, data: 0.002) G_GAN: 1.076 G_L1: 1.026 D_real: 0.599 D_fake: 0.575 \n",
      "(epoch: 185, iters: 380, time: 0.076, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.756 D_fake: 0.666 \n",
      "(epoch: 185, iters: 480, time: 0.072, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.731 D_fake: 0.668 \n",
      "saving the latest model (epoch 185, total_steps 420000)\n",
      "(epoch: 185, iters: 580, time: 0.073, data: 0.002) G_GAN: 1.129 G_L1: 3.541 D_real: 0.528 D_fake: 0.606 \n",
      "(epoch: 185, iters: 680, time: 0.074, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.708 D_fake: 0.661 \n",
      "(epoch: 185, iters: 780, time: 0.072, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.708 D_fake: 0.672 \n",
      "(epoch: 185, iters: 880, time: 0.072, data: 0.002) G_GAN: 1.122 G_L1: 2.571 D_real: 0.533 D_fake: 0.582 \n",
      "(epoch: 185, iters: 980, time: 0.073, data: 0.003) G_GAN: 0.743 G_L1: 0.000 D_real: 0.756 D_fake: 0.623 \n",
      "(epoch: 185, iters: 1080, time: 0.071, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.699 D_fake: 0.690 \n",
      "(epoch: 185, iters: 1180, time: 0.075, data: 0.002) G_GAN: 1.054 G_L1: 2.021 D_real: 0.547 D_fake: 0.576 \n",
      "(epoch: 185, iters: 1280, time: 0.073, data: 0.003) G_GAN: 0.727 G_L1: 0.000 D_real: 0.726 D_fake: 0.668 \n",
      "(epoch: 185, iters: 1380, time: 0.073, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.722 D_fake: 0.665 \n",
      "(epoch: 185, iters: 1480, time: 0.074, data: 0.002) G_GAN: 1.217 G_L1: 1.813 D_real: 0.585 D_fake: 0.626 \n",
      "(epoch: 185, iters: 1580, time: 0.072, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.735 D_fake: 0.631 \n",
      "(epoch: 185, iters: 1680, time: 0.071, data: 0.003) G_GAN: 0.711 G_L1: 0.000 D_real: 0.717 D_fake: 0.648 \n",
      "(epoch: 185, iters: 1780, time: 0.075, data: 0.002) G_GAN: 0.884 G_L1: 2.503 D_real: 0.541 D_fake: 0.618 \n",
      "(epoch: 185, iters: 1880, time: 0.072, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.722 D_fake: 0.648 \n",
      "(epoch: 185, iters: 1980, time: 0.072, data: 0.003) G_GAN: 0.689 G_L1: 0.000 D_real: 0.695 D_fake: 0.674 \n",
      "(epoch: 185, iters: 2080, time: 0.075, data: 0.002) G_GAN: 0.956 G_L1: 2.297 D_real: 0.512 D_fake: 0.605 \n",
      "(epoch: 185, iters: 2180, time: 0.074, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.748 D_fake: 0.619 \n",
      "(epoch: 185, iters: 2280, time: 0.072, data: 0.003) G_GAN: 0.684 G_L1: 0.000 D_real: 0.690 D_fake: 0.679 \n",
      "saving the model at the end of epoch 185, iters 421800\n",
      "End of epoch 185 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0002376\n",
      "(epoch: 186, iters: 100, time: 0.073, data: 0.431) G_GAN: 1.094 G_L1: 2.485 D_real: 0.557 D_fake: 0.602 \n",
      "(epoch: 186, iters: 200, time: 0.077, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.709 D_fake: 0.677 \n",
      "(epoch: 186, iters: 300, time: 0.075, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.740 D_fake: 0.671 \n",
      "(epoch: 186, iters: 400, time: 0.079, data: 0.002) G_GAN: 1.203 G_L1: 1.437 D_real: 0.558 D_fake: 0.632 \n",
      "(epoch: 186, iters: 500, time: 0.074, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.738 D_fake: 0.595 \n",
      "(epoch: 186, iters: 600, time: 0.075, data: 0.003) G_GAN: 0.732 G_L1: 0.000 D_real: 0.739 D_fake: 0.630 \n",
      "(epoch: 186, iters: 700, time: 0.077, data: 0.002) G_GAN: 1.084 G_L1: 1.919 D_real: 0.539 D_fake: 0.581 \n",
      "(epoch: 186, iters: 800, time: 0.071, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.735 D_fake: 0.669 \n",
      "(epoch: 186, iters: 900, time: 0.070, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.712 D_fake: 0.660 \n",
      "(epoch: 186, iters: 1000, time: 0.075, data: 0.003) G_GAN: 1.060 G_L1: 1.678 D_real: 0.583 D_fake: 0.600 \n",
      "(epoch: 186, iters: 1100, time: 0.074, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.728 D_fake: 0.622 \n",
      "(epoch: 186, iters: 1200, time: 0.077, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.743 D_fake: 0.624 \n",
      "(epoch: 186, iters: 1300, time: 0.073, data: 0.002) G_GAN: 1.015 G_L1: 1.744 D_real: 0.607 D_fake: 0.558 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 186, iters: 1400, time: 0.072, data: 0.002) G_GAN: 0.778 G_L1: 0.000 D_real: 0.778 D_fake: 0.647 \n",
      "(epoch: 186, iters: 1500, time: 0.074, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.729 D_fake: 0.662 \n",
      "(epoch: 186, iters: 1600, time: 0.071, data: 0.002) G_GAN: 1.078 G_L1: 2.124 D_real: 0.548 D_fake: 0.575 \n",
      "(epoch: 186, iters: 1700, time: 0.073, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.749 D_fake: 0.625 \n",
      "(epoch: 186, iters: 1800, time: 0.075, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.728 D_fake: 0.666 \n",
      "(epoch: 186, iters: 1900, time: 0.076, data: 0.003) G_GAN: 0.921 G_L1: 3.702 D_real: 0.504 D_fake: 0.652 \n",
      "(epoch: 186, iters: 2000, time: 0.073, data: 0.003) G_GAN: 0.736 G_L1: 0.000 D_real: 0.738 D_fake: 0.642 \n",
      "(epoch: 186, iters: 2100, time: 0.074, data: 0.002) G_GAN: 0.688 G_L1: 0.000 D_real: 0.696 D_fake: 0.668 \n",
      "(epoch: 186, iters: 2200, time: 0.073, data: 0.002) G_GAN: 0.967 G_L1: 1.583 D_real: 0.580 D_fake: 0.606 \n",
      "End of epoch 186 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0002218\n",
      "(epoch: 187, iters: 20, time: 0.072, data: 0.003) G_GAN: 0.706 G_L1: 0.000 D_real: 0.704 D_fake: 0.690 \n",
      "(epoch: 187, iters: 120, time: 0.072, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.732 D_fake: 0.647 \n",
      "(epoch: 187, iters: 220, time: 0.075, data: 0.002) G_GAN: 1.135 G_L1: 2.749 D_real: 0.525 D_fake: 0.560 \n",
      "(epoch: 187, iters: 320, time: 0.073, data: 0.003) G_GAN: 0.727 G_L1: 0.000 D_real: 0.729 D_fake: 0.643 \n",
      "(epoch: 187, iters: 420, time: 0.073, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.726 D_fake: 0.669 \n",
      "(epoch: 187, iters: 520, time: 0.071, data: 0.003) G_GAN: 1.048 G_L1: 1.419 D_real: 0.595 D_fake: 0.628 \n",
      "(epoch: 187, iters: 620, time: 0.074, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.767 D_fake: 0.651 \n",
      "(epoch: 187, iters: 720, time: 0.072, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.727 D_fake: 0.623 \n",
      "(epoch: 187, iters: 820, time: 0.074, data: 0.002) G_GAN: 0.999 G_L1: 1.824 D_real: 0.568 D_fake: 0.615 \n",
      "(epoch: 187, iters: 920, time: 0.077, data: 0.003) G_GAN: 0.712 G_L1: 0.000 D_real: 0.717 D_fake: 0.627 \n",
      "saving the latest model (epoch 187, total_steps 425000)\n",
      "(epoch: 187, iters: 1020, time: 0.072, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.712 D_fake: 0.690 \n",
      "(epoch: 187, iters: 1120, time: 0.074, data: 0.002) G_GAN: 0.912 G_L1: 1.957 D_real: 0.539 D_fake: 0.621 \n",
      "(epoch: 187, iters: 1220, time: 0.076, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.736 D_fake: 0.637 \n",
      "(epoch: 187, iters: 1320, time: 0.079, data: 0.004) G_GAN: 0.729 G_L1: 0.000 D_real: 0.730 D_fake: 0.615 \n",
      "(epoch: 187, iters: 1420, time: 0.073, data: 0.002) G_GAN: 1.153 G_L1: 2.010 D_real: 0.562 D_fake: 0.596 \n",
      "(epoch: 187, iters: 1520, time: 0.072, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.727 D_fake: 0.661 \n",
      "(epoch: 187, iters: 1620, time: 0.072, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.766 D_fake: 0.615 \n",
      "(epoch: 187, iters: 1720, time: 0.073, data: 0.002) G_GAN: 1.195 G_L1: 3.150 D_real: 0.520 D_fake: 0.637 \n",
      "(epoch: 187, iters: 1820, time: 0.072, data: 0.002) G_GAN: 0.776 G_L1: 0.000 D_real: 0.784 D_fake: 0.632 \n",
      "(epoch: 187, iters: 1920, time: 0.075, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.727 D_fake: 0.623 \n",
      "(epoch: 187, iters: 2020, time: 0.072, data: 0.003) G_GAN: 1.105 G_L1: 1.672 D_real: 0.600 D_fake: 0.573 \n",
      "(epoch: 187, iters: 2120, time: 0.075, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.717 D_fake: 0.692 \n",
      "(epoch: 187, iters: 2220, time: 0.075, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.723 D_fake: 0.617 \n",
      "End of epoch 187 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0002059\n",
      "(epoch: 188, iters: 40, time: 0.072, data: 0.002) G_GAN: 1.086 G_L1: 1.820 D_real: 0.561 D_fake: 0.576 \n",
      "(epoch: 188, iters: 140, time: 0.070, data: 0.001) G_GAN: 0.724 G_L1: 0.000 D_real: 0.725 D_fake: 0.608 \n",
      "(epoch: 188, iters: 240, time: 0.073, data: 0.001) G_GAN: 0.682 G_L1: 0.000 D_real: 0.684 D_fake: 0.677 \n",
      "(epoch: 188, iters: 340, time: 0.074, data: 0.002) G_GAN: 0.880 G_L1: 1.290 D_real: 0.570 D_fake: 0.607 \n",
      "(epoch: 188, iters: 440, time: 0.071, data: 0.003) G_GAN: 0.719 G_L1: 0.000 D_real: 0.723 D_fake: 0.668 \n",
      "(epoch: 188, iters: 540, time: 0.073, data: 0.003) G_GAN: 0.695 G_L1: 0.000 D_real: 0.707 D_fake: 0.636 \n",
      "(epoch: 188, iters: 640, time: 0.075, data: 0.002) G_GAN: 0.984 G_L1: 2.682 D_real: 0.542 D_fake: 0.596 \n",
      "(epoch: 188, iters: 740, time: 0.078, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.740 D_fake: 0.626 \n",
      "(epoch: 188, iters: 840, time: 0.074, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.705 D_fake: 0.598 \n",
      "(epoch: 188, iters: 940, time: 0.075, data: 0.002) G_GAN: 1.164 G_L1: 3.230 D_real: 0.536 D_fake: 0.590 \n",
      "(epoch: 188, iters: 1040, time: 0.071, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.759 D_fake: 0.638 \n",
      "(epoch: 188, iters: 1140, time: 0.071, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.716 D_fake: 0.648 \n",
      "(epoch: 188, iters: 1240, time: 0.072, data: 0.002) G_GAN: 1.343 G_L1: 2.399 D_real: 0.540 D_fake: 0.556 \n",
      "(epoch: 188, iters: 1340, time: 0.071, data: 0.003) G_GAN: 0.807 G_L1: 0.000 D_real: 0.816 D_fake: 0.607 \n",
      "(epoch: 188, iters: 1440, time: 0.073, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.746 D_fake: 0.614 \n",
      "(epoch: 188, iters: 1540, time: 0.071, data: 0.002) G_GAN: 1.130 G_L1: 1.508 D_real: 0.567 D_fake: 0.570 \n",
      "(epoch: 188, iters: 1640, time: 0.077, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.735 D_fake: 0.660 \n",
      "(epoch: 188, iters: 1740, time: 0.074, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.741 D_fake: 0.659 \n",
      "(epoch: 188, iters: 1840, time: 0.071, data: 0.002) G_GAN: 1.140 G_L1: 0.842 D_real: 0.641 D_fake: 0.575 \n",
      "(epoch: 188, iters: 1940, time: 0.075, data: 0.004) G_GAN: 0.728 G_L1: 0.000 D_real: 0.729 D_fake: 0.647 \n",
      "(epoch: 188, iters: 2040, time: 0.073, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.726 D_fake: 0.619 \n",
      "(epoch: 188, iters: 2140, time: 0.072, data: 0.002) G_GAN: 0.964 G_L1: 0.917 D_real: 0.668 D_fake: 0.575 \n",
      "(epoch: 188, iters: 2240, time: 0.072, data: 0.001) G_GAN: 0.787 G_L1: 0.000 D_real: 0.826 D_fake: 0.581 \n",
      "End of epoch 188 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0001901\n",
      "(epoch: 189, iters: 60, time: 0.077, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.704 D_fake: 0.639 \n",
      "(epoch: 189, iters: 160, time: 0.072, data: 0.001) G_GAN: 0.971 G_L1: 2.187 D_real: 0.557 D_fake: 0.614 \n",
      "(epoch: 189, iters: 260, time: 0.073, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.734 D_fake: 0.668 \n",
      "(epoch: 189, iters: 360, time: 0.072, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.720 D_fake: 0.646 \n",
      "(epoch: 189, iters: 460, time: 0.073, data: 0.003) G_GAN: 1.026 G_L1: 2.055 D_real: 0.568 D_fake: 0.645 \n",
      "(epoch: 189, iters: 560, time: 0.074, data: 0.003) G_GAN: 0.720 G_L1: 0.000 D_real: 0.721 D_fake: 0.663 \n",
      "(epoch: 189, iters: 660, time: 0.074, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.729 D_fake: 0.627 \n",
      "(epoch: 189, iters: 760, time: 0.073, data: 0.002) G_GAN: 1.146 G_L1: 2.009 D_real: 0.567 D_fake: 0.626 \n",
      "(epoch: 189, iters: 860, time: 0.072, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.735 D_fake: 0.630 \n",
      "(epoch: 189, iters: 960, time: 0.072, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.730 D_fake: 0.663 \n",
      "(epoch: 189, iters: 1060, time: 0.072, data: 0.002) G_GAN: 0.942 G_L1: 0.699 D_real: 0.634 D_fake: 0.594 \n",
      "(epoch: 189, iters: 1160, time: 0.072, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.734 D_fake: 0.573 \n",
      "(epoch: 189, iters: 1260, time: 0.074, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.711 D_fake: 0.698 \n",
      "(epoch: 189, iters: 1360, time: 0.072, data: 0.002) G_GAN: 0.843 G_L1: 2.029 D_real: 0.537 D_fake: 0.648 \n",
      "saving the latest model (epoch 189, total_steps 430000)\n",
      "(epoch: 189, iters: 1460, time: 0.071, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.733 D_fake: 0.635 \n",
      "(epoch: 189, iters: 1560, time: 0.075, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.717 D_fake: 0.623 \n",
      "(epoch: 189, iters: 1660, time: 0.075, data: 0.002) G_GAN: 0.961 G_L1: 1.703 D_real: 0.577 D_fake: 0.585 \n",
      "(epoch: 189, iters: 1760, time: 0.073, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.730 D_fake: 0.613 \n",
      "(epoch: 189, iters: 1860, time: 0.073, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.760 D_fake: 0.656 \n",
      "(epoch: 189, iters: 1960, time: 0.072, data: 0.002) G_GAN: 0.910 G_L1: 2.015 D_real: 0.564 D_fake: 0.606 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 189, iters: 2060, time: 0.074, data: 0.003) G_GAN: 0.744 G_L1: 0.000 D_real: 0.750 D_fake: 0.631 \n",
      "(epoch: 189, iters: 2160, time: 0.072, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.725 D_fake: 0.646 \n",
      "(epoch: 189, iters: 2260, time: 0.072, data: 0.003) G_GAN: 1.085 G_L1: 2.749 D_real: 0.521 D_fake: 0.597 \n",
      "End of epoch 189 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0001743\n",
      "(epoch: 190, iters: 80, time: 0.077, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.736 D_fake: 0.605 \n",
      "(epoch: 190, iters: 180, time: 0.071, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.735 D_fake: 0.637 \n",
      "(epoch: 190, iters: 280, time: 0.075, data: 0.003) G_GAN: 1.055 G_L1: 1.026 D_real: 0.600 D_fake: 0.581 \n",
      "(epoch: 190, iters: 380, time: 0.073, data: 0.003) G_GAN: 0.761 G_L1: 0.000 D_real: 0.767 D_fake: 0.650 \n",
      "(epoch: 190, iters: 480, time: 0.072, data: 0.003) G_GAN: 0.713 G_L1: 0.000 D_real: 0.714 D_fake: 0.635 \n",
      "(epoch: 190, iters: 580, time: 0.073, data: 0.003) G_GAN: 1.149 G_L1: 3.541 D_real: 0.521 D_fake: 0.580 \n",
      "(epoch: 190, iters: 680, time: 0.074, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.720 D_fake: 0.659 \n",
      "(epoch: 190, iters: 780, time: 0.071, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.721 D_fake: 0.637 \n",
      "(epoch: 190, iters: 880, time: 0.071, data: 0.003) G_GAN: 1.104 G_L1: 2.571 D_real: 0.526 D_fake: 0.577 \n",
      "(epoch: 190, iters: 980, time: 0.075, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.773 D_fake: 0.610 \n",
      "(epoch: 190, iters: 1080, time: 0.073, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.702 D_fake: 0.660 \n",
      "(epoch: 190, iters: 1180, time: 0.073, data: 0.002) G_GAN: 1.069 G_L1: 2.021 D_real: 0.548 D_fake: 0.570 \n",
      "(epoch: 190, iters: 1280, time: 0.072, data: 0.003) G_GAN: 0.722 G_L1: 0.000 D_real: 0.723 D_fake: 0.649 \n",
      "(epoch: 190, iters: 1380, time: 0.072, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.719 D_fake: 0.659 \n",
      "(epoch: 190, iters: 1480, time: 0.071, data: 0.002) G_GAN: 1.234 G_L1: 1.813 D_real: 0.587 D_fake: 0.590 \n",
      "(epoch: 190, iters: 1580, time: 0.072, data: 0.003) G_GAN: 0.733 G_L1: 0.000 D_real: 0.732 D_fake: 0.643 \n",
      "(epoch: 190, iters: 1680, time: 0.072, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.717 D_fake: 0.634 \n",
      "(epoch: 190, iters: 1780, time: 0.073, data: 0.002) G_GAN: 0.883 G_L1: 2.503 D_real: 0.536 D_fake: 0.602 \n",
      "(epoch: 190, iters: 1880, time: 0.075, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.748 D_fake: 0.641 \n",
      "(epoch: 190, iters: 1980, time: 0.074, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.697 D_fake: 0.655 \n",
      "(epoch: 190, iters: 2080, time: 0.073, data: 0.002) G_GAN: 1.034 G_L1: 2.297 D_real: 0.527 D_fake: 0.636 \n",
      "(epoch: 190, iters: 2180, time: 0.072, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.736 D_fake: 0.634 \n",
      "(epoch: 190, iters: 2280, time: 0.074, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.693 D_fake: 0.654 \n",
      "saving the model at the end of epoch 190, iters 433200\n",
      "End of epoch 190 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0001584\n",
      "(epoch: 191, iters: 100, time: 0.073, data: 0.428) G_GAN: 1.097 G_L1: 2.485 D_real: 0.546 D_fake: 0.577 \n",
      "(epoch: 191, iters: 200, time: 0.074, data: 0.003) G_GAN: 0.712 G_L1: 0.000 D_real: 0.722 D_fake: 0.625 \n",
      "(epoch: 191, iters: 300, time: 0.072, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.748 D_fake: 0.612 \n",
      "(epoch: 191, iters: 400, time: 0.073, data: 0.002) G_GAN: 1.220 G_L1: 1.437 D_real: 0.560 D_fake: 0.651 \n",
      "(epoch: 191, iters: 500, time: 0.074, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.737 D_fake: 0.592 \n",
      "(epoch: 191, iters: 600, time: 0.071, data: 0.003) G_GAN: 0.731 G_L1: 0.000 D_real: 0.735 D_fake: 0.616 \n",
      "(epoch: 191, iters: 700, time: 0.074, data: 0.003) G_GAN: 1.096 G_L1: 1.919 D_real: 0.540 D_fake: 0.650 \n",
      "(epoch: 191, iters: 800, time: 0.073, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.729 D_fake: 0.667 \n",
      "(epoch: 191, iters: 900, time: 0.074, data: 0.003) G_GAN: 0.721 G_L1: 0.000 D_real: 0.725 D_fake: 0.702 \n",
      "(epoch: 191, iters: 1000, time: 0.075, data: 0.002) G_GAN: 1.112 G_L1: 1.678 D_real: 0.592 D_fake: 0.580 \n",
      "(epoch: 191, iters: 1100, time: 0.075, data: 0.003) G_GAN: 0.702 G_L1: 0.000 D_real: 0.714 D_fake: 0.651 \n",
      "(epoch: 191, iters: 1200, time: 0.075, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.736 D_fake: 0.649 \n",
      "(epoch: 191, iters: 1300, time: 0.074, data: 0.002) G_GAN: 1.044 G_L1: 1.744 D_real: 0.590 D_fake: 0.582 \n",
      "(epoch: 191, iters: 1400, time: 0.075, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.764 D_fake: 0.643 \n",
      "(epoch: 191, iters: 1500, time: 0.076, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.727 D_fake: 0.678 \n",
      "(epoch: 191, iters: 1600, time: 0.073, data: 0.001) G_GAN: 1.125 G_L1: 2.124 D_real: 0.552 D_fake: 0.565 \n",
      "(epoch: 191, iters: 1700, time: 0.073, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.742 D_fake: 0.623 \n",
      "(epoch: 191, iters: 1800, time: 0.073, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.735 D_fake: 0.660 \n",
      "saving the latest model (epoch 191, total_steps 435000)\n",
      "(epoch: 191, iters: 1900, time: 0.076, data: 0.002) G_GAN: 0.948 G_L1: 3.702 D_real: 0.501 D_fake: 0.594 \n",
      "(epoch: 191, iters: 2000, time: 0.071, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.741 D_fake: 0.617 \n",
      "(epoch: 191, iters: 2100, time: 0.074, data: 0.003) G_GAN: 0.719 G_L1: 0.000 D_real: 0.722 D_fake: 0.661 \n",
      "(epoch: 191, iters: 2200, time: 0.072, data: 0.002) G_GAN: 0.946 G_L1: 1.583 D_real: 0.564 D_fake: 0.619 \n",
      "End of epoch 191 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0001426\n",
      "(epoch: 192, iters: 20, time: 0.076, data: 0.003) G_GAN: 0.706 G_L1: 0.000 D_real: 0.708 D_fake: 0.650 \n",
      "(epoch: 192, iters: 120, time: 0.071, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.725 D_fake: 0.651 \n",
      "(epoch: 192, iters: 220, time: 0.072, data: 0.003) G_GAN: 1.138 G_L1: 2.749 D_real: 0.516 D_fake: 0.562 \n",
      "(epoch: 192, iters: 320, time: 0.074, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.719 D_fake: 0.678 \n",
      "(epoch: 192, iters: 420, time: 0.072, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.737 D_fake: 0.635 \n",
      "(epoch: 192, iters: 520, time: 0.071, data: 0.002) G_GAN: 1.003 G_L1: 1.419 D_real: 0.573 D_fake: 0.625 \n",
      "(epoch: 192, iters: 620, time: 0.072, data: 0.003) G_GAN: 0.764 G_L1: 0.000 D_real: 0.770 D_fake: 0.625 \n",
      "(epoch: 192, iters: 720, time: 0.073, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.714 D_fake: 0.644 \n",
      "(epoch: 192, iters: 820, time: 0.074, data: 0.002) G_GAN: 0.984 G_L1: 1.824 D_real: 0.563 D_fake: 0.600 \n",
      "(epoch: 192, iters: 920, time: 0.072, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.702 D_fake: 0.656 \n",
      "(epoch: 192, iters: 1020, time: 0.071, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.722 D_fake: 0.653 \n",
      "(epoch: 192, iters: 1120, time: 0.074, data: 0.003) G_GAN: 0.911 G_L1: 1.957 D_real: 0.544 D_fake: 0.621 \n",
      "(epoch: 192, iters: 1220, time: 0.073, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.741 D_fake: 0.672 \n",
      "(epoch: 192, iters: 1320, time: 0.072, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.726 D_fake: 0.648 \n",
      "(epoch: 192, iters: 1420, time: 0.072, data: 0.002) G_GAN: 1.134 G_L1: 2.010 D_real: 0.550 D_fake: 0.594 \n",
      "(epoch: 192, iters: 1520, time: 0.075, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.726 D_fake: 0.647 \n",
      "(epoch: 192, iters: 1620, time: 0.073, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.765 D_fake: 0.636 \n",
      "(epoch: 192, iters: 1720, time: 0.073, data: 0.002) G_GAN: 1.170 G_L1: 3.150 D_real: 0.528 D_fake: 0.569 \n",
      "(epoch: 192, iters: 1820, time: 0.072, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.757 D_fake: 0.640 \n",
      "(epoch: 192, iters: 1920, time: 0.071, data: 0.004) G_GAN: 0.728 G_L1: 0.000 D_real: 0.731 D_fake: 0.664 \n",
      "(epoch: 192, iters: 2020, time: 0.075, data: 0.002) G_GAN: 1.097 G_L1: 1.672 D_real: 0.607 D_fake: 0.596 \n",
      "(epoch: 192, iters: 2120, time: 0.076, data: 0.003) G_GAN: 0.730 G_L1: 0.000 D_real: 0.731 D_fake: 0.618 \n",
      "(epoch: 192, iters: 2220, time: 0.075, data: 0.001) G_GAN: 0.721 G_L1: 0.000 D_real: 0.723 D_fake: 0.676 \n",
      "End of epoch 192 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0001267\n",
      "(epoch: 193, iters: 40, time: 0.079, data: 0.002) G_GAN: 1.065 G_L1: 1.820 D_real: 0.553 D_fake: 0.584 \n",
      "(epoch: 193, iters: 140, time: 0.075, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.735 D_fake: 0.627 \n",
      "(epoch: 193, iters: 240, time: 0.077, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.692 D_fake: 0.662 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 193, iters: 340, time: 0.073, data: 0.002) G_GAN: 0.902 G_L1: 1.290 D_real: 0.578 D_fake: 0.606 \n",
      "(epoch: 193, iters: 440, time: 0.071, data: 0.001) G_GAN: 0.714 G_L1: 0.000 D_real: 0.715 D_fake: 0.677 \n",
      "(epoch: 193, iters: 540, time: 0.070, data: 0.001) G_GAN: 0.720 G_L1: 0.000 D_real: 0.726 D_fake: 0.645 \n",
      "(epoch: 193, iters: 640, time: 0.072, data: 0.002) G_GAN: 0.998 G_L1: 2.682 D_real: 0.538 D_fake: 0.587 \n",
      "(epoch: 193, iters: 740, time: 0.072, data: 0.001) G_GAN: 0.721 G_L1: 0.000 D_real: 0.723 D_fake: 0.659 \n",
      "(epoch: 193, iters: 840, time: 0.071, data: 0.004) G_GAN: 0.702 G_L1: 0.000 D_real: 0.706 D_fake: 0.667 \n",
      "(epoch: 193, iters: 940, time: 0.072, data: 0.003) G_GAN: 1.195 G_L1: 3.230 D_real: 0.527 D_fake: 0.592 \n",
      "(epoch: 193, iters: 1040, time: 0.072, data: 0.003) G_GAN: 0.756 G_L1: 0.000 D_real: 0.761 D_fake: 0.655 \n",
      "(epoch: 193, iters: 1140, time: 0.071, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.717 D_fake: 0.676 \n",
      "(epoch: 193, iters: 1240, time: 0.074, data: 0.002) G_GAN: 1.292 G_L1: 2.399 D_real: 0.545 D_fake: 0.597 \n",
      "(epoch: 193, iters: 1340, time: 0.074, data: 0.002) G_GAN: 0.812 G_L1: 0.000 D_real: 0.820 D_fake: 0.607 \n",
      "(epoch: 193, iters: 1440, time: 0.071, data: 0.004) G_GAN: 0.728 G_L1: 0.000 D_real: 0.730 D_fake: 0.653 \n",
      "(epoch: 193, iters: 1540, time: 0.072, data: 0.003) G_GAN: 1.160 G_L1: 1.508 D_real: 0.558 D_fake: 0.613 \n",
      "(epoch: 193, iters: 1640, time: 0.072, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.733 D_fake: 0.672 \n",
      "(epoch: 193, iters: 1740, time: 0.072, data: 0.003) G_GAN: 0.732 G_L1: 0.000 D_real: 0.735 D_fake: 0.653 \n",
      "(epoch: 193, iters: 1840, time: 0.072, data: 0.002) G_GAN: 1.171 G_L1: 0.842 D_real: 0.642 D_fake: 0.613 \n",
      "(epoch: 193, iters: 1940, time: 0.071, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.708 D_fake: 0.637 \n",
      "(epoch: 193, iters: 2040, time: 0.073, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.718 D_fake: 0.651 \n",
      "(epoch: 193, iters: 2140, time: 0.076, data: 0.002) G_GAN: 1.100 G_L1: 0.917 D_real: 0.607 D_fake: 0.619 \n",
      "(epoch: 193, iters: 2240, time: 0.075, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.731 D_fake: 0.663 \n",
      "saving the latest model (epoch 193, total_steps 440000)\n",
      "End of epoch 193 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0001109\n",
      "(epoch: 194, iters: 60, time: 0.077, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.695 D_fake: 0.637 \n",
      "(epoch: 194, iters: 160, time: 0.073, data: 0.002) G_GAN: 1.014 G_L1: 2.187 D_real: 0.564 D_fake: 0.582 \n",
      "(epoch: 194, iters: 260, time: 0.072, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.713 D_fake: 0.672 \n",
      "(epoch: 194, iters: 360, time: 0.071, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.717 D_fake: 0.691 \n",
      "(epoch: 194, iters: 460, time: 0.072, data: 0.002) G_GAN: 1.061 G_L1: 2.055 D_real: 0.557 D_fake: 0.614 \n",
      "(epoch: 194, iters: 560, time: 0.073, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.716 D_fake: 0.597 \n",
      "(epoch: 194, iters: 660, time: 0.075, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.739 D_fake: 0.637 \n",
      "(epoch: 194, iters: 760, time: 0.075, data: 0.003) G_GAN: 1.161 G_L1: 2.009 D_real: 0.558 D_fake: 0.553 \n",
      "(epoch: 194, iters: 860, time: 0.073, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.735 D_fake: 0.662 \n",
      "(epoch: 194, iters: 960, time: 0.073, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.730 D_fake: 0.668 \n",
      "(epoch: 194, iters: 1060, time: 0.073, data: 0.002) G_GAN: 1.043 G_L1: 0.699 D_real: 0.669 D_fake: 0.591 \n",
      "(epoch: 194, iters: 1160, time: 0.069, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.730 D_fake: 0.652 \n",
      "(epoch: 194, iters: 1260, time: 0.072, data: 0.002) G_GAN: 0.702 G_L1: 0.000 D_real: 0.710 D_fake: 0.679 \n",
      "(epoch: 194, iters: 1360, time: 0.072, data: 0.002) G_GAN: 0.849 G_L1: 2.029 D_real: 0.539 D_fake: 0.612 \n",
      "(epoch: 194, iters: 1460, time: 0.071, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.741 D_fake: 0.627 \n",
      "(epoch: 194, iters: 1560, time: 0.076, data: 0.003) G_GAN: 0.718 G_L1: 0.000 D_real: 0.722 D_fake: 0.640 \n",
      "(epoch: 194, iters: 1660, time: 0.074, data: 0.003) G_GAN: 0.949 G_L1: 1.703 D_real: 0.566 D_fake: 0.610 \n",
      "(epoch: 194, iters: 1760, time: 0.072, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.724 D_fake: 0.670 \n",
      "(epoch: 194, iters: 1860, time: 0.075, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.762 D_fake: 0.631 \n",
      "(epoch: 194, iters: 1960, time: 0.072, data: 0.002) G_GAN: 0.915 G_L1: 2.015 D_real: 0.556 D_fake: 0.604 \n",
      "(epoch: 194, iters: 2060, time: 0.072, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.738 D_fake: 0.642 \n",
      "(epoch: 194, iters: 2160, time: 0.072, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.724 D_fake: 0.608 \n",
      "(epoch: 194, iters: 2260, time: 0.072, data: 0.002) G_GAN: 1.065 G_L1: 2.749 D_real: 0.532 D_fake: 0.591 \n",
      "End of epoch 194 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0000950\n",
      "(epoch: 195, iters: 80, time: 0.073, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.728 D_fake: 0.681 \n",
      "(epoch: 195, iters: 180, time: 0.071, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.733 D_fake: 0.642 \n",
      "(epoch: 195, iters: 280, time: 0.072, data: 0.002) G_GAN: 1.041 G_L1: 1.026 D_real: 0.589 D_fake: 0.584 \n",
      "(epoch: 195, iters: 380, time: 0.075, data: 0.002) G_GAN: 0.762 G_L1: 0.000 D_real: 0.764 D_fake: 0.621 \n",
      "(epoch: 195, iters: 480, time: 0.072, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.717 D_fake: 0.606 \n",
      "(epoch: 195, iters: 580, time: 0.074, data: 0.002) G_GAN: 1.123 G_L1: 3.541 D_real: 0.517 D_fake: 0.612 \n",
      "(epoch: 195, iters: 680, time: 0.073, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.716 D_fake: 0.656 \n",
      "(epoch: 195, iters: 780, time: 0.072, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.720 D_fake: 0.645 \n",
      "(epoch: 195, iters: 880, time: 0.074, data: 0.003) G_GAN: 1.069 G_L1: 2.571 D_real: 0.535 D_fake: 0.620 \n",
      "(epoch: 195, iters: 980, time: 0.075, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.767 D_fake: 0.668 \n",
      "(epoch: 195, iters: 1080, time: 0.071, data: 0.003) G_GAN: 0.706 G_L1: 0.000 D_real: 0.707 D_fake: 0.681 \n",
      "(epoch: 195, iters: 1180, time: 0.072, data: 0.002) G_GAN: 1.037 G_L1: 2.021 D_real: 0.538 D_fake: 0.602 \n",
      "(epoch: 195, iters: 1280, time: 0.076, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.718 D_fake: 0.611 \n",
      "(epoch: 195, iters: 1380, time: 0.071, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.716 D_fake: 0.674 \n",
      "(epoch: 195, iters: 1480, time: 0.071, data: 0.002) G_GAN: 1.205 G_L1: 1.813 D_real: 0.581 D_fake: 0.637 \n",
      "(epoch: 195, iters: 1580, time: 0.073, data: 0.003) G_GAN: 0.729 G_L1: 0.000 D_real: 0.729 D_fake: 0.627 \n",
      "(epoch: 195, iters: 1680, time: 0.071, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.722 D_fake: 0.657 \n",
      "(epoch: 195, iters: 1780, time: 0.072, data: 0.003) G_GAN: 0.889 G_L1: 2.503 D_real: 0.530 D_fake: 0.622 \n",
      "(epoch: 195, iters: 1880, time: 0.074, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.758 D_fake: 0.665 \n",
      "(epoch: 195, iters: 1980, time: 0.073, data: 0.003) G_GAN: 0.697 G_L1: 0.000 D_real: 0.700 D_fake: 0.684 \n",
      "(epoch: 195, iters: 2080, time: 0.071, data: 0.002) G_GAN: 1.066 G_L1: 2.297 D_real: 0.537 D_fake: 0.601 \n",
      "(epoch: 195, iters: 2180, time: 0.074, data: 0.003) G_GAN: 0.738 G_L1: 0.000 D_real: 0.738 D_fake: 0.631 \n",
      "(epoch: 195, iters: 2280, time: 0.070, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.696 D_fake: 0.684 \n",
      "saving the model at the end of epoch 195, iters 444600\n",
      "End of epoch 195 / 200 \t Time Taken: 111 sec\n",
      "learning rate = 0.0000792\n",
      "(epoch: 196, iters: 100, time: 0.075, data: 0.431) G_GAN: 1.139 G_L1: 2.485 D_real: 0.551 D_fake: 0.578 \n",
      "(epoch: 196, iters: 200, time: 0.076, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.724 D_fake: 0.631 \n",
      "(epoch: 196, iters: 300, time: 0.071, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.743 D_fake: 0.623 \n",
      "(epoch: 196, iters: 400, time: 0.073, data: 0.004) G_GAN: 1.274 G_L1: 1.437 D_real: 0.567 D_fake: 0.613 \n",
      "saving the latest model (epoch 196, total_steps 445000)\n",
      "(epoch: 196, iters: 500, time: 0.073, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.726 D_fake: 0.666 \n",
      "(epoch: 196, iters: 600, time: 0.073, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.729 D_fake: 0.643 \n",
      "(epoch: 196, iters: 700, time: 0.073, data: 0.002) G_GAN: 1.098 G_L1: 1.919 D_real: 0.545 D_fake: 0.590 \n",
      "(epoch: 196, iters: 800, time: 0.074, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.718 D_fake: 0.644 \n",
      "(epoch: 196, iters: 900, time: 0.074, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.729 D_fake: 0.667 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 196, iters: 1000, time: 0.072, data: 0.002) G_GAN: 1.138 G_L1: 1.678 D_real: 0.591 D_fake: 0.593 \n",
      "(epoch: 196, iters: 1100, time: 0.076, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.716 D_fake: 0.647 \n",
      "(epoch: 196, iters: 1200, time: 0.073, data: 0.003) G_GAN: 0.732 G_L1: 0.000 D_real: 0.734 D_fake: 0.635 \n",
      "(epoch: 196, iters: 1300, time: 0.072, data: 0.002) G_GAN: 1.053 G_L1: 1.744 D_real: 0.577 D_fake: 0.573 \n",
      "(epoch: 196, iters: 1400, time: 0.072, data: 0.003) G_GAN: 0.766 G_L1: 0.000 D_real: 0.766 D_fake: 0.654 \n",
      "(epoch: 196, iters: 1500, time: 0.072, data: 0.003) G_GAN: 0.719 G_L1: 0.000 D_real: 0.724 D_fake: 0.595 \n",
      "(epoch: 196, iters: 1600, time: 0.074, data: 0.002) G_GAN: 1.115 G_L1: 2.124 D_real: 0.548 D_fake: 0.593 \n",
      "(epoch: 196, iters: 1700, time: 0.073, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.740 D_fake: 0.657 \n",
      "(epoch: 196, iters: 1800, time: 0.072, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.736 D_fake: 0.625 \n",
      "(epoch: 196, iters: 1900, time: 0.073, data: 0.002) G_GAN: 0.929 G_L1: 3.702 D_real: 0.516 D_fake: 0.566 \n",
      "(epoch: 196, iters: 2000, time: 0.075, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.737 D_fake: 0.639 \n",
      "(epoch: 196, iters: 2100, time: 0.072, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.724 D_fake: 0.646 \n",
      "(epoch: 196, iters: 2200, time: 0.071, data: 0.002) G_GAN: 0.920 G_L1: 1.583 D_real: 0.567 D_fake: 0.588 \n",
      "End of epoch 196 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0000634\n",
      "(epoch: 197, iters: 20, time: 0.072, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.722 D_fake: 0.654 \n",
      "(epoch: 197, iters: 120, time: 0.071, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.727 D_fake: 0.646 \n",
      "(epoch: 197, iters: 220, time: 0.072, data: 0.003) G_GAN: 1.132 G_L1: 2.749 D_real: 0.528 D_fake: 0.580 \n",
      "(epoch: 197, iters: 320, time: 0.075, data: 0.003) G_GAN: 0.724 G_L1: 0.000 D_real: 0.724 D_fake: 0.638 \n",
      "(epoch: 197, iters: 420, time: 0.071, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.733 D_fake: 0.629 \n",
      "(epoch: 197, iters: 520, time: 0.075, data: 0.003) G_GAN: 1.024 G_L1: 1.419 D_real: 0.565 D_fake: 0.618 \n",
      "(epoch: 197, iters: 620, time: 0.071, data: 0.003) G_GAN: 0.764 G_L1: 0.000 D_real: 0.765 D_fake: 0.635 \n",
      "(epoch: 197, iters: 720, time: 0.072, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.722 D_fake: 0.642 \n",
      "(epoch: 197, iters: 820, time: 0.072, data: 0.002) G_GAN: 1.018 G_L1: 1.824 D_real: 0.578 D_fake: 0.625 \n",
      "(epoch: 197, iters: 920, time: 0.074, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.710 D_fake: 0.652 \n",
      "(epoch: 197, iters: 1020, time: 0.071, data: 0.003) G_GAN: 0.721 G_L1: 0.000 D_real: 0.722 D_fake: 0.648 \n",
      "(epoch: 197, iters: 1120, time: 0.072, data: 0.002) G_GAN: 0.955 G_L1: 1.957 D_real: 0.558 D_fake: 0.593 \n",
      "(epoch: 197, iters: 1220, time: 0.073, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.738 D_fake: 0.635 \n",
      "(epoch: 197, iters: 1320, time: 0.071, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.721 D_fake: 0.665 \n",
      "(epoch: 197, iters: 1420, time: 0.075, data: 0.002) G_GAN: 1.153 G_L1: 2.010 D_real: 0.540 D_fake: 0.611 \n",
      "(epoch: 197, iters: 1520, time: 0.074, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.738 D_fake: 0.607 \n",
      "(epoch: 197, iters: 1620, time: 0.072, data: 0.002) G_GAN: 0.773 G_L1: 0.000 D_real: 0.777 D_fake: 0.602 \n",
      "(epoch: 197, iters: 1720, time: 0.072, data: 0.002) G_GAN: 1.205 G_L1: 3.150 D_real: 0.529 D_fake: 0.595 \n",
      "(epoch: 197, iters: 1820, time: 0.074, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.738 D_fake: 0.641 \n",
      "(epoch: 197, iters: 1920, time: 0.071, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.735 D_fake: 0.649 \n",
      "(epoch: 197, iters: 2020, time: 0.072, data: 0.002) G_GAN: 1.071 G_L1: 1.672 D_real: 0.596 D_fake: 0.565 \n",
      "(epoch: 197, iters: 2120, time: 0.072, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.737 D_fake: 0.656 \n",
      "(epoch: 197, iters: 2220, time: 0.073, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.719 D_fake: 0.671 \n",
      "End of epoch 197 / 200 \t Time Taken: 109 sec\n",
      "learning rate = 0.0000475\n",
      "(epoch: 198, iters: 40, time: 0.076, data: 0.002) G_GAN: 1.076 G_L1: 1.820 D_real: 0.562 D_fake: 0.582 \n",
      "(epoch: 198, iters: 140, time: 0.072, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.723 D_fake: 0.634 \n",
      "(epoch: 198, iters: 240, time: 0.071, data: 0.003) G_GAN: 0.703 G_L1: 0.000 D_real: 0.704 D_fake: 0.651 \n",
      "(epoch: 198, iters: 340, time: 0.075, data: 0.003) G_GAN: 0.904 G_L1: 1.290 D_real: 0.573 D_fake: 0.593 \n",
      "(epoch: 198, iters: 440, time: 0.074, data: 0.003) G_GAN: 0.718 G_L1: 0.000 D_real: 0.719 D_fake: 0.647 \n",
      "(epoch: 198, iters: 540, time: 0.074, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.714 D_fake: 0.678 \n",
      "(epoch: 198, iters: 640, time: 0.073, data: 0.002) G_GAN: 1.020 G_L1: 2.682 D_real: 0.545 D_fake: 0.580 \n",
      "(epoch: 198, iters: 740, time: 0.072, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.721 D_fake: 0.631 \n",
      "(epoch: 198, iters: 840, time: 0.071, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.710 D_fake: 0.668 \n",
      "saving the latest model (epoch 198, total_steps 450000)\n",
      "(epoch: 198, iters: 940, time: 0.071, data: 0.002) G_GAN: 1.105 G_L1: 3.230 D_real: 0.522 D_fake: 0.617 \n",
      "(epoch: 198, iters: 1040, time: 0.077, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.761 D_fake: 0.633 \n",
      "(epoch: 198, iters: 1140, time: 0.078, data: 0.003) G_GAN: 0.711 G_L1: 0.000 D_real: 0.712 D_fake: 0.603 \n",
      "(epoch: 198, iters: 1240, time: 0.072, data: 0.002) G_GAN: 1.294 G_L1: 2.399 D_real: 0.537 D_fake: 0.562 \n",
      "(epoch: 198, iters: 1340, time: 0.071, data: 0.002) G_GAN: 0.812 G_L1: 0.000 D_real: 0.815 D_fake: 0.616 \n",
      "(epoch: 198, iters: 1440, time: 0.073, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.725 D_fake: 0.669 \n",
      "(epoch: 198, iters: 1540, time: 0.074, data: 0.003) G_GAN: 1.178 G_L1: 1.508 D_real: 0.563 D_fake: 0.618 \n",
      "(epoch: 198, iters: 1640, time: 0.074, data: 0.003) G_GAN: 0.731 G_L1: 0.000 D_real: 0.731 D_fake: 0.637 \n",
      "(epoch: 198, iters: 1740, time: 0.073, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.745 D_fake: 0.664 \n",
      "(epoch: 198, iters: 1840, time: 0.074, data: 0.002) G_GAN: 1.192 G_L1: 0.842 D_real: 0.644 D_fake: 0.562 \n",
      "(epoch: 198, iters: 1940, time: 0.074, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.714 D_fake: 0.662 \n",
      "(epoch: 198, iters: 2040, time: 0.073, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.714 D_fake: 0.663 \n",
      "(epoch: 198, iters: 2140, time: 0.072, data: 0.002) G_GAN: 1.058 G_L1: 0.917 D_real: 0.597 D_fake: 0.635 \n",
      "(epoch: 198, iters: 2240, time: 0.071, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.721 D_fake: 0.644 \n",
      "End of epoch 198 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0000317\n",
      "(epoch: 199, iters: 60, time: 0.072, data: 0.001) G_GAN: 0.708 G_L1: 0.000 D_real: 0.709 D_fake: 0.673 \n",
      "(epoch: 199, iters: 160, time: 0.073, data: 0.001) G_GAN: 1.012 G_L1: 2.187 D_real: 0.565 D_fake: 0.610 \n",
      "(epoch: 199, iters: 260, time: 0.071, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.711 D_fake: 0.638 \n",
      "(epoch: 199, iters: 360, time: 0.076, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.716 D_fake: 0.643 \n",
      "(epoch: 199, iters: 460, time: 0.072, data: 0.003) G_GAN: 1.097 G_L1: 2.055 D_real: 0.552 D_fake: 0.647 \n",
      "(epoch: 199, iters: 560, time: 0.073, data: 0.003) G_GAN: 0.723 G_L1: 0.000 D_real: 0.723 D_fake: 0.673 \n",
      "(epoch: 199, iters: 660, time: 0.074, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.731 D_fake: 0.638 \n",
      "(epoch: 199, iters: 760, time: 0.076, data: 0.002) G_GAN: 1.155 G_L1: 2.009 D_real: 0.562 D_fake: 0.583 \n",
      "(epoch: 199, iters: 860, time: 0.074, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.740 D_fake: 0.677 \n",
      "(epoch: 199, iters: 960, time: 0.076, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.720 D_fake: 0.610 \n",
      "(epoch: 199, iters: 1060, time: 0.075, data: 0.002) G_GAN: 1.118 G_L1: 0.699 D_real: 0.666 D_fake: 0.619 \n",
      "(epoch: 199, iters: 1160, time: 0.073, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.725 D_fake: 0.650 \n",
      "(epoch: 199, iters: 1260, time: 0.072, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.740 D_fake: 0.672 \n",
      "(epoch: 199, iters: 1360, time: 0.073, data: 0.002) G_GAN: 0.873 G_L1: 2.029 D_real: 0.540 D_fake: 0.636 \n",
      "(epoch: 199, iters: 1460, time: 0.074, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.715 D_fake: 0.644 \n",
      "(epoch: 199, iters: 1560, time: 0.074, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.717 D_fake: 0.676 \n",
      "(epoch: 199, iters: 1660, time: 0.073, data: 0.002) G_GAN: 0.969 G_L1: 1.703 D_real: 0.571 D_fake: 0.650 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 199, iters: 1760, time: 0.071, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.725 D_fake: 0.627 \n",
      "(epoch: 199, iters: 1860, time: 0.070, data: 0.002) G_GAN: 0.776 G_L1: 0.000 D_real: 0.777 D_fake: 0.645 \n",
      "(epoch: 199, iters: 1960, time: 0.075, data: 0.003) G_GAN: 0.919 G_L1: 2.015 D_real: 0.553 D_fake: 0.598 \n",
      "(epoch: 199, iters: 2060, time: 0.072, data: 0.003) G_GAN: 0.732 G_L1: 0.000 D_real: 0.734 D_fake: 0.632 \n",
      "(epoch: 199, iters: 2160, time: 0.072, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.722 D_fake: 0.656 \n",
      "(epoch: 199, iters: 2260, time: 0.074, data: 0.002) G_GAN: 0.995 G_L1: 2.749 D_real: 0.506 D_fake: 0.604 \n",
      "End of epoch 199 / 200 \t Time Taken: 110 sec\n",
      "learning rate = 0.0000158\n",
      "(epoch: 200, iters: 80, time: 0.072, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.724 D_fake: 0.670 \n",
      "(epoch: 200, iters: 180, time: 0.072, data: 0.003) G_GAN: 0.729 G_L1: 0.000 D_real: 0.730 D_fake: 0.646 \n",
      "(epoch: 200, iters: 280, time: 0.072, data: 0.002) G_GAN: 1.037 G_L1: 1.026 D_real: 0.587 D_fake: 0.612 \n",
      "(epoch: 200, iters: 380, time: 0.072, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.755 D_fake: 0.652 \n",
      "(epoch: 200, iters: 480, time: 0.073, data: 0.001) G_GAN: 0.715 G_L1: 0.000 D_real: 0.715 D_fake: 0.651 \n",
      "(epoch: 200, iters: 580, time: 0.073, data: 0.002) G_GAN: 1.121 G_L1: 3.541 D_real: 0.513 D_fake: 0.589 \n",
      "(epoch: 200, iters: 680, time: 0.075, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.721 D_fake: 0.619 \n",
      "(epoch: 200, iters: 780, time: 0.071, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.721 D_fake: 0.651 \n",
      "(epoch: 200, iters: 880, time: 0.072, data: 0.002) G_GAN: 1.106 G_L1: 2.571 D_real: 0.535 D_fake: 0.595 \n",
      "(epoch: 200, iters: 980, time: 0.075, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.753 D_fake: 0.627 \n",
      "(epoch: 200, iters: 1080, time: 0.072, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.722 D_fake: 0.642 \n",
      "(epoch: 200, iters: 1180, time: 0.074, data: 0.002) G_GAN: 1.071 G_L1: 2.021 D_real: 0.545 D_fake: 0.582 \n",
      "(epoch: 200, iters: 1280, time: 0.075, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.723 D_fake: 0.679 \n",
      "saving the latest model (epoch 200, total_steps 455000)\n",
      "(epoch: 200, iters: 1380, time: 0.072, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.715 D_fake: 0.628 \n",
      "(epoch: 200, iters: 1480, time: 0.073, data: 0.002) G_GAN: 1.233 G_L1: 1.813 D_real: 0.581 D_fake: 0.558 \n",
      "(epoch: 200, iters: 1580, time: 0.076, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.731 D_fake: 0.644 \n",
      "(epoch: 200, iters: 1680, time: 0.075, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.721 D_fake: 0.629 \n",
      "(epoch: 200, iters: 1780, time: 0.073, data: 0.002) G_GAN: 0.883 G_L1: 2.503 D_real: 0.538 D_fake: 0.617 \n",
      "(epoch: 200, iters: 1880, time: 0.077, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.759 D_fake: 0.609 \n",
      "(epoch: 200, iters: 1980, time: 0.075, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.699 D_fake: 0.674 \n",
      "(epoch: 200, iters: 2080, time: 0.071, data: 0.002) G_GAN: 1.068 G_L1: 2.297 D_real: 0.560 D_fake: 0.600 \n",
      "(epoch: 200, iters: 2180, time: 0.075, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.734 D_fake: 0.615 \n",
      "(epoch: 200, iters: 2280, time: 0.070, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.700 D_fake: 0.639 \n",
      "saving the model at the end of epoch 200, iters 456000\n",
      "End of epoch 200 / 200 \t Time Taken: 112 sec\n",
      "learning rate = 0.0000000\n"
     ]
    }
   ],
   "source": [
    "experiments = [(4,8*0.0002)]\n",
    "for batch_size,learning_rate in experiments[::-1]:\n",
    "        new_opt = Map(opt)\n",
    "        new_opt.batchSize = batch_size\n",
    "        new_opt.lr = learning_rate\n",
    "        new_opt.name = 'prostate_cyc_batch_'+'_lr_'+str(learning_rate)+'_batch'+str(batch_size)\n",
    "        if not os.path.exists(os.path.join(new_opt.checkpoints_dir,new_opt.name)):\n",
    "            os.mkdir(os.path.join(new_opt.checkpoints_dir,new_opt.name))\n",
    "        train(new_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [(8,16*0.0002)]\n",
    "for batch_size,learning_rate in experiments[::-1]:\n",
    "        new_opt = Map(opt)\n",
    "        new_opt.batchSize = batch_size\n",
    "        new_opt.lr = learning_rate\n",
    "        new_opt.name = 'prostate_cyc_batch_'+'_lr_'+str(learning_rate)+'_batch'+str(batch_size)\n",
    "        if not os.path.exists(os.path.join(new_opt.checkpoints_dir,new_opt.name)):\n",
    "            os.mkdir(os.path.join(new_opt.checkpoints_dir,new_opt.name))\n",
    "        train(new_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 2280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "DataParallel(\n",
      "  (module): UnetGenerator(\n",
      "    (model): UnetSkipConnectionBlock(\n",
      "      (model): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): UnetSkipConnectionBlock(\n",
      "          (model): Sequential(\n",
      "            (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "            (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (3): UnetSkipConnectionBlock(\n",
      "              (model): Sequential(\n",
      "                (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (3): UnetSkipConnectionBlock(\n",
      "                  (model): Sequential(\n",
      "                    (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                    (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (3): UnetSkipConnectionBlock(\n",
      "                      (model): Sequential(\n",
      "                        (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                        (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                        (3): UnetSkipConnectionBlock(\n",
      "                          (model): Sequential(\n",
      "                            (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                            (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                            (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                            (3): UnetSkipConnectionBlock(\n",
      "                              (model): Sequential(\n",
      "                                (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                                (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                                (3): UnetSkipConnectionBlock(\n",
      "                                  (model): Sequential(\n",
      "                                    (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                                    (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                    (2): ReLU(inplace)\n",
      "                                    (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                                  )\n",
      "                                )\n",
      "                                (4): ReLU(inplace)\n",
      "                                (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                                (7): Dropout(p=0.5)\n",
      "                              )\n",
      "                            )\n",
      "                            (4): ReLU(inplace)\n",
      "                            (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                            (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                            (7): Dropout(p=0.5)\n",
      "                          )\n",
      "                        )\n",
      "                        (4): ReLU(inplace)\n",
      "                        (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                        (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                        (7): Dropout(p=0.5)\n",
      "                      )\n",
      "                    )\n",
      "                    (4): ReLU(inplace)\n",
      "                    (5): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                )\n",
      "                (4): ReLU(inplace)\n",
      "                (5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (4): ReLU(inplace)\n",
      "            (5): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): ReLU(inplace)\n",
      "        (3): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "        (4): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "DataParallel(\n",
      "  (module): NLayerDiscriminator(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (3): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (5): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (6): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (7): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (8): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "      (9): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network D] Total number of parameters : 2.767 M\n",
      "-----------------------------------------------\n",
      "(epoch: 1, iters: 100, time: 0.129, data: 0.270) G_GAN: 0.712 G_L1: 6.077 D_real: 0.615 D_fake: 0.481 \n",
      "(epoch: 1, iters: 200, time: 0.099, data: 0.001) G_GAN: 0.740 G_L1: 0.220 D_real: 0.988 D_fake: 0.494 \n",
      "(epoch: 1, iters: 300, time: 0.098, data: 0.001) G_GAN: 0.652 G_L1: 0.090 D_real: 0.647 D_fake: 0.743 \n",
      "(epoch: 1, iters: 400, time: 0.099, data: 0.001) G_GAN: 0.725 G_L1: 1.912 D_real: 0.613 D_fake: 0.681 \n",
      "(epoch: 1, iters: 500, time: 0.100, data: 0.001) G_GAN: 0.716 G_L1: 0.152 D_real: 0.718 D_fake: 0.669 \n",
      "(epoch: 1, iters: 600, time: 0.109, data: 0.001) G_GAN: 0.735 G_L1: 0.084 D_real: 0.754 D_fake: 0.637 \n",
      "(epoch: 1, iters: 700, time: 0.098, data: 0.001) G_GAN: 0.796 G_L1: 2.270 D_real: 0.661 D_fake: 0.601 \n",
      "(epoch: 1, iters: 800, time: 0.101, data: 0.001) G_GAN: 0.717 G_L1: 0.113 D_real: 0.734 D_fake: 0.656 \n",
      "(epoch: 1, iters: 900, time: 0.094, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.744 D_fake: 0.648 \n",
      "(epoch: 1, iters: 1000, time: 0.099, data: 0.001) G_GAN: 0.762 G_L1: 2.208 D_real: 0.633 D_fake: 0.610 \n",
      "(epoch: 1, iters: 1100, time: 0.097, data: 0.001) G_GAN: 0.638 G_L1: 0.071 D_real: 0.751 D_fake: 0.532 \n",
      "(epoch: 1, iters: 1200, time: 0.099, data: 0.001) G_GAN: 0.696 G_L1: 0.009 D_real: 0.698 D_fake: 0.688 \n",
      "(epoch: 1, iters: 1300, time: 0.108, data: 0.001) G_GAN: 0.760 G_L1: 3.100 D_real: 0.602 D_fake: 0.631 \n",
      "(epoch: 1, iters: 1400, time: 0.110, data: 0.002) G_GAN: 0.765 G_L1: 0.011 D_real: 0.773 D_fake: 0.620 \n",
      "(epoch: 1, iters: 1500, time: 0.098, data: 0.001) G_GAN: 0.712 G_L1: 0.002 D_real: 0.714 D_fake: 0.673 \n",
      "(epoch: 1, iters: 1600, time: 0.098, data: 0.001) G_GAN: 0.770 G_L1: 1.704 D_real: 0.643 D_fake: 0.625 \n",
      "(epoch: 1, iters: 1700, time: 0.100, data: 0.001) G_GAN: 0.768 G_L1: 0.048 D_real: 0.781 D_fake: 0.634 \n",
      "(epoch: 1, iters: 1800, time: 0.097, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.728 D_fake: 0.653 \n",
      "(epoch: 1, iters: 1900, time: 0.098, data: 0.001) G_GAN: 0.765 G_L1: 4.038 D_real: 0.601 D_fake: 0.633 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 1, iters: 2000, time: 0.098, data: 0.001) G_GAN: 0.762 G_L1: 0.002 D_real: 0.772 D_fake: 0.620 \n",
      "(epoch: 1, iters: 2100, time: 0.095, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.673 D_fake: 0.715 \n",
      "(epoch: 1, iters: 2200, time: 0.107, data: 0.001) G_GAN: 0.768 G_L1: 1.928 D_real: 0.637 D_fake: 0.631 \n",
      "End of epoch 1 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 20, time: 0.105, data: 0.000) G_GAN: 0.713 G_L1: 0.017 D_real: 0.720 D_fake: 0.668 \n",
      "(epoch: 2, iters: 120, time: 0.098, data: 0.001) G_GAN: 0.689 G_L1: 0.012 D_real: 0.683 D_fake: 0.709 \n",
      "(epoch: 2, iters: 220, time: 0.109, data: 0.002) G_GAN: 0.823 G_L1: 3.204 D_real: 0.649 D_fake: 0.574 \n",
      "(epoch: 2, iters: 320, time: 0.098, data: 0.002) G_GAN: 0.739 G_L1: 0.027 D_real: 0.752 D_fake: 0.651 \n",
      "(epoch: 2, iters: 420, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.001 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 2, iters: 520, time: 0.097, data: 0.001) G_GAN: 0.766 G_L1: 1.603 D_real: 0.634 D_fake: 0.631 \n",
      "(epoch: 2, iters: 620, time: 0.109, data: 0.001) G_GAN: 0.680 G_L1: 0.008 D_real: 0.714 D_fake: 0.650 \n",
      "(epoch: 2, iters: 720, time: 0.096, data: 0.002) G_GAN: 0.675 G_L1: 0.001 D_real: 0.675 D_fake: 0.713 \n",
      "(epoch: 2, iters: 820, time: 0.098, data: 0.001) G_GAN: 0.776 G_L1: 2.187 D_real: 0.636 D_fake: 0.613 \n",
      "(epoch: 2, iters: 920, time: 0.096, data: 0.001) G_GAN: 0.712 G_L1: 0.000 D_real: 0.716 D_fake: 0.671 \n",
      "(epoch: 2, iters: 1020, time: 0.096, data: 0.001) G_GAN: 0.630 G_L1: 0.008 D_real: 0.643 D_fake: 0.692 \n",
      "(epoch: 2, iters: 1120, time: 0.098, data: 0.001) G_GAN: 0.699 G_L1: 1.020 D_real: 0.621 D_fake: 0.765 \n",
      "(epoch: 2, iters: 1220, time: 0.096, data: 0.001) G_GAN: 0.739 G_L1: 0.001 D_real: 0.743 D_fake: 0.644 \n",
      "(epoch: 2, iters: 1320, time: 0.097, data: 0.001) G_GAN: 0.736 G_L1: 0.000 D_real: 0.735 D_fake: 0.642 \n",
      "(epoch: 2, iters: 1420, time: 0.097, data: 0.001) G_GAN: 0.729 G_L1: 2.201 D_real: 0.587 D_fake: 0.642 \n",
      "(epoch: 2, iters: 1520, time: 0.109, data: 0.001) G_GAN: 0.724 G_L1: 0.000 D_real: 0.734 D_fake: 0.661 \n",
      "(epoch: 2, iters: 1620, time: 0.095, data: 0.001) G_GAN: 0.713 G_L1: 0.000 D_real: 0.714 D_fake: 0.666 \n",
      "(epoch: 2, iters: 1720, time: 0.099, data: 0.001) G_GAN: 0.815 G_L1: 3.258 D_real: 0.627 D_fake: 0.587 \n",
      "(epoch: 2, iters: 1820, time: 0.099, data: 0.001) G_GAN: 0.733 G_L1: 0.011 D_real: 0.748 D_fake: 0.643 \n",
      "(epoch: 2, iters: 1920, time: 0.108, data: 0.001) G_GAN: 0.703 G_L1: 0.006 D_real: 0.714 D_fake: 0.690 \n",
      "(epoch: 2, iters: 2020, time: 0.104, data: 0.001) G_GAN: 0.787 G_L1: 1.906 D_real: 0.638 D_fake: 0.612 \n",
      "(epoch: 2, iters: 2120, time: 0.110, data: 0.001) G_GAN: 0.607 G_L1: 0.001 D_real: 0.952 D_fake: 0.716 \n",
      "(epoch: 2, iters: 2220, time: 0.100, data: 0.001) G_GAN: 0.718 G_L1: 0.009 D_real: 0.723 D_fake: 0.666 \n",
      "End of epoch 2 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 3, iters: 40, time: 0.121, data: 0.001) G_GAN: 0.716 G_L1: 1.546 D_real: 0.598 D_fake: 0.672 \n",
      "(epoch: 3, iters: 140, time: 0.095, data: 0.001) G_GAN: 0.756 G_L1: 0.000 D_real: 0.761 D_fake: 0.631 \n",
      "(epoch: 3, iters: 240, time: 0.098, data: 0.001) G_GAN: 0.707 G_L1: 0.000 D_real: 0.707 D_fake: 0.679 \n",
      "(epoch: 3, iters: 340, time: 0.098, data: 0.001) G_GAN: 0.739 G_L1: 0.576 D_real: 0.665 D_fake: 0.651 \n",
      "(epoch: 3, iters: 440, time: 0.109, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.746 D_fake: 0.643 \n",
      "saving the latest model (epoch 3, total_steps 5000)\n",
      "(epoch: 3, iters: 540, time: 0.096, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.714 D_fake: 0.670 \n",
      "(epoch: 3, iters: 640, time: 0.097, data: 0.001) G_GAN: 0.757 G_L1: 3.338 D_real: 0.581 D_fake: 0.640 \n",
      "(epoch: 3, iters: 740, time: 0.095, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.758 D_fake: 0.634 \n",
      "(epoch: 3, iters: 840, time: 0.095, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.695 D_fake: 0.701 \n",
      "(epoch: 3, iters: 940, time: 0.098, data: 0.001) G_GAN: 0.791 G_L1: 1.225 D_real: 0.667 D_fake: 0.608 \n",
      "(epoch: 3, iters: 1040, time: 0.095, data: 0.001) G_GAN: 0.719 G_L1: 0.000 D_real: 0.729 D_fake: 0.658 \n",
      "(epoch: 3, iters: 1140, time: 0.097, data: 0.001) G_GAN: 0.714 G_L1: 0.000 D_real: 0.714 D_fake: 0.673 \n",
      "(epoch: 3, iters: 1240, time: 0.095, data: 0.001) G_GAN: 0.808 G_L1: 2.557 D_real: 0.641 D_fake: 0.592 \n",
      "(epoch: 3, iters: 1340, time: 0.098, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.797 D_fake: 0.611 \n",
      "(epoch: 3, iters: 1440, time: 0.099, data: 0.001) G_GAN: 0.713 G_L1: 0.002 D_real: 0.715 D_fake: 0.673 \n",
      "(epoch: 3, iters: 1540, time: 0.098, data: 0.001) G_GAN: 0.744 G_L1: 1.958 D_real: 0.603 D_fake: 0.643 \n",
      "(epoch: 3, iters: 1640, time: 0.099, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.743 D_fake: 0.627 \n",
      "(epoch: 3, iters: 1740, time: 0.099, data: 0.001) G_GAN: 0.507 G_L1: 0.004 D_real: 0.393 D_fake: 1.135 \n",
      "(epoch: 3, iters: 1840, time: 0.099, data: 0.001) G_GAN: 0.749 G_L1: 0.311 D_real: 0.665 D_fake: 0.646 \n",
      "(epoch: 3, iters: 1940, time: 0.100, data: 0.001) G_GAN: 0.753 G_L1: 0.000 D_real: 0.760 D_fake: 0.631 \n",
      "(epoch: 3, iters: 2040, time: 0.098, data: 0.001) G_GAN: 0.707 G_L1: 0.002 D_real: 0.711 D_fake: 0.675 \n",
      "(epoch: 3, iters: 2140, time: 0.113, data: 0.001) G_GAN: 0.737 G_L1: 0.787 D_real: 0.635 D_fake: 0.660 \n",
      "(epoch: 3, iters: 2240, time: 0.108, data: 0.001) G_GAN: 0.725 G_L1: 0.008 D_real: 0.725 D_fake: 0.663 \n",
      "End of epoch 3 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 4, iters: 60, time: 0.109, data: 0.001) G_GAN: 0.717 G_L1: 0.003 D_real: 0.718 D_fake: 0.670 \n",
      "(epoch: 4, iters: 160, time: 0.110, data: 0.001) G_GAN: 0.752 G_L1: 2.773 D_real: 0.574 D_fake: 0.647 \n",
      "(epoch: 4, iters: 260, time: 0.100, data: 0.002) G_GAN: 0.634 G_L1: 0.021 D_real: 0.623 D_fake: 0.827 \n",
      "(epoch: 4, iters: 360, time: 0.097, data: 0.001) G_GAN: 0.709 G_L1: 0.010 D_real: 0.710 D_fake: 0.677 \n",
      "(epoch: 4, iters: 460, time: 0.098, data: 0.001) G_GAN: 0.721 G_L1: 1.874 D_real: 0.634 D_fake: 0.665 \n",
      "(epoch: 4, iters: 560, time: 0.097, data: 0.001) G_GAN: 0.725 G_L1: 0.003 D_real: 0.726 D_fake: 0.662 \n",
      "(epoch: 4, iters: 660, time: 0.099, data: 0.001) G_GAN: 0.712 G_L1: 0.001 D_real: 0.712 D_fake: 0.675 \n",
      "(epoch: 4, iters: 760, time: 0.098, data: 0.002) G_GAN: 0.665 G_L1: 0.912 D_real: 0.665 D_fake: 0.699 \n",
      "(epoch: 4, iters: 860, time: 0.101, data: 0.001) G_GAN: 0.689 G_L1: 1.556 D_real: 0.702 D_fake: 0.699 \n",
      "(epoch: 4, iters: 960, time: 0.095, data: 0.001) G_GAN: 0.725 G_L1: 0.010 D_real: 0.724 D_fake: 0.658 \n",
      "(epoch: 4, iters: 1060, time: 0.106, data: 0.001) G_GAN: 0.684 G_L1: 0.119 D_real: 0.685 D_fake: 0.701 \n",
      "(epoch: 4, iters: 1160, time: 0.095, data: 0.002) G_GAN: 0.698 G_L1: 0.312 D_real: 0.700 D_fake: 0.712 \n",
      "(epoch: 4, iters: 1260, time: 0.099, data: 0.001) G_GAN: 0.690 G_L1: 0.939 D_real: 0.704 D_fake: 0.707 \n",
      "(epoch: 4, iters: 1360, time: 0.096, data: 0.001) G_GAN: 0.701 G_L1: 4.502 D_real: 0.639 D_fake: 0.687 \n",
      "(epoch: 4, iters: 1460, time: 0.097, data: 0.001) G_GAN: 0.714 G_L1: 0.005 D_real: 0.716 D_fake: 0.672 \n",
      "(epoch: 4, iters: 1560, time: 0.096, data: 0.001) G_GAN: 0.711 G_L1: 0.001 D_real: 0.711 D_fake: 0.678 \n",
      "(epoch: 4, iters: 1660, time: 0.099, data: 0.001) G_GAN: 0.698 G_L1: 0.547 D_real: 0.701 D_fake: 0.670 \n",
      "(epoch: 4, iters: 1760, time: 0.098, data: 0.002) G_GAN: 0.695 G_L1: 0.005 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 4, iters: 1860, time: 0.096, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 4, iters: 1960, time: 0.099, data: 0.001) G_GAN: 0.702 G_L1: 0.650 D_real: 0.701 D_fake: 0.685 \n",
      "(epoch: 4, iters: 2060, time: 0.095, data: 0.001) G_GAN: 0.690 G_L1: 0.001 D_real: 0.692 D_fake: 0.691 \n",
      "(epoch: 4, iters: 2160, time: 0.099, data: 0.001) G_GAN: 0.681 G_L1: 0.000 D_real: 0.671 D_fake: 0.762 \n",
      "(epoch: 4, iters: 2260, time: 0.094, data: 0.001) G_GAN: 0.714 G_L1: 1.274 D_real: 0.705 D_fake: 0.673 \n",
      "End of epoch 4 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 5, iters: 80, time: 0.101, data: 0.001) G_GAN: 0.710 G_L1: 0.000 D_real: 0.711 D_fake: 0.676 \n",
      "(epoch: 5, iters: 180, time: 0.099, data: 0.001) G_GAN: 0.647 G_L1: 0.000 D_real: 0.663 D_fake: 0.728 \n",
      "(epoch: 5, iters: 280, time: 0.098, data: 0.001) G_GAN: 0.696 G_L1: 0.783 D_real: 0.697 D_fake: 0.691 \n",
      "(epoch: 5, iters: 380, time: 0.108, data: 0.001) G_GAN: 0.703 G_L1: 0.000 D_real: 0.703 D_fake: 0.684 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 5, iters: 480, time: 0.096, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.701 D_fake: 0.704 \n",
      "(epoch: 5, iters: 580, time: 0.102, data: 0.001) G_GAN: 0.668 G_L1: 1.060 D_real: 0.643 D_fake: 0.741 \n",
      "(epoch: 5, iters: 680, time: 0.099, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.702 D_fake: 0.685 \n",
      "(epoch: 5, iters: 780, time: 0.094, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.701 D_fake: 0.685 \n",
      "(epoch: 5, iters: 880, time: 0.093, data: 0.001) G_GAN: 0.685 G_L1: 0.634 D_real: 0.687 D_fake: 0.701 \n",
      "saving the latest model (epoch 5, total_steps 10000)\n",
      "(epoch: 5, iters: 980, time: 0.097, data: 0.002) G_GAN: 0.680 G_L1: 1.904 D_real: 0.669 D_fake: 0.728 \n",
      "(epoch: 5, iters: 1080, time: 0.097, data: 0.001) G_GAN: 0.678 G_L1: 0.000 D_real: 0.681 D_fake: 0.696 \n",
      "(epoch: 5, iters: 1180, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.424 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 5, iters: 1280, time: 0.098, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.701 D_fake: 0.686 \n",
      "(epoch: 5, iters: 1380, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.696 D_fake: 0.710 \n",
      "(epoch: 5, iters: 1480, time: 0.098, data: 0.001) G_GAN: 0.684 G_L1: 0.336 D_real: 0.688 D_fake: 0.703 \n",
      "(epoch: 5, iters: 1580, time: 0.099, data: 0.001) G_GAN: 0.699 G_L1: 0.000 D_real: 0.700 D_fake: 0.699 \n",
      "(epoch: 5, iters: 1680, time: 0.097, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.689 \n",
      "(epoch: 5, iters: 1780, time: 0.098, data: 0.001) G_GAN: 0.676 G_L1: 0.836 D_real: 0.678 D_fake: 0.686 \n",
      "(epoch: 5, iters: 1880, time: 0.097, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.701 D_fake: 0.685 \n",
      "(epoch: 5, iters: 1980, time: 0.097, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.688 \n",
      "(epoch: 5, iters: 2080, time: 0.108, data: 0.001) G_GAN: 0.684 G_L1: 0.429 D_real: 0.685 D_fake: 0.702 \n",
      "(epoch: 5, iters: 2180, time: 0.097, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.701 D_fake: 0.685 \n",
      "(epoch: 5, iters: 2280, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 5, iters 11400\n",
      "End of epoch 5 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 6, iters: 100, time: 0.105, data: 0.287) G_GAN: 0.683 G_L1: 0.854 D_real: 0.674 D_fake: 0.703 \n",
      "(epoch: 6, iters: 200, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.002 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 6, iters: 300, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 6, iters: 400, time: 0.098, data: 0.001) G_GAN: 0.696 G_L1: 0.457 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 6, iters: 500, time: 0.099, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.701 D_fake: 0.686 \n",
      "(epoch: 6, iters: 600, time: 0.099, data: 0.001) G_GAN: 0.700 G_L1: 0.028 D_real: 0.700 D_fake: 0.687 \n",
      "(epoch: 6, iters: 700, time: 0.103, data: 0.001) G_GAN: 0.706 G_L1: 0.608 D_real: 0.701 D_fake: 0.681 \n",
      "(epoch: 6, iters: 800, time: 0.098, data: 0.001) G_GAN: 0.701 G_L1: 0.029 D_real: 0.701 D_fake: 0.685 \n",
      "(epoch: 6, iters: 900, time: 0.093, data: 0.001) G_GAN: 0.668 G_L1: 0.000 D_real: 0.671 D_fake: 0.703 \n",
      "(epoch: 6, iters: 1000, time: 0.104, data: 0.001) G_GAN: 0.696 G_L1: 1.284 D_real: 0.682 D_fake: 0.696 \n",
      "(epoch: 6, iters: 1100, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 6, iters: 1200, time: 0.096, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.694 \n",
      "(epoch: 6, iters: 1300, time: 0.097, data: 0.001) G_GAN: 0.696 G_L1: 0.845 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 6, iters: 1400, time: 0.109, data: 0.001) G_GAN: 0.694 G_L1: 0.910 D_real: 0.697 D_fake: 0.692 \n",
      "(epoch: 6, iters: 1500, time: 0.099, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 6, iters: 1600, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.355 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 6, iters: 1700, time: 0.098, data: 0.001) G_GAN: 0.700 G_L1: 0.001 D_real: 0.700 D_fake: 0.704 \n",
      "(epoch: 6, iters: 1800, time: 0.107, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.689 \n",
      "(epoch: 6, iters: 1900, time: 0.098, data: 0.001) G_GAN: 0.678 G_L1: 1.181 D_real: 0.655 D_fake: 0.702 \n",
      "(epoch: 6, iters: 2000, time: 0.098, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.701 D_fake: 0.686 \n",
      "(epoch: 6, iters: 2100, time: 0.094, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 6, iters: 2200, time: 0.099, data: 0.001) G_GAN: 0.689 G_L1: 0.518 D_real: 0.678 D_fake: 0.682 \n",
      "End of epoch 6 / 200 \t Time Taken: 121 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 7, iters: 20, time: 0.106, data: 0.001) G_GAN: 0.697 G_L1: 0.011 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 7, iters: 120, time: 0.095, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.691 \n",
      "(epoch: 7, iters: 220, time: 0.097, data: 0.001) G_GAN: 0.719 G_L1: 0.659 D_real: 0.720 D_fake: 0.665 \n",
      "(epoch: 7, iters: 320, time: 0.096, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.700 D_fake: 0.687 \n",
      "(epoch: 7, iters: 420, time: 0.095, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.697 D_fake: 0.692 \n",
      "(epoch: 7, iters: 520, time: 0.094, data: 0.001) G_GAN: 0.702 G_L1: 0.575 D_real: 0.704 D_fake: 0.689 \n",
      "(epoch: 7, iters: 620, time: 0.099, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.695 \n",
      "(epoch: 7, iters: 720, time: 0.098, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.706 D_fake: 0.684 \n",
      "(epoch: 7, iters: 820, time: 0.096, data: 0.001) G_GAN: 0.684 G_L1: 0.445 D_real: 0.679 D_fake: 0.700 \n",
      "(epoch: 7, iters: 920, time: 0.096, data: 0.001) G_GAN: 0.710 G_L1: 0.000 D_real: 0.710 D_fake: 0.677 \n",
      "(epoch: 7, iters: 1020, time: 0.099, data: 0.001) G_GAN: 0.685 G_L1: 0.000 D_real: 0.685 D_fake: 0.702 \n",
      "(epoch: 7, iters: 1120, time: 0.097, data: 0.001) G_GAN: 0.685 G_L1: 0.431 D_real: 0.683 D_fake: 0.702 \n",
      "(epoch: 7, iters: 1220, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.689 \n",
      "(epoch: 7, iters: 1320, time: 0.098, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.697 \n",
      "saving the latest model (epoch 7, total_steps 15000)\n",
      "(epoch: 7, iters: 1420, time: 0.097, data: 0.001) G_GAN: 0.678 G_L1: 0.543 D_real: 0.673 D_fake: 0.710 \n",
      "(epoch: 7, iters: 1520, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 7, iters: 1620, time: 0.093, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.699 D_fake: 0.690 \n",
      "(epoch: 7, iters: 1720, time: 0.097, data: 0.001) G_GAN: 0.659 G_L1: 0.538 D_real: 0.640 D_fake: 0.759 \n",
      "(epoch: 7, iters: 1820, time: 0.098, data: 0.001) G_GAN: 0.705 G_L1: 0.000 D_real: 0.705 D_fake: 0.681 \n",
      "(epoch: 7, iters: 1920, time: 0.097, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.701 D_fake: 0.685 \n",
      "(epoch: 7, iters: 2020, time: 0.100, data: 0.001) G_GAN: 0.688 G_L1: 0.779 D_real: 0.687 D_fake: 0.699 \n",
      "(epoch: 7, iters: 2120, time: 0.099, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.641 \n",
      "(epoch: 7, iters: 2220, time: 0.099, data: 0.001) G_GAN: 0.705 G_L1: 0.000 D_real: 0.709 D_fake: 0.649 \n",
      "End of epoch 7 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 8, iters: 40, time: 0.105, data: 0.001) G_GAN: 0.701 G_L1: 0.368 D_real: 0.691 D_fake: 0.679 \n",
      "(epoch: 8, iters: 140, time: 0.100, data: 0.001) G_GAN: 0.711 G_L1: 0.000 D_real: 0.712 D_fake: 0.675 \n",
      "(epoch: 8, iters: 240, time: 0.095, data: 0.001) G_GAN: 0.712 G_L1: 0.000 D_real: 0.712 D_fake: 0.675 \n",
      "(epoch: 8, iters: 340, time: 0.097, data: 0.001) G_GAN: 0.700 G_L1: 0.576 D_real: 0.691 D_fake: 0.683 \n",
      "(epoch: 8, iters: 440, time: 0.094, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.693 \n",
      "(epoch: 8, iters: 540, time: 0.096, data: 0.001) G_GAN: 0.679 G_L1: 0.000 D_real: 0.679 D_fake: 0.708 \n",
      "(epoch: 8, iters: 640, time: 0.096, data: 0.001) G_GAN: 0.743 G_L1: 0.612 D_real: 0.742 D_fake: 0.646 \n",
      "(epoch: 8, iters: 740, time: 0.095, data: 0.001) G_GAN: 0.713 G_L1: 0.000 D_real: 0.712 D_fake: 0.652 \n",
      "(epoch: 8, iters: 840, time: 0.105, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.703 D_fake: 0.595 \n",
      "(epoch: 8, iters: 940, time: 0.100, data: 0.001) G_GAN: 0.696 G_L1: 1.155 D_real: 0.690 D_fake: 0.657 \n",
      "(epoch: 8, iters: 1040, time: 0.096, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.701 D_fake: 0.689 \n",
      "(epoch: 8, iters: 1140, time: 0.107, data: 0.001) G_GAN: 0.703 G_L1: 0.000 D_real: 0.705 D_fake: 0.682 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 8, iters: 1240, time: 0.107, data: 0.001) G_GAN: 0.705 G_L1: 0.539 D_real: 0.701 D_fake: 0.700 \n",
      "(epoch: 8, iters: 1340, time: 0.110, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.690 \n",
      "(epoch: 8, iters: 1440, time: 0.099, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.701 D_fake: 0.687 \n",
      "(epoch: 8, iters: 1540, time: 0.101, data: 0.001) G_GAN: 0.694 G_L1: 0.981 D_real: 0.682 D_fake: 0.692 \n",
      "(epoch: 8, iters: 1640, time: 0.099, data: 0.001) G_GAN: 0.702 G_L1: 0.000 D_real: 0.702 D_fake: 0.684 \n",
      "(epoch: 8, iters: 1740, time: 0.101, data: 0.001) G_GAN: 0.702 G_L1: 0.001 D_real: 0.702 D_fake: 0.683 \n",
      "(epoch: 8, iters: 1840, time: 0.111, data: 0.001) G_GAN: 0.700 G_L1: 0.194 D_real: 0.697 D_fake: 0.686 \n",
      "(epoch: 8, iters: 1940, time: 0.106, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.455 D_fake: 1.299 \n",
      "(epoch: 8, iters: 2040, time: 0.097, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.700 D_fake: 0.687 \n",
      "(epoch: 8, iters: 2140, time: 0.102, data: 0.001) G_GAN: 0.741 G_L1: 0.225 D_real: 0.732 D_fake: 0.665 \n",
      "(epoch: 8, iters: 2240, time: 0.098, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.688 D_fake: 0.698 \n",
      "End of epoch 8 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 9, iters: 60, time: 0.105, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.676 \n",
      "(epoch: 9, iters: 160, time: 0.099, data: 0.002) G_GAN: 0.678 G_L1: 0.793 D_real: 0.627 D_fake: 0.677 \n",
      "(epoch: 9, iters: 260, time: 0.097, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.763 D_fake: 0.702 \n",
      "(epoch: 9, iters: 360, time: 0.095, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.653 \n",
      "(epoch: 9, iters: 460, time: 0.099, data: 0.002) G_GAN: 0.738 G_L1: 0.880 D_real: 0.662 D_fake: 0.649 \n",
      "(epoch: 9, iters: 560, time: 0.109, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.699 D_fake: 0.684 \n",
      "(epoch: 9, iters: 660, time: 0.098, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.702 D_fake: 0.685 \n",
      "(epoch: 9, iters: 760, time: 0.097, data: 0.001) G_GAN: 0.625 G_L1: 0.679 D_real: 0.556 D_fake: 0.763 \n",
      "(epoch: 9, iters: 860, time: 0.095, data: 0.001) G_GAN: 0.674 G_L1: 1.956 D_real: 0.663 D_fake: 0.718 \n",
      "(epoch: 9, iters: 960, time: 0.094, data: 0.001) G_GAN: 0.790 G_L1: 0.000 D_real: 0.795 D_fake: 0.604 \n",
      "(epoch: 9, iters: 1060, time: 0.096, data: 0.001) G_GAN: 0.663 G_L1: 0.123 D_real: 0.658 D_fake: 0.730 \n",
      "(epoch: 9, iters: 1160, time: 0.095, data: 0.001) G_GAN: 0.688 G_L1: 1.017 D_real: 0.687 D_fake: 0.698 \n",
      "(epoch: 9, iters: 1260, time: 0.099, data: 0.001) G_GAN: 0.679 G_L1: 1.480 D_real: 0.691 D_fake: 0.710 \n",
      "(epoch: 9, iters: 1360, time: 0.098, data: 0.001) G_GAN: 0.685 G_L1: 0.794 D_real: 0.698 D_fake: 0.700 \n",
      "(epoch: 9, iters: 1460, time: 0.108, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.706 D_fake: 0.680 \n",
      "(epoch: 9, iters: 1560, time: 0.097, data: 0.001) G_GAN: 0.718 G_L1: 0.000 D_real: 0.719 D_fake: 0.669 \n",
      "(epoch: 9, iters: 1660, time: 0.096, data: 0.001) G_GAN: 0.705 G_L1: 0.585 D_real: 0.705 D_fake: 0.685 \n",
      "(epoch: 9, iters: 1760, time: 0.108, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.706 D_fake: 0.680 \n",
      "saving the latest model (epoch 9, total_steps 20000)\n",
      "(epoch: 9, iters: 1860, time: 0.099, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 9, iters: 1960, time: 0.098, data: 0.001) G_GAN: 0.701 G_L1: 0.417 D_real: 0.700 D_fake: 0.687 \n",
      "(epoch: 9, iters: 2060, time: 0.093, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.687 D_fake: 0.699 \n",
      "(epoch: 9, iters: 2160, time: 0.110, data: 0.001) G_GAN: 0.714 G_L1: 0.000 D_real: 0.715 D_fake: 0.672 \n",
      "(epoch: 9, iters: 2260, time: 0.099, data: 0.001) G_GAN: 0.682 G_L1: 0.357 D_real: 0.690 D_fake: 0.686 \n",
      "End of epoch 9 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 10, iters: 80, time: 0.103, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.697 D_fake: 0.693 \n",
      "(epoch: 10, iters: 180, time: 0.099, data: 0.001) G_GAN: 0.707 G_L1: 0.000 D_real: 0.706 D_fake: 0.669 \n",
      "(epoch: 10, iters: 280, time: 0.098, data: 0.001) G_GAN: 0.685 G_L1: 1.103 D_real: 0.681 D_fake: 0.708 \n",
      "(epoch: 10, iters: 380, time: 0.097, data: 0.001) G_GAN: 0.684 G_L1: 0.000 D_real: 0.684 D_fake: 0.703 \n",
      "(epoch: 10, iters: 480, time: 0.098, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.707 D_fake: 0.674 \n",
      "(epoch: 10, iters: 580, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.413 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 10, iters: 680, time: 0.098, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.704 D_fake: 0.679 \n",
      "(epoch: 10, iters: 780, time: 0.096, data: 0.001) G_GAN: 0.671 G_L1: 0.004 D_real: 0.675 D_fake: 0.709 \n",
      "(epoch: 10, iters: 880, time: 0.106, data: 0.001) G_GAN: 0.667 G_L1: 0.423 D_real: 0.666 D_fake: 0.722 \n",
      "(epoch: 10, iters: 980, time: 0.096, data: 0.002) G_GAN: 0.712 G_L1: 1.841 D_real: 0.715 D_fake: 0.674 \n",
      "(epoch: 10, iters: 1080, time: 0.096, data: 0.002) G_GAN: 0.675 G_L1: 0.000 D_real: 0.674 D_fake: 0.713 \n",
      "(epoch: 10, iters: 1180, time: 0.098, data: 0.001) G_GAN: 0.690 G_L1: 0.616 D_real: 0.689 D_fake: 0.696 \n",
      "(epoch: 10, iters: 1280, time: 0.096, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.700 D_fake: 0.686 \n",
      "(epoch: 10, iters: 1380, time: 0.098, data: 0.001) G_GAN: 0.690 G_L1: 0.002 D_real: 0.690 D_fake: 0.700 \n",
      "(epoch: 10, iters: 1480, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.216 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 10, iters: 1580, time: 0.099, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.702 D_fake: 0.689 \n",
      "(epoch: 10, iters: 1680, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 10, iters: 1780, time: 0.099, data: 0.001) G_GAN: 0.696 G_L1: 0.888 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 10, iters: 1880, time: 0.099, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 10, iters: 1980, time: 0.101, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 10, iters: 2080, time: 0.098, data: 0.001) G_GAN: 0.689 G_L1: 0.239 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 10, iters: 2180, time: 0.097, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.702 D_fake: 0.710 \n",
      "(epoch: 10, iters: 2280, time: 0.108, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.689 D_fake: 0.699 \n",
      "saving the model at the end of epoch 10, iters 22800\n",
      "End of epoch 10 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 11, iters: 100, time: 0.108, data: 0.286) G_GAN: 0.675 G_L1: 0.482 D_real: 0.655 D_fake: 0.719 \n",
      "(epoch: 11, iters: 200, time: 0.099, data: 0.001) G_GAN: 0.702 G_L1: 0.000 D_real: 0.702 D_fake: 0.684 \n",
      "(epoch: 11, iters: 300, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 11, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.689 G_L1: 0.512 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 11, iters: 500, time: 0.099, data: 0.001) G_GAN: 0.704 G_L1: 0.000 D_real: 0.705 D_fake: 0.713 \n",
      "(epoch: 11, iters: 600, time: 0.099, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.700 D_fake: 0.683 \n",
      "(epoch: 11, iters: 700, time: 0.098, data: 0.001) G_GAN: 0.706 G_L1: 0.519 D_real: 0.706 D_fake: 0.681 \n",
      "(epoch: 11, iters: 800, time: 0.100, data: 0.001) G_GAN: 0.705 G_L1: 0.000 D_real: 0.705 D_fake: 0.681 \n",
      "(epoch: 11, iters: 900, time: 0.093, data: 0.001) G_GAN: 0.654 G_L1: 0.002 D_real: 0.672 D_fake: 0.696 \n",
      "(epoch: 11, iters: 1000, time: 0.100, data: 0.001) G_GAN: 0.711 G_L1: 0.530 D_real: 0.685 D_fake: 0.676 \n",
      "(epoch: 11, iters: 1100, time: 0.097, data: 0.001) G_GAN: 0.678 G_L1: 0.000 D_real: 0.687 D_fake: 0.699 \n",
      "(epoch: 11, iters: 1200, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 11, iters: 1300, time: 0.099, data: 0.001) G_GAN: 0.688 G_L1: 0.695 D_real: 0.687 D_fake: 0.698 \n",
      "(epoch: 11, iters: 1400, time: 0.099, data: 0.001) G_GAN: 0.697 G_L1: 0.578 D_real: 0.701 D_fake: 0.687 \n",
      "(epoch: 11, iters: 1500, time: 0.098, data: 0.001) G_GAN: 0.699 G_L1: 0.000 D_real: 0.699 D_fake: 0.687 \n",
      "(epoch: 11, iters: 1600, time: 0.096, data: 0.001) G_GAN: 0.695 G_L1: 0.276 D_real: 0.694 D_fake: 0.688 \n",
      "(epoch: 11, iters: 1700, time: 0.101, data: 0.001) G_GAN: 0.699 G_L1: 0.000 D_real: 0.699 D_fake: 0.700 \n",
      "(epoch: 11, iters: 1800, time: 0.097, data: 0.001) G_GAN: 0.698 G_L1: 0.001 D_real: 0.698 D_fake: 0.688 \n",
      "(epoch: 11, iters: 1900, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 1.634 D_real: 0.681 D_fake: 0.692 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 11, iters: 2000, time: 0.097, data: 0.001) G_GAN: 0.699 G_L1: 0.000 D_real: 0.699 D_fake: 0.687 \n",
      "(epoch: 11, iters: 2100, time: 0.093, data: 0.001) G_GAN: 0.668 G_L1: 0.000 D_real: 0.667 D_fake: 0.720 \n",
      "(epoch: 11, iters: 2200, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.354 D_real: 0.692 D_fake: 0.693 \n",
      "saving the latest model (epoch 11, total_steps 25000)\n",
      "End of epoch 11 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 12, iters: 20, time: 0.109, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.688 \n",
      "(epoch: 12, iters: 120, time: 0.096, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.689 \n",
      "(epoch: 12, iters: 220, time: 0.098, data: 0.001) G_GAN: 0.688 G_L1: 0.523 D_real: 0.687 D_fake: 0.691 \n",
      "(epoch: 12, iters: 320, time: 0.097, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.689 \n",
      "(epoch: 12, iters: 420, time: 0.098, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 12, iters: 520, time: 0.095, data: 0.002) G_GAN: 0.694 G_L1: 0.332 D_real: 0.692 D_fake: 0.692 \n",
      "(epoch: 12, iters: 620, time: 0.100, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.690 \n",
      "(epoch: 12, iters: 720, time: 0.099, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.688 \n",
      "(epoch: 12, iters: 820, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.389 D_real: 0.693 D_fake: 0.691 \n",
      "(epoch: 12, iters: 920, time: 0.106, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.685 D_fake: 0.701 \n",
      "(epoch: 12, iters: 1020, time: 0.099, data: 0.001) G_GAN: 0.704 G_L1: 0.973 D_real: 0.706 D_fake: 0.686 \n",
      "(epoch: 12, iters: 1120, time: 0.102, data: 0.001) G_GAN: 0.704 G_L1: 0.912 D_real: 0.694 D_fake: 0.682 \n",
      "(epoch: 12, iters: 1220, time: 0.099, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.700 D_fake: 0.686 \n",
      "(epoch: 12, iters: 1320, time: 0.099, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.689 \n",
      "(epoch: 12, iters: 1420, time: 0.100, data: 0.001) G_GAN: 0.691 G_L1: 0.602 D_real: 0.686 D_fake: 0.684 \n",
      "(epoch: 12, iters: 1520, time: 0.097, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 12, iters: 1620, time: 0.106, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.700 D_fake: 0.686 \n",
      "(epoch: 12, iters: 1720, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.479 D_real: 0.679 D_fake: 0.695 \n",
      "(epoch: 12, iters: 1820, time: 0.100, data: 0.001) G_GAN: 0.703 G_L1: 0.000 D_real: 0.703 D_fake: 0.694 \n",
      "(epoch: 12, iters: 1920, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.685 \n",
      "(epoch: 12, iters: 2020, time: 0.099, data: 0.001) G_GAN: 0.681 G_L1: 0.585 D_real: 0.683 D_fake: 0.707 \n",
      "(epoch: 12, iters: 2120, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 12, iters: 2220, time: 0.097, data: 0.001) G_GAN: 0.652 G_L1: 0.000 D_real: 0.650 D_fake: 0.735 \n",
      "End of epoch 12 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 13, iters: 40, time: 0.106, data: 0.001) G_GAN: 0.685 G_L1: 0.511 D_real: 0.680 D_fake: 0.703 \n",
      "(epoch: 13, iters: 140, time: 0.096, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.701 D_fake: 0.717 \n",
      "(epoch: 13, iters: 240, time: 0.099, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 13, iters: 340, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.576 D_real: 0.690 D_fake: 0.680 \n",
      "(epoch: 13, iters: 440, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 13, iters: 540, time: 0.094, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 13, iters: 640, time: 0.097, data: 0.002) G_GAN: 0.689 G_L1: 0.283 D_real: 0.697 D_fake: 0.699 \n",
      "(epoch: 13, iters: 740, time: 0.092, data: 0.001) G_GAN: 0.704 G_L1: 0.000 D_real: 0.704 D_fake: 0.683 \n",
      "(epoch: 13, iters: 840, time: 0.106, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.689 \n",
      "(epoch: 13, iters: 940, time: 0.100, data: 0.001) G_GAN: 0.702 G_L1: 1.224 D_real: 0.699 D_fake: 0.685 \n",
      "(epoch: 13, iters: 1040, time: 0.098, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.689 \n",
      "(epoch: 13, iters: 1140, time: 0.099, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.699 \n",
      "(epoch: 13, iters: 1240, time: 0.095, data: 0.001) G_GAN: 0.696 G_L1: 0.617 D_real: 0.689 D_fake: 0.699 \n",
      "(epoch: 13, iters: 1340, time: 0.104, data: 0.001) G_GAN: 0.710 G_L1: 0.000 D_real: 0.710 D_fake: 0.677 \n",
      "(epoch: 13, iters: 1440, time: 0.100, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 13, iters: 1540, time: 0.102, data: 0.001) G_GAN: 0.696 G_L1: 1.169 D_real: 0.697 D_fake: 0.690 \n",
      "(epoch: 13, iters: 1640, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.691 D_fake: 0.698 \n",
      "(epoch: 13, iters: 1740, time: 0.109, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 13, iters: 1840, time: 0.100, data: 0.001) G_GAN: 0.686 G_L1: 0.310 D_real: 0.686 D_fake: 0.701 \n",
      "(epoch: 13, iters: 1940, time: 0.099, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 13, iters: 2040, time: 0.099, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.689 \n",
      "(epoch: 13, iters: 2140, time: 0.103, data: 0.001) G_GAN: 0.702 G_L1: 0.409 D_real: 0.704 D_fake: 0.683 \n",
      "(epoch: 13, iters: 2240, time: 0.098, data: 0.001) G_GAN: 0.681 G_L1: 0.000 D_real: 0.682 D_fake: 0.702 \n",
      "End of epoch 13 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 14, iters: 60, time: 0.106, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.688 D_fake: 0.698 \n",
      "(epoch: 14, iters: 160, time: 0.100, data: 0.001) G_GAN: 0.684 G_L1: 0.461 D_real: 0.685 D_fake: 0.693 \n",
      "(epoch: 14, iters: 260, time: 0.097, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.706 D_fake: 0.686 \n",
      "(epoch: 14, iters: 360, time: 0.095, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.696 D_fake: 0.692 \n",
      "saving the latest model (epoch 14, total_steps 30000)\n",
      "(epoch: 14, iters: 460, time: 0.108, data: 0.001) G_GAN: 0.698 G_L1: 0.517 D_real: 0.697 D_fake: 0.688 \n",
      "(epoch: 14, iters: 560, time: 0.097, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 14, iters: 660, time: 0.096, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 14, iters: 760, time: 0.109, data: 0.001) G_GAN: 0.696 G_L1: 0.649 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 14, iters: 860, time: 0.096, data: 0.001) G_GAN: 0.696 G_L1: 0.011 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 14, iters: 960, time: 0.097, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.719 D_fake: 0.667 \n",
      "(epoch: 14, iters: 1060, time: 0.094, data: 0.001) G_GAN: 0.680 G_L1: 0.314 D_real: 0.680 D_fake: 0.706 \n",
      "(epoch: 14, iters: 1160, time: 0.094, data: 0.001) G_GAN: 0.681 G_L1: 0.000 D_real: 0.681 D_fake: 0.705 \n",
      "(epoch: 14, iters: 1260, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 1.432 D_real: 0.697 D_fake: 0.693 \n",
      "(epoch: 14, iters: 1360, time: 0.099, data: 0.001) G_GAN: 0.686 G_L1: 0.770 D_real: 0.687 D_fake: 0.699 \n",
      "(epoch: 14, iters: 1460, time: 0.095, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 14, iters: 1560, time: 0.095, data: 0.001) G_GAN: 0.703 G_L1: 0.000 D_real: 0.703 D_fake: 0.684 \n",
      "(epoch: 14, iters: 1660, time: 0.097, data: 0.001) G_GAN: 0.702 G_L1: 0.570 D_real: 0.702 D_fake: 0.685 \n",
      "(epoch: 14, iters: 1760, time: 0.098, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.698 D_fake: 0.689 \n",
      "(epoch: 14, iters: 1860, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 14, iters: 1960, time: 0.097, data: 0.002) G_GAN: 0.691 G_L1: 0.417 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 14, iters: 2060, time: 0.095, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 14, iters: 2160, time: 0.097, data: 0.001) G_GAN: 0.699 G_L1: 0.000 D_real: 0.699 D_fake: 0.688 \n",
      "(epoch: 14, iters: 2260, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.573 D_real: 0.694 D_fake: 0.692 \n",
      "End of epoch 14 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 15, iters: 80, time: 0.121, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.687 \n",
      "(epoch: 15, iters: 180, time: 0.109, data: 0.001) G_GAN: 0.699 G_L1: 0.000 D_real: 0.699 D_fake: 0.687 \n",
      "(epoch: 15, iters: 280, time: 0.096, data: 0.001) G_GAN: 0.689 G_L1: 0.627 D_real: 0.689 D_fake: 0.697 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 15, iters: 380, time: 0.108, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 15, iters: 480, time: 0.109, data: 0.001) G_GAN: 0.706 G_L1: 0.000 D_real: 0.707 D_fake: 0.685 \n",
      "(epoch: 15, iters: 580, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.510 D_real: 0.691 D_fake: 0.693 \n",
      "(epoch: 15, iters: 680, time: 0.109, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 15, iters: 780, time: 0.096, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.691 D_fake: 0.697 \n",
      "(epoch: 15, iters: 880, time: 0.095, data: 0.001) G_GAN: 0.675 G_L1: 0.606 D_real: 0.675 D_fake: 0.702 \n",
      "(epoch: 15, iters: 980, time: 0.097, data: 0.001) G_GAN: 0.702 G_L1: 3.436 D_real: 0.704 D_fake: 0.682 \n",
      "(epoch: 15, iters: 1080, time: 0.096, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 15, iters: 1180, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.536 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 15, iters: 1280, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 15, iters: 1380, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 15, iters: 1480, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.413 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 15, iters: 1580, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 15, iters: 1680, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 15, iters: 1780, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.249 D_real: 0.691 D_fake: 0.692 \n",
      "(epoch: 15, iters: 1880, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 15, iters: 1980, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 15, iters: 2080, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.399 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 15, iters: 2180, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 15, iters: 2280, time: 0.108, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "saving the model at the end of epoch 15, iters 34200\n",
      "End of epoch 15 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 16, iters: 100, time: 0.108, data: 0.276) G_GAN: 0.690 G_L1: 0.367 D_real: 0.690 D_fake: 0.693 \n",
      "(epoch: 16, iters: 200, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.699 \n",
      "(epoch: 16, iters: 300, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 16, iters: 400, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.169 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 16, iters: 500, time: 0.114, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 16, iters: 600, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.695 \n",
      "(epoch: 16, iters: 700, time: 0.109, data: 0.001) G_GAN: 0.694 G_L1: 0.291 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 16, iters: 800, time: 0.099, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "saving the latest model (epoch 16, total_steps 35000)\n",
      "(epoch: 16, iters: 900, time: 0.103, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.698 \n",
      "(epoch: 16, iters: 1000, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.493 D_real: 0.691 D_fake: 0.693 \n",
      "(epoch: 16, iters: 1100, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 16, iters: 1200, time: 0.097, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.699 D_fake: 0.687 \n",
      "(epoch: 16, iters: 1300, time: 0.110, data: 0.002) G_GAN: 0.695 G_L1: 0.857 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 16, iters: 1400, time: 0.108, data: 0.001) G_GAN: 0.694 G_L1: 0.720 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 16, iters: 1500, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 16, iters: 1600, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.389 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 16, iters: 1700, time: 0.100, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 16, iters: 1800, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 16, iters: 1900, time: 0.100, data: 0.001) G_GAN: 0.688 G_L1: 0.776 D_real: 0.686 D_fake: 0.698 \n",
      "(epoch: 16, iters: 2000, time: 0.098, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 16, iters: 2100, time: 0.096, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.698 \n",
      "(epoch: 16, iters: 2200, time: 0.100, data: 0.002) G_GAN: 0.656 G_L1: 0.214 D_real: 0.669 D_fake: 0.687 \n",
      "End of epoch 16 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 17, iters: 20, time: 0.108, data: 0.001) G_GAN: 0.718 G_L1: 0.000 D_real: 0.719 D_fake: 0.656 \n",
      "(epoch: 17, iters: 120, time: 0.097, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.701 D_fake: 0.686 \n",
      "(epoch: 17, iters: 220, time: 0.110, data: 0.001) G_GAN: 0.698 G_L1: 0.422 D_real: 0.697 D_fake: 0.692 \n",
      "(epoch: 17, iters: 320, time: 0.102, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.699 \n",
      "(epoch: 17, iters: 420, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 17, iters: 520, time: 0.093, data: 0.001) G_GAN: 0.704 G_L1: 0.389 D_real: 0.704 D_fake: 0.682 \n",
      "(epoch: 17, iters: 620, time: 0.108, data: 0.001) G_GAN: 0.680 G_L1: 0.000 D_real: 0.679 D_fake: 0.707 \n",
      "(epoch: 17, iters: 720, time: 0.096, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.700 D_fake: 0.690 \n",
      "(epoch: 17, iters: 820, time: 0.094, data: 0.002) G_GAN: 0.703 G_L1: 0.405 D_real: 0.704 D_fake: 0.683 \n",
      "(epoch: 17, iters: 920, time: 0.098, data: 0.001) G_GAN: 0.648 G_L1: 0.000 D_real: 0.643 D_fake: 0.748 \n",
      "(epoch: 17, iters: 1020, time: 0.098, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.700 D_fake: 0.687 \n",
      "(epoch: 17, iters: 1120, time: 0.097, data: 0.001) G_GAN: 0.704 G_L1: 0.939 D_real: 0.703 D_fake: 0.679 \n",
      "(epoch: 17, iters: 1220, time: 0.095, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.689 \n",
      "(epoch: 17, iters: 1320, time: 0.108, data: 0.001) G_GAN: 0.681 G_L1: 0.000 D_real: 0.681 D_fake: 0.713 \n",
      "(epoch: 17, iters: 1420, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.531 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 17, iters: 1520, time: 0.097, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.689 \n",
      "(epoch: 17, iters: 1620, time: 0.093, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.689 D_fake: 0.691 \n",
      "(epoch: 17, iters: 1720, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.568 D_real: 0.693 D_fake: 0.690 \n",
      "(epoch: 17, iters: 1820, time: 0.112, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 17, iters: 1920, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 17, iters: 2020, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.745 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 17, iters: 2120, time: 0.111, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 17, iters: 2220, time: 0.111, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
      "End of epoch 17 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 18, iters: 40, time: 0.104, data: 0.001) G_GAN: 0.692 G_L1: 0.260 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 18, iters: 140, time: 0.096, data: 0.002) G_GAN: 0.699 G_L1: 0.043 D_real: 0.699 D_fake: 0.687 \n",
      "(epoch: 18, iters: 240, time: 0.097, data: 0.001) G_GAN: 0.703 G_L1: 0.000 D_real: 0.703 D_fake: 0.683 \n",
      "(epoch: 18, iters: 340, time: 0.095, data: 0.001) G_GAN: 0.698 G_L1: 0.576 D_real: 0.697 D_fake: 0.688 \n",
      "(epoch: 18, iters: 440, time: 0.097, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.692 \n",
      "(epoch: 18, iters: 540, time: 0.093, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 18, iters: 640, time: 0.095, data: 0.001) G_GAN: 0.691 G_L1: 0.600 D_real: 0.692 D_fake: 0.692 \n",
      "(epoch: 18, iters: 740, time: 0.094, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 18, iters: 840, time: 0.106, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 18, iters: 940, time: 0.101, data: 0.001) G_GAN: 0.705 G_L1: 1.225 D_real: 0.704 D_fake: 0.682 \n",
      "(epoch: 18, iters: 1040, time: 0.107, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.689 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 18, iters: 1140, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 18, iters: 1240, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.783 D_real: 0.694 D_fake: 0.692 \n",
      "saving the latest model (epoch 18, total_steps 40000)\n",
      "(epoch: 18, iters: 1340, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 18, iters: 1440, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 18, iters: 1540, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.900 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 18, iters: 1640, time: 0.096, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 18, iters: 1740, time: 0.110, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 18, iters: 1840, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.335 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 18, iters: 1940, time: 0.101, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 18, iters: 2040, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 18, iters: 2140, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.482 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 18, iters: 2240, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "End of epoch 18 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 19, iters: 60, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 19, iters: 160, time: 0.098, data: 0.001) G_GAN: 0.690 G_L1: 0.552 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 19, iters: 260, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 19, iters: 360, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 19, iters: 460, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.502 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 19, iters: 560, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 19, iters: 660, time: 0.107, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.695 \n",
      "(epoch: 19, iters: 760, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.598 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 19, iters: 860, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 19, iters: 960, time: 0.094, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.688 \n",
      "(epoch: 19, iters: 1060, time: 0.095, data: 0.001) G_GAN: 0.700 G_L1: 0.122 D_real: 0.699 D_fake: 0.687 \n",
      "(epoch: 19, iters: 1160, time: 0.095, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.696 D_fake: 0.692 \n",
      "(epoch: 19, iters: 1260, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.813 D_real: 0.694 D_fake: 0.691 \n",
      "(epoch: 19, iters: 1360, time: 0.096, data: 0.001) G_GAN: 0.695 G_L1: 0.641 D_real: 0.694 D_fake: 0.689 \n",
      "(epoch: 19, iters: 1460, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 19, iters: 1560, time: 0.095, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 19, iters: 1660, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.391 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 19, iters: 1760, time: 0.097, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 19, iters: 1860, time: 0.111, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 19, iters: 1960, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.365 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 19, iters: 2060, time: 0.096, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 19, iters: 2160, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 19, iters: 2260, time: 0.096, data: 0.001) G_GAN: 0.701 G_L1: 0.457 D_real: 0.704 D_fake: 0.684 \n",
      "End of epoch 19 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 20, iters: 80, time: 0.102, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.693 D_fake: 0.688 \n",
      "(epoch: 20, iters: 180, time: 0.100, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.694 D_fake: 0.705 \n",
      "(epoch: 20, iters: 280, time: 0.096, data: 0.002) G_GAN: 0.689 G_L1: 0.586 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 20, iters: 380, time: 0.099, data: 0.001) G_GAN: 0.724 G_L1: 0.000 D_real: 0.733 D_fake: 0.663 \n",
      "(epoch: 20, iters: 480, time: 0.097, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.703 D_fake: 0.683 \n",
      "(epoch: 20, iters: 580, time: 0.098, data: 0.002) G_GAN: 0.704 G_L1: 0.574 D_real: 0.706 D_fake: 0.680 \n",
      "(epoch: 20, iters: 680, time: 0.099, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.702 D_fake: 0.687 \n",
      "(epoch: 20, iters: 780, time: 0.094, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.687 \n",
      "(epoch: 20, iters: 880, time: 0.093, data: 0.002) G_GAN: 0.694 G_L1: 0.263 D_real: 0.695 D_fake: 0.688 \n",
      "(epoch: 20, iters: 980, time: 0.097, data: 0.001) G_GAN: 0.691 G_L1: 2.436 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 20, iters: 1080, time: 0.105, data: 0.001) G_GAN: 0.677 G_L1: 0.000 D_real: 0.676 D_fake: 0.710 \n",
      "(epoch: 20, iters: 1180, time: 0.098, data: 0.002) G_GAN: 0.704 G_L1: 0.565 D_real: 0.703 D_fake: 0.683 \n",
      "(epoch: 20, iters: 1280, time: 0.099, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.698 D_fake: 0.689 \n",
      "(epoch: 20, iters: 1380, time: 0.095, data: 0.002) G_GAN: 0.695 G_L1: 0.004 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 20, iters: 1480, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.517 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 20, iters: 1580, time: 0.099, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 20, iters: 1680, time: 0.104, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.697 D_fake: 0.689 \n",
      "saving the latest model (epoch 20, total_steps 45000)\n",
      "(epoch: 20, iters: 1780, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.352 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 20, iters: 1880, time: 0.100, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.687 D_fake: 0.700 \n",
      "(epoch: 20, iters: 1980, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.692 D_fake: 0.696 \n",
      "(epoch: 20, iters: 2080, time: 0.098, data: 0.001) G_GAN: 0.698 G_L1: 0.267 D_real: 0.698 D_fake: 0.688 \n",
      "(epoch: 20, iters: 2180, time: 0.096, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.692 \n",
      "(epoch: 20, iters: 2280, time: 0.096, data: 0.001) G_GAN: 0.664 G_L1: 0.000 D_real: 0.674 D_fake: 0.696 \n",
      "saving the model at the end of epoch 20, iters 45600\n",
      "End of epoch 20 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 21, iters: 100, time: 0.110, data: 0.284) G_GAN: 0.696 G_L1: 0.270 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 21, iters: 200, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 21, iters: 300, time: 0.108, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.693 \n",
      "(epoch: 21, iters: 400, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.384 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 21, iters: 500, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 21, iters: 600, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.696 \n",
      "(epoch: 21, iters: 700, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.409 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 21, iters: 800, time: 0.110, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 21, iters: 900, time: 0.095, data: 0.002) G_GAN: 0.678 G_L1: 0.000 D_real: 0.680 D_fake: 0.709 \n",
      "(epoch: 21, iters: 1000, time: 0.112, data: 0.001) G_GAN: 0.711 G_L1: 0.783 D_real: 0.711 D_fake: 0.683 \n",
      "(epoch: 21, iters: 1100, time: 0.107, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 21, iters: 1200, time: 0.096, data: 0.002) G_GAN: 0.684 G_L1: 0.000 D_real: 0.687 D_fake: 0.707 \n",
      "(epoch: 21, iters: 1300, time: 0.096, data: 0.001) G_GAN: 0.748 G_L1: 0.839 D_real: 0.675 D_fake: 0.521 \n",
      "(epoch: 21, iters: 1400, time: 0.099, data: 0.001) G_GAN: 0.676 G_L1: 0.125 D_real: 0.676 D_fake: 0.712 \n",
      "(epoch: 21, iters: 1500, time: 0.096, data: 0.001) G_GAN: 0.675 G_L1: 0.000 D_real: 0.673 D_fake: 0.713 \n",
      "(epoch: 21, iters: 1600, time: 0.099, data: 0.001) G_GAN: 0.682 G_L1: 0.224 D_real: 0.682 D_fake: 0.705 \n",
      "(epoch: 21, iters: 1700, time: 0.100, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.698 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 21, iters: 1800, time: 0.095, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.688 D_fake: 0.699 \n",
      "(epoch: 21, iters: 1900, time: 0.100, data: 0.002) G_GAN: 0.680 G_L1: 0.500 D_real: 0.682 D_fake: 0.669 \n",
      "(epoch: 21, iters: 2000, time: 0.098, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.700 D_fake: 0.686 \n",
      "(epoch: 21, iters: 2100, time: 0.095, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.688 D_fake: 0.698 \n",
      "(epoch: 21, iters: 2200, time: 0.100, data: 0.001) G_GAN: 0.688 G_L1: 0.412 D_real: 0.688 D_fake: 0.695 \n",
      "End of epoch 21 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 22, iters: 20, time: 0.106, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.692 \n",
      "(epoch: 22, iters: 120, time: 0.099, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 22, iters: 220, time: 0.099, data: 0.001) G_GAN: 0.695 G_L1: 0.669 D_real: 0.695 D_fake: 0.690 \n",
      "(epoch: 22, iters: 320, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.691 \n",
      "(epoch: 22, iters: 420, time: 0.097, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 22, iters: 520, time: 0.106, data: 0.001) G_GAN: 0.700 G_L1: 0.543 D_real: 0.701 D_fake: 0.694 \n",
      "(epoch: 22, iters: 620, time: 0.096, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.685 \n",
      "(epoch: 22, iters: 720, time: 0.097, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.702 D_fake: 0.700 \n",
      "(epoch: 22, iters: 820, time: 0.096, data: 0.002) G_GAN: 0.691 G_L1: 0.352 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 22, iters: 920, time: 0.096, data: 0.001) G_GAN: 0.663 G_L1: 0.000 D_real: 0.666 D_fake: 0.707 \n",
      "(epoch: 22, iters: 1020, time: 0.097, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.692 \n",
      "(epoch: 22, iters: 1120, time: 0.100, data: 0.001) G_GAN: 0.692 G_L1: 0.771 D_real: 0.692 D_fake: 0.696 \n",
      "(epoch: 22, iters: 1220, time: 0.098, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.700 D_fake: 0.688 \n",
      "(epoch: 22, iters: 1320, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 22, iters: 1420, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.391 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 22, iters: 1520, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 22, iters: 1620, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 22, iters: 1720, time: 0.108, data: 0.001) G_GAN: 0.692 G_L1: 0.476 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 22, iters: 1820, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 22, iters: 1920, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 22, iters: 2020, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.350 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 22, iters: 2120, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 22, total_steps 50000)\n",
      "(epoch: 22, iters: 2220, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 22 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 23, iters: 40, time: 0.124, data: 0.001) G_GAN: 0.694 G_L1: 0.362 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 23, iters: 140, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.695 D_fake: 0.693 \n",
      "(epoch: 23, iters: 240, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 23, iters: 340, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 23, iters: 440, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 23, iters: 540, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 23, iters: 640, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.543 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 23, iters: 740, time: 0.095, data: 0.001) G_GAN: 0.695 G_L1: 0.001 D_real: 0.695 D_fake: 0.694 \n",
      "(epoch: 23, iters: 840, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 23, iters: 940, time: 0.098, data: 0.002) G_GAN: 0.695 G_L1: 1.028 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 23, iters: 1040, time: 0.092, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 23, iters: 1140, time: 0.097, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.701 D_fake: 0.686 \n",
      "(epoch: 23, iters: 1240, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.624 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 23, iters: 1340, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 23, iters: 1440, time: 0.109, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 23, iters: 1540, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.616 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 23, iters: 1640, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 23, iters: 1740, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 23, iters: 1840, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.308 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 23, iters: 1940, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 23, iters: 2040, time: 0.101, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 23, iters: 2140, time: 0.097, data: 0.001) G_GAN: 0.696 G_L1: 0.171 D_real: 0.696 D_fake: 0.696 \n",
      "(epoch: 23, iters: 2240, time: 0.098, data: 0.001) G_GAN: 0.674 G_L1: 0.000 D_real: 0.677 D_fake: 0.710 \n",
      "End of epoch 23 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 24, iters: 60, time: 0.105, data: 0.002) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.698 \n",
      "(epoch: 24, iters: 160, time: 0.101, data: 0.001) G_GAN: 0.692 G_L1: 0.670 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 24, iters: 260, time: 0.100, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.688 \n",
      "(epoch: 24, iters: 360, time: 0.098, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.689 D_fake: 0.696 \n",
      "(epoch: 24, iters: 460, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.323 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 24, iters: 560, time: 0.098, data: 0.001) G_GAN: 0.686 G_L1: 0.000 D_real: 0.686 D_fake: 0.701 \n",
      "(epoch: 24, iters: 660, time: 0.103, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 24, iters: 760, time: 0.100, data: 0.001) G_GAN: 0.690 G_L1: 0.486 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 24, iters: 860, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 2.415 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 24, iters: 960, time: 0.095, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 24, iters: 1060, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.087 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 24, iters: 1160, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 1.292 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 24, iters: 1260, time: 0.098, data: 0.001) G_GAN: 0.688 G_L1: 0.438 D_real: 0.689 D_fake: 0.698 \n",
      "(epoch: 24, iters: 1360, time: 0.111, data: 0.001) G_GAN: 0.665 G_L1: 0.767 D_real: 0.671 D_fake: 0.687 \n",
      "(epoch: 24, iters: 1460, time: 0.098, data: 0.001) G_GAN: 0.696 G_L1: 0.103 D_real: 0.697 D_fake: 0.686 \n",
      "(epoch: 24, iters: 1560, time: 0.095, data: 0.001) G_GAN: 0.702 G_L1: 0.000 D_real: 0.702 D_fake: 0.684 \n",
      "(epoch: 24, iters: 1660, time: 0.097, data: 0.001) G_GAN: 0.697 G_L1: 0.422 D_real: 0.697 D_fake: 0.689 \n",
      "(epoch: 24, iters: 1760, time: 0.097, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 24, iters: 1860, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.691 \n",
      "(epoch: 24, iters: 1960, time: 0.098, data: 0.001) G_GAN: 0.688 G_L1: 0.382 D_real: 0.688 D_fake: 0.698 \n",
      "(epoch: 24, iters: 2060, time: 0.094, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 24, iters: 2160, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.713 D_fake: 0.711 \n",
      "(epoch: 24, iters: 2260, time: 0.094, data: 0.001) G_GAN: 0.694 G_L1: 0.517 D_real: 0.695 D_fake: 0.689 \n",
      "End of epoch 24 / 200 \t Time Taken: 121 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 25, iters: 80, time: 0.111, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.699 D_fake: 0.693 \n",
      "(epoch: 25, iters: 180, time: 0.096, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.681 D_fake: 0.705 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 25, iters: 280, time: 0.101, data: 0.001) G_GAN: 0.694 G_L1: 0.312 D_real: 0.694 D_fake: 0.692 \n",
      "saving the latest model (epoch 25, total_steps 55000)\n",
      "(epoch: 25, iters: 380, time: 0.100, data: 0.001) G_GAN: 0.712 G_L1: 0.000 D_real: 0.712 D_fake: 0.675 \n",
      "(epoch: 25, iters: 480, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.690 \n",
      "(epoch: 25, iters: 580, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.546 D_real: 0.693 D_fake: 0.688 \n",
      "(epoch: 25, iters: 680, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.696 \n",
      "(epoch: 25, iters: 780, time: 0.096, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.698 D_fake: 0.693 \n",
      "(epoch: 25, iters: 880, time: 0.096, data: 0.001) G_GAN: 0.683 G_L1: 0.473 D_real: 0.684 D_fake: 0.696 \n",
      "(epoch: 25, iters: 980, time: 0.096, data: 0.001) G_GAN: 0.691 G_L1: 1.699 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 25, iters: 1080, time: 0.095, data: 0.001) G_GAN: 0.664 G_L1: 0.000 D_real: 0.663 D_fake: 0.725 \n",
      "(epoch: 25, iters: 1180, time: 0.097, data: 0.001) G_GAN: 0.691 G_L1: 0.717 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 25, iters: 1280, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 25, iters: 1380, time: 0.097, data: 0.001) G_GAN: 0.683 G_L1: 0.000 D_real: 0.685 D_fake: 0.709 \n",
      "(epoch: 25, iters: 1480, time: 0.098, data: 0.001) G_GAN: 0.681 G_L1: 0.613 D_real: 0.681 D_fake: 0.706 \n",
      "(epoch: 25, iters: 1580, time: 0.100, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.690 \n",
      "(epoch: 25, iters: 1680, time: 0.111, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.700 D_fake: 0.687 \n",
      "(epoch: 25, iters: 1780, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.382 D_real: 0.692 D_fake: 0.691 \n",
      "(epoch: 25, iters: 1880, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.699 \n",
      "(epoch: 25, iters: 1980, time: 0.109, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.696 \n",
      "(epoch: 25, iters: 2080, time: 0.096, data: 0.001) G_GAN: 0.689 G_L1: 0.333 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 25, iters: 2180, time: 0.096, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.741 D_fake: 0.649 \n",
      "(epoch: 25, iters: 2280, time: 0.111, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.706 \n",
      "saving the model at the end of epoch 25, iters 57000\n",
      "End of epoch 25 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 26, iters: 100, time: 0.107, data: 0.284) G_GAN: 0.698 G_L1: 0.272 D_real: 0.700 D_fake: 0.700 \n",
      "(epoch: 26, iters: 200, time: 0.095, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 26, iters: 300, time: 0.097, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.685 D_fake: 0.699 \n",
      "(epoch: 26, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.688 G_L1: 0.305 D_real: 0.687 D_fake: 0.699 \n",
      "(epoch: 26, iters: 500, time: 0.097, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.691 D_fake: 0.700 \n",
      "(epoch: 26, iters: 600, time: 0.098, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.699 \n",
      "(epoch: 26, iters: 700, time: 0.097, data: 0.001) G_GAN: 0.690 G_L1: 0.227 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 26, iters: 800, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.695 \n",
      "(epoch: 26, iters: 900, time: 0.104, data: 0.001) G_GAN: 0.699 G_L1: 0.000 D_real: 0.699 D_fake: 0.687 \n",
      "(epoch: 26, iters: 1000, time: 0.099, data: 0.001) G_GAN: 0.714 G_L1: 0.419 D_real: 0.713 D_fake: 0.673 \n",
      "(epoch: 26, iters: 1100, time: 0.100, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.698 D_fake: 0.703 \n",
      "(epoch: 26, iters: 1200, time: 0.101, data: 0.001) G_GAN: 0.684 G_L1: 0.000 D_real: 0.684 D_fake: 0.692 \n",
      "(epoch: 26, iters: 1300, time: 0.097, data: 0.001) G_GAN: 0.687 G_L1: 0.746 D_real: 0.687 D_fake: 0.697 \n",
      "(epoch: 26, iters: 1400, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.541 D_real: 0.696 D_fake: 0.696 \n",
      "(epoch: 26, iters: 1500, time: 0.099, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.698 \n",
      "(epoch: 26, iters: 1600, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.215 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 26, iters: 1700, time: 0.112, data: 0.001) G_GAN: 0.694 G_L1: 0.008 D_real: 0.695 D_fake: 0.694 \n",
      "(epoch: 26, iters: 1800, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 26, iters: 1900, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.492 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 26, iters: 2000, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 26, iters: 2100, time: 0.095, data: 0.001) G_GAN: 0.681 G_L1: 0.000 D_real: 0.680 D_fake: 0.706 \n",
      "(epoch: 26, iters: 2200, time: 0.098, data: 0.001) G_GAN: 0.727 G_L1: 0.241 D_real: 0.718 D_fake: 0.655 \n",
      "End of epoch 26 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 27, iters: 20, time: 0.117, data: 0.002) G_GAN: 0.678 G_L1: 0.000 D_real: 0.678 D_fake: 0.708 \n",
      "(epoch: 27, iters: 120, time: 0.098, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.703 \n",
      "(epoch: 27, iters: 220, time: 0.099, data: 0.001) G_GAN: 0.690 G_L1: 0.510 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 27, iters: 320, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 27, iters: 420, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 27, iters: 520, time: 0.105, data: 0.001) G_GAN: 0.689 G_L1: 0.383 D_real: 0.689 D_fake: 0.692 \n",
      "(epoch: 27, iters: 620, time: 0.097, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 27, iters: 720, time: 0.099, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "saving the latest model (epoch 27, total_steps 60000)\n",
      "(epoch: 27, iters: 820, time: 0.096, data: 0.001) G_GAN: 0.691 G_L1: 0.396 D_real: 0.691 D_fake: 0.692 \n",
      "(epoch: 27, iters: 920, time: 0.095, data: 0.001) G_GAN: 0.662 G_L1: 0.000 D_real: 0.666 D_fake: 0.714 \n",
      "(epoch: 27, iters: 1020, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 27, iters: 1120, time: 0.097, data: 0.001) G_GAN: 0.666 G_L1: 0.295 D_real: 0.665 D_fake: 0.722 \n",
      "(epoch: 27, iters: 1220, time: 0.109, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.699 \n",
      "(epoch: 27, iters: 1320, time: 0.099, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.687 \n",
      "(epoch: 27, iters: 1420, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.394 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 27, iters: 1520, time: 0.097, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.689 \n",
      "(epoch: 27, iters: 1620, time: 0.094, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 27, iters: 1720, time: 0.099, data: 0.001) G_GAN: 0.690 G_L1: 0.511 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 27, iters: 1820, time: 0.098, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.689 \n",
      "(epoch: 27, iters: 1920, time: 0.099, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 27, iters: 2020, time: 0.107, data: 0.002) G_GAN: 0.695 G_L1: 0.394 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 27, iters: 2120, time: 0.097, data: 0.001) G_GAN: 0.708 G_L1: 0.000 D_real: 0.709 D_fake: 0.689 \n",
      "(epoch: 27, iters: 2220, time: 0.097, data: 0.002) G_GAN: 0.682 G_L1: 0.000 D_real: 0.683 D_fake: 0.693 \n",
      "End of epoch 27 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 28, iters: 40, time: 0.105, data: 0.001) G_GAN: 0.680 G_L1: 0.402 D_real: 0.680 D_fake: 0.707 \n",
      "(epoch: 28, iters: 140, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 28, iters: 240, time: 0.094, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.687 \n",
      "(epoch: 28, iters: 340, time: 0.096, data: 0.002) G_GAN: 0.691 G_L1: 0.576 D_real: 0.690 D_fake: 0.694 \n",
      "(epoch: 28, iters: 440, time: 0.095, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 28, iters: 540, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 28, iters: 640, time: 0.110, data: 0.001) G_GAN: 0.690 G_L1: 0.414 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 28, iters: 740, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 28, iters: 840, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.691 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 28, iters: 940, time: 0.098, data: 0.001) G_GAN: 0.685 G_L1: 1.368 D_real: 0.666 D_fake: 0.724 \n",
      "(epoch: 28, iters: 1040, time: 0.095, data: 0.001) G_GAN: 0.686 G_L1: 0.000 D_real: 0.686 D_fake: 0.698 \n",
      "(epoch: 28, iters: 1140, time: 0.099, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 28, iters: 1240, time: 0.099, data: 0.001) G_GAN: 0.691 G_L1: 0.740 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 28, iters: 1340, time: 0.100, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.700 D_fake: 0.686 \n",
      "(epoch: 28, iters: 1440, time: 0.109, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.697 \n",
      "(epoch: 28, iters: 1540, time: 0.100, data: 0.001) G_GAN: 0.696 G_L1: 0.621 D_real: 0.696 D_fake: 0.694 \n",
      "(epoch: 28, iters: 1640, time: 0.097, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 28, iters: 1740, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.692 D_fake: 0.698 \n",
      "(epoch: 28, iters: 1840, time: 0.098, data: 0.002) G_GAN: 0.691 G_L1: 0.260 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 28, iters: 1940, time: 0.097, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.687 D_fake: 0.699 \n",
      "(epoch: 28, iters: 2040, time: 0.108, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 28, iters: 2140, time: 0.099, data: 0.001) G_GAN: 0.706 G_L1: 0.257 D_real: 0.707 D_fake: 0.689 \n",
      "(epoch: 28, iters: 2240, time: 0.099, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.699 \n",
      "End of epoch 28 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 29, iters: 60, time: 0.105, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 29, iters: 160, time: 0.098, data: 0.001) G_GAN: 0.690 G_L1: 0.753 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 29, iters: 260, time: 0.106, data: 0.001) G_GAN: 0.699 G_L1: 0.000 D_real: 0.700 D_fake: 0.693 \n",
      "(epoch: 29, iters: 360, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 29, iters: 460, time: 0.099, data: 0.001) G_GAN: 0.695 G_L1: 0.338 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 29, iters: 560, time: 0.099, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.693 \n",
      "(epoch: 29, iters: 660, time: 0.096, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 29, iters: 760, time: 0.107, data: 0.001) G_GAN: 0.694 G_L1: 0.559 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 29, iters: 860, time: 0.096, data: 0.001) G_GAN: 0.696 G_L1: 0.041 D_real: 0.695 D_fake: 0.686 \n",
      "(epoch: 29, iters: 960, time: 0.108, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 29, iters: 1060, time: 0.097, data: 0.001) G_GAN: 0.672 G_L1: 0.389 D_real: 0.673 D_fake: 0.690 \n",
      "(epoch: 29, iters: 1160, time: 0.096, data: 0.001) G_GAN: 0.666 G_L1: 1.065 D_real: 0.665 D_fake: 0.722 \n",
      "saving the latest model (epoch 29, total_steps 65000)\n",
      "(epoch: 29, iters: 1260, time: 0.102, data: 0.001) G_GAN: 0.675 G_L1: 1.194 D_real: 0.674 D_fake: 0.653 \n",
      "(epoch: 29, iters: 1360, time: 0.108, data: 0.001) G_GAN: 0.688 G_L1: 0.564 D_real: 0.687 D_fake: 0.689 \n",
      "(epoch: 29, iters: 1460, time: 0.096, data: 0.001) G_GAN: 0.682 G_L1: 0.000 D_real: 0.682 D_fake: 0.696 \n",
      "(epoch: 29, iters: 1560, time: 0.100, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.701 \n",
      "(epoch: 29, iters: 1660, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.387 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 29, iters: 1760, time: 0.097, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 29, iters: 1860, time: 0.098, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.695 \n",
      "(epoch: 29, iters: 1960, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.343 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 29, iters: 2060, time: 0.103, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.689 \n",
      "(epoch: 29, iters: 2160, time: 0.100, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.745 D_fake: 0.641 \n",
      "(epoch: 29, iters: 2260, time: 0.095, data: 0.001) G_GAN: 0.708 G_L1: 0.417 D_real: 0.715 D_fake: 0.724 \n",
      "End of epoch 29 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 30, iters: 80, time: 0.104, data: 0.001) G_GAN: 0.684 G_L1: 0.000 D_real: 0.684 D_fake: 0.702 \n",
      "(epoch: 30, iters: 180, time: 0.096, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 30, iters: 280, time: 0.099, data: 0.002) G_GAN: 0.697 G_L1: 0.853 D_real: 0.700 D_fake: 0.682 \n",
      "(epoch: 30, iters: 380, time: 0.098, data: 0.001) G_GAN: 0.708 G_L1: 0.000 D_real: 0.720 D_fake: 0.653 \n",
      "(epoch: 30, iters: 480, time: 0.108, data: 0.001) G_GAN: 0.710 G_L1: 0.000 D_real: 0.710 D_fake: 0.676 \n",
      "(epoch: 30, iters: 580, time: 0.100, data: 0.001) G_GAN: 0.699 G_L1: 0.403 D_real: 0.699 D_fake: 0.688 \n",
      "(epoch: 30, iters: 680, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 30, iters: 780, time: 0.097, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 30, iters: 880, time: 0.093, data: 0.001) G_GAN: 0.687 G_L1: 0.375 D_real: 0.687 D_fake: 0.700 \n",
      "(epoch: 30, iters: 980, time: 0.107, data: 0.002) G_GAN: 0.687 G_L1: 2.126 D_real: 0.688 D_fake: 0.697 \n",
      "(epoch: 30, iters: 1080, time: 0.095, data: 0.001) G_GAN: 0.644 G_L1: 0.000 D_real: 0.640 D_fake: 0.750 \n",
      "(epoch: 30, iters: 1180, time: 0.100, data: 0.001) G_GAN: 0.684 G_L1: 0.468 D_real: 0.682 D_fake: 0.687 \n",
      "(epoch: 30, iters: 1280, time: 0.097, data: 0.001) G_GAN: 0.706 G_L1: 0.000 D_real: 0.707 D_fake: 0.697 \n",
      "(epoch: 30, iters: 1380, time: 0.096, data: 0.001) G_GAN: 0.686 G_L1: 0.000 D_real: 0.686 D_fake: 0.704 \n",
      "(epoch: 30, iters: 1480, time: 0.098, data: 0.001) G_GAN: 0.699 G_L1: 0.413 D_real: 0.699 D_fake: 0.685 \n",
      "(epoch: 30, iters: 1580, time: 0.108, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.696 \n",
      "(epoch: 30, iters: 1680, time: 0.109, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.689 \n",
      "(epoch: 30, iters: 1780, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.366 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 30, iters: 1880, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 30, iters: 1980, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 30, iters: 2080, time: 0.095, data: 0.001) G_GAN: 0.691 G_L1: 0.251 D_real: 0.691 D_fake: 0.689 \n",
      "(epoch: 30, iters: 2180, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 30, iters: 2280, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.703 \n",
      "saving the model at the end of epoch 30, iters 68400\n",
      "End of epoch 30 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 31, iters: 100, time: 0.107, data: 0.272) G_GAN: 0.693 G_L1: 0.314 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 31, iters: 200, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 31, iters: 300, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 31, iters: 400, time: 0.096, data: 0.001) G_GAN: 0.691 G_L1: 0.229 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 31, iters: 500, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 31, iters: 600, time: 0.099, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 31, iters: 700, time: 0.099, data: 0.001) G_GAN: 0.691 G_L1: 0.505 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 31, iters: 800, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 31, iters: 900, time: 0.093, data: 0.001) G_GAN: 0.661 G_L1: 0.000 D_real: 0.659 D_fake: 0.704 \n",
      "(epoch: 31, iters: 1000, time: 0.105, data: 0.001) G_GAN: 0.694 G_L1: 0.684 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 31, iters: 1100, time: 0.113, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 31, iters: 1200, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 31, iters: 1300, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.776 D_real: 0.692 D_fake: 0.692 \n",
      "(epoch: 31, iters: 1400, time: 0.098, data: 0.001) G_GAN: 0.696 G_L1: 0.635 D_real: 0.696 D_fake: 0.692 \n",
      "(epoch: 31, iters: 1500, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.691 \n",
      "(epoch: 31, iters: 1600, time: 0.095, data: 0.001) G_GAN: 0.691 G_L1: 0.213 D_real: 0.691 D_fake: 0.695 \n",
      "saving the latest model (epoch 31, total_steps 70000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 31, iters: 1700, time: 0.111, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.689 \n",
      "(epoch: 31, iters: 1800, time: 0.095, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 31, iters: 1900, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.383 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 31, iters: 2000, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 31, iters: 2100, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.691 \n",
      "(epoch: 31, iters: 2200, time: 0.100, data: 0.002) G_GAN: 0.692 G_L1: 0.164 D_real: 0.692 D_fake: 0.694 \n",
      "End of epoch 31 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 32, iters: 20, time: 0.104, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 32, iters: 120, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 32, iters: 220, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.430 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 32, iters: 320, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 32, iters: 420, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 32, iters: 520, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.410 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 32, iters: 620, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 32, iters: 720, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 32, iters: 820, time: 0.096, data: 0.002) G_GAN: 0.694 G_L1: 0.262 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 32, iters: 920, time: 0.095, data: 0.001) G_GAN: 0.702 G_L1: 0.000 D_real: 0.700 D_fake: 0.687 \n",
      "(epoch: 32, iters: 1020, time: 0.097, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.702 D_fake: 0.678 \n",
      "(epoch: 32, iters: 1120, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 1.002 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 32, iters: 1220, time: 0.096, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 32, iters: 1320, time: 0.098, data: 0.002) G_GAN: 0.686 G_L1: 0.000 D_real: 0.685 D_fake: 0.701 \n",
      "(epoch: 32, iters: 1420, time: 0.097, data: 0.002) G_GAN: 0.702 G_L1: 0.404 D_real: 0.702 D_fake: 0.684 \n",
      "(epoch: 32, iters: 1520, time: 0.097, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 32, iters: 1620, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 32, iters: 1720, time: 0.111, data: 0.002) G_GAN: 0.689 G_L1: 0.346 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 32, iters: 1820, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 32, iters: 1920, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 32, iters: 2020, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.373 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 32, iters: 2120, time: 0.097, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.697 D_fake: 0.691 \n",
      "(epoch: 32, iters: 2220, time: 0.099, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.697 \n",
      "End of epoch 32 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 33, iters: 40, time: 0.105, data: 0.002) G_GAN: 0.691 G_L1: 0.331 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 33, iters: 140, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 33, iters: 240, time: 0.108, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 33, iters: 340, time: 0.095, data: 0.002) G_GAN: 0.695 G_L1: 0.576 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 33, iters: 440, time: 0.095, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 33, iters: 540, time: 0.094, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 33, iters: 640, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.811 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 33, iters: 740, time: 0.095, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 33, iters: 840, time: 0.095, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 33, iters: 940, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.910 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 33, iters: 1040, time: 0.096, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 33, iters: 1140, time: 0.098, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.697 \n",
      "(epoch: 33, iters: 1240, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.621 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 33, iters: 1340, time: 0.099, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 33, iters: 1440, time: 0.099, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 33, iters: 1540, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.560 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 33, iters: 1640, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 33, iters: 1740, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 33, iters: 1840, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.703 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 33, iters: 1940, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 33, iters: 2040, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 33, total_steps 75000)\n",
      "(epoch: 33, iters: 2140, time: 0.098, data: 0.002) G_GAN: 0.696 G_L1: 0.241 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 33, iters: 2240, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "End of epoch 33 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 34, iters: 60, time: 0.115, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 34, iters: 160, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.794 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 34, iters: 260, time: 0.096, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 34, iters: 360, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 34, iters: 460, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.708 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 34, iters: 560, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 34, iters: 660, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 34, iters: 760, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.512 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 34, iters: 860, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.001 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 34, iters: 960, time: 0.095, data: 0.001) G_GAN: 0.843 G_L1: 0.000 D_real: 0.950 D_fake: 0.514 \n",
      "(epoch: 34, iters: 1060, time: 0.096, data: 0.001) G_GAN: 0.683 G_L1: 0.571 D_real: 0.683 D_fake: 0.704 \n",
      "(epoch: 34, iters: 1160, time: 0.108, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 34, iters: 1260, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 1.293 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 34, iters: 1360, time: 0.100, data: 0.001) G_GAN: 0.697 G_L1: 0.544 D_real: 0.697 D_fake: 0.689 \n",
      "(epoch: 34, iters: 1460, time: 0.108, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 34, iters: 1560, time: 0.094, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 34, iters: 1660, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.528 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 34, iters: 1760, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 34, iters: 1860, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 34, iters: 1960, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.443 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 34, iters: 2060, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 34, iters: 2160, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 34, iters: 2260, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.386 D_real: 0.692 D_fake: 0.695 \n",
      "End of epoch 34 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 35, iters: 80, time: 0.106, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.698 D_fake: 0.691 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 35, iters: 180, time: 0.098, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.696 \n",
      "(epoch: 35, iters: 280, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 1.035 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 35, iters: 380, time: 0.097, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.689 \n",
      "(epoch: 35, iters: 480, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 35, iters: 580, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.406 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 35, iters: 680, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 35, iters: 780, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 35, iters: 880, time: 0.094, data: 0.001) G_GAN: 0.665 G_L1: 0.291 D_real: 0.663 D_fake: 0.725 \n",
      "(epoch: 35, iters: 980, time: 0.108, data: 0.002) G_GAN: 0.705 G_L1: 1.194 D_real: 0.705 D_fake: 0.680 \n",
      "(epoch: 35, iters: 1080, time: 0.097, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 35, iters: 1180, time: 0.112, data: 0.001) G_GAN: 0.696 G_L1: 0.519 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 35, iters: 1280, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 35, iters: 1380, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.028 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 35, iters: 1480, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.323 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 35, iters: 1580, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 35, iters: 1680, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 35, iters: 1780, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.402 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 35, iters: 1880, time: 0.110, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 35, iters: 1980, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 35, iters: 2080, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.274 D_real: 0.694 D_fake: 0.691 \n",
      "(epoch: 35, iters: 2180, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 35, iters: 2280, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "saving the model at the end of epoch 35, iters 79800\n",
      "End of epoch 35 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 36, iters: 100, time: 0.107, data: 0.274) G_GAN: 0.693 G_L1: 0.298 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 36, iters: 200, time: 0.104, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "saving the latest model (epoch 36, total_steps 80000)\n",
      "(epoch: 36, iters: 300, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 36, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.186 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 36, iters: 500, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 36, iters: 600, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 36, iters: 700, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.233 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 36, iters: 800, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 36, iters: 900, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 36, iters: 1000, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.410 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 36, iters: 1100, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 36, iters: 1200, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 36, iters: 1300, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.451 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 36, iters: 1400, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.890 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 36, iters: 1500, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 36, iters: 1600, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.219 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 36, iters: 1700, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 36, iters: 1800, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 36, iters: 1900, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.420 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 36, iters: 2000, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 36, iters: 2100, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 36, iters: 2200, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.241 D_real: 0.692 D_fake: 0.694 \n",
      "End of epoch 36 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 37, iters: 20, time: 0.105, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 37, iters: 120, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 37, iters: 220, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.496 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 37, iters: 320, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 37, iters: 420, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 37, iters: 520, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.314 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 37, iters: 620, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 37, iters: 720, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 37, iters: 820, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.219 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 37, iters: 920, time: 0.095, data: 0.001) G_GAN: 0.676 G_L1: 0.000 D_real: 0.675 D_fake: 0.712 \n",
      "(epoch: 37, iters: 1020, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 37, iters: 1120, time: 0.100, data: 0.001) G_GAN: 0.683 G_L1: 0.967 D_real: 0.684 D_fake: 0.703 \n",
      "(epoch: 37, iters: 1220, time: 0.092, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.692 \n",
      "(epoch: 37, iters: 1320, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 37, iters: 1420, time: 0.112, data: 0.001) G_GAN: 0.695 G_L1: 0.325 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 37, iters: 1520, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 37, iters: 1620, time: 0.106, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 37, iters: 1720, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.199 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 37, iters: 1820, time: 0.098, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 37, iters: 1920, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 37, iters: 2020, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.362 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 37, iters: 2120, time: 0.108, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.689 \n",
      "(epoch: 37, iters: 2220, time: 0.100, data: 0.001) G_GAN: 0.689 G_L1: 0.001 D_real: 0.689 D_fake: 0.697 \n",
      "End of epoch 37 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 38, iters: 40, time: 0.107, data: 0.002) G_GAN: 0.692 G_L1: 0.305 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 38, iters: 140, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 38, iters: 240, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 38, iters: 340, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 38, iters: 440, time: 0.106, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.689 \n",
      "(epoch: 38, iters: 540, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 38, iters: 640, time: 0.107, data: 0.002) G_GAN: 0.692 G_L1: 0.298 D_real: 0.692 D_fake: 0.694 \n",
      "saving the latest model (epoch 38, total_steps 85000)\n",
      "(epoch: 38, iters: 740, time: 0.094, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.691 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 38, iters: 840, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.690 \n",
      "(epoch: 38, iters: 940, time: 0.108, data: 0.001) G_GAN: 0.692 G_L1: 0.823 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 38, iters: 1040, time: 0.094, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 38, iters: 1140, time: 0.097, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 38, iters: 1240, time: 0.100, data: 0.001) G_GAN: 0.692 G_L1: 0.649 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 38, iters: 1340, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 38, iters: 1440, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 38, iters: 1540, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.586 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 38, iters: 1640, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 38, iters: 1740, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 38, iters: 1840, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.366 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 38, iters: 1940, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 38, iters: 2040, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 38, iters: 2140, time: 0.111, data: 0.001) G_GAN: 0.695 G_L1: 0.272 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 38, iters: 2240, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "End of epoch 38 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 39, iters: 60, time: 0.105, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 39, iters: 160, time: 0.099, data: 0.002) G_GAN: 0.691 G_L1: 0.329 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 39, iters: 260, time: 0.096, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 39, iters: 360, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 39, iters: 460, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.266 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 39, iters: 560, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 39, iters: 660, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 39, iters: 760, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.513 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 39, iters: 860, time: 0.107, data: 0.001) G_GAN: 0.694 G_L1: 0.002 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 39, iters: 960, time: 0.096, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.708 D_fake: 0.684 \n",
      "(epoch: 39, iters: 1060, time: 0.096, data: 0.001) G_GAN: 0.685 G_L1: 0.334 D_real: 0.685 D_fake: 0.700 \n",
      "(epoch: 39, iters: 1160, time: 0.095, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 39, iters: 1260, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 1.426 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 39, iters: 1360, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.544 D_real: 0.694 D_fake: 0.691 \n",
      "(epoch: 39, iters: 1460, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 39, iters: 1560, time: 0.095, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 39, iters: 1660, time: 0.109, data: 0.001) G_GAN: 0.692 G_L1: 0.466 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 39, iters: 1760, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 39, iters: 1860, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 39, iters: 1960, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.417 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 39, iters: 2060, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 39, iters: 2160, time: 0.100, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 39, iters: 2260, time: 0.094, data: 0.001) G_GAN: 0.692 G_L1: 0.407 D_real: 0.692 D_fake: 0.694 \n",
      "End of epoch 39 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 40, iters: 80, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 40, iters: 180, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 40, iters: 280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.307 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 40, iters: 380, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 40, iters: 480, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 40, iters: 580, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.339 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 40, iters: 680, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 40, iters: 780, time: 0.107, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 40, iters: 880, time: 0.095, data: 0.001) G_GAN: 0.692 G_L1: 0.221 D_real: 0.692 D_fake: 0.691 \n",
      "(epoch: 40, iters: 980, time: 0.099, data: 0.001) G_GAN: 0.685 G_L1: 0.809 D_real: 0.686 D_fake: 0.703 \n",
      "(epoch: 40, iters: 1080, time: 0.097, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.687 D_fake: 0.699 \n",
      "saving the latest model (epoch 40, total_steps 90000)\n",
      "(epoch: 40, iters: 1180, time: 0.098, data: 0.002) G_GAN: 0.690 G_L1: 0.405 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 40, iters: 1280, time: 0.098, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.697 \n",
      "(epoch: 40, iters: 1380, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 40, iters: 1480, time: 0.099, data: 0.002) G_GAN: 0.692 G_L1: 0.324 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 40, iters: 1580, time: 0.095, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 40, iters: 1680, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 40, iters: 1780, time: 0.109, data: 0.001) G_GAN: 0.694 G_L1: 0.352 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 40, iters: 1880, time: 0.100, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 40, iters: 1980, time: 0.099, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 40, iters: 2080, time: 0.108, data: 0.002) G_GAN: 0.694 G_L1: 0.364 D_real: 0.694 D_fake: 0.690 \n",
      "(epoch: 40, iters: 2180, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 40, iters: 2280, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.691 \n",
      "saving the model at the end of epoch 40, iters 91200\n",
      "End of epoch 40 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 41, iters: 100, time: 0.114, data: 0.280) G_GAN: 0.693 G_L1: 0.316 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 41, iters: 200, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 41, iters: 300, time: 0.098, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 41, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.137 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 41, iters: 500, time: 0.100, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 41, iters: 600, time: 0.110, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 41, iters: 700, time: 0.100, data: 0.001) G_GAN: 0.692 G_L1: 0.195 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 41, iters: 800, time: 0.103, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 41, iters: 900, time: 0.094, data: 0.002) G_GAN: 0.686 G_L1: 0.000 D_real: 0.686 D_fake: 0.702 \n",
      "(epoch: 41, iters: 1000, time: 0.099, data: 0.002) G_GAN: 0.694 G_L1: 0.335 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 41, iters: 1100, time: 0.098, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 41, iters: 1200, time: 0.097, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 41, iters: 1300, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.498 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 41, iters: 1400, time: 0.111, data: 0.002) G_GAN: 0.696 G_L1: 0.432 D_real: 0.696 D_fake: 0.692 \n",
      "(epoch: 41, iters: 1500, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 41, iters: 1600, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.228 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 41, iters: 1700, time: 0.107, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 41, iters: 1800, time: 0.095, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 41, iters: 1900, time: 0.096, data: 0.001) G_GAN: 0.690 G_L1: 0.510 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 41, iters: 2000, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 41, iters: 2100, time: 0.096, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 41, iters: 2200, time: 0.100, data: 0.001) G_GAN: 0.691 G_L1: 0.189 D_real: 0.691 D_fake: 0.696 \n",
      "End of epoch 41 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 42, iters: 20, time: 0.103, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 42, iters: 120, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 42, iters: 220, time: 0.108, data: 0.001) G_GAN: 0.695 G_L1: 0.430 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 42, iters: 320, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 42, iters: 420, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 42, iters: 520, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.218 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 42, iters: 620, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 42, iters: 720, time: 0.096, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 42, iters: 820, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.335 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 42, iters: 920, time: 0.094, data: 0.001) G_GAN: 0.699 G_L1: 0.000 D_real: 0.699 D_fake: 0.687 \n",
      "(epoch: 42, iters: 1020, time: 0.098, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 42, iters: 1120, time: 0.097, data: 0.001) G_GAN: 0.684 G_L1: 0.626 D_real: 0.685 D_fake: 0.695 \n",
      "(epoch: 42, iters: 1220, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 42, iters: 1320, time: 0.098, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.688 \n",
      "(epoch: 42, iters: 1420, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.270 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 42, iters: 1520, time: 0.097, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "saving the latest model (epoch 42, total_steps 95000)\n",
      "(epoch: 42, iters: 1620, time: 0.092, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 42, iters: 1720, time: 0.100, data: 0.001) G_GAN: 0.690 G_L1: 0.391 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 42, iters: 1820, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 42, iters: 1920, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 42, iters: 2020, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.294 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 42, iters: 2120, time: 0.096, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 42, iters: 2220, time: 0.099, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "End of epoch 42 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 43, iters: 40, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.326 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 43, iters: 140, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 43, iters: 240, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 43, iters: 340, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 43, iters: 440, time: 0.093, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 43, iters: 540, time: 0.094, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 43, iters: 640, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.280 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 43, iters: 740, time: 0.093, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 43, iters: 840, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 43, iters: 940, time: 0.099, data: 0.002) G_GAN: 0.694 G_L1: 0.845 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 43, iters: 1040, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 43, iters: 1140, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 43, iters: 1240, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.671 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 43, iters: 1340, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 43, iters: 1440, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 43, iters: 1540, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.646 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 43, iters: 1640, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 43, iters: 1740, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 43, iters: 1840, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.078 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 43, iters: 1940, time: 0.111, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 43, iters: 2040, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 43, iters: 2140, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.254 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 43, iters: 2240, time: 0.108, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "End of epoch 43 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 44, iters: 60, time: 0.105, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.690 D_fake: 0.694 \n",
      "(epoch: 44, iters: 160, time: 0.099, data: 0.002) G_GAN: 0.692 G_L1: 0.404 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 44, iters: 260, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 44, iters: 360, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 44, iters: 460, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.329 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 44, iters: 560, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 44, iters: 660, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 44, iters: 760, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.353 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 44, iters: 860, time: 0.097, data: 0.005) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 44, iters: 960, time: 0.096, data: 0.001) G_GAN: 0.856 G_L1: 0.000 D_real: 0.907 D_fake: 0.534 \n",
      "(epoch: 44, iters: 1060, time: 0.097, data: 0.001) G_GAN: 0.665 G_L1: 0.181 D_real: 0.666 D_fake: 0.722 \n",
      "(epoch: 44, iters: 1160, time: 0.099, data: 0.001) G_GAN: 0.647 G_L1: 0.000 D_real: 0.646 D_fake: 0.718 \n",
      "(epoch: 44, iters: 1260, time: 0.100, data: 0.001) G_GAN: 0.681 G_L1: 0.793 D_real: 0.681 D_fake: 0.717 \n",
      "(epoch: 44, iters: 1360, time: 0.096, data: 0.001) G_GAN: 0.680 G_L1: 0.447 D_real: 0.680 D_fake: 0.707 \n",
      "(epoch: 44, iters: 1460, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.697 D_fake: 0.683 \n",
      "(epoch: 44, iters: 1560, time: 0.096, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.700 D_fake: 0.687 \n",
      "(epoch: 44, iters: 1660, time: 0.097, data: 0.001) G_GAN: 0.686 G_L1: 0.484 D_real: 0.687 D_fake: 0.693 \n",
      "(epoch: 44, iters: 1760, time: 0.111, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.694 \n",
      "(epoch: 44, iters: 1860, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 44, iters: 1960, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.417 D_real: 0.695 D_fake: 0.691 \n",
      "saving the latest model (epoch 44, total_steps 100000)\n",
      "(epoch: 44, iters: 2060, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.685 \n",
      "(epoch: 44, iters: 2160, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 44, iters: 2260, time: 0.094, data: 0.001) G_GAN: 0.694 G_L1: 0.516 D_real: 0.694 D_fake: 0.692 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 44 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 45, iters: 80, time: 0.115, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 45, iters: 180, time: 0.098, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.688 D_fake: 0.697 \n",
      "(epoch: 45, iters: 280, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.204 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 45, iters: 380, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.695 \n",
      "(epoch: 45, iters: 480, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 45, iters: 580, time: 0.098, data: 0.002) G_GAN: 0.691 G_L1: 0.368 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 45, iters: 680, time: 0.096, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 45, iters: 780, time: 0.095, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.688 \n",
      "(epoch: 45, iters: 880, time: 0.094, data: 0.001) G_GAN: 0.694 G_L1: 0.270 D_real: 0.694 D_fake: 0.687 \n",
      "(epoch: 45, iters: 980, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 45, iters: 1080, time: 0.105, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.685 \n",
      "(epoch: 45, iters: 1180, time: 0.109, data: 0.002) G_GAN: 0.694 G_L1: 0.399 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 45, iters: 1280, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 45, iters: 1380, time: 0.096, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 45, iters: 1480, time: 0.097, data: 0.002) G_GAN: 0.691 G_L1: 0.546 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 45, iters: 1580, time: 0.101, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 45, iters: 1680, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.696 \n",
      "(epoch: 45, iters: 1780, time: 0.106, data: 0.001) G_GAN: 0.692 G_L1: 0.470 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 45, iters: 1880, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 45, iters: 1980, time: 0.107, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 45, iters: 2080, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.247 D_real: 0.692 D_fake: 0.691 \n",
      "(epoch: 45, iters: 2180, time: 0.095, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 45, iters: 2280, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "saving the model at the end of epoch 45, iters 102600\n",
      "End of epoch 45 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 46, iters: 100, time: 0.106, data: 0.279) G_GAN: 0.692 G_L1: 0.299 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 46, iters: 200, time: 0.101, data: 0.003) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 46, iters: 300, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 46, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.217 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 46, iters: 500, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 46, iters: 600, time: 0.099, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 46, iters: 700, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.420 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 46, iters: 800, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 46, iters: 900, time: 0.093, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 46, iters: 1000, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.432 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 46, iters: 1100, time: 0.098, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 46, iters: 1200, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 46, iters: 1300, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.507 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 46, iters: 1400, time: 0.098, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 46, iters: 1500, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 46, iters: 1600, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.179 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 46, iters: 1700, time: 0.109, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 46, iters: 1800, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 46, iters: 1900, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.653 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 46, iters: 2000, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 46, iters: 2100, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 46, iters: 2200, time: 0.099, data: 0.002) G_GAN: 0.692 G_L1: 0.377 D_real: 0.692 D_fake: 0.695 \n",
      "End of epoch 46 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 47, iters: 20, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 47, iters: 120, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "saving the latest model (epoch 47, total_steps 105000)\n",
      "(epoch: 47, iters: 220, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.309 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 47, iters: 320, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 47, iters: 420, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 47, iters: 520, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.298 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 47, iters: 620, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 47, iters: 720, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 47, iters: 820, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.644 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 47, iters: 920, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.683 \n",
      "(epoch: 47, iters: 1020, time: 0.099, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.716 D_fake: 0.580 \n",
      "(epoch: 47, iters: 1120, time: 0.110, data: 0.001) G_GAN: 0.681 G_L1: 0.133 D_real: 0.681 D_fake: 0.705 \n",
      "(epoch: 47, iters: 1220, time: 0.098, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.687 D_fake: 0.699 \n",
      "(epoch: 47, iters: 1320, time: 0.100, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.698 \n",
      "(epoch: 47, iters: 1420, time: 0.097, data: 0.001) G_GAN: 0.689 G_L1: 0.239 D_real: 0.689 D_fake: 0.698 \n",
      "(epoch: 47, iters: 1520, time: 0.097, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.691 \n",
      "(epoch: 47, iters: 1620, time: 0.095, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 47, iters: 1720, time: 0.099, data: 0.002) G_GAN: 0.692 G_L1: 0.278 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 47, iters: 1820, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 47, iters: 1920, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 47, iters: 2020, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.668 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 47, iters: 2120, time: 0.095, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 47, iters: 2220, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "End of epoch 47 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 48, iters: 40, time: 0.108, data: 0.002) G_GAN: 0.692 G_L1: 0.276 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 48, iters: 140, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 48, iters: 240, time: 0.095, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 48, iters: 340, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 48, iters: 440, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 48, iters: 540, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 48, iters: 640, time: 0.095, data: 0.001) G_GAN: 0.691 G_L1: 0.677 D_real: 0.691 D_fake: 0.694 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 48, iters: 740, time: 0.094, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 48, iters: 840, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 48, iters: 940, time: 0.099, data: 0.001) G_GAN: 0.696 G_L1: 0.734 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 48, iters: 1040, time: 0.094, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 48, iters: 1140, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 48, iters: 1240, time: 0.096, data: 0.001) G_GAN: 0.690 G_L1: 0.587 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 48, iters: 1340, time: 0.101, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.689 \n",
      "(epoch: 48, iters: 1440, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 48, iters: 1540, time: 0.110, data: 0.002) G_GAN: 0.694 G_L1: 0.450 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 48, iters: 1640, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 48, iters: 1740, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.696 \n",
      "(epoch: 48, iters: 1840, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.311 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 48, iters: 1940, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 48, iters: 2040, time: 0.101, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.695 \n",
      "(epoch: 48, iters: 2140, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.113 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 48, iters: 2240, time: 0.107, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "End of epoch 48 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 49, iters: 60, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 49, iters: 160, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.398 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 49, iters: 260, time: 0.107, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.693 \n",
      "(epoch: 49, iters: 360, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 49, iters: 460, time: 0.100, data: 0.002) G_GAN: 0.694 G_L1: 0.278 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 49, iters: 560, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "saving the latest model (epoch 49, total_steps 110000)\n",
      "(epoch: 49, iters: 660, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 49, iters: 760, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.696 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 49, iters: 860, time: 0.093, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 49, iters: 960, time: 0.106, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 49, iters: 1060, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.563 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 49, iters: 1160, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 49, iters: 1260, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.728 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 49, iters: 1360, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.366 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 49, iters: 1460, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 49, iters: 1560, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 49, iters: 1660, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.410 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 49, iters: 1760, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 49, iters: 1860, time: 0.108, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 49, iters: 1960, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.496 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 49, iters: 2060, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 49, iters: 2160, time: 0.096, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 49, iters: 2260, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.352 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 49 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 50, iters: 80, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 180, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 280, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.524 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 380, time: 0.107, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 50, iters: 480, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 580, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.388 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 680, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 780, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 880, time: 0.104, data: 0.001) G_GAN: 0.632 G_L1: 0.338 D_real: 0.629 D_fake: 0.763 \n",
      "(epoch: 50, iters: 980, time: 0.097, data: 0.001) G_GAN: 0.704 G_L1: 1.386 D_real: 0.705 D_fake: 0.682 \n",
      "(epoch: 50, iters: 1080, time: 0.097, data: 0.001) G_GAN: 0.676 G_L1: 0.001 D_real: 0.675 D_fake: 0.712 \n",
      "(epoch: 50, iters: 1180, time: 0.100, data: 0.001) G_GAN: 0.692 G_L1: 0.349 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 50, iters: 1280, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 50, iters: 1380, time: 0.096, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.698 \n",
      "(epoch: 50, iters: 1480, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.368 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 50, iters: 1580, time: 0.098, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 50, iters: 1680, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 50, iters: 1780, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.484 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 1880, time: 0.110, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 50, iters: 1980, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 2080, time: 0.098, data: 0.002) G_GAN: 0.691 G_L1: 0.278 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 50, iters: 2180, time: 0.097, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 50, iters: 2280, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "saving the model at the end of epoch 50, iters 114000\n",
      "End of epoch 50 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 51, iters: 100, time: 0.110, data: 0.281) G_GAN: 0.693 G_L1: 0.288 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 200, time: 0.099, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 51, iters: 300, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 51, iters: 400, time: 0.109, data: 0.001) G_GAN: 0.692 G_L1: 0.203 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 51, iters: 500, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 51, iters: 600, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 700, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.287 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 800, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 51, iters: 900, time: 0.093, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 51, iters: 1000, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.378 D_real: 0.694 D_fake: 0.692 \n",
      "saving the latest model (epoch 51, total_steps 115000)\n",
      "(epoch: 51, iters: 1100, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 51, iters: 1200, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 1300, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.656 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 51, iters: 1400, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.007 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 1500, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 1600, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.289 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 1700, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 51, iters: 1800, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 1900, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.270 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 2000, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 51, iters: 2100, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 2200, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.142 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 51 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 52, iters: 20, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 120, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 220, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.325 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 320, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 420, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 520, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.174 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 620, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 720, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 820, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.203 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 920, time: 0.095, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 52, iters: 1020, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 1120, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.469 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 52, iters: 1220, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 1320, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.003 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 1420, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.171 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 1520, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 1620, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 1720, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.472 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 1820, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 1920, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 2020, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.778 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 2120, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 2220, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "End of epoch 52 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 53, iters: 40, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.394 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 53, iters: 140, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 53, iters: 240, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 53, iters: 340, time: 0.104, data: 0.001) G_GAN: 0.686 G_L1: 0.576 D_real: 0.685 D_fake: 0.701 \n",
      "(epoch: 53, iters: 440, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 53, iters: 540, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 53, iters: 640, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.498 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 53, iters: 740, time: 0.093, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 53, iters: 840, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 53, iters: 940, time: 0.100, data: 0.001) G_GAN: 0.691 G_L1: 0.501 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 53, iters: 1040, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 53, iters: 1140, time: 0.098, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.689 D_fake: 0.702 \n",
      "(epoch: 53, iters: 1240, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.640 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 53, iters: 1340, time: 0.108, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.689 \n",
      "(epoch: 53, iters: 1440, time: 0.099, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.699 \n",
      "saving the latest model (epoch 53, total_steps 120000)\n",
      "(epoch: 53, iters: 1540, time: 0.097, data: 0.001) G_GAN: 0.690 G_L1: 0.344 D_real: 0.690 D_fake: 0.695 \n",
      "(epoch: 53, iters: 1640, time: 0.096, data: 0.001) G_GAN: 0.699 G_L1: 0.000 D_real: 0.699 D_fake: 0.687 \n",
      "(epoch: 53, iters: 1740, time: 0.097, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.682 \n",
      "(epoch: 53, iters: 1840, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.127 D_real: 0.695 D_fake: 0.696 \n",
      "(epoch: 53, iters: 1940, time: 0.111, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.695 D_fake: 0.702 \n",
      "(epoch: 53, iters: 2040, time: 0.097, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 53, iters: 2140, time: 0.100, data: 0.001) G_GAN: 0.691 G_L1: 0.120 D_real: 0.690 D_fake: 0.695 \n",
      "(epoch: 53, iters: 2240, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.684 \n",
      "End of epoch 53 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 54, iters: 60, time: 0.106, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 54, iters: 160, time: 0.110, data: 0.001) G_GAN: 0.691 G_L1: 0.293 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 54, iters: 260, time: 0.107, data: 0.001) G_GAN: 0.684 G_L1: 0.000 D_real: 0.684 D_fake: 0.703 \n",
      "(epoch: 54, iters: 360, time: 0.096, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 54, iters: 460, time: 0.100, data: 0.001) G_GAN: 0.719 G_L1: 0.292 D_real: 0.721 D_fake: 0.666 \n",
      "(epoch: 54, iters: 560, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 54, iters: 660, time: 0.100, data: 0.001) G_GAN: 0.684 G_L1: 0.000 D_real: 0.683 D_fake: 0.695 \n",
      "(epoch: 54, iters: 760, time: 0.097, data: 0.001) G_GAN: 0.687 G_L1: 0.348 D_real: 0.690 D_fake: 0.698 \n",
      "(epoch: 54, iters: 860, time: 0.094, data: 0.001) G_GAN: 0.641 G_L1: 0.000 D_real: 0.632 D_fake: 0.757 \n",
      "(epoch: 54, iters: 960, time: 0.095, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.729 D_fake: 0.658 \n",
      "(epoch: 54, iters: 1060, time: 0.097, data: 0.001) G_GAN: 0.690 G_L1: 0.325 D_real: 0.691 D_fake: 0.684 \n",
      "(epoch: 54, iters: 1160, time: 0.105, data: 0.001) G_GAN: 0.704 G_L1: 0.000 D_real: 0.704 D_fake: 0.683 \n",
      "(epoch: 54, iters: 1260, time: 0.096, data: 0.002) G_GAN: 0.692 G_L1: 0.794 D_real: 0.692 D_fake: 0.685 \n",
      "(epoch: 54, iters: 1360, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.392 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 54, iters: 1460, time: 0.096, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 54, iters: 1560, time: 0.096, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.688 \n",
      "(epoch: 54, iters: 1660, time: 0.096, data: 0.001) G_GAN: 0.697 G_L1: 0.482 D_real: 0.697 D_fake: 0.694 \n",
      "(epoch: 54, iters: 1760, time: 0.098, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.696 \n",
      "(epoch: 54, iters: 1860, time: 0.108, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 54, iters: 1960, time: 0.095, data: 0.001) G_GAN: 0.689 G_L1: 0.417 D_real: 0.688 D_fake: 0.693 \n",
      "(epoch: 54, iters: 2060, time: 0.095, data: 0.003) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.691 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 54, iters: 2160, time: 0.100, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 54, iters: 2260, time: 0.094, data: 0.001) G_GAN: 0.695 G_L1: 0.378 D_real: 0.696 D_fake: 0.691 \n",
      "End of epoch 54 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 55, iters: 80, time: 0.102, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 55, iters: 180, time: 0.100, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 55, iters: 280, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.176 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 55, iters: 380, time: 0.097, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 55, iters: 480, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 55, iters: 580, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.198 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 55, iters: 680, time: 0.099, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 55, iters: 780, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 55, iters: 880, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.228 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 55, iters: 980, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.288 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 55, iters: 1080, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 55, iters: 1180, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.546 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 55, iters: 1280, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 55, iters: 1380, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 55, iters: 1480, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.550 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 55, iters: 1580, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 55, iters: 1680, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 55, iters: 1780, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.658 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 55, iters: 1880, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 55, total_steps 125000)\n",
      "(epoch: 55, iters: 1980, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 55, iters: 2080, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.189 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 55, iters: 2180, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 55, iters: 2280, time: 0.096, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "saving the model at the end of epoch 55, iters 125400\n",
      "End of epoch 55 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 56, iters: 100, time: 0.104, data: 0.291) G_GAN: 0.692 G_L1: 0.280 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 56, iters: 200, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 56, iters: 300, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 56, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.174 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 56, iters: 500, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 56, iters: 600, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 56, iters: 700, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.244 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 56, iters: 800, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 56, iters: 900, time: 0.099, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.695 \n",
      "(epoch: 56, iters: 1000, time: 0.107, data: 0.001) G_GAN: 0.685 G_L1: 0.320 D_real: 0.685 D_fake: 0.702 \n",
      "(epoch: 56, iters: 1100, time: 0.098, data: 0.001) G_GAN: 0.686 G_L1: 0.000 D_real: 0.686 D_fake: 0.701 \n",
      "(epoch: 56, iters: 1200, time: 0.096, data: 0.001) G_GAN: 0.685 G_L1: 0.000 D_real: 0.685 D_fake: 0.701 \n",
      "(epoch: 56, iters: 1300, time: 0.098, data: 0.001) G_GAN: 0.690 G_L1: 0.629 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 56, iters: 1400, time: 0.108, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 56, iters: 1500, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 56, iters: 1600, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.148 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 56, iters: 1700, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 56, iters: 1800, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 56, iters: 1900, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.541 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 56, iters: 2000, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.483 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 56, iters: 2100, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 56, iters: 2200, time: 0.100, data: 0.001) G_GAN: 0.692 G_L1: 0.154 D_real: 0.692 D_fake: 0.694 \n",
      "End of epoch 56 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 57, iters: 20, time: 0.117, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 120, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 220, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.269 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 320, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 420, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 520, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.406 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 620, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 57, iters: 720, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 820, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.115 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 920, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 57, iters: 1020, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 1120, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.830 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 57, iters: 1220, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 1320, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 1420, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.446 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 1520, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 1620, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 1720, time: 0.112, data: 0.002) G_GAN: 0.693 G_L1: 0.190 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 1820, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 1920, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 2020, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.364 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 57, iters: 2120, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 57, iters: 2220, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 57 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 58, iters: 40, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.315 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 58, total_steps 130000)\n",
      "(epoch: 58, iters: 140, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 58, iters: 240, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 58, iters: 340, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 58, iters: 440, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 58, iters: 540, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 58, iters: 640, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.476 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 58, iters: 740, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 58, iters: 840, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 58, iters: 940, time: 0.099, data: 0.000) G_GAN: 0.694 G_L1: 0.816 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 58, iters: 1040, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 58, iters: 1140, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 58, iters: 1240, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.673 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 58, iters: 1340, time: 0.101, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 58, iters: 1440, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 58, iters: 1540, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.358 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 58, iters: 1640, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 58, iters: 1740, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 58, iters: 1840, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.167 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 58, iters: 1940, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 58, iters: 2040, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 58, iters: 2140, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.147 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 58, iters: 2240, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "End of epoch 58 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 59, iters: 60, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 59, iters: 160, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.359 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 59, iters: 260, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 59, iters: 360, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 59, iters: 460, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.244 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 59, iters: 560, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 59, iters: 660, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 59, iters: 760, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.251 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 59, iters: 860, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 59, iters: 960, time: 0.107, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.699 D_fake: 0.687 \n",
      "(epoch: 59, iters: 1060, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.427 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 59, iters: 1160, time: 0.096, data: 0.002) G_GAN: 0.675 G_L1: 0.000 D_real: 0.676 D_fake: 0.716 \n",
      "(epoch: 59, iters: 1260, time: 0.098, data: 0.002) G_GAN: 0.674 G_L1: 0.594 D_real: 0.675 D_fake: 0.712 \n",
      "(epoch: 59, iters: 1360, time: 0.095, data: 0.002) G_GAN: 0.681 G_L1: 0.399 D_real: 0.681 D_fake: 0.705 \n",
      "(epoch: 59, iters: 1460, time: 0.107, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.687 D_fake: 0.700 \n",
      "(epoch: 59, iters: 1560, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 59, iters: 1660, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.323 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 59, iters: 1760, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 59, iters: 1860, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 59, iters: 1960, time: 0.112, data: 0.001) G_GAN: 0.693 G_L1: 0.417 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 59, iters: 2060, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 59, iters: 2160, time: 0.107, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 59, iters: 2260, time: 0.100, data: 0.001) G_GAN: 0.692 G_L1: 0.341 D_real: 0.692 D_fake: 0.693 \n",
      "End of epoch 59 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 60, iters: 80, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 180, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 280, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.308 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 380, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 480, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 60, total_steps 135000)\n",
      "(epoch: 60, iters: 580, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.413 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 680, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 780, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 880, time: 0.095, data: 0.001) G_GAN: 0.692 G_L1: 0.191 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 60, iters: 980, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 1.239 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 60, iters: 1080, time: 0.106, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 60, iters: 1180, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.383 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 60, iters: 1280, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 1380, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 1480, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.321 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 1580, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 1680, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 1780, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.255 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 1880, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 1980, time: 0.113, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 2080, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.301 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 60, iters: 2180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 2280, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "saving the model at the end of epoch 60, iters 136800\n",
      "End of epoch 60 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 61, iters: 100, time: 0.106, data: 0.285) G_GAN: 0.693 G_L1: 0.412 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 61, iters: 200, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 61, iters: 300, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 61, iters: 400, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.154 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 61, iters: 500, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 61, iters: 600, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 61, iters: 700, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.226 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 61, iters: 800, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 61, iters: 900, time: 0.093, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 61, iters: 1000, time: 0.101, data: 0.001) G_GAN: 0.694 G_L1: 0.454 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 61, iters: 1100, time: 0.110, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 61, iters: 1200, time: 0.099, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.698 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 61, iters: 1300, time: 0.108, data: 0.002) G_GAN: 0.691 G_L1: 0.464 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 61, iters: 1400, time: 0.100, data: 0.001) G_GAN: 0.683 G_L1: 0.000 D_real: 0.683 D_fake: 0.713 \n",
      "(epoch: 61, iters: 1500, time: 0.097, data: 0.002) G_GAN: 0.683 G_L1: 0.000 D_real: 0.683 D_fake: 0.703 \n",
      "(epoch: 61, iters: 1600, time: 0.095, data: 0.002) G_GAN: 0.690 G_L1: 0.174 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 61, iters: 1700, time: 0.097, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.689 \n",
      "(epoch: 61, iters: 1800, time: 0.095, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 61, iters: 1900, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.828 D_real: 0.693 D_fake: 0.686 \n",
      "(epoch: 61, iters: 2000, time: 0.109, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 61, iters: 2100, time: 0.093, data: 0.001) G_GAN: 0.686 G_L1: 0.000 D_real: 0.686 D_fake: 0.700 \n",
      "(epoch: 61, iters: 2200, time: 0.098, data: 0.002) G_GAN: 0.696 G_L1: 0.197 D_real: 0.696 D_fake: 0.690 \n",
      "End of epoch 61 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 62, iters: 20, time: 0.104, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 62, iters: 120, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 62, iters: 220, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.205 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 62, iters: 320, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 62, iters: 420, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 62, iters: 520, time: 0.095, data: 0.001) G_GAN: 0.695 G_L1: 0.196 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 62, iters: 620, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 62, iters: 720, time: 0.111, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.695 \n",
      "(epoch: 62, iters: 820, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.195 D_real: 0.693 D_fake: 0.696 \n",
      "(epoch: 62, iters: 920, time: 0.094, data: 0.002) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.699 \n",
      "saving the latest model (epoch 62, total_steps 140000)\n",
      "(epoch: 62, iters: 1020, time: 0.108, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 62, iters: 1120, time: 0.099, data: 0.002) G_GAN: 0.694 G_L1: 0.645 D_real: 0.694 D_fake: 0.690 \n",
      "(epoch: 62, iters: 1220, time: 0.097, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.690 \n",
      "(epoch: 62, iters: 1320, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 62, iters: 1420, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.211 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 62, iters: 1520, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 62, iters: 1620, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 62, iters: 1720, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.355 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 62, iters: 1820, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 62, iters: 1920, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 62, iters: 2020, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.234 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 62, iters: 2120, time: 0.097, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 62, iters: 2220, time: 0.109, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.691 \n",
      "End of epoch 62 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 63, iters: 40, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.217 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 140, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 63, iters: 240, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 340, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 440, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 540, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 640, time: 0.094, data: 0.001) G_GAN: 0.694 G_L1: 0.257 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 63, iters: 740, time: 0.093, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 63, iters: 840, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 63, iters: 940, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.706 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 1040, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 1140, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 63, iters: 1240, time: 0.101, data: 0.001) G_GAN: 0.694 G_L1: 0.649 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 63, iters: 1340, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 1440, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 1540, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.305 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 1640, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 1740, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 1840, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.105 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 1940, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 2040, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 2140, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.212 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 2240, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 63 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 64, iters: 60, time: 0.117, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 64, iters: 160, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.220 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 64, iters: 260, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 64, iters: 360, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 64, iters: 460, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.342 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 64, iters: 560, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 64, iters: 660, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 64, iters: 760, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.299 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 64, iters: 860, time: 0.099, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 64, iters: 960, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 64, iters: 1060, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.366 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 64, iters: 1160, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 64, iters: 1260, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.986 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 64, iters: 1360, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.394 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 64, total_steps 145000)\n",
      "(epoch: 64, iters: 1460, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 64, iters: 1560, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 64, iters: 1660, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.343 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 64, iters: 1760, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 64, iters: 1860, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 64, iters: 1960, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.315 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 64, iters: 2060, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 64, iters: 2160, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 64, iters: 2260, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.245 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 64 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 65, iters: 80, time: 0.122, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 65, iters: 180, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 65, iters: 280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.345 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 65, iters: 380, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 65, iters: 480, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 65, iters: 580, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.286 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 65, iters: 680, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 65, iters: 780, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 65, iters: 880, time: 0.094, data: 0.001) G_GAN: 0.682 G_L1: 0.294 D_real: 0.692 D_fake: 0.681 \n",
      "(epoch: 65, iters: 980, time: 0.098, data: 0.001) G_GAN: 0.706 G_L1: 1.644 D_real: 0.706 D_fake: 0.681 \n",
      "(epoch: 65, iters: 1080, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 65, iters: 1180, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.221 D_real: 0.695 D_fake: 0.693 \n",
      "(epoch: 65, iters: 1280, time: 0.108, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 65, iters: 1380, time: 0.097, data: 0.001) G_GAN: 0.684 G_L1: 0.000 D_real: 0.686 D_fake: 0.700 \n",
      "(epoch: 65, iters: 1480, time: 0.098, data: 0.001) G_GAN: 0.689 G_L1: 0.258 D_real: 0.690 D_fake: 0.704 \n",
      "(epoch: 65, iters: 1580, time: 0.095, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 65, iters: 1680, time: 0.098, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.687 D_fake: 0.699 \n",
      "(epoch: 65, iters: 1780, time: 0.097, data: 0.002) G_GAN: 0.688 G_L1: 0.548 D_real: 0.689 D_fake: 0.698 \n",
      "(epoch: 65, iters: 1880, time: 0.097, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 65, iters: 1980, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 65, iters: 2080, time: 0.097, data: 0.001) G_GAN: 0.686 G_L1: 0.332 D_real: 0.685 D_fake: 0.704 \n",
      "(epoch: 65, iters: 2180, time: 0.098, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.700 D_fake: 0.687 \n",
      "(epoch: 65, iters: 2280, time: 0.097, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "saving the model at the end of epoch 65, iters 148200\n",
      "End of epoch 65 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 66, iters: 100, time: 0.106, data: 0.280) G_GAN: 0.691 G_L1: 0.308 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 66, iters: 200, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 66, iters: 300, time: 0.095, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.692 D_fake: 0.692 \n",
      "(epoch: 66, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.173 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 66, iters: 500, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 66, iters: 600, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 66, iters: 700, time: 0.097, data: 0.002) G_GAN: 0.700 G_L1: 0.298 D_real: 0.700 D_fake: 0.686 \n",
      "(epoch: 66, iters: 800, time: 0.111, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 66, iters: 900, time: 0.093, data: 0.002) G_GAN: 0.672 G_L1: 0.000 D_real: 0.673 D_fake: 0.714 \n",
      "(epoch: 66, iters: 1000, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.338 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 66, iters: 1100, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 66, iters: 1200, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 66, iters: 1300, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.438 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 66, iters: 1400, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 66, iters: 1500, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 66, iters: 1600, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.215 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 66, iters: 1700, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 66, iters: 1800, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 66, total_steps 150000)\n",
      "(epoch: 66, iters: 1900, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.451 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 66, iters: 2000, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 66, iters: 2100, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 66, iters: 2200, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.132 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 66 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 67, iters: 20, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 67, iters: 120, time: 0.099, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 67, iters: 220, time: 0.106, data: 0.002) G_GAN: 0.692 G_L1: 0.451 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 67, iters: 320, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 67, iters: 420, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 67, iters: 520, time: 0.095, data: 0.002) G_GAN: 0.695 G_L1: 0.171 D_real: 0.695 D_fake: 0.693 \n",
      "(epoch: 67, iters: 620, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 67, iters: 720, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 67, iters: 820, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.303 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 67, iters: 920, time: 0.095, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 67, iters: 1020, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 67, iters: 1120, time: 0.100, data: 0.002) G_GAN: 0.694 G_L1: 0.561 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 67, iters: 1220, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 67, iters: 1320, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 67, iters: 1420, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.165 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 67, iters: 1520, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 67, iters: 1620, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 67, iters: 1720, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.227 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 67, iters: 1820, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 67, iters: 1920, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 67, iters: 2020, time: 0.100, data: 0.001) G_GAN: 0.692 G_L1: 0.207 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 67, iters: 2120, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 67, iters: 2220, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 67 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 68, iters: 40, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.222 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 68, iters: 140, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 68, iters: 240, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 340, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 68, iters: 440, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 540, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 640, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.257 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 68, iters: 740, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 68, iters: 840, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 940, time: 0.108, data: 0.002) G_GAN: 0.694 G_L1: 0.492 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 68, iters: 1040, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 1140, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 1240, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.661 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 1340, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 1440, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 1540, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.245 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 1640, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 1740, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 1840, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.309 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 1940, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 2040, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 2140, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.098 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 2240, time: 0.109, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "saving the latest model (epoch 68, total_steps 155000)\n",
      "End of epoch 68 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 69, iters: 60, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 69, iters: 160, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.319 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 260, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 69, iters: 360, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 460, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.288 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 560, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 660, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 69, iters: 760, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.316 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 69, iters: 860, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 960, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 1060, time: 0.105, data: 0.003) G_GAN: 0.693 G_L1: 0.501 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 1160, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.006 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 1260, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.223 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 1360, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.441 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 1460, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 1560, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 1660, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.313 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 1760, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 1860, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 1960, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.359 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 2060, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 2160, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 2260, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.420 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 69 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 70, iters: 80, time: 0.118, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 180, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 280, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.147 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 380, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 480, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 580, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.225 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 680, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 780, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 880, time: 0.104, data: 0.001) G_GAN: 0.690 G_L1: 0.330 D_real: 0.692 D_fake: 0.691 \n",
      "(epoch: 70, iters: 980, time: 0.097, data: 0.001) G_GAN: 0.702 G_L1: 0.000 D_real: 0.702 D_fake: 0.684 \n",
      "(epoch: 70, iters: 1080, time: 0.094, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 70, iters: 1180, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.159 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 70, iters: 1280, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 1380, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 1480, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.422 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 1580, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 1680, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 1780, time: 0.107, data: 0.002) G_GAN: 0.692 G_L1: 0.171 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 70, iters: 1880, time: 0.109, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 70, iters: 1980, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 70, iters: 2080, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.196 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 2180, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 2280, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 70, iters 159600\n",
      "End of epoch 70 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 71, iters: 100, time: 0.116, data: 0.296) G_GAN: 0.692 G_L1: 0.454 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 71, iters: 200, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 71, iters: 300, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 71, iters: 400, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.209 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 71, total_steps 160000)\n",
      "(epoch: 71, iters: 500, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 71, iters: 600, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 71, iters: 700, time: 0.099, data: 0.002) G_GAN: 0.694 G_L1: 0.195 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 71, iters: 800, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 71, iters: 900, time: 0.093, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.693 D_fake: 0.696 \n",
      "(epoch: 71, iters: 1000, time: 0.112, data: 0.001) G_GAN: 0.693 G_L1: 0.405 D_real: 0.693 D_fake: 0.694 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 71, iters: 1100, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 71, iters: 1200, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 71, iters: 1300, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.321 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 71, iters: 1400, time: 0.096, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 71, iters: 1500, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 71, iters: 1600, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.217 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 71, iters: 1700, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.001 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 71, iters: 1800, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 71, iters: 1900, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.377 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 71, iters: 2000, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 71, iters: 2100, time: 0.107, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 71, iters: 2200, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.141 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 71 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 72, iters: 20, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 72, iters: 120, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 72, iters: 220, time: 0.108, data: 0.001) G_GAN: 0.694 G_L1: 0.287 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 72, iters: 320, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 72, iters: 420, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 72, iters: 520, time: 0.095, data: 0.002) G_GAN: 0.694 G_L1: 0.222 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 72, iters: 620, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 72, iters: 720, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 72, iters: 820, time: 0.110, data: 0.001) G_GAN: 0.694 G_L1: 0.455 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 72, iters: 920, time: 0.097, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 72, iters: 1020, time: 0.099, data: 0.002) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.699 \n",
      "(epoch: 72, iters: 1120, time: 0.103, data: 0.002) G_GAN: 0.691 G_L1: 0.213 D_real: 0.691 D_fake: 0.698 \n",
      "(epoch: 72, iters: 1220, time: 0.111, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.697 \n",
      "(epoch: 72, iters: 1320, time: 0.097, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 72, iters: 1420, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.415 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 72, iters: 1520, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 72, iters: 1620, time: 0.104, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 72, iters: 1720, time: 0.101, data: 0.002) G_GAN: 0.692 G_L1: 0.271 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 72, iters: 1820, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 72, iters: 1920, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 72, iters: 2020, time: 0.100, data: 0.002) G_GAN: 0.694 G_L1: 0.420 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 72, iters: 2120, time: 0.109, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 72, iters: 2220, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "End of epoch 72 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 73, iters: 40, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.251 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 73, iters: 140, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 73, iters: 240, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 73, iters: 340, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 73, iters: 440, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 73, iters: 540, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 73, iters: 640, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.291 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 73, iters: 740, time: 0.092, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 73, iters: 840, time: 0.095, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "saving the latest model (epoch 73, total_steps 165000)\n",
      "(epoch: 73, iters: 940, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.700 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 73, iters: 1040, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 73, iters: 1140, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 73, iters: 1240, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.490 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 73, iters: 1340, time: 0.099, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 73, iters: 1440, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 73, iters: 1540, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.306 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 73, iters: 1640, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 73, iters: 1740, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 73, iters: 1840, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.311 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 73, iters: 1940, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 73, iters: 2040, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 73, iters: 2140, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.282 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 73, iters: 2240, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 73 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 74, iters: 60, time: 0.115, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 74, iters: 160, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.304 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 74, iters: 260, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 74, iters: 360, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 74, iters: 460, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.190 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 74, iters: 560, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 74, iters: 660, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 74, iters: 760, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.290 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 74, iters: 860, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 74, iters: 960, time: 0.095, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 74, iters: 1060, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.128 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 74, iters: 1160, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 74, iters: 1260, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 74, iters: 1360, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.612 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 74, iters: 1460, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 74, iters: 1560, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 74, iters: 1660, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.205 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 74, iters: 1760, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 74, iters: 1860, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 74, iters: 1960, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.417 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 74, iters: 2060, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 74, iters: 2160, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 74, iters: 2260, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.299 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 74 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 75, iters: 80, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 280, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.299 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 380, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 480, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 580, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.421 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 680, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 780, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 880, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.317 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 980, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 1080, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 1180, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.146 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 1280, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 75, total_steps 170000)\n",
      "(epoch: 75, iters: 1380, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 1480, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.361 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 1580, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 1680, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 1780, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.293 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 1880, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 1980, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 2080, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.235 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 2180, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 2280, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 75, iters 171000\n",
      "End of epoch 75 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 76, iters: 100, time: 0.105, data: 0.284) G_GAN: 0.693 G_L1: 0.313 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 200, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 300, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 400, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.210 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 500, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 600, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 700, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.165 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 800, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 900, time: 0.092, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.679 D_fake: 0.709 \n",
      "(epoch: 76, iters: 1000, time: 0.109, data: 0.002) G_GAN: 0.687 G_L1: 0.494 D_real: 0.687 D_fake: 0.700 \n",
      "(epoch: 76, iters: 1100, time: 0.110, data: 0.001) G_GAN: 0.685 G_L1: 0.000 D_real: 0.685 D_fake: 0.676 \n",
      "(epoch: 76, iters: 1200, time: 0.097, data: 0.002) G_GAN: 0.680 G_L1: 0.000 D_real: 0.680 D_fake: 0.707 \n",
      "(epoch: 76, iters: 1300, time: 0.098, data: 0.001) G_GAN: 0.685 G_L1: 0.701 D_real: 0.685 D_fake: 0.702 \n",
      "(epoch: 76, iters: 1400, time: 0.098, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.698 \n",
      "(epoch: 76, iters: 1500, time: 0.096, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 76, iters: 1600, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.169 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 76, iters: 1700, time: 0.100, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 76, iters: 1800, time: 0.107, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.694 \n",
      "(epoch: 76, iters: 1900, time: 0.100, data: 0.001) G_GAN: 0.691 G_L1: 0.342 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 76, iters: 2000, time: 0.109, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 76, iters: 2100, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 76, iters: 2200, time: 0.102, data: 0.001) G_GAN: 0.691 G_L1: 0.162 D_real: 0.691 D_fake: 0.695 \n",
      "End of epoch 76 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 77, iters: 20, time: 0.105, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 77, iters: 120, time: 0.107, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 77, iters: 220, time: 0.099, data: 0.003) G_GAN: 0.693 G_L1: 0.281 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 320, time: 0.109, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 77, iters: 420, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 520, time: 0.094, data: 0.001) G_GAN: 0.695 G_L1: 0.217 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 77, iters: 620, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 77, iters: 720, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 77, iters: 820, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.310 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 920, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.690 \n",
      "(epoch: 77, iters: 1020, time: 0.108, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 77, iters: 1120, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.272 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 77, iters: 1220, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 77, iters: 1320, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.071 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 1420, time: 0.112, data: 0.001) G_GAN: 0.693 G_L1: 0.125 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 1520, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 77, iters: 1620, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 77, iters: 1720, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.245 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 77, total_steps 175000)\n",
      "(epoch: 77, iters: 1820, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 1920, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 77, iters: 2020, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.299 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 2120, time: 0.097, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 77, iters: 2220, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "End of epoch 77 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 78, iters: 40, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.190 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 140, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 78, iters: 240, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 78, iters: 340, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 440, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 540, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 640, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.310 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 740, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 840, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 940, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.537 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 78, iters: 1040, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 1140, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 78, iters: 1240, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.453 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 78, iters: 1340, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 1440, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 1540, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.343 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 1640, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 1740, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.692 \n",
      "(epoch: 78, iters: 1840, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.094 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 1940, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 2040, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 2140, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.211 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 78, iters: 2240, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 78 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 79, iters: 60, time: 0.119, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 160, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.346 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 260, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 360, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 460, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.214 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 560, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 660, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 760, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.451 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 860, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 960, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 79, iters: 1060, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.077 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 1160, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 1260, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.547 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 1360, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.471 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 1460, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 1560, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 1660, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.439 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 1760, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 1860, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 1960, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.417 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 2060, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 2160, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 79, total_steps 180000)\n",
      "(epoch: 79, iters: 2260, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.328 D_real: 0.694 D_fake: 0.693 \n",
      "End of epoch 79 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 80, iters: 80, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 180, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.434 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 380, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 480, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 580, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.300 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 680, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 780, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 880, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.263 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 980, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.014 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 1080, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 1180, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.277 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 1280, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 1380, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 1480, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.375 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 1580, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 1680, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 1780, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.244 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 1880, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 1980, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 2080, time: 0.096, data: 0.001) G_GAN: 0.689 G_L1: 0.284 D_real: 0.690 D_fake: 0.695 \n",
      "(epoch: 80, iters: 2180, time: 0.097, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.697 D_fake: 0.689 \n",
      "(epoch: 80, iters: 2280, time: 0.095, data: 0.001) G_GAN: 0.705 G_L1: 0.000 D_real: 0.705 D_fake: 0.682 \n",
      "saving the model at the end of epoch 80, iters 182400\n",
      "End of epoch 80 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 81, iters: 100, time: 0.109, data: 0.283) G_GAN: 0.679 G_L1: 0.344 D_real: 0.679 D_fake: 0.708 \n",
      "(epoch: 81, iters: 200, time: 0.094, data: 0.001) G_GAN: 0.706 G_L1: 0.000 D_real: 0.705 D_fake: 0.690 \n",
      "(epoch: 81, iters: 300, time: 0.097, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.688 \n",
      "(epoch: 81, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.699 G_L1: 0.148 D_real: 0.700 D_fake: 0.687 \n",
      "(epoch: 81, iters: 500, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.690 \n",
      "(epoch: 81, iters: 600, time: 0.097, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 81, iters: 700, time: 0.099, data: 0.002) G_GAN: 0.698 G_L1: 0.201 D_real: 0.699 D_fake: 0.688 \n",
      "(epoch: 81, iters: 800, time: 0.097, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.691 D_fake: 0.689 \n",
      "(epoch: 81, iters: 900, time: 0.107, data: 0.001) G_GAN: 0.706 G_L1: 0.000 D_real: 0.706 D_fake: 0.680 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 81, iters: 1000, time: 0.098, data: 0.002) G_GAN: 0.691 G_L1: 0.315 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 81, iters: 1100, time: 0.100, data: 0.001) G_GAN: 0.686 G_L1: 0.000 D_real: 0.688 D_fake: 0.697 \n",
      "(epoch: 81, iters: 1200, time: 0.108, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.695 \n",
      "(epoch: 81, iters: 1300, time: 0.099, data: 0.001) G_GAN: 0.696 G_L1: 0.431 D_real: 0.696 D_fake: 0.695 \n",
      "(epoch: 81, iters: 1400, time: 0.097, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 81, iters: 1500, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 81, iters: 1600, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.244 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 81, iters: 1700, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 81, iters: 1800, time: 0.096, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 81, iters: 1900, time: 0.100, data: 0.002) G_GAN: 0.689 G_L1: 0.395 D_real: 0.689 D_fake: 0.698 \n",
      "(epoch: 81, iters: 2000, time: 0.099, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 81, iters: 2100, time: 0.094, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 81, iters: 2200, time: 0.100, data: 0.001) G_GAN: 0.689 G_L1: 0.194 D_real: 0.689 D_fake: 0.694 \n",
      "End of epoch 81 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 82, iters: 20, time: 0.103, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 82, iters: 120, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 82, iters: 220, time: 0.099, data: 0.001) G_GAN: 0.695 G_L1: 0.256 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 82, iters: 320, time: 0.108, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "saving the latest model (epoch 82, total_steps 185000)\n",
      "(epoch: 82, iters: 420, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 82, iters: 520, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.285 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 82, iters: 620, time: 0.098, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 82, iters: 720, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 82, iters: 820, time: 0.096, data: 0.001) G_GAN: 0.695 G_L1: 0.174 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 82, iters: 920, time: 0.095, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 82, iters: 1020, time: 0.108, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 82, iters: 1120, time: 0.097, data: 0.002) G_GAN: 0.691 G_L1: 0.331 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 82, iters: 1220, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 82, iters: 1320, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 82, iters: 1420, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.160 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 1520, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 82, iters: 1620, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 1720, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.279 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 82, iters: 1820, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 82, iters: 1920, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 82, iters: 2020, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.200 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 2120, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.691 \n",
      "(epoch: 82, iters: 2220, time: 0.099, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "End of epoch 82 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 83, iters: 40, time: 0.118, data: 0.002) G_GAN: 0.694 G_L1: 0.285 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 83, iters: 140, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 240, time: 0.095, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 83, iters: 340, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 440, time: 0.094, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 83, iters: 540, time: 0.094, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 83, iters: 640, time: 0.097, data: 0.002) G_GAN: 0.695 G_L1: 0.261 D_real: 0.695 D_fake: 0.694 \n",
      "(epoch: 83, iters: 740, time: 0.094, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 83, iters: 840, time: 0.094, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 83, iters: 940, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.360 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 83, iters: 1040, time: 0.095, data: 0.001) G_GAN: 0.672 G_L1: 0.000 D_real: 0.671 D_fake: 0.716 \n",
      "(epoch: 83, iters: 1140, time: 0.096, data: 0.001) G_GAN: 0.743 G_L1: 0.000 D_real: 0.741 D_fake: 0.647 \n",
      "(epoch: 83, iters: 1240, time: 0.097, data: 0.001) G_GAN: 0.703 G_L1: 0.583 D_real: 0.703 D_fake: 0.683 \n",
      "(epoch: 83, iters: 1340, time: 0.098, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.688 \n",
      "(epoch: 83, iters: 1440, time: 0.102, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.694 \n",
      "(epoch: 83, iters: 1540, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.336 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 83, iters: 1640, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 1740, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 83, iters: 1840, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.164 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 83, iters: 1940, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 83, iters: 2040, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 83, iters: 2140, time: 0.098, data: 0.002) G_GAN: 0.696 G_L1: 0.273 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 83, iters: 2240, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 83 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 84, iters: 60, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 84, iters: 160, time: 0.110, data: 0.001) G_GAN: 0.694 G_L1: 0.227 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 84, iters: 260, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 84, iters: 360, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 84, iters: 460, time: 0.109, data: 0.001) G_GAN: 0.695 G_L1: 0.246 D_real: 0.695 D_fake: 0.694 \n",
      "(epoch: 84, iters: 560, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 84, iters: 660, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 760, time: 0.095, data: 0.002) G_GAN: 0.694 G_L1: 0.293 D_real: 0.694 D_fake: 0.693 \n",
      "saving the latest model (epoch 84, total_steps 190000)\n",
      "(epoch: 84, iters: 860, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 84, iters: 960, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 84, iters: 1060, time: 0.107, data: 0.002) G_GAN: 0.692 G_L1: 0.353 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 84, iters: 1160, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 1260, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.216 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 84, iters: 1360, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.355 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 84, iters: 1460, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 84, iters: 1560, time: 0.096, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 84, iters: 1660, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.227 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 84, iters: 1760, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 84, iters: 1860, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 1960, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.390 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 2060, time: 0.092, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 2160, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 2260, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.240 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 84 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 85, iters: 80, time: 0.115, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 180, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 280, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.187 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 380, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 480, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 580, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.368 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 680, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 780, time: 0.110, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 85, iters: 880, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.207 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 980, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.003 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 1080, time: 0.106, data: 0.003) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 85, iters: 1180, time: 0.111, data: 0.001) G_GAN: 0.694 G_L1: 0.175 D_real: 0.694 D_fake: 0.695 \n",
      "(epoch: 85, iters: 1280, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 1380, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 1480, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.204 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 1580, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 1680, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 1780, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.337 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 1880, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 1980, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 2080, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.240 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 2180, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 2280, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 85, iters 193800\n",
      "End of epoch 85 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 86, iters: 100, time: 0.107, data: 0.287) G_GAN: 0.693 G_L1: 0.403 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 86, iters: 200, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.033 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 86, iters: 300, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 86, iters: 400, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.214 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 86, iters: 500, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 86, iters: 600, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 86, iters: 700, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.251 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 86, iters: 800, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 86, iters: 900, time: 0.092, data: 0.001) G_GAN: 0.678 G_L1: 0.000 D_real: 0.686 D_fake: 0.694 \n",
      "(epoch: 86, iters: 1000, time: 0.098, data: 0.002) G_GAN: 0.677 G_L1: 0.390 D_real: 0.677 D_fake: 0.714 \n",
      "(epoch: 86, iters: 1100, time: 0.097, data: 0.002) G_GAN: 0.684 G_L1: 0.000 D_real: 0.684 D_fake: 0.690 \n",
      "(epoch: 86, iters: 1200, time: 0.099, data: 0.002) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.698 \n",
      "saving the latest model (epoch 86, total_steps 195000)\n",
      "(epoch: 86, iters: 1300, time: 0.097, data: 0.001) G_GAN: 0.691 G_L1: 0.332 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 86, iters: 1400, time: 0.096, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 86, iters: 1500, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 86, iters: 1600, time: 0.098, data: 0.002) G_GAN: 0.696 G_L1: 0.238 D_real: 0.696 D_fake: 0.692 \n",
      "(epoch: 86, iters: 1700, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 86, iters: 1800, time: 0.096, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.693 \n",
      "(epoch: 86, iters: 1900, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.229 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 86, iters: 2000, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 86, iters: 2100, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 86, iters: 2200, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.172 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 86 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 87, iters: 20, time: 0.108, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 87, iters: 120, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 220, time: 0.115, data: 0.001) G_GAN: 0.693 G_L1: 0.313 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 320, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 420, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 520, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.273 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 620, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 87, iters: 720, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 87, iters: 820, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.263 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 920, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 87, iters: 1020, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 1120, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.297 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 1220, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 1320, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 1420, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.154 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 1520, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 1620, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 1720, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.186 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 1820, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 1920, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 2020, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.374 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 2120, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 87, iters: 2220, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 87 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 88, iters: 40, time: 0.115, data: 0.004) G_GAN: 0.693 G_L1: 0.179 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 88, iters: 140, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 240, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 340, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 440, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 540, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 640, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.242 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 740, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 840, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 940, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.463 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 1040, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 1140, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 1240, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.591 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 1340, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 1440, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 1540, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.295 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 1640, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 88, total_steps 200000)\n",
      "(epoch: 88, iters: 1740, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 1840, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.110 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 1940, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 2040, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 2140, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.263 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 2240, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 88 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 89, iters: 60, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 160, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.419 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 260, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 360, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 460, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.235 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 560, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 660, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 760, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.369 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 860, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 960, time: 0.107, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 89, iters: 1060, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.353 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 1160, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 1260, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 1360, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.314 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 1460, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 1560, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 1660, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.397 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 1760, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 1860, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 1960, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.417 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 2060, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 2160, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 2260, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.338 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 89 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 90, iters: 80, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 180, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 280, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.147 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 380, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 480, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 580, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.402 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 680, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 780, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 880, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.281 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 980, time: 0.098, data: 0.001) G_GAN: 0.680 G_L1: 0.005 D_real: 0.680 D_fake: 0.707 \n",
      "(epoch: 90, iters: 1080, time: 0.092, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 90, iters: 1180, time: 0.098, data: 0.002) G_GAN: 0.688 G_L1: 0.156 D_real: 0.688 D_fake: 0.698 \n",
      "(epoch: 90, iters: 1280, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 90, iters: 1380, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 1480, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.266 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 1580, time: 0.106, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 90, iters: 1680, time: 0.100, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 90, iters: 1780, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.300 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 90, iters: 1880, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 90, iters: 1980, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 90, iters: 2080, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.247 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 90, total_steps 205000)\n",
      "(epoch: 90, iters: 2180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 2280, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 90, iters 205200\n",
      "End of epoch 90 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 91, iters: 100, time: 0.109, data: 0.289) G_GAN: 0.693 G_L1: 0.300 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 200, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 300, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 400, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.152 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 500, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 600, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 700, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.182 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 91, iters: 800, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 900, time: 0.091, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 91, iters: 1000, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.316 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 1100, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 91, iters: 1200, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 1300, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.484 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 1400, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 1500, time: 0.113, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 1600, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.170 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 1700, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 1800, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 1900, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.487 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 2000, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 2100, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 2200, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.153 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 91 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 92, iters: 20, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 120, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 220, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.267 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 320, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 420, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 520, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.139 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 620, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 720, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 820, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.117 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 920, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 92, iters: 1020, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 1120, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.385 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 1220, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 1320, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 1420, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.162 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 1520, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 1620, time: 0.103, data: 0.004) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 1720, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.191 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 1820, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 1920, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 92, iters: 2020, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.281 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 2120, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 2220, time: 0.098, data: 0.002) G_GAN: 0.688 G_L1: 0.000 D_real: 0.690 D_fake: 0.689 \n",
      "End of epoch 92 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 93, iters: 40, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.267 D_real: 0.693 D_fake: 0.691 \n",
      "(epoch: 93, iters: 140, time: 0.105, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 93, iters: 240, time: 0.096, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "saving the latest model (epoch 93, total_steps 210000)\n",
      "(epoch: 93, iters: 340, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 93, iters: 440, time: 0.095, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 93, iters: 540, time: 0.095, data: 0.004) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 93, iters: 640, time: 0.096, data: 0.002) G_GAN: 0.695 G_L1: 0.321 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 93, iters: 740, time: 0.094, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 93, iters: 840, time: 0.096, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 93, iters: 940, time: 0.100, data: 0.002) G_GAN: 0.692 G_L1: 0.463 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 1040, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 93, iters: 1140, time: 0.108, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 93, iters: 1240, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.528 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 93, iters: 1340, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 93, iters: 1440, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 93, iters: 1540, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.283 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 1640, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 1740, time: 0.100, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 93, iters: 1840, time: 0.100, data: 0.001) G_GAN: 0.692 G_L1: 0.147 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 93, iters: 1940, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 2040, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 93, iters: 2140, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.123 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 2240, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "End of epoch 93 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 94, iters: 60, time: 0.115, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 94, iters: 160, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.190 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 260, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 360, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 460, time: 0.101, data: 0.002) G_GAN: 0.692 G_L1: 0.354 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 94, iters: 560, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 660, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 94, iters: 760, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.297 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 94, iters: 860, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 960, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 1060, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.378 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 1160, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 1260, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 1360, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.442 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 1460, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 94, iters: 1560, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 1660, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.345 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 1760, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 1860, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.018 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 1960, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.417 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 2060, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 2160, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 2260, time: 0.094, data: 0.002) G_GAN: 0.694 G_L1: 0.183 D_real: 0.693 D_fake: 0.694 \n",
      "End of epoch 94 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 95, iters: 80, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 95, iters: 180, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 95, iters: 280, time: 0.098, data: 0.002) G_GAN: 0.689 G_L1: 0.212 D_real: 0.689 D_fake: 0.698 \n",
      "(epoch: 95, iters: 380, time: 0.099, data: 0.001) G_GAN: 0.709 G_L1: 0.000 D_real: 0.707 D_fake: 0.679 \n",
      "(epoch: 95, iters: 480, time: 0.099, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.687 D_fake: 0.699 \n",
      "(epoch: 95, iters: 580, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.252 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 95, iters: 680, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 95, total_steps 215000)\n",
      "(epoch: 95, iters: 780, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 95, iters: 880, time: 0.095, data: 0.001) G_GAN: 0.701 G_L1: 0.286 D_real: 0.702 D_fake: 0.684 \n",
      "(epoch: 95, iters: 980, time: 0.099, data: 0.002) G_GAN: 0.686 G_L1: 1.118 D_real: 0.686 D_fake: 0.700 \n",
      "(epoch: 95, iters: 1080, time: 0.106, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 95, iters: 1180, time: 0.098, data: 0.001) G_GAN: 0.690 G_L1: 0.076 D_real: 0.690 D_fake: 0.693 \n",
      "(epoch: 95, iters: 1280, time: 0.098, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 95, iters: 1380, time: 0.105, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 95, iters: 1480, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.330 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 95, iters: 1580, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 95, iters: 1680, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 95, iters: 1780, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.318 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 95, iters: 1880, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 95, iters: 1980, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.690 \n",
      "(epoch: 95, iters: 2080, time: 0.096, data: 0.002) G_GAN: 0.694 G_L1: 0.159 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 95, iters: 2180, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 95, iters: 2280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "saving the model at the end of epoch 95, iters 216600\n",
      "End of epoch 95 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 96, iters: 100, time: 0.105, data: 0.281) G_GAN: 0.691 G_L1: 0.328 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 96, iters: 200, time: 0.107, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 96, iters: 300, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 400, time: 0.108, data: 0.001) G_GAN: 0.694 G_L1: 0.137 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 96, iters: 500, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 96, iters: 600, time: 0.109, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 96, iters: 700, time: 0.111, data: 0.002) G_GAN: 0.695 G_L1: 0.185 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 96, iters: 800, time: 0.110, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 900, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 1000, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.214 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 1100, time: 0.100, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 96, iters: 1200, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 1300, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.280 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 1400, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 1500, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 1600, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.234 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 96, iters: 1700, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 1800, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 96, iters: 1900, time: 0.112, data: 0.001) G_GAN: 0.692 G_L1: 0.364 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 96, iters: 2000, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 2100, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 2200, time: 0.100, data: 0.001) G_GAN: 0.692 G_L1: 0.158 D_real: 0.692 D_fake: 0.694 \n",
      "End of epoch 96 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 97, iters: 20, time: 0.105, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.692 \n",
      "(epoch: 97, iters: 120, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 97, iters: 220, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.251 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 320, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 420, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 520, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.178 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 97, iters: 620, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 97, iters: 720, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 820, time: 0.096, data: 0.002) G_GAN: 0.694 G_L1: 0.156 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 97, iters: 920, time: 0.097, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 97, iters: 1020, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 1120, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.232 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 97, total_steps 220000)\n",
      "(epoch: 97, iters: 1220, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 1320, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 1420, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.116 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 97, iters: 1520, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 97, iters: 1620, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 1720, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.332 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 1820, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 1920, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 2020, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.220 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 2120, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 97, iters: 2220, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 97 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 98, iters: 40, time: 0.114, data: 0.001) G_GAN: 0.693 G_L1: 0.227 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 140, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 240, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 340, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 440, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 540, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 640, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.175 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 740, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 98, iters: 840, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 940, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 1.163 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 1040, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 1140, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 1240, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.377 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 1340, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 1440, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 1540, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.256 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 1640, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 1740, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 1840, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.242 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 1940, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 2040, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 2140, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.141 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 2240, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 98 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 99, iters: 60, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 160, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.269 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 260, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 360, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 460, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.236 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 560, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 660, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 760, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.283 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 860, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 960, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 1060, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.088 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 1160, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 1260, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.898 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 1360, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.286 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 1460, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 1560, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 99, total_steps 225000)\n",
      "(epoch: 99, iters: 1660, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.253 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 1760, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 1860, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 1960, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.356 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 2060, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 2160, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 2260, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.194 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 99 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 100, iters: 80, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 100, iters: 180, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 100, iters: 280, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.238 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 100, iters: 380, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 100, iters: 480, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 100, iters: 580, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.332 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 100, iters: 680, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 100, iters: 780, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 100, iters: 880, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.160 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 100, iters: 980, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.098 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 100, iters: 1080, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 100, iters: 1180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.202 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 100, iters: 1280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 100, iters: 1380, time: 0.095, data: 0.002) G_GAN: 0.660 G_L1: 0.000 D_real: 0.660 D_fake: 0.727 \n",
      "(epoch: 100, iters: 1480, time: 0.098, data: 0.001) G_GAN: 0.666 G_L1: 0.393 D_real: 0.666 D_fake: 0.711 \n",
      "(epoch: 100, iters: 1580, time: 0.095, data: 0.001) G_GAN: 0.671 G_L1: 0.000 D_real: 0.671 D_fake: 0.678 \n",
      "(epoch: 100, iters: 1680, time: 0.097, data: 0.001) G_GAN: 0.677 G_L1: 0.000 D_real: 0.677 D_fake: 0.709 \n",
      "(epoch: 100, iters: 1780, time: 0.096, data: 0.002) G_GAN: 0.683 G_L1: 0.340 D_real: 0.683 D_fake: 0.703 \n",
      "(epoch: 100, iters: 1880, time: 0.101, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.694 \n",
      "(epoch: 100, iters: 1980, time: 0.097, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 100, iters: 2080, time: 0.107, data: 0.003) G_GAN: 0.688 G_L1: 0.205 D_real: 0.688 D_fake: 0.698 \n",
      "(epoch: 100, iters: 2180, time: 0.100, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 100, iters: 2280, time: 0.097, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.696 \n",
      "saving the model at the end of epoch 100, iters 228000\n",
      "End of epoch 100 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001980\n",
      "(epoch: 101, iters: 100, time: 0.117, data: 0.295) G_GAN: 0.693 G_L1: 0.257 D_real: 0.693 D_fake: 0.696 \n",
      "(epoch: 101, iters: 200, time: 0.095, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 101, iters: 300, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 101, iters: 400, time: 0.095, data: 0.002) G_GAN: 0.694 G_L1: 0.200 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 101, iters: 500, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 101, iters: 600, time: 0.109, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.688 \n",
      "(epoch: 101, iters: 700, time: 0.099, data: 0.002) G_GAN: 0.699 G_L1: 0.149 D_real: 0.699 D_fake: 0.688 \n",
      "(epoch: 101, iters: 800, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 101, iters: 900, time: 0.093, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 101, iters: 1000, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.204 D_real: 0.695 D_fake: 0.693 \n",
      "(epoch: 101, iters: 1100, time: 0.096, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.691 \n",
      "(epoch: 101, iters: 1200, time: 0.096, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.688 \n",
      "(epoch: 101, iters: 1300, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.298 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 101, iters: 1400, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.692 \n",
      "(epoch: 101, iters: 1500, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 101, iters: 1600, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.158 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 101, iters: 1700, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 101, iters: 1800, time: 0.108, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 101, iters: 1900, time: 0.111, data: 0.002) G_GAN: 0.692 G_L1: 0.205 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 101, iters: 2000, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.695 \n",
      "saving the latest model (epoch 101, total_steps 230000)\n",
      "(epoch: 101, iters: 2100, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 101, iters: 2200, time: 0.109, data: 0.002) G_GAN: 0.692 G_L1: 0.144 D_real: 0.692 D_fake: 0.694 \n",
      "End of epoch 101 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001960\n",
      "(epoch: 102, iters: 20, time: 0.114, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 102, iters: 120, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 102, iters: 220, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.325 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 102, iters: 320, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 102, iters: 420, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 102, iters: 520, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.115 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 102, iters: 620, time: 0.099, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 102, iters: 720, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 102, iters: 820, time: 0.095, data: 0.002) G_GAN: 0.694 G_L1: 0.228 D_real: 0.695 D_fake: 0.695 \n",
      "(epoch: 102, iters: 920, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 102, iters: 1020, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 102, iters: 1120, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.171 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 102, iters: 1220, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 102, iters: 1320, time: 0.100, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 102, iters: 1420, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.141 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 102, iters: 1520, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 102, iters: 1620, time: 0.094, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 102, iters: 1720, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.261 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 102, iters: 1820, time: 0.100, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 102, iters: 1920, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.178 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 102, iters: 2020, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.328 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 102, iters: 2120, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 102, iters: 2220, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 102 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001941\n",
      "(epoch: 103, iters: 40, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.283 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 103, iters: 140, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 103, iters: 240, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 103, iters: 340, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.514 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 103, iters: 440, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 103, iters: 540, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 103, iters: 640, time: 0.098, data: 0.002) G_GAN: 0.695 G_L1: 0.280 D_real: 0.695 D_fake: 0.693 \n",
      "(epoch: 103, iters: 740, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.695 \n",
      "(epoch: 103, iters: 840, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 103, iters: 940, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.306 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 103, iters: 1040, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 103, iters: 1140, time: 0.096, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 103, iters: 1240, time: 0.095, data: 0.002) G_GAN: 0.694 G_L1: 0.659 D_real: 0.694 D_fake: 0.705 \n",
      "(epoch: 103, iters: 1340, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 103, iters: 1440, time: 0.113, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 103, iters: 1540, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.388 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 103, iters: 1640, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 103, iters: 1740, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 103, iters: 1840, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.197 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 103, iters: 1940, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 103, iters: 2040, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 103, iters: 2140, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.098 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 103, iters: 2240, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "End of epoch 103 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001921\n",
      "(epoch: 104, iters: 60, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 104, iters: 160, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.284 D_real: 0.693 D_fake: 0.694 \n",
      "saving the latest model (epoch 104, total_steps 235000)\n",
      "(epoch: 104, iters: 260, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 104, iters: 360, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 104, iters: 460, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.218 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 104, iters: 560, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 104, iters: 660, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 104, iters: 760, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.276 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 104, iters: 860, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 104, iters: 960, time: 0.095, data: 0.006) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 104, iters: 1060, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.088 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 104, iters: 1160, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 104, iters: 1260, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.463 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 104, iters: 1360, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.274 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 104, iters: 1460, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 104, iters: 1560, time: 0.105, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 104, iters: 1660, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.283 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 104, iters: 1760, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 104, iters: 1860, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 104, iters: 1960, time: 0.113, data: 0.001) G_GAN: 0.693 G_L1: 0.320 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 104, iters: 2060, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 104, iters: 2160, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 104, iters: 2260, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.458 D_real: 0.693 D_fake: 0.694 \n",
      "End of epoch 104 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001901\n",
      "(epoch: 105, iters: 80, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 180, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.291 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 380, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 480, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 580, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.298 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 105, iters: 680, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 780, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 880, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.232 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 980, time: 0.106, data: 0.002) G_GAN: 0.671 G_L1: 0.000 D_real: 0.672 D_fake: 0.715 \n",
      "(epoch: 105, iters: 1080, time: 0.097, data: 0.002) G_GAN: 0.675 G_L1: 0.000 D_real: 0.675 D_fake: 0.712 \n",
      "(epoch: 105, iters: 1180, time: 0.100, data: 0.002) G_GAN: 0.686 G_L1: 0.253 D_real: 0.686 D_fake: 0.701 \n",
      "(epoch: 105, iters: 1280, time: 0.109, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 105, iters: 1380, time: 0.096, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 105, iters: 1480, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.261 D_real: 0.692 D_fake: 0.696 \n",
      "(epoch: 105, iters: 1580, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 105, iters: 1680, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 105, iters: 1780, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.266 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 105, iters: 1880, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 1980, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 2080, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.242 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 105, iters: 2180, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 2280, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "saving the model at the end of epoch 105, iters 239400\n",
      "End of epoch 105 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001881\n",
      "(epoch: 106, iters: 100, time: 0.114, data: 0.286) G_GAN: 0.693 G_L1: 0.239 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 200, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 300, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 106, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.180 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 500, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 600, time: 0.107, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "saving the latest model (epoch 106, total_steps 240000)\n",
      "(epoch: 106, iters: 700, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.237 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 106, iters: 800, time: 0.099, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 106, iters: 900, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 1000, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.301 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 1100, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 1200, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 106, iters: 1300, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.341 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 106, iters: 1400, time: 0.113, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 1500, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 1600, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.126 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 1700, time: 0.099, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 106, iters: 1800, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 1900, time: 0.099, data: 0.003) G_GAN: 0.693 G_L1: 0.239 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 2000, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 2100, time: 0.094, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 106, iters: 2200, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.166 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 106 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001861\n",
      "(epoch: 107, iters: 20, time: 0.106, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 107, iters: 120, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 107, iters: 220, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.455 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 320, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 107, iters: 420, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 520, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.142 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 620, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 720, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 820, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.161 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 920, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 107, iters: 1020, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 107, iters: 1120, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.200 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 107, iters: 1220, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 1320, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 1420, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.236 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 1520, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 1620, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 1720, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.200 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 1820, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 107, iters: 1920, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 2020, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.258 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 2120, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 2220, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 107 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001842\n",
      "(epoch: 108, iters: 40, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.260 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 140, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 240, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 340, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 440, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 540, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 640, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.322 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 740, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 840, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 940, time: 0.098, data: 0.003) G_GAN: 0.693 G_L1: 0.554 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 1040, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 108, total_steps 245000)\n",
      "(epoch: 108, iters: 1140, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 108, iters: 1240, time: 0.106, data: 0.001) G_GAN: 0.694 G_L1: 0.367 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 108, iters: 1340, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 1440, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 1540, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.241 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 1640, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 1740, time: 0.112, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 1840, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.175 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 1940, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 2040, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 2140, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.100 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 2240, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "End of epoch 108 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001822\n",
      "(epoch: 109, iters: 60, time: 0.125, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 109, iters: 160, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.250 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 109, iters: 260, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 109, iters: 360, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 109, iters: 460, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.353 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 109, iters: 560, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 109, iters: 660, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 109, iters: 760, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.239 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 109, iters: 860, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 109, iters: 960, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 109, iters: 1060, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.072 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 109, iters: 1160, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 109, iters: 1260, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.216 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 109, iters: 1360, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.241 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 109, iters: 1460, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 109, iters: 1560, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 109, iters: 1660, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.248 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 109, iters: 1760, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 109, iters: 1860, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 109, iters: 1960, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.417 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 109, iters: 2060, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 109, iters: 2160, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 109, iters: 2260, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.221 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 109 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001802\n",
      "(epoch: 110, iters: 80, time: 0.115, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 180, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 280, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.161 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 380, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 480, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 580, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.395 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 680, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 780, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 880, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.200 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 980, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.016 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 1080, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 1180, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.082 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 1280, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 1380, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 1480, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.274 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 110, total_steps 250000)\n",
      "(epoch: 110, iters: 1580, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 1680, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 1780, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.412 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 1880, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 1980, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 2080, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.175 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 2180, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 2280, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 110, iters 250800\n",
      "End of epoch 110 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0001782\n",
      "(epoch: 111, iters: 100, time: 0.107, data: 0.289) G_GAN: 0.693 G_L1: 0.236 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 111, iters: 200, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 300, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.173 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 500, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 600, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 700, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.147 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 800, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 900, time: 0.108, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 111, iters: 1000, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.249 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 111, iters: 1100, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 1200, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 1300, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.272 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 1400, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 1500, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 1600, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.150 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 1700, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 1800, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 1900, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.369 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 2000, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 2100, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 2200, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.232 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 111 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001762\n",
      "(epoch: 112, iters: 20, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 120, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 220, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.234 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 320, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 420, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 520, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.162 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 620, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 720, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 820, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.146 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 920, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 1020, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 1120, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.118 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 1220, time: 0.106, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 1320, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 1420, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.222 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 1520, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 1620, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 1720, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.238 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 1820, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 1920, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 112, total_steps 255000)\n",
      "(epoch: 112, iters: 2020, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.315 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 2120, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 2220, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 112 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001743\n",
      "(epoch: 113, iters: 40, time: 0.114, data: 0.002) G_GAN: 0.693 G_L1: 0.165 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 140, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 240, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 340, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 440, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 540, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 640, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.230 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 740, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 840, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 940, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.363 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 1040, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 1140, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 1240, time: 0.112, data: 0.001) G_GAN: 0.693 G_L1: 0.451 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 1340, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 1440, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 1540, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.238 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 1640, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 1740, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 1840, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.109 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 1940, time: 0.112, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 2040, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 2140, time: 0.114, data: 0.002) G_GAN: 0.693 G_L1: 0.089 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 2240, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 113 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001723\n",
      "(epoch: 114, iters: 60, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 160, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.278 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 260, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 360, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 460, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.215 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 560, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 660, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 760, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.194 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 860, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 114, iters: 960, time: 0.098, data: 0.001) G_GAN: 0.758 G_L1: 0.000 D_real: 0.770 D_fake: 0.634 \n",
      "(epoch: 114, iters: 1060, time: 0.095, data: 0.001) G_GAN: 0.684 G_L1: 0.089 D_real: 0.684 D_fake: 0.703 \n",
      "(epoch: 114, iters: 1160, time: 0.096, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.687 D_fake: 0.700 \n",
      "(epoch: 114, iters: 1260, time: 0.100, data: 0.001) G_GAN: 0.690 G_L1: 0.039 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 114, iters: 1360, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.403 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 114, iters: 1460, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 114, iters: 1560, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 114, iters: 1660, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.288 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 114, iters: 1760, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 1860, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 114, iters: 1960, time: 0.097, data: 0.003) G_GAN: 0.694 G_L1: 0.262 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 114, iters: 2060, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 2160, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 114, iters: 2260, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.357 D_real: 0.693 D_fake: 0.694 \n",
      "End of epoch 114 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001703\n",
      "(epoch: 115, iters: 80, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 115, total_steps 260000)\n",
      "(epoch: 115, iters: 180, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 115, iters: 280, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.156 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 115, iters: 380, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 115, iters: 480, time: 0.100, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 115, iters: 580, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.246 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 680, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 780, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 880, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.255 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 115, iters: 980, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 1080, time: 0.109, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 115, iters: 1180, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.099 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 115, iters: 1280, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 1380, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 1480, time: 0.096, data: 0.002) G_GAN: 0.694 G_L1: 0.190 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 115, iters: 1580, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 115, iters: 1680, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 115, iters: 1780, time: 0.099, data: 0.003) G_GAN: 0.693 G_L1: 0.217 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 1880, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 1980, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 2080, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.201 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 115, iters: 2180, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 2280, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 115, iters 262200\n",
      "End of epoch 115 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001683\n",
      "(epoch: 116, iters: 100, time: 0.108, data: 0.289) G_GAN: 0.693 G_L1: 0.215 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 200, time: 0.108, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 116, iters: 300, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.126 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 500, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 116, iters: 600, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 116, iters: 700, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.124 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 800, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 900, time: 0.105, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 116, iters: 1000, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.189 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 116, iters: 1100, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 1200, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 116, iters: 1300, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.279 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 1400, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 1500, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 1600, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.176 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 1700, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 1800, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 1900, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.322 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 2000, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 2100, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 2200, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.179 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 116 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001663\n",
      "(epoch: 117, iters: 20, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 120, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 220, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.261 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 320, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 420, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 520, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.179 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 117, total_steps 265000)\n",
      "(epoch: 117, iters: 620, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 720, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 820, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.195 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 920, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 1020, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 117, iters: 1120, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.168 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 1220, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 1320, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 1420, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.229 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 1520, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 117, iters: 1620, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 1720, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.195 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 1820, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 1920, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.192 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 2020, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.177 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 2120, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 2220, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 117 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001644\n",
      "(epoch: 118, iters: 40, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.213 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 140, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 240, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 340, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 440, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 540, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 640, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.232 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 740, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 840, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 940, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.199 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 1040, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 1140, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 1240, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.478 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 1340, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 1440, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 1540, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.422 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 1640, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 1740, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 1840, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.175 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 1940, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 2040, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 2140, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.271 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 2240, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 118 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001624\n",
      "(epoch: 119, iters: 60, time: 0.117, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 160, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.298 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 260, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 360, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 460, time: 0.114, data: 0.002) G_GAN: 0.693 G_L1: 0.210 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 560, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 660, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 760, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.215 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 860, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 960, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 119, total_steps 270000)\n",
      "(epoch: 119, iters: 1060, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.087 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 1160, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 1260, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.580 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 1360, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.330 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 1460, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 1560, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 1660, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.173 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 1760, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 1860, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 1960, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.409 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 2060, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 2160, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 2260, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.144 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 119 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001604\n",
      "(epoch: 120, iters: 80, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 280, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.155 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 380, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 480, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 580, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.316 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 680, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 780, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 880, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.150 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 980, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 1080, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 1180, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.163 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 1280, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 1380, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 1480, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.271 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 1580, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 1680, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 1780, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.302 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 1880, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 1980, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 2080, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.171 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 2180, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 2280, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 120, iters 273600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 120 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0001584\n",
      "(epoch: 121, iters: 100, time: 0.108, data: 0.288) G_GAN: 0.693 G_L1: 0.214 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 200, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 300, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 400, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.198 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 500, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 600, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 700, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.157 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 800, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 900, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 1000, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.158 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 1100, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 121, iters: 1200, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 1300, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.236 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 1400, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 121, total_steps 275000)\n",
      "(epoch: 121, iters: 1500, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 1600, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.182 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 1700, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 1800, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 1900, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.297 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 2000, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 2100, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 2200, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.130 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 121 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001564\n",
      "(epoch: 122, iters: 20, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 120, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 220, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.260 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 320, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 420, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 520, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.229 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 620, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 720, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 820, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.226 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 920, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 1020, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 1120, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.132 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 1220, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 1320, time: 0.099, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 1420, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.134 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 1520, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 1620, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 1720, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.142 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 1820, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 1920, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 2020, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.166 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 2120, time: 0.116, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 2220, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 122 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001545\n",
      "(epoch: 123, iters: 40, time: 0.119, data: 0.002) G_GAN: 0.693 G_L1: 0.218 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 140, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 240, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 340, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.470 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 440, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 540, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 640, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.202 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 740, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 840, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 940, time: 0.113, data: 0.001) G_GAN: 0.693 G_L1: 0.169 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 1040, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 1140, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 1240, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.683 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 1340, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 1440, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 1540, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.197 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 1640, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 1740, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 1840, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.035 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 123, total_steps 280000)\n",
      "(epoch: 123, iters: 1940, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 2040, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 2140, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.089 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 2240, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 123 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001525\n",
      "(epoch: 124, iters: 60, time: 0.118, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 160, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.171 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 260, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 360, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 460, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.194 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 560, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 124, iters: 660, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 760, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.298 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 860, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 960, time: 0.099, data: 0.001) G_GAN: 0.749 G_L1: 0.000 D_real: 0.738 D_fake: 0.632 \n",
      "(epoch: 124, iters: 1060, time: 0.096, data: 0.002) G_GAN: 0.685 G_L1: 0.058 D_real: 0.684 D_fake: 0.652 \n",
      "(epoch: 124, iters: 1160, time: 0.095, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 124, iters: 1260, time: 0.100, data: 0.001) G_GAN: 0.691 G_L1: 0.200 D_real: 0.691 D_fake: 0.699 \n",
      "(epoch: 124, iters: 1360, time: 0.096, data: 0.002) G_GAN: 0.694 G_L1: 0.395 D_real: 0.694 D_fake: 0.696 \n",
      "(epoch: 124, iters: 1460, time: 0.105, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.696 \n",
      "(epoch: 124, iters: 1560, time: 0.095, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.711 D_fake: 0.676 \n",
      "(epoch: 124, iters: 1660, time: 0.096, data: 0.001) G_GAN: 0.700 G_L1: 0.289 D_real: 0.700 D_fake: 0.695 \n",
      "(epoch: 124, iters: 1760, time: 0.101, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 124, iters: 1860, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 124, iters: 1960, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.280 D_real: 0.692 D_fake: 0.692 \n",
      "(epoch: 124, iters: 2060, time: 0.108, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 124, iters: 2160, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 124, iters: 2260, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.276 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 124 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001505\n",
      "(epoch: 125, iters: 80, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 180, time: 0.098, data: 0.003) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 125, iters: 280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.214 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 380, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.690 \n",
      "(epoch: 125, iters: 480, time: 0.109, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 125, iters: 580, time: 0.099, data: 0.002) G_GAN: 0.692 G_L1: 0.233 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 125, iters: 680, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 125, iters: 780, time: 0.107, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 125, iters: 880, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.154 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 980, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 1080, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 1180, time: 0.100, data: 0.002) G_GAN: 0.694 G_L1: 0.113 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 125, iters: 1280, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 1380, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 1480, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.238 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 1580, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 125, iters: 1680, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 1780, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.184 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 1880, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 1980, time: 0.110, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 2080, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.157 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 2180, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 2280, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "saving the latest model (epoch 125, total_steps 285000)\n",
      "saving the model at the end of epoch 125, iters 285000\n",
      "End of epoch 125 / 200 \t Time Taken: 127 sec\n",
      "learning rate = 0.0001485\n",
      "(epoch: 126, iters: 100, time: 0.117, data: 0.282) G_GAN: 0.693 G_L1: 0.181 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 200, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 300, time: 0.097, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 400, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.150 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 126, iters: 500, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 600, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 126, iters: 700, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.162 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 800, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 900, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 1000, time: 0.096, data: 0.002) G_GAN: 0.694 G_L1: 0.138 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 126, iters: 1100, time: 0.114, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 1200, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 1300, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.254 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 1400, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 1500, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 1600, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.164 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 1700, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 1800, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 1900, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.179 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 2000, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 2100, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 126, iters: 2200, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.103 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 126 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001465\n",
      "(epoch: 127, iters: 20, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 120, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 220, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.221 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 320, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 420, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 520, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.185 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 620, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 720, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 820, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.286 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 920, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 127, iters: 1020, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 1120, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.193 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 1220, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 127, iters: 1320, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 1420, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.200 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 1520, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 1620, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 1720, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.230 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 1820, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 127, iters: 1920, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 2020, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.368 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 2120, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 2220, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 127 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001446\n",
      "(epoch: 128, iters: 40, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.181 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 140, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 240, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 340, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 440, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 128, total_steps 290000)\n",
      "(epoch: 128, iters: 540, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 640, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.206 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 740, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 840, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 940, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.246 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 1040, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 1140, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 1240, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.608 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 1340, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 1440, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 1540, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.275 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 1640, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 1740, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 1840, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.102 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 1940, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 2040, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 2140, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.129 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 2240, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 128 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001426\n",
      "(epoch: 129, iters: 60, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 129, iters: 160, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.249 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 129, iters: 260, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 129, iters: 360, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 129, iters: 460, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.213 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 129, iters: 560, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 129, iters: 660, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 129, iters: 760, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.218 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 129, iters: 860, time: 0.092, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 129, iters: 960, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 129, iters: 1060, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.087 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 129, iters: 1160, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 129, iters: 1260, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.631 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 129, iters: 1360, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.325 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 129, iters: 1460, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 129, iters: 1560, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 129, iters: 1660, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.250 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 129, iters: 1760, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 129, iters: 1860, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 129, iters: 1960, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.284 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 129, iters: 2060, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 129, iters: 2160, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 129, iters: 2260, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.213 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 129 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001406\n",
      "(epoch: 130, iters: 80, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 130, iters: 180, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 130, iters: 280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.227 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 130, iters: 380, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 130, iters: 480, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 130, iters: 580, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.243 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 130, iters: 680, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 130, iters: 780, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 130, iters: 880, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.167 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 130, total_steps 295000)\n",
      "(epoch: 130, iters: 980, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 130, iters: 1080, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 130, iters: 1180, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.258 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 130, iters: 1280, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 130, iters: 1380, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 130, iters: 1480, time: 0.113, data: 0.001) G_GAN: 0.693 G_L1: 0.130 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 130, iters: 1580, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 130, iters: 1680, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 130, iters: 1780, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.233 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 130, iters: 1880, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 130, iters: 1980, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 130, iters: 2080, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.210 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 130, iters: 2180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 130, iters: 2280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 130, iters 296400\n",
      "End of epoch 130 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001386\n",
      "(epoch: 131, iters: 100, time: 0.118, data: 0.277) G_GAN: 0.693 G_L1: 0.156 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 200, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 300, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 400, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.138 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 500, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 600, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 700, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.199 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 800, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 900, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 1000, time: 0.098, data: 0.003) G_GAN: 0.693 G_L1: 0.290 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 1100, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 1200, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 1300, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.276 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 1400, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 1500, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 1600, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.176 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 1700, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 1800, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 1900, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.381 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 2000, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 2100, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 2200, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.096 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 131 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001366\n",
      "(epoch: 132, iters: 20, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 120, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 220, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.222 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 320, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 420, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 520, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.138 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 620, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 720, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 820, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.174 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 920, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 1020, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 1120, time: 0.112, data: 0.002) G_GAN: 0.693 G_L1: 0.140 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 1220, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 1320, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 132, total_steps 300000)\n",
      "(epoch: 132, iters: 1420, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.123 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 1520, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 1620, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 1720, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.212 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 1820, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 1920, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 2020, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.211 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 2120, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 2220, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 132 / 200 \t Time Taken: 127 sec\n",
      "learning rate = 0.0001347\n",
      "(epoch: 133, iters: 40, time: 0.115, data: 0.002) G_GAN: 0.693 G_L1: 0.149 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 140, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 240, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 340, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.455 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 440, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 540, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 640, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.204 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 740, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 840, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 940, time: 0.101, data: 0.001) G_GAN: 0.690 G_L1: 0.226 D_real: 0.690 D_fake: 0.699 \n",
      "(epoch: 133, iters: 1040, time: 0.095, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 133, iters: 1140, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 1240, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.360 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 1340, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 1440, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 1540, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.279 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 1640, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 1740, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 1840, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.035 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 1940, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 2040, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 2140, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.085 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 2240, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 133 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001327\n",
      "(epoch: 134, iters: 60, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 160, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.209 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 134, iters: 260, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 360, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 460, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.167 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 560, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 660, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 760, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.214 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 860, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 960, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 1060, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.151 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 1160, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 1260, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.028 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 1360, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.345 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 1460, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 1560, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 1660, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.198 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 1760, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 134, total_steps 305000)\n",
      "(epoch: 134, iters: 1860, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 1960, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.129 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 2060, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 2160, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 2260, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.247 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 134 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001307\n",
      "(epoch: 135, iters: 80, time: 0.106, data: 0.004) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 180, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 280, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.273 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 380, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 480, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 580, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.267 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 680, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 780, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 880, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.210 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 980, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 1080, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 1180, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.137 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 1280, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 1380, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 1480, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.194 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 1580, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 1680, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 1780, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.364 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 1880, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 1980, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 2080, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.137 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 2180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 2280, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 135, iters 307800\n",
      "End of epoch 135 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001287\n",
      "(epoch: 136, iters: 100, time: 0.108, data: 0.271) G_GAN: 0.693 G_L1: 0.177 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 200, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 300, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 400, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.194 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 500, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 600, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 700, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.180 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 800, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 900, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 1000, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.159 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 1100, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 1200, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 1300, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.188 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 1400, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 1500, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 1600, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.101 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 1700, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 1800, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 1900, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.343 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 2000, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 2100, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 2200, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.130 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 136, total_steps 310000)\n",
      "End of epoch 136 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0001267\n",
      "(epoch: 137, iters: 20, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 120, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 220, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.192 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 320, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 420, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 520, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.240 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 620, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 720, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 820, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.174 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 137, iters: 920, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 1020, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 1120, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.255 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 1220, time: 0.099, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 1320, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 1420, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.150 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 1520, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 1620, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 1720, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.252 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 1820, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 1920, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 2020, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.128 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 2120, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 2220, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 137 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001248\n",
      "(epoch: 138, iters: 40, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.199 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 140, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 240, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 340, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 440, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 540, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 640, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.236 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 740, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 840, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 940, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.166 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 1040, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 1140, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 1240, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.321 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 1340, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 1440, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 1540, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.266 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 1640, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 1740, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 1840, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.108 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 1940, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 2040, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 2140, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.169 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 2240, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 138 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001228\n",
      "(epoch: 139, iters: 60, time: 0.115, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 160, time: 0.100, data: 0.006) G_GAN: 0.693 G_L1: 0.259 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 260, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 360, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 139, total_steps 315000)\n",
      "(epoch: 139, iters: 460, time: 0.112, data: 0.001) G_GAN: 0.693 G_L1: 0.160 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 560, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 660, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 760, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.223 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 860, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 960, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 1060, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.087 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 1160, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 1260, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.002 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 1360, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.242 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 1460, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 1560, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 1660, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.148 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 1760, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 1860, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 1960, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.257 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 2060, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 2160, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 2260, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.191 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 139 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001208\n",
      "(epoch: 140, iters: 80, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.239 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 380, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 480, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 580, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.246 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 680, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 780, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 880, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.274 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 980, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 1080, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 1180, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.158 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 1280, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 1380, time: 0.095, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 1480, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.267 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 1580, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 140, iters: 1680, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 1780, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.219 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 1880, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 1980, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 2080, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.140 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 2180, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 2280, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 140, iters 319200\n",
      "End of epoch 140 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001188\n",
      "(epoch: 141, iters: 100, time: 0.105, data: 0.265) G_GAN: 0.693 G_L1: 0.286 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 200, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 300, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 400, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.167 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 500, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 600, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 700, time: 0.112, data: 0.001) G_GAN: 0.693 G_L1: 0.166 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 800, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 141, total_steps 320000)\n",
      "(epoch: 141, iters: 900, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 1000, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.232 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 1100, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 1200, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 1300, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.184 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 1400, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 1500, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 1600, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.249 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 1700, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 1800, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 1900, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.315 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 2000, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 2100, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 2200, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.193 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 141 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001168\n",
      "(epoch: 142, iters: 20, time: 0.115, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 120, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 220, time: 0.117, data: 0.002) G_GAN: 0.693 G_L1: 0.280 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 320, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 420, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 520, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.120 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 620, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 720, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 820, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.191 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 920, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 1020, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 1120, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.151 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 1220, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 1320, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 1420, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.163 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 1520, time: 0.113, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 1620, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 1720, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.238 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 1820, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 1920, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 2020, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.324 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 2120, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 2220, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 142 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001149\n",
      "(epoch: 143, iters: 40, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.132 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 140, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 240, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 340, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 440, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 540, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 640, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.201 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 740, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 840, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 940, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.251 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 1040, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 1140, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 1240, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.349 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 143, total_steps 325000)\n",
      "(epoch: 143, iters: 1340, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 1440, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 1540, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.270 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 1640, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 1740, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 1840, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.078 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 1940, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 2040, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 2140, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.121 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 143, iters: 2240, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 143 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001129\n",
      "(epoch: 144, iters: 60, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 160, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.310 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 260, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 360, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 460, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.174 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 560, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 660, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 760, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.187 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 860, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 960, time: 0.095, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 1060, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.080 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 1160, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 1260, time: 0.097, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 1360, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.226 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 1460, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 1560, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 1660, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.215 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 1760, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 1860, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 1960, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.086 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 2060, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 2160, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 2260, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.203 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 144 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001109\n",
      "(epoch: 145, iters: 80, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 180, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 280, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.230 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 380, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 480, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 580, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.379 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 680, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 780, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 880, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.245 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 980, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 1080, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 1180, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.231 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 1280, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 1380, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 1480, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.160 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 1580, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 1680, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 145, total_steps 330000)\n",
      "(epoch: 145, iters: 1780, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.165 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 1880, time: 0.098, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 1980, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 2080, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.207 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 2180, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 2280, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 145, iters 330600\n",
      "End of epoch 145 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001089\n",
      "(epoch: 146, iters: 100, time: 0.105, data: 0.279) G_GAN: 0.693 G_L1: 0.244 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 200, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 300, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.194 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 500, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 600, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 700, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.160 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 800, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 900, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 1000, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.148 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 1100, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 1200, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 1300, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.237 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 1400, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 1500, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 1600, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.104 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 1700, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 1800, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 1900, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.336 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 2000, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 2100, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 2200, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.136 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 146 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001069\n",
      "(epoch: 147, iters: 20, time: 0.116, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 120, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 220, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.273 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 320, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 420, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 147, iters: 520, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.129 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 620, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 720, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 820, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.137 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 920, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 1020, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 1120, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.166 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 1220, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 1320, time: 0.112, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 1420, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.113 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 1520, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 1620, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 1720, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.207 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 1820, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 1920, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 2020, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.140 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 2120, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 147, total_steps 335000)\n",
      "(epoch: 147, iters: 2220, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 147 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001050\n",
      "(epoch: 148, iters: 40, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.156 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 140, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 240, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 340, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.351 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 440, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 540, time: 0.092, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 640, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.219 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 740, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 840, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 940, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.448 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 1040, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 1140, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 148, iters: 1240, time: 0.097, data: 0.002) G_GAN: 0.684 G_L1: 0.351 D_real: 0.684 D_fake: 0.702 \n",
      "(epoch: 148, iters: 1340, time: 0.100, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.714 D_fake: 0.673 \n",
      "(epoch: 148, iters: 1440, time: 0.099, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.687 D_fake: 0.708 \n",
      "(epoch: 148, iters: 1540, time: 0.097, data: 0.002) G_GAN: 0.696 G_L1: 0.203 D_real: 0.697 D_fake: 0.689 \n",
      "(epoch: 148, iters: 1640, time: 0.097, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.699 \n",
      "(epoch: 148, iters: 1740, time: 0.101, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 148, iters: 1840, time: 0.099, data: 0.002) G_GAN: 0.691 G_L1: 0.164 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 148, iters: 1940, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 148, iters: 2040, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 148, iters: 2140, time: 0.109, data: 0.002) G_GAN: 0.694 G_L1: 0.110 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 148, iters: 2240, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "End of epoch 148 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001030\n",
      "(epoch: 149, iters: 60, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 160, time: 0.110, data: 0.001) G_GAN: 0.694 G_L1: 0.201 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 149, iters: 260, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 360, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 460, time: 0.099, data: 0.002) G_GAN: 0.694 G_L1: 0.129 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 149, iters: 560, time: 0.113, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 660, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 760, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.251 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 860, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 960, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 1060, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.072 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 1160, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 1260, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 149, iters: 1360, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.261 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 1460, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 1560, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 1660, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.185 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 1760, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 1860, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 1960, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.142 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 149, iters: 2060, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 2160, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 2260, time: 0.095, data: 0.003) G_GAN: 0.694 G_L1: 0.227 D_real: 0.694 D_fake: 0.693 \n",
      "End of epoch 149 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001010\n",
      "(epoch: 150, iters: 80, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 180, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 280, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.105 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 150, total_steps 340000)\n",
      "(epoch: 150, iters: 380, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 480, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 580, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.184 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 680, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 780, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 880, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.160 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 980, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 1080, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 150, iters: 1180, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.166 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 1280, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 1380, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 1480, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.141 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 1580, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 1680, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 1780, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.233 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 1880, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 1980, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 2080, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.150 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 2180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 2280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "saving the model at the end of epoch 150, iters 342000\n",
      "End of epoch 150 / 200 \t Time Taken: 127 sec\n",
      "learning rate = 0.0000990\n",
      "(epoch: 151, iters: 100, time: 0.107, data: 0.267) G_GAN: 0.693 G_L1: 0.277 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 200, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 300, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 400, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.220 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 500, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 600, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 700, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.133 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 151, iters: 800, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 900, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 1000, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.192 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 1100, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 1200, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 1300, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.231 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 1400, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 1500, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 1600, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.148 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 1700, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 1800, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 1900, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.206 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 2000, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 2100, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 2200, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.115 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 151 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000970\n",
      "(epoch: 152, iters: 20, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 120, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 220, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.175 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 320, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 420, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 520, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.124 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 620, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 720, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 152, total_steps 345000)\n",
      "(epoch: 152, iters: 820, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.123 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 920, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 1020, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 1120, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.155 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 1220, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 1320, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 1420, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.120 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 1520, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 1620, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 1720, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.179 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 1820, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 1920, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 2020, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.154 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 2120, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 2220, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 152 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000950\n",
      "(epoch: 153, iters: 40, time: 0.115, data: 0.002) G_GAN: 0.693 G_L1: 0.159 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 140, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 240, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 340, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.446 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 440, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 540, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 640, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.205 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 740, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 840, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 940, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.494 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 1040, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 1140, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 1240, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.457 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 1340, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 1440, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 1540, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.185 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 1640, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 1740, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 153, iters: 1840, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.085 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 1940, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 2040, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 2140, time: 0.112, data: 0.002) G_GAN: 0.693 G_L1: 0.149 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 2240, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 153 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000931\n",
      "(epoch: 154, iters: 60, time: 0.115, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 160, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.232 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 260, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 360, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 460, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.153 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 560, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 660, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 760, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.238 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 860, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 960, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 1060, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.079 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 1160, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 154, total_steps 350000)\n",
      "(epoch: 154, iters: 1260, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 1360, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.227 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 1460, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 1560, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 1660, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.180 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 1760, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 1860, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 1960, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.151 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 2060, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 2160, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 2260, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.200 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 154 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000911\n",
      "(epoch: 155, iters: 80, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 180, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 280, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.193 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 380, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 480, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 580, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.172 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 680, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 780, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 880, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.301 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 980, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 1080, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 1180, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.109 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 1280, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 1380, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 1480, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.188 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 1580, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 1680, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 1780, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.194 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 1880, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 1980, time: 0.113, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 2080, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.186 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 2180, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 2280, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 155, iters 353400\n",
      "End of epoch 155 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0000891\n",
      "(epoch: 156, iters: 100, time: 0.120, data: 0.278) G_GAN: 0.693 G_L1: 0.156 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 200, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 300, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 400, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.181 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 500, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 600, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 700, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.139 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 800, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 900, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 1000, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.224 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 1100, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 1200, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 1300, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.183 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 1400, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 1500, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 1600, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.118 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 156, total_steps 355000)\n",
      "(epoch: 156, iters: 1700, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 1800, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 1900, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.271 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 2000, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 2100, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 2200, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.104 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 156 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000871\n",
      "(epoch: 157, iters: 20, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.002 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 157, iters: 120, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 220, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.130 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 320, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 420, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 520, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.126 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 620, time: 0.110, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 720, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 820, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.178 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 920, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 1020, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 1120, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.188 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 1220, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 1320, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 1420, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.182 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 1520, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 1620, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 1720, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.209 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 1820, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 1920, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 2020, time: 0.108, data: 0.003) G_GAN: 0.693 G_L1: 0.137 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 2120, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 2220, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 157 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000851\n",
      "(epoch: 158, iters: 40, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.133 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 140, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 240, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 340, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.523 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 440, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 540, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 640, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.177 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 740, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 840, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 940, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.287 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 1040, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 1140, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 1240, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.363 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 1340, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 1440, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 1540, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.197 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 1640, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 1740, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 1840, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.153 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 1940, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 2040, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 158, total_steps 360000)\n",
      "(epoch: 158, iters: 2140, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.074 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 2240, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 158 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000832\n",
      "(epoch: 159, iters: 60, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 160, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.207 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 260, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 360, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 460, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.195 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 560, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 660, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 760, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.194 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 860, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 960, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 1060, time: 0.095, data: 0.003) G_GAN: 0.693 G_L1: 0.153 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 1160, time: 0.095, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 1260, time: 0.112, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 1360, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.263 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 1460, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 1560, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 1660, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.214 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 1760, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 1860, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 1960, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.125 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 2060, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 2160, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 2260, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.170 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 159 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000812\n",
      "(epoch: 160, iters: 80, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 180, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 280, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.181 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 380, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 480, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 580, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.183 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 680, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 780, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 160, iters: 880, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.258 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 980, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 1080, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 1180, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.218 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 1280, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 1380, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 1480, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.169 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 1580, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 1680, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 1780, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.205 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 1880, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 1980, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 2080, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.142 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 2180, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 2280, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 160, iters 364800\n",
      "End of epoch 160 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000792\n",
      "(epoch: 161, iters: 100, time: 0.104, data: 0.278) G_GAN: 0.693 G_L1: 0.139 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 200, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 161, total_steps 365000)\n",
      "(epoch: 161, iters: 300, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 400, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.138 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 500, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 600, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 700, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.122 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 800, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 900, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 1000, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.179 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 1100, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 1200, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 1300, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.232 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 1400, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 1500, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 1600, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.131 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 1700, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 1800, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 1900, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.328 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 2000, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 2100, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 2200, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.099 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 161 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000772\n",
      "(epoch: 162, iters: 20, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 120, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 220, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.187 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 320, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 420, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 520, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.113 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 620, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 720, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 820, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.222 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 920, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 1020, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 1120, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.197 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 1220, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 1320, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 1420, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.129 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 1520, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 1620, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 1720, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.194 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 1820, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 1920, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 2020, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.129 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 2120, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 2220, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 162 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000752\n",
      "(epoch: 163, iters: 40, time: 0.123, data: 0.002) G_GAN: 0.693 G_L1: 0.190 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 140, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 240, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 340, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.475 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 440, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 540, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 640, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.203 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 163, total_steps 370000)\n",
      "(epoch: 163, iters: 740, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 840, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 940, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.299 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 1040, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 1140, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 1240, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.311 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 1340, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 1440, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 163, iters: 1540, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.198 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 1640, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 1740, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 1840, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.078 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 1940, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 2040, time: 0.101, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 2140, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.101 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 2240, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 163 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000733\n",
      "(epoch: 164, iters: 60, time: 0.119, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 160, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.176 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 260, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 360, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 460, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.171 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 560, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 660, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 760, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.167 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 860, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 960, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 1060, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.061 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 1160, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 1260, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 1360, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.184 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 1460, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 1560, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 1660, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.134 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 1760, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 1860, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 1960, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.145 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 2060, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 2160, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 2260, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.140 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 164 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000713\n",
      "(epoch: 165, iters: 80, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 180, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 280, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.161 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 380, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 480, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 580, time: 0.113, data: 0.001) G_GAN: 0.693 G_L1: 0.199 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 680, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 780, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 880, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.162 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 980, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 1080, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 165, total_steps 375000)\n",
      "(epoch: 165, iters: 1180, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.095 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 1280, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 1380, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 1480, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.167 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 1580, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 1680, time: 0.099, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 1780, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.234 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 1880, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 1980, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 2080, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.133 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 2180, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 2280, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 165, iters 376200\n",
      "End of epoch 165 / 200 \t Time Taken: 127 sec\n",
      "learning rate = 0.0000693\n",
      "(epoch: 166, iters: 100, time: 0.107, data: 0.287) G_GAN: 0.693 G_L1: 0.160 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 200, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 300, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 400, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.169 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 500, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 600, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 700, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.137 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 800, time: 0.114, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 900, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 1000, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.161 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 1100, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 1200, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 1300, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.144 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 1400, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 1500, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 1600, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.139 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 1700, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 1800, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 1900, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.245 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 2000, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 2100, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 166, iters: 2200, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.159 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 166 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000673\n",
      "(epoch: 167, iters: 20, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 120, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 220, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.180 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 320, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 420, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 520, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.161 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 620, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 720, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 820, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.143 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 920, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 1020, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 1120, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.090 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 1220, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 1320, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 1420, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.147 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 1520, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 167, total_steps 380000)\n",
      "(epoch: 167, iters: 1620, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 1720, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.176 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 1820, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 1920, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 2020, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.217 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 2120, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 2220, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 167 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000653\n",
      "(epoch: 168, iters: 40, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.132 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 140, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 240, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 340, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.272 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 440, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 540, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 640, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.203 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 740, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 840, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 940, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.325 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 1040, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 1140, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 1240, time: 0.095, data: 0.005) G_GAN: 0.693 G_L1: 0.342 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 1340, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 1440, time: 0.114, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 1540, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.204 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 1640, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 1740, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 1840, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.129 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 1940, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 2040, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 2140, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.058 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 2240, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 168 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000634\n",
      "(epoch: 169, iters: 60, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 160, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.171 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 260, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 360, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 460, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.135 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 560, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 660, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 760, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.286 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 860, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 960, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 1060, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.126 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 1160, time: 0.106, data: 0.000) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 1260, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.002 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 1360, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.226 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 1460, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 1560, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 1660, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.183 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 1760, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 1860, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 1960, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.085 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 169, total_steps 385000)\n",
      "(epoch: 169, iters: 2060, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 2160, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 2260, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.213 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 169 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000614\n",
      "(epoch: 170, iters: 80, time: 0.104, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 180, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 280, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.169 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 380, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 170, iters: 480, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 580, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.168 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 680, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 780, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 880, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.194 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 980, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 1080, time: 0.095, data: 0.000) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 1180, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.103 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 1280, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 1380, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 1480, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.175 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 1580, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 1680, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 1780, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.181 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 1880, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 1980, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 2080, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.173 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 2180, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 2280, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 170, iters 387600\n",
      "End of epoch 170 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000594\n",
      "(epoch: 171, iters: 100, time: 0.108, data: 0.299) G_GAN: 0.693 G_L1: 0.181 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 200, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 300, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 400, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.177 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 500, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 600, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 700, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.122 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 800, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 900, time: 0.092, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 1000, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.118 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 1100, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 1200, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 1300, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.204 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 1400, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 1500, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 1600, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.213 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 1700, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 1800, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 1900, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.202 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 2000, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 2100, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 2200, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.105 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 171 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000574\n",
      "(epoch: 172, iters: 20, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 120, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 172, total_steps 390000)\n",
      "(epoch: 172, iters: 220, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.174 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 320, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 420, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 520, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.111 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 620, time: 0.113, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 720, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 820, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.202 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 920, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 1020, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 1120, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.087 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 1220, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 1320, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 1420, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.105 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 1520, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 1620, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 1720, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.177 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 1820, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 1920, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 2020, time: 0.112, data: 0.001) G_GAN: 0.693 G_L1: 0.216 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 2120, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 2220, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 172 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000554\n",
      "(epoch: 173, iters: 40, time: 0.114, data: 0.001) G_GAN: 0.693 G_L1: 0.172 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 140, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 240, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 340, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.364 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 440, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 540, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 640, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.159 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 740, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 840, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 940, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.197 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 1040, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 173, iters: 1140, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 1240, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.366 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 1340, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 1440, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 1540, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.218 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 1640, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 1740, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 1840, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.052 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 1940, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 2040, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 2140, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.067 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 2240, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 173 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000535\n",
      "(epoch: 174, iters: 60, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 160, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.200 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 260, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 360, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 460, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.169 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 560, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 174, total_steps 395000)\n",
      "(epoch: 174, iters: 660, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 760, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.193 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 860, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 960, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 1060, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.065 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 1160, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 1260, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 1360, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.241 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 1460, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 1560, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 1660, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.147 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 1760, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 1860, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 1960, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.188 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 2060, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 2160, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 2260, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.162 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 174 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000515\n",
      "(epoch: 175, iters: 80, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 180, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 280, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.122 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 380, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 480, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 580, time: 0.117, data: 0.002) G_GAN: 0.693 G_L1: 0.225 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 680, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 780, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 880, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.143 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 980, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 1080, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 1180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.142 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 1280, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 1380, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 1480, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.149 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 1580, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 1680, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 1780, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.203 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 1880, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 1980, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 2080, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.159 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 2180, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 2280, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 175, iters 399000\n",
      "End of epoch 175 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000495\n",
      "(epoch: 176, iters: 100, time: 0.105, data: 0.280) G_GAN: 0.693 G_L1: 0.160 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 200, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 300, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 400, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.134 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 500, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 600, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 700, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.116 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 800, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 900, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 1000, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.125 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 176, total_steps 400000)\n",
      "(epoch: 176, iters: 1100, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 1200, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 1300, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.248 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 1400, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 1500, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 1600, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.121 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 176, iters: 1700, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 1800, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 1900, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.379 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 2000, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 2100, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 2200, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.112 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 176 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000475\n",
      "(epoch: 177, iters: 20, time: 0.118, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 120, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 220, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.168 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 320, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 420, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 520, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.113 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 620, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 720, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 820, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.104 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 920, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 1020, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 1120, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.203 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 1220, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 1320, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 1420, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.106 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 1520, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 1620, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 1720, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.171 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 1820, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 1920, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 2020, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.167 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 2120, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 2220, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 177 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000455\n",
      "(epoch: 178, iters: 40, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.104 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 140, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 240, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 340, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.560 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 440, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 540, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 640, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.151 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 740, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 840, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 940, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.213 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 1040, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 1140, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 1240, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.295 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 1340, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 1440, time: 0.114, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 178, total_steps 405000)\n",
      "(epoch: 178, iters: 1540, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.195 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 1640, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 1740, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 1840, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.099 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 1940, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 2040, time: 0.114, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 2140, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.115 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 2240, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 178 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000436\n",
      "(epoch: 179, iters: 60, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 160, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.148 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 260, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 360, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 460, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.171 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 560, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 660, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 760, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.232 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 860, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 960, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 1060, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.086 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 1160, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 1260, time: 0.112, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 1360, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.285 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 1460, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 1560, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 1660, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.171 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 1760, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 1860, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 1960, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.115 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 2060, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 2160, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 2260, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.157 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 179 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 180, iters: 80, time: 0.114, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 180, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 280, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.096 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 380, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 480, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 580, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.186 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 680, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 780, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 880, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.155 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 980, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 1080, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 1180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.140 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 1280, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 1380, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 1480, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.153 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 1580, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 1680, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 1780, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.161 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 1880, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 180, total_steps 410000)\n",
      "(epoch: 180, iters: 1980, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 2080, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.134 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 2180, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 2280, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 180, iters 410400\n",
      "End of epoch 180 / 200 \t Time Taken: 127 sec\n",
      "learning rate = 0.0000396\n",
      "(epoch: 181, iters: 100, time: 0.118, data: 3.273) G_GAN: 0.693 G_L1: 0.189 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 200, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 300, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.189 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 500, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 600, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 700, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.118 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 800, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 900, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 1000, time: 0.112, data: 0.002) G_GAN: 0.693 G_L1: 0.174 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 1100, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 1200, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 1300, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.183 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 1400, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 1500, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 1600, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.129 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 1700, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 1800, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 1900, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.203 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 2000, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 2100, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 2200, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.189 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 181 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0000376\n",
      "(epoch: 182, iters: 20, time: 0.118, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 120, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 220, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.189 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 320, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 420, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 520, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.122 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 620, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 720, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 820, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.138 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 920, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 1020, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 1120, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.095 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 1220, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 1320, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 1420, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.127 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 1520, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 1620, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 1720, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.173 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 1820, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 1920, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 2020, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.110 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 2120, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 2220, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 182 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000356\n",
      "(epoch: 183, iters: 40, time: 0.113, data: 0.002) G_GAN: 0.693 G_L1: 0.121 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 183, total_steps 415000)\n",
      "(epoch: 183, iters: 140, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 240, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 340, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.475 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 440, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 540, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 640, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.145 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 183, iters: 740, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 840, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 940, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.166 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 1040, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 1140, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 1240, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.392 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 1340, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 1440, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 1540, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.153 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 1640, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 1740, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 1840, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.132 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 1940, time: 0.114, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 2040, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 2140, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.132 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 2240, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 183 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000337\n",
      "(epoch: 184, iters: 60, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 160, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.248 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 260, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 360, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 460, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.151 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 560, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 660, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 760, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.221 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 860, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 960, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 1060, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.031 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 1160, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 1260, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 1360, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.259 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 1460, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 1560, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 1660, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.134 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 1760, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 1860, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 1960, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.120 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 2060, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 2160, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 2260, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.166 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 184 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000317\n",
      "(epoch: 185, iters: 80, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 180, time: 0.097, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 280, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.147 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 380, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 480, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 185, total_steps 420000)\n",
      "(epoch: 185, iters: 580, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.227 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 680, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 780, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 880, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.166 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 980, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 1080, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 1180, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.201 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 1280, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 1380, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 1480, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.188 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 1580, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 1680, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 1780, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.194 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 1880, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 1980, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 2080, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.134 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 2180, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 2280, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 185, iters 421800\n",
      "End of epoch 185 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0000297\n",
      "(epoch: 186, iters: 100, time: 0.121, data: 0.291) G_GAN: 0.693 G_L1: 0.192 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 200, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 300, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 400, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.139 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 500, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 600, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 700, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.109 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 800, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 900, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 1000, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.151 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 1100, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 1200, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 1300, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.147 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 186, iters: 1400, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 1500, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 1600, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.129 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 1700, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 1800, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 1900, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.151 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 2000, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 2100, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 2200, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.120 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 186 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000277\n",
      "(epoch: 187, iters: 20, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 120, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 220, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.208 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 320, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 420, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 520, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.137 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 620, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 720, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 820, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.139 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 920, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 187, total_steps 425000)\n",
      "(epoch: 187, iters: 1020, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 1120, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.102 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 1220, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 1320, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 1420, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.100 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 1520, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 1620, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 1720, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.172 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 1820, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 1920, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 2020, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.161 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 2120, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 2220, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 187 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000257\n",
      "(epoch: 188, iters: 40, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.143 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 140, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 240, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 340, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.308 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 440, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 540, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 640, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.154 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 740, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 840, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 940, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.215 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 1040, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 1140, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 1240, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.395 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 1340, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 1440, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 1540, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.196 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 1640, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 1740, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 1840, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.070 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 1940, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 2040, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 2140, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.098 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 2240, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 188 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000238\n",
      "(epoch: 189, iters: 60, time: 0.113, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 160, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.185 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 260, time: 0.098, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 360, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 460, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.143 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 560, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 660, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 760, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.196 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 860, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 960, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 1060, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.043 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 1160, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 1260, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 1360, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.169 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 189, total_steps 430000)\n",
      "(epoch: 189, iters: 1460, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 1560, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 1660, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.180 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 1760, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 1860, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 1960, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.140 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 189, iters: 2060, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 2160, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 2260, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.191 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 189 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0000218\n",
      "(epoch: 190, iters: 80, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 180, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 280, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.121 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 380, time: 0.112, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 480, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 580, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.153 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 680, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 780, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 880, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.168 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 980, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 1080, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 1180, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.231 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 1280, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 1380, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 1480, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.189 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 1580, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 1680, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 1780, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.188 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 1880, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 1980, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 2080, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.171 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 2180, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 2280, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 190, iters 433200\n",
      "End of epoch 190 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000198\n",
      "(epoch: 191, iters: 100, time: 0.120, data: 0.284) G_GAN: 0.693 G_L1: 0.212 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 200, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 300, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 400, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.110 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 500, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 600, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 700, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.169 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 800, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 900, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 1000, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.115 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 1100, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 1200, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 1300, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.217 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 1400, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 1500, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 1600, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.099 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 1700, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 1800, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 191, total_steps 435000)\n",
      "(epoch: 191, iters: 1900, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.166 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 2000, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 2100, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 2200, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.095 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 191 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000178\n",
      "(epoch: 192, iters: 20, time: 0.121, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 120, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 220, time: 0.119, data: 0.002) G_GAN: 0.693 G_L1: 0.236 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 320, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 420, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 520, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.128 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 620, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 720, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 820, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.129 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 920, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 1020, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 1120, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.146 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 1220, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 1320, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 1420, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.101 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 1520, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 1620, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 1720, time: 0.112, data: 0.001) G_GAN: 0.693 G_L1: 0.173 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 1820, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 1920, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 2020, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.122 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 2120, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 2220, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 192 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000158\n",
      "(epoch: 193, iters: 40, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.122 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 140, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 240, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 193, iters: 340, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.269 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 440, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 540, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 640, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.151 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 740, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 840, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 940, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.564 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 1040, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 1140, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 1240, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.324 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 1340, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 1440, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 1540, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.215 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 1640, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 1740, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 1840, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.104 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 1940, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 2040, time: 0.097, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 2140, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.064 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 2240, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 193, total_steps 440000)\n",
      "End of epoch 193 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000139\n",
      "(epoch: 194, iters: 60, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 160, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.155 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 260, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 360, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 460, time: 0.114, data: 0.001) G_GAN: 0.693 G_L1: 0.170 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 560, time: 0.112, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 660, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 760, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.171 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 860, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 960, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 1060, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.084 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 1160, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 1260, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 1360, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.216 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 1460, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 1560, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 1660, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.135 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 1760, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 1860, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 1960, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.125 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 2060, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 2160, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 2260, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.191 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 194 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000119\n",
      "(epoch: 195, iters: 80, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 180, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 280, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.128 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 380, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 480, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 580, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.177 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 680, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 780, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 880, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.155 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 980, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 1080, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 1180, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.141 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 1280, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 1380, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 1480, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.165 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 1580, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 1680, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 1780, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.219 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 1880, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 1980, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 2080, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.139 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 2180, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 2280, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 195, iters 444600\n",
      "End of epoch 195 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000099\n",
      "(epoch: 196, iters: 100, time: 0.107, data: 0.274) G_GAN: 0.693 G_L1: 0.156 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 200, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 300, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 400, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.137 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 196, total_steps 445000)\n",
      "(epoch: 196, iters: 500, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 600, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 700, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.180 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 800, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 900, time: 0.092, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 196, iters: 1000, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.166 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 1100, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 1200, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 1300, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.177 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 1400, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 1500, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 1600, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.122 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 1700, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 1800, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 1900, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.213 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 2000, time: 0.116, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 2100, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 2200, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.073 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 196 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000079\n",
      "(epoch: 197, iters: 20, time: 0.119, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 120, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 220, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.171 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 320, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 420, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 520, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.110 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 620, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 720, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 820, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.166 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 920, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 1020, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 1120, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.135 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 1220, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 1320, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 1420, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.121 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 1520, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 1620, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 1720, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.172 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 1820, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 1920, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 2020, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.129 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 2120, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 2220, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 197 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000059\n",
      "(epoch: 198, iters: 40, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.137 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 140, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 240, time: 0.108, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 340, time: 0.096, data: 0.003) G_GAN: 0.693 G_L1: 0.323 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 440, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 540, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 640, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.159 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 740, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 840, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 198, total_steps 450000)\n",
      "(epoch: 198, iters: 940, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.173 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 1040, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 1140, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 1240, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.203 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 1340, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 1440, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 1540, time: 0.112, data: 0.002) G_GAN: 0.693 G_L1: 0.207 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 1640, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 1740, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 1840, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.064 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 1940, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 2040, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 2140, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.078 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 2240, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 198 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000040\n",
      "(epoch: 199, iters: 60, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 160, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.181 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 260, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 360, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 460, time: 0.113, data: 0.001) G_GAN: 0.693 G_L1: 0.148 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 560, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 660, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 760, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.185 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 860, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 960, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 1060, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.051 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 1160, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 1260, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.347 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 1360, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.248 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 1460, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 1560, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 1660, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.149 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 199, iters: 1760, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 1860, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 1960, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.131 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 2060, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 2160, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 2260, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.139 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 199 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0000020\n",
      "(epoch: 200, iters: 80, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 280, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.103 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 380, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 480, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 580, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.178 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 680, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 780, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 880, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.220 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 980, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 1080, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 1180, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.162 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 1280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 200, total_steps 455000)\n",
      "(epoch: 200, iters: 1380, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 1480, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.115 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 1580, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 1680, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 1780, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.190 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 1880, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 1980, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 2080, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.142 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 2180, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 2280, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 200, iters 456000\n",
      "End of epoch 200 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0000000\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 2280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "DataParallel(\n",
      "  (module): UnetGenerator(\n",
      "    (model): UnetSkipConnectionBlock(\n",
      "      (model): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): UnetSkipConnectionBlock(\n",
      "          (model): Sequential(\n",
      "            (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "            (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (3): UnetSkipConnectionBlock(\n",
      "              (model): Sequential(\n",
      "                (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (3): UnetSkipConnectionBlock(\n",
      "                  (model): Sequential(\n",
      "                    (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                    (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (3): UnetSkipConnectionBlock(\n",
      "                      (model): Sequential(\n",
      "                        (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                        (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                        (3): UnetSkipConnectionBlock(\n",
      "                          (model): Sequential(\n",
      "                            (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                            (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                            (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                            (3): UnetSkipConnectionBlock(\n",
      "                              (model): Sequential(\n",
      "                                (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                                (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                                (3): UnetSkipConnectionBlock(\n",
      "                                  (model): Sequential(\n",
      "                                    (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                                    (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                    (2): ReLU(inplace)\n",
      "                                    (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                                  )\n",
      "                                )\n",
      "                                (4): ReLU(inplace)\n",
      "                                (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                                (7): Dropout(p=0.5)\n",
      "                              )\n",
      "                            )\n",
      "                            (4): ReLU(inplace)\n",
      "                            (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                            (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                            (7): Dropout(p=0.5)\n",
      "                          )\n",
      "                        )\n",
      "                        (4): ReLU(inplace)\n",
      "                        (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                        (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                        (7): Dropout(p=0.5)\n",
      "                      )\n",
      "                    )\n",
      "                    (4): ReLU(inplace)\n",
      "                    (5): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                )\n",
      "                (4): ReLU(inplace)\n",
      "                (5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (4): ReLU(inplace)\n",
      "            (5): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): ReLU(inplace)\n",
      "        (3): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "        (4): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "DataParallel(\n",
      "  (module): NLayerDiscriminator(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (3): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (5): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (6): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (7): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (8): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "      (9): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network D] Total number of parameters : 2.767 M\n",
      "-----------------------------------------------\n",
      "(epoch: 1, iters: 100, time: 0.119, data: 0.271) G_GAN: 3.555 G_L1: 12.700 D_real: 0.006 D_fake: 0.004 \n",
      "(epoch: 1, iters: 200, time: 0.115, data: 0.001) G_GAN: 5.656 G_L1: 5.184 D_real: 0.001 D_fake: 0.000 \n",
      "(epoch: 1, iters: 300, time: 0.117, data: 0.001) G_GAN: 9.409 G_L1: 6.494 D_real: 0.000 D_fake: 0.001 \n",
      "(epoch: 1, iters: 400, time: 0.110, data: 0.001) G_GAN: 14.792 G_L1: 6.256 D_real: 0.000 D_fake: 0.000 \n",
      "(epoch: 1, iters: 500, time: 0.116, data: 0.002) G_GAN: 11.128 G_L1: 8.750 D_real: 0.000 D_fake: 0.000 \n",
      "(epoch: 1, iters: 600, time: 0.123, data: 0.001) G_GAN: 1.577 G_L1: 1.524 D_real: 0.754 D_fake: 0.041 \n",
      "(epoch: 1, iters: 700, time: 0.101, data: 0.001) G_GAN: 10.686 G_L1: 4.482 D_real: 0.002 D_fake: 0.000 \n",
      "(epoch: 1, iters: 800, time: 0.118, data: 0.001) G_GAN: 9.556 G_L1: 10.400 D_real: 0.001 D_fake: 0.000 \n",
      "(epoch: 1, iters: 900, time: 0.094, data: 0.001) G_GAN: 0.588 G_L1: 0.024 D_real: 0.583 D_fake: 0.820 \n",
      "(epoch: 1, iters: 1000, time: 0.114, data: 0.001) G_GAN: 0.569 G_L1: 2.329 D_real: 0.547 D_fake: 0.843 \n",
      "(epoch: 1, iters: 1100, time: 0.115, data: 0.001) G_GAN: 0.616 G_L1: 0.149 D_real: 0.629 D_fake: 0.663 \n",
      "(epoch: 1, iters: 1200, time: 0.098, data: 0.001) G_GAN: 0.732 G_L1: 0.025 D_real: 0.749 D_fake: 0.641 \n",
      "(epoch: 1, iters: 1300, time: 0.107, data: 0.001) G_GAN: 0.692 G_L1: 3.029 D_real: 0.608 D_fake: 0.708 \n",
      "(epoch: 1, iters: 1400, time: 0.098, data: 0.001) G_GAN: 0.719 G_L1: 0.356 D_real: 0.729 D_fake: 0.671 \n",
      "(epoch: 1, iters: 1500, time: 0.097, data: 0.001) G_GAN: 0.721 G_L1: 0.004 D_real: 0.723 D_fake: 0.679 \n",
      "(epoch: 1, iters: 1600, time: 0.107, data: 0.001) G_GAN: 0.728 G_L1: 1.704 D_real: 0.637 D_fake: 0.661 \n",
      "(epoch: 1, iters: 1700, time: 0.101, data: 0.002) G_GAN: 0.708 G_L1: 0.047 D_real: 0.714 D_fake: 0.673 \n",
      "(epoch: 1, iters: 1800, time: 0.096, data: 0.002) G_GAN: 0.727 G_L1: 0.001 D_real: 0.723 D_fake: 0.629 \n",
      "(epoch: 1, iters: 1900, time: 0.104, data: 0.001) G_GAN: 0.789 G_L1: 3.402 D_real: 0.607 D_fake: 0.634 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 1, iters: 2000, time: 0.107, data: 0.002) G_GAN: 0.700 G_L1: 0.005 D_real: 0.701 D_fake: 0.686 \n",
      "(epoch: 1, iters: 2100, time: 0.094, data: 0.001) G_GAN: 0.678 G_L1: 0.000 D_real: 0.630 D_fake: 0.768 \n",
      "(epoch: 1, iters: 2200, time: 0.099, data: 0.001) G_GAN: 0.836 G_L1: 1.548 D_real: 0.636 D_fake: 0.528 \n",
      "End of epoch 1 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 20, time: 0.105, data: 0.001) G_GAN: 0.707 G_L1: 0.022 D_real: 0.721 D_fake: 0.620 \n",
      "(epoch: 2, iters: 120, time: 0.097, data: 0.001) G_GAN: 0.639 G_L1: 0.011 D_real: 0.649 D_fake: 0.739 \n",
      "(epoch: 2, iters: 220, time: 0.100, data: 0.001) G_GAN: 0.842 G_L1: 2.839 D_real: 0.599 D_fake: 0.641 \n",
      "(epoch: 2, iters: 320, time: 0.107, data: 0.001) G_GAN: 0.702 G_L1: 0.009 D_real: 0.708 D_fake: 0.679 \n",
      "(epoch: 2, iters: 420, time: 0.110, data: 0.001) G_GAN: 0.641 G_L1: 0.002 D_real: 0.638 D_fake: 0.751 \n",
      "(epoch: 2, iters: 520, time: 0.097, data: 0.001) G_GAN: 0.785 G_L1: 1.561 D_real: 0.656 D_fake: 0.623 \n",
      "(epoch: 2, iters: 620, time: 0.101, data: 0.001) G_GAN: 0.703 G_L1: 0.007 D_real: 0.717 D_fake: 0.670 \n",
      "(epoch: 2, iters: 720, time: 0.098, data: 0.001) G_GAN: 0.664 G_L1: 0.002 D_real: 0.664 D_fake: 0.723 \n",
      "(epoch: 2, iters: 820, time: 0.107, data: 0.001) G_GAN: 0.898 G_L1: 1.956 D_real: 0.672 D_fake: 0.549 \n",
      "(epoch: 2, iters: 920, time: 0.096, data: 0.001) G_GAN: 0.829 G_L1: 0.000 D_real: 0.876 D_fake: 0.840 \n",
      "(epoch: 2, iters: 1020, time: 0.097, data: 0.001) G_GAN: 0.689 G_L1: 0.005 D_real: 0.689 D_fake: 0.698 \n",
      "(epoch: 2, iters: 1120, time: 0.101, data: 0.001) G_GAN: 0.675 G_L1: 1.056 D_real: 0.599 D_fake: 0.687 \n",
      "(epoch: 2, iters: 1220, time: 0.110, data: 0.001) G_GAN: 0.698 G_L1: 0.001 D_real: 0.713 D_fake: 0.684 \n",
      "(epoch: 2, iters: 1320, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.001 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 2, iters: 1420, time: 0.097, data: 0.001) G_GAN: 0.744 G_L1: 2.049 D_real: 0.595 D_fake: 0.655 \n",
      "(epoch: 2, iters: 1520, time: 0.100, data: 0.001) G_GAN: 0.721 G_L1: 0.008 D_real: 0.732 D_fake: 0.656 \n",
      "(epoch: 2, iters: 1620, time: 0.094, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.690 D_fake: 0.685 \n",
      "(epoch: 2, iters: 1720, time: 0.100, data: 0.002) G_GAN: 0.856 G_L1: 3.102 D_real: 0.632 D_fake: 0.613 \n",
      "(epoch: 2, iters: 1820, time: 0.102, data: 0.001) G_GAN: 0.672 G_L1: 0.002 D_real: 0.681 D_fake: 0.706 \n",
      "(epoch: 2, iters: 1920, time: 0.097, data: 0.001) G_GAN: 0.680 G_L1: 0.009 D_real: 0.679 D_fake: 0.708 \n",
      "(epoch: 2, iters: 2020, time: 0.098, data: 0.001) G_GAN: 0.844 G_L1: 1.669 D_real: 0.676 D_fake: 0.569 \n",
      "(epoch: 2, iters: 2120, time: 0.110, data: 0.001) G_GAN: 0.747 G_L1: 0.001 D_real: 0.819 D_fake: 0.591 \n",
      "(epoch: 2, iters: 2220, time: 0.097, data: 0.001) G_GAN: 0.689 G_L1: 0.005 D_real: 0.693 D_fake: 0.697 \n",
      "End of epoch 2 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 3, iters: 40, time: 0.105, data: 0.001) G_GAN: 0.797 G_L1: 1.451 D_real: 0.655 D_fake: 0.578 \n",
      "(epoch: 3, iters: 140, time: 0.095, data: 0.001) G_GAN: 0.702 G_L1: 0.001 D_real: 0.716 D_fake: 0.671 \n",
      "(epoch: 3, iters: 240, time: 0.095, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.704 D_fake: 0.684 \n",
      "(epoch: 3, iters: 340, time: 0.097, data: 0.001) G_GAN: 0.762 G_L1: 0.576 D_real: 0.669 D_fake: 0.629 \n",
      "(epoch: 3, iters: 440, time: 0.097, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.755 D_fake: 0.635 \n",
      "saving the latest model (epoch 3, total_steps 5000)\n",
      "(epoch: 3, iters: 540, time: 0.106, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.688 D_fake: 0.689 \n",
      "(epoch: 3, iters: 640, time: 0.111, data: 0.002) G_GAN: 0.725 G_L1: 2.378 D_real: 0.611 D_fake: 0.584 \n",
      "(epoch: 3, iters: 740, time: 0.105, data: 0.001) G_GAN: 0.765 G_L1: 0.000 D_real: 0.773 D_fake: 0.620 \n",
      "(epoch: 3, iters: 840, time: 0.094, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.734 D_fake: 0.655 \n",
      "(epoch: 3, iters: 940, time: 0.101, data: 0.001) G_GAN: 0.837 G_L1: 1.610 D_real: 0.680 D_fake: 0.574 \n",
      "(epoch: 3, iters: 1040, time: 0.097, data: 0.001) G_GAN: 0.722 G_L1: 0.195 D_real: 0.715 D_fake: 0.668 \n",
      "(epoch: 3, iters: 1140, time: 0.107, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.697 D_fake: 0.690 \n",
      "(epoch: 3, iters: 1240, time: 0.095, data: 0.001) G_GAN: 0.843 G_L1: 2.348 D_real: 0.632 D_fake: 0.586 \n",
      "(epoch: 3, iters: 1340, time: 0.099, data: 0.001) G_GAN: 0.701 G_L1: 0.002 D_real: 0.725 D_fake: 0.679 \n",
      "(epoch: 3, iters: 1440, time: 0.099, data: 0.001) G_GAN: 0.687 G_L1: 0.005 D_real: 0.681 D_fake: 0.707 \n",
      "(epoch: 3, iters: 1540, time: 0.111, data: 0.001) G_GAN: 0.764 G_L1: 1.729 D_real: 0.629 D_fake: 0.626 \n",
      "(epoch: 3, iters: 1640, time: 0.097, data: 0.001) G_GAN: 0.678 G_L1: 0.001 D_real: 0.664 D_fake: 0.724 \n",
      "(epoch: 3, iters: 1740, time: 0.099, data: 0.001) G_GAN: 0.684 G_L1: 0.003 D_real: 0.676 D_fake: 0.712 \n",
      "(epoch: 3, iters: 1840, time: 0.097, data: 0.001) G_GAN: 0.771 G_L1: 0.334 D_real: 0.694 D_fake: 0.612 \n",
      "(epoch: 3, iters: 1940, time: 0.097, data: 0.001) G_GAN: 0.698 G_L1: 0.002 D_real: 0.693 D_fake: 0.679 \n",
      "(epoch: 3, iters: 2040, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.001 D_real: 0.696 D_fake: 0.685 \n",
      "(epoch: 3, iters: 2140, time: 0.102, data: 0.001) G_GAN: 0.761 G_L1: 0.735 D_real: 0.661 D_fake: 0.632 \n",
      "(epoch: 3, iters: 2240, time: 0.107, data: 0.001) G_GAN: 0.691 G_L1: 0.004 D_real: 0.702 D_fake: 0.676 \n",
      "End of epoch 3 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 4, iters: 60, time: 0.117, data: 0.001) G_GAN: 0.695 G_L1: 0.002 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 4, iters: 160, time: 0.100, data: 0.001) G_GAN: 0.779 G_L1: 3.043 D_real: 0.558 D_fake: 0.663 \n",
      "(epoch: 4, iters: 260, time: 0.096, data: 0.001) G_GAN: 0.704 G_L1: 0.005 D_real: 0.677 D_fake: 0.711 \n",
      "(epoch: 4, iters: 360, time: 0.097, data: 0.001) G_GAN: 0.677 G_L1: 0.000 D_real: 0.662 D_fake: 0.726 \n",
      "(epoch: 4, iters: 460, time: 0.102, data: 0.001) G_GAN: 0.814 G_L1: 2.557 D_real: 0.616 D_fake: 0.613 \n",
      "(epoch: 4, iters: 560, time: 0.100, data: 0.001) G_GAN: 0.680 G_L1: 0.001 D_real: 0.682 D_fake: 0.706 \n",
      "(epoch: 4, iters: 660, time: 0.099, data: 0.001) G_GAN: 0.684 G_L1: 0.001 D_real: 0.683 D_fake: 0.704 \n",
      "(epoch: 4, iters: 760, time: 0.099, data: 0.001) G_GAN: 0.792 G_L1: 2.143 D_real: 0.639 D_fake: 0.607 \n",
      "(epoch: 4, iters: 860, time: 0.106, data: 0.001) G_GAN: 0.738 G_L1: 0.734 D_real: 0.690 D_fake: 0.659 \n",
      "(epoch: 4, iters: 960, time: 0.105, data: 0.001) G_GAN: 0.742 G_L1: 0.001 D_real: 0.744 D_fake: 0.646 \n",
      "(epoch: 4, iters: 1060, time: 0.096, data: 0.001) G_GAN: 0.711 G_L1: 0.258 D_real: 0.696 D_fake: 0.678 \n",
      "(epoch: 4, iters: 1160, time: 0.095, data: 0.002) G_GAN: 0.707 G_L1: 0.104 D_real: 0.712 D_fake: 0.617 \n",
      "(epoch: 4, iters: 1260, time: 0.097, data: 0.001) G_GAN: 0.721 G_L1: 1.723 D_real: 0.705 D_fake: 0.680 \n",
      "(epoch: 4, iters: 1360, time: 0.097, data: 0.002) G_GAN: 0.706 G_L1: 4.502 D_real: 0.602 D_fake: 0.775 \n",
      "(epoch: 4, iters: 1460, time: 0.094, data: 0.001) G_GAN: 0.708 G_L1: 0.001 D_real: 0.708 D_fake: 0.678 \n",
      "(epoch: 4, iters: 1560, time: 0.096, data: 0.001) G_GAN: 0.704 G_L1: 0.001 D_real: 0.704 D_fake: 0.682 \n",
      "(epoch: 4, iters: 1660, time: 0.096, data: 0.001) G_GAN: 0.673 G_L1: 0.611 D_real: 0.682 D_fake: 0.682 \n",
      "(epoch: 4, iters: 1760, time: 0.101, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.707 D_fake: 0.679 \n",
      "(epoch: 4, iters: 1860, time: 0.099, data: 0.001) G_GAN: 0.700 G_L1: 0.001 D_real: 0.700 D_fake: 0.686 \n",
      "(epoch: 4, iters: 1960, time: 0.108, data: 0.001) G_GAN: 0.698 G_L1: 0.481 D_real: 0.700 D_fake: 0.689 \n",
      "(epoch: 4, iters: 2060, time: 0.093, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.692 D_fake: 0.684 \n",
      "(epoch: 4, iters: 2160, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 4, iters: 2260, time: 0.093, data: 0.001) G_GAN: 0.673 G_L1: 1.115 D_real: 0.670 D_fake: 0.718 \n",
      "End of epoch 4 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 5, iters: 80, time: 0.103, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.700 D_fake: 0.686 \n",
      "(epoch: 5, iters: 180, time: 0.090, data: 0.001) G_GAN: 0.710 G_L1: 0.001 D_real: 0.714 D_fake: 0.673 \n",
      "(epoch: 5, iters: 280, time: 0.098, data: 0.002) G_GAN: 0.687 G_L1: 1.150 D_real: 0.690 D_fake: 0.693 \n",
      "(epoch: 5, iters: 380, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 5, iters: 480, time: 0.097, data: 0.001) G_GAN: 0.697 G_L1: 0.001 D_real: 0.697 D_fake: 0.688 \n",
      "(epoch: 5, iters: 580, time: 0.101, data: 0.001) G_GAN: 0.668 G_L1: 0.727 D_real: 0.665 D_fake: 0.691 \n",
      "(epoch: 5, iters: 680, time: 0.097, data: 0.002) G_GAN: 0.696 G_L1: 0.399 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 5, iters: 780, time: 0.096, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 5, iters: 880, time: 0.105, data: 0.002) G_GAN: 0.685 G_L1: 0.594 D_real: 0.684 D_fake: 0.692 \n",
      "saving the latest model (epoch 5, total_steps 10000)\n",
      "(epoch: 5, iters: 980, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 2.142 D_real: 0.699 D_fake: 0.687 \n",
      "(epoch: 5, iters: 1080, time: 0.095, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 5, iters: 1180, time: 0.111, data: 0.001) G_GAN: 0.683 G_L1: 0.995 D_real: 0.692 D_fake: 0.706 \n",
      "(epoch: 5, iters: 1280, time: 0.097, data: 0.001) G_GAN: 0.698 G_L1: 0.394 D_real: 0.698 D_fake: 0.689 \n",
      "(epoch: 5, iters: 1380, time: 0.096, data: 0.001) G_GAN: 0.698 G_L1: 0.001 D_real: 0.698 D_fake: 0.700 \n",
      "(epoch: 5, iters: 1480, time: 0.096, data: 0.001) G_GAN: 0.690 G_L1: 0.324 D_real: 0.688 D_fake: 0.697 \n",
      "(epoch: 5, iters: 1580, time: 0.095, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.695 \n",
      "(epoch: 5, iters: 1680, time: 0.111, data: 0.001) G_GAN: 0.696 G_L1: 0.001 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 5, iters: 1780, time: 0.099, data: 0.001) G_GAN: 0.686 G_L1: 0.694 D_real: 0.683 D_fake: 0.701 \n",
      "(epoch: 5, iters: 1880, time: 0.099, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.699 D_fake: 0.688 \n",
      "(epoch: 5, iters: 1980, time: 0.100, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.689 \n",
      "(epoch: 5, iters: 2080, time: 0.096, data: 0.001) G_GAN: 0.695 G_L1: 0.369 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 5, iters: 2180, time: 0.099, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.701 D_fake: 0.685 \n",
      "(epoch: 5, iters: 2280, time: 0.095, data: 0.001) G_GAN: 0.691 G_L1: 0.001 D_real: 0.691 D_fake: 0.696 \n",
      "saving the model at the end of epoch 5, iters 11400\n",
      "End of epoch 5 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 6, iters: 100, time: 0.108, data: 0.308) G_GAN: 0.686 G_L1: 0.445 D_real: 0.684 D_fake: 0.701 \n",
      "(epoch: 6, iters: 200, time: 0.096, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.697 \n",
      "(epoch: 6, iters: 300, time: 0.106, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 6, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.691 G_L1: 0.331 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 6, iters: 500, time: 0.098, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.704 D_fake: 0.689 \n",
      "(epoch: 6, iters: 600, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.693 \n",
      "(epoch: 6, iters: 700, time: 0.111, data: 0.001) G_GAN: 0.692 G_L1: 0.465 D_real: 0.690 D_fake: 0.694 \n",
      "(epoch: 6, iters: 800, time: 0.111, data: 0.001) G_GAN: 0.696 G_L1: 0.002 D_real: 0.696 D_fake: 0.704 \n",
      "(epoch: 6, iters: 900, time: 0.094, data: 0.001) G_GAN: 0.670 G_L1: 0.000 D_real: 0.668 D_fake: 0.719 \n",
      "(epoch: 6, iters: 1000, time: 0.100, data: 0.001) G_GAN: 0.706 G_L1: 0.726 D_real: 0.707 D_fake: 0.679 \n",
      "(epoch: 6, iters: 1100, time: 0.108, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.688 D_fake: 0.698 \n",
      "(epoch: 6, iters: 1200, time: 0.098, data: 0.001) G_GAN: 0.708 G_L1: 0.000 D_real: 0.707 D_fake: 0.680 \n",
      "(epoch: 6, iters: 1300, time: 0.111, data: 0.002) G_GAN: 0.665 G_L1: 0.963 D_real: 0.667 D_fake: 0.723 \n",
      "(epoch: 6, iters: 1400, time: 0.098, data: 0.001) G_GAN: 0.684 G_L1: 1.180 D_real: 0.683 D_fake: 0.698 \n",
      "(epoch: 6, iters: 1500, time: 0.097, data: 0.001) G_GAN: 0.671 G_L1: 0.000 D_real: 0.670 D_fake: 0.718 \n",
      "(epoch: 6, iters: 1600, time: 0.097, data: 0.001) G_GAN: 0.685 G_L1: 0.370 D_real: 0.686 D_fake: 0.701 \n",
      "(epoch: 6, iters: 1700, time: 0.099, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.697 D_fake: 0.673 \n",
      "(epoch: 6, iters: 1800, time: 0.095, data: 0.001) G_GAN: 0.683 G_L1: 0.001 D_real: 0.683 D_fake: 0.704 \n",
      "(epoch: 6, iters: 1900, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.778 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 6, iters: 2000, time: 0.110, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.687 D_fake: 0.699 \n",
      "(epoch: 6, iters: 2100, time: 0.107, data: 0.002) G_GAN: 0.699 G_L1: 0.001 D_real: 0.667 D_fake: 0.614 \n",
      "(epoch: 6, iters: 2200, time: 0.113, data: 0.002) G_GAN: 0.672 G_L1: 0.297 D_real: 0.670 D_fake: 0.719 \n",
      "End of epoch 6 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 7, iters: 20, time: 0.108, data: 0.001) G_GAN: 0.703 G_L1: 0.009 D_real: 0.703 D_fake: 0.683 \n",
      "(epoch: 7, iters: 120, time: 0.098, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.699 D_fake: 0.681 \n",
      "(epoch: 7, iters: 220, time: 0.101, data: 0.001) G_GAN: 0.673 G_L1: 0.702 D_real: 0.673 D_fake: 0.714 \n",
      "(epoch: 7, iters: 320, time: 0.095, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.695 D_fake: 0.690 \n",
      "(epoch: 7, iters: 420, time: 0.099, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 7, iters: 520, time: 0.106, data: 0.001) G_GAN: 0.708 G_L1: 0.760 D_real: 0.708 D_fake: 0.684 \n",
      "(epoch: 7, iters: 620, time: 0.096, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.704 D_fake: 0.689 \n",
      "(epoch: 7, iters: 720, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.696 \n",
      "(epoch: 7, iters: 820, time: 0.094, data: 0.001) G_GAN: 0.690 G_L1: 0.657 D_real: 0.691 D_fake: 0.697 \n",
      "(epoch: 7, iters: 920, time: 0.094, data: 0.001) G_GAN: 0.685 G_L1: 0.000 D_real: 0.686 D_fake: 0.688 \n",
      "(epoch: 7, iters: 1020, time: 0.096, data: 0.001) G_GAN: 0.699 G_L1: 0.000 D_real: 0.699 D_fake: 0.688 \n",
      "(epoch: 7, iters: 1120, time: 0.098, data: 0.001) G_GAN: 0.700 G_L1: 1.002 D_real: 0.697 D_fake: 0.687 \n",
      "(epoch: 7, iters: 1220, time: 0.108, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.689 \n",
      "(epoch: 7, iters: 1320, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.696 \n",
      "saving the latest model (epoch 7, total_steps 15000)\n",
      "(epoch: 7, iters: 1420, time: 0.113, data: 0.001) G_GAN: 0.693 G_L1: 0.626 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 7, iters: 1520, time: 0.100, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 7, iters: 1620, time: 0.093, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 7, iters: 1720, time: 0.099, data: 0.001) G_GAN: 0.685 G_L1: 0.776 D_real: 0.683 D_fake: 0.696 \n",
      "(epoch: 7, iters: 1820, time: 0.109, data: 0.001) G_GAN: 0.705 G_L1: 0.099 D_real: 0.705 D_fake: 0.682 \n",
      "(epoch: 7, iters: 1920, time: 0.098, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.689 \n",
      "(epoch: 7, iters: 2020, time: 0.099, data: 0.001) G_GAN: 0.690 G_L1: 0.527 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 7, iters: 2120, time: 0.108, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.690 D_fake: 0.701 \n",
      "(epoch: 7, iters: 2220, time: 0.100, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.699 D_fake: 0.687 \n",
      "End of epoch 7 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 8, iters: 40, time: 0.107, data: 0.001) G_GAN: 0.694 G_L1: 0.438 D_real: 0.693 D_fake: 0.689 \n",
      "(epoch: 8, iters: 140, time: 0.097, data: 0.001) G_GAN: 0.702 G_L1: 0.000 D_real: 0.703 D_fake: 0.687 \n",
      "(epoch: 8, iters: 240, time: 0.097, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.691 D_fake: 0.697 \n",
      "(epoch: 8, iters: 340, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 8, iters: 440, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 8, iters: 540, time: 0.092, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 8, iters: 640, time: 0.097, data: 0.001) G_GAN: 0.691 G_L1: 0.741 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 8, iters: 740, time: 0.107, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.688 \n",
      "(epoch: 8, iters: 840, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 8, iters: 940, time: 0.097, data: 0.001) G_GAN: 0.697 G_L1: 1.273 D_real: 0.693 D_fake: 0.690 \n",
      "(epoch: 8, iters: 1040, time: 0.096, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 8, iters: 1140, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 8, iters: 1240, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.832 D_real: 0.691 D_fake: 0.693 \n",
      "(epoch: 8, iters: 1340, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.695 \n",
      "(epoch: 8, iters: 1440, time: 0.118, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 8, iters: 1540, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.584 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 8, iters: 1640, time: 0.097, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.697 D_fake: 0.690 \n",
      "(epoch: 8, iters: 1740, time: 0.111, data: 0.001) G_GAN: 0.697 G_L1: 0.015 D_real: 0.697 D_fake: 0.689 \n",
      "(epoch: 8, iters: 1840, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 1.106 D_real: 0.697 D_fake: 0.689 \n",
      "(epoch: 8, iters: 1940, time: 0.098, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.689 \n",
      "(epoch: 8, iters: 2040, time: 0.111, data: 0.001) G_GAN: 0.685 G_L1: 0.000 D_real: 0.687 D_fake: 0.699 \n",
      "(epoch: 8, iters: 2140, time: 0.098, data: 0.002) G_GAN: 0.705 G_L1: 0.162 D_real: 0.704 D_fake: 0.693 \n",
      "(epoch: 8, iters: 2240, time: 0.100, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.688 D_fake: 0.692 \n",
      "End of epoch 8 / 200 \t Time Taken: 121 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 9, iters: 60, time: 0.107, data: 0.001) G_GAN: 0.681 G_L1: 0.000 D_real: 0.681 D_fake: 0.693 \n",
      "(epoch: 9, iters: 160, time: 0.108, data: 0.002) G_GAN: 0.686 G_L1: 0.551 D_real: 0.686 D_fake: 0.697 \n",
      "(epoch: 9, iters: 260, time: 0.096, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.695 D_fake: 0.693 \n",
      "(epoch: 9, iters: 360, time: 0.106, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 9, iters: 460, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.309 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 9, iters: 560, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.180 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 9, iters: 660, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 9, iters: 760, time: 0.100, data: 0.001) G_GAN: 0.692 G_L1: 0.651 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 9, iters: 860, time: 0.094, data: 0.001) G_GAN: 0.692 G_L1: 3.584 D_real: 0.696 D_fake: 0.694 \n",
      "(epoch: 9, iters: 960, time: 0.098, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.691 D_fake: 0.699 \n",
      "(epoch: 9, iters: 1060, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.109 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 9, iters: 1160, time: 0.095, data: 0.001) G_GAN: 0.699 G_L1: 1.384 D_real: 0.700 D_fake: 0.683 \n",
      "(epoch: 9, iters: 1260, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 1.468 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 9, iters: 1360, time: 0.099, data: 0.001) G_GAN: 0.689 G_L1: 1.134 D_real: 0.688 D_fake: 0.694 \n",
      "(epoch: 9, iters: 1460, time: 0.096, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.695 \n",
      "(epoch: 9, iters: 1560, time: 0.100, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.690 \n",
      "(epoch: 9, iters: 1660, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.596 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 9, iters: 1760, time: 0.097, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.689 \n",
      "saving the latest model (epoch 9, total_steps 20000)\n",
      "(epoch: 9, iters: 1860, time: 0.097, data: 0.001) G_GAN: 0.685 G_L1: 0.000 D_real: 0.683 D_fake: 0.704 \n",
      "(epoch: 9, iters: 1960, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.417 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 9, iters: 2060, time: 0.094, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 9, iters: 2160, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 9, iters: 2260, time: 0.094, data: 0.002) G_GAN: 0.673 G_L1: 0.614 D_real: 0.680 D_fake: 0.702 \n",
      "End of epoch 9 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 10, iters: 80, time: 0.102, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.695 D_fake: 0.694 \n",
      "(epoch: 10, iters: 180, time: 0.099, data: 0.002) G_GAN: 0.675 G_L1: 0.000 D_real: 0.674 D_fake: 0.713 \n",
      "(epoch: 10, iters: 280, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.779 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 10, iters: 380, time: 0.101, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 10, iters: 480, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 10, iters: 580, time: 0.100, data: 0.001) G_GAN: 0.692 G_L1: 0.572 D_real: 0.692 D_fake: 0.691 \n",
      "(epoch: 10, iters: 680, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 10, iters: 780, time: 0.106, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.698 \n",
      "(epoch: 10, iters: 880, time: 0.096, data: 0.001) G_GAN: 0.699 G_L1: 0.688 D_real: 0.698 D_fake: 0.687 \n",
      "(epoch: 10, iters: 980, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 2.595 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 10, iters: 1080, time: 0.095, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 10, iters: 1180, time: 0.102, data: 0.001) G_GAN: 0.690 G_L1: 0.479 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 10, iters: 1280, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 10, iters: 1380, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.697 \n",
      "(epoch: 10, iters: 1480, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.245 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 10, iters: 1580, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 10, iters: 1680, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 10, iters: 1780, time: 0.099, data: 0.001) G_GAN: 0.689 G_L1: 0.680 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 10, iters: 1880, time: 0.110, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 10, iters: 1980, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 10, iters: 2080, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.273 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 10, iters: 2180, time: 0.107, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 10, iters: 2280, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "saving the model at the end of epoch 10, iters 22800\n",
      "End of epoch 10 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 11, iters: 100, time: 0.120, data: 0.277) G_GAN: 0.691 G_L1: 0.481 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 11, iters: 200, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 11, iters: 300, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 11, iters: 400, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.214 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 11, iters: 500, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 11, iters: 600, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.001 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 11, iters: 700, time: 0.107, data: 0.001) G_GAN: 0.694 G_L1: 0.432 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 11, iters: 800, time: 0.100, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 11, iters: 900, time: 0.094, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 11, iters: 1000, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.760 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 11, iters: 1100, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 11, iters: 1200, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 11, iters: 1300, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.678 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 11, iters: 1400, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 1.540 D_real: 0.694 D_fake: 0.695 \n",
      "(epoch: 11, iters: 1500, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 11, iters: 1600, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.292 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 11, iters: 1700, time: 0.099, data: 0.001) G_GAN: 0.695 G_L1: 0.002 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 11, iters: 1800, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.001 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 11, iters: 1900, time: 0.098, data: 0.001) G_GAN: 0.688 G_L1: 0.508 D_real: 0.687 D_fake: 0.699 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 11, iters: 2000, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.001 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 11, iters: 2100, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 11, iters: 2200, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.461 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 11, total_steps 25000)\n",
      "End of epoch 11 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 12, iters: 20, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.015 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 12, iters: 120, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 12, iters: 220, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.322 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 12, iters: 320, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 12, iters: 420, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 12, iters: 520, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.956 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 12, iters: 620, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 12, iters: 720, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 12, iters: 820, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.211 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 12, iters: 920, time: 0.097, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.700 D_fake: 0.686 \n",
      "(epoch: 12, iters: 1020, time: 0.101, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 12, iters: 1120, time: 0.101, data: 0.001) G_GAN: 0.694 G_L1: 0.922 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 12, iters: 1220, time: 0.113, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.695 \n",
      "(epoch: 12, iters: 1320, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 12, iters: 1420, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.452 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 12, iters: 1520, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 12, iters: 1620, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 12, iters: 1720, time: 0.101, data: 0.001) G_GAN: 0.692 G_L1: 0.582 D_real: 0.692 D_fake: 0.692 \n",
      "(epoch: 12, iters: 1820, time: 0.100, data: 0.001) G_GAN: 0.698 G_L1: 0.021 D_real: 0.698 D_fake: 0.688 \n",
      "(epoch: 12, iters: 1920, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 12, iters: 2020, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 1.165 D_real: 0.692 D_fake: 0.696 \n",
      "(epoch: 12, iters: 2120, time: 0.098, data: 0.001) G_GAN: 0.702 G_L1: 0.000 D_real: 0.702 D_fake: 0.684 \n",
      "(epoch: 12, iters: 2220, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "End of epoch 12 / 200 \t Time Taken: 121 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 13, iters: 40, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.425 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 13, iters: 140, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 13, iters: 240, time: 0.097, data: 0.001) G_GAN: 0.655 G_L1: 0.000 D_real: 0.658 D_fake: 0.716 \n",
      "(epoch: 13, iters: 340, time: 0.096, data: 0.001) G_GAN: 0.689 G_L1: 0.576 D_real: 0.689 D_fake: 0.698 \n",
      "(epoch: 13, iters: 440, time: 0.094, data: 0.001) G_GAN: 0.685 G_L1: 0.000 D_real: 0.686 D_fake: 0.695 \n",
      "(epoch: 13, iters: 540, time: 0.096, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.687 D_fake: 0.699 \n",
      "(epoch: 13, iters: 640, time: 0.098, data: 0.001) G_GAN: 0.697 G_L1: 0.345 D_real: 0.698 D_fake: 0.689 \n",
      "(epoch: 13, iters: 740, time: 0.094, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 13, iters: 840, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 13, iters: 940, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 1.402 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 13, iters: 1040, time: 0.092, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 13, iters: 1140, time: 0.103, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 13, iters: 1240, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.498 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 13, iters: 1340, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 13, iters: 1440, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 13, iters: 1540, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.794 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 13, iters: 1640, time: 0.109, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 13, iters: 1740, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 13, iters: 1840, time: 0.099, data: 0.002) G_GAN: 0.694 G_L1: 0.303 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 13, iters: 1940, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 13, iters: 2040, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 13, iters: 2140, time: 0.112, data: 0.001) G_GAN: 0.692 G_L1: 0.163 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 13, iters: 2240, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 13 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 14, iters: 60, time: 0.107, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 14, iters: 160, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.445 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 14, iters: 260, time: 0.113, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 14, iters: 360, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 14, total_steps 30000)\n",
      "(epoch: 14, iters: 460, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.606 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 14, iters: 560, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 14, iters: 660, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 14, iters: 760, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.688 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 14, iters: 860, time: 0.095, data: 0.001) G_GAN: 0.690 G_L1: 0.001 D_real: 0.690 D_fake: 0.699 \n",
      "(epoch: 14, iters: 960, time: 0.095, data: 0.001) G_GAN: 0.714 G_L1: 0.000 D_real: 0.715 D_fake: 0.672 \n",
      "(epoch: 14, iters: 1060, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.232 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 14, iters: 1160, time: 0.106, data: 0.001) G_GAN: 0.708 G_L1: 0.000 D_real: 0.708 D_fake: 0.679 \n",
      "(epoch: 14, iters: 1260, time: 0.098, data: 0.001) G_GAN: 0.699 G_L1: 0.714 D_real: 0.699 D_fake: 0.688 \n",
      "(epoch: 14, iters: 1360, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.818 D_real: 0.694 D_fake: 0.691 \n",
      "(epoch: 14, iters: 1460, time: 0.096, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 14, iters: 1560, time: 0.096, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 14, iters: 1660, time: 0.099, data: 0.001) G_GAN: 0.695 G_L1: 0.492 D_real: 0.695 D_fake: 0.693 \n",
      "(epoch: 14, iters: 1760, time: 0.098, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.690 \n",
      "(epoch: 14, iters: 1860, time: 0.099, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.694 D_fake: 0.689 \n",
      "(epoch: 14, iters: 1960, time: 0.109, data: 0.002) G_GAN: 0.691 G_L1: 0.438 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 14, iters: 2060, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 14, iters: 2160, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 14, iters: 2260, time: 0.096, data: 0.001) G_GAN: 0.696 G_L1: 0.530 D_real: 0.696 D_fake: 0.690 \n",
      "End of epoch 14 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 15, iters: 80, time: 0.104, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 15, iters: 180, time: 0.097, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.690 \n",
      "(epoch: 15, iters: 280, time: 0.097, data: 0.001) G_GAN: 0.690 G_L1: 0.646 D_real: 0.690 D_fake: 0.697 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 15, iters: 380, time: 0.099, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 15, iters: 480, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 15, iters: 580, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.618 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 15, iters: 680, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.001 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 15, iters: 780, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 15, iters: 880, time: 0.094, data: 0.001) G_GAN: 0.689 G_L1: 0.435 D_real: 0.689 D_fake: 0.696 \n",
      "(epoch: 15, iters: 980, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 1.093 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 15, iters: 1080, time: 0.107, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 15, iters: 1180, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.396 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 15, iters: 1280, time: 0.099, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 15, iters: 1380, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 15, iters: 1480, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.669 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 15, iters: 1580, time: 0.096, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 15, iters: 1680, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 15, iters: 1780, time: 0.100, data: 0.001) G_GAN: 0.691 G_L1: 0.569 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 15, iters: 1880, time: 0.098, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 15, iters: 1980, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 15, iters: 2080, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.203 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 15, iters: 2180, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 15, iters: 2280, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "saving the model at the end of epoch 15, iters 34200\n",
      "End of epoch 15 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 16, iters: 100, time: 0.110, data: 0.281) G_GAN: 0.691 G_L1: 0.350 D_real: 0.691 D_fake: 0.693 \n",
      "(epoch: 16, iters: 200, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.697 \n",
      "(epoch: 16, iters: 300, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 16, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.387 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 16, iters: 500, time: 0.097, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 16, iters: 600, time: 0.099, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 16, iters: 700, time: 0.096, data: 0.001) G_GAN: 0.695 G_L1: 0.372 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 16, iters: 800, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "saving the latest model (epoch 16, total_steps 35000)\n",
      "(epoch: 16, iters: 900, time: 0.090, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 16, iters: 1000, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.599 D_real: 0.691 D_fake: 0.692 \n",
      "(epoch: 16, iters: 1100, time: 0.100, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 16, iters: 1200, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 16, iters: 1300, time: 0.106, data: 0.002) G_GAN: 0.696 G_L1: 0.979 D_real: 0.697 D_fake: 0.690 \n",
      "(epoch: 16, iters: 1400, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 1.062 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 16, iters: 1500, time: 0.096, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 16, iters: 1600, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.279 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 16, iters: 1700, time: 0.101, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.689 \n",
      "(epoch: 16, iters: 1800, time: 0.105, data: 0.001) G_GAN: 0.688 G_L1: 0.001 D_real: 0.688 D_fake: 0.699 \n",
      "(epoch: 16, iters: 1900, time: 0.110, data: 0.001) G_GAN: 0.687 G_L1: 0.430 D_real: 0.688 D_fake: 0.699 \n",
      "(epoch: 16, iters: 2000, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 16, iters: 2100, time: 0.105, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 16, iters: 2200, time: 0.099, data: 0.001) G_GAN: 0.696 G_L1: 0.256 D_real: 0.696 D_fake: 0.690 \n",
      "End of epoch 16 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 17, iters: 20, time: 0.108, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 17, iters: 120, time: 0.104, data: 0.001) G_GAN: 0.685 G_L1: 0.000 D_real: 0.685 D_fake: 0.703 \n",
      "(epoch: 17, iters: 220, time: 0.099, data: 0.001) G_GAN: 0.683 G_L1: 0.482 D_real: 0.683 D_fake: 0.703 \n",
      "(epoch: 17, iters: 320, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 17, iters: 420, time: 0.100, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.698 \n",
      "(epoch: 17, iters: 520, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.670 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 17, iters: 620, time: 0.098, data: 0.001) G_GAN: 0.696 G_L1: 0.005 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 17, iters: 720, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 17, iters: 820, time: 0.096, data: 0.001) G_GAN: 0.691 G_L1: 1.065 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 17, iters: 920, time: 0.095, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.687 D_fake: 0.699 \n",
      "(epoch: 17, iters: 1020, time: 0.098, data: 0.001) G_GAN: 0.686 G_L1: 0.000 D_real: 0.686 D_fake: 0.701 \n",
      "(epoch: 17, iters: 1120, time: 0.099, data: 0.002) G_GAN: 0.686 G_L1: 0.584 D_real: 0.685 D_fake: 0.698 \n",
      "(epoch: 17, iters: 1220, time: 0.097, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 17, iters: 1320, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 17, iters: 1420, time: 0.107, data: 0.001) G_GAN: 0.692 G_L1: 0.400 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 17, iters: 1520, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 17, iters: 1620, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 17, iters: 1720, time: 0.102, data: 0.001) G_GAN: 0.692 G_L1: 0.333 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 17, iters: 1820, time: 0.100, data: 0.000) G_GAN: 0.695 G_L1: 0.002 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 17, iters: 1920, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 17, iters: 2020, time: 0.099, data: 0.001) G_GAN: 0.691 G_L1: 0.581 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 17, iters: 2120, time: 0.096, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.696 D_fake: 0.693 \n",
      "(epoch: 17, iters: 2220, time: 0.099, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.698 \n",
      "End of epoch 17 / 200 \t Time Taken: 121 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 18, iters: 40, time: 0.118, data: 0.001) G_GAN: 0.693 G_L1: 0.305 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 18, iters: 140, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 18, iters: 240, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 18, iters: 340, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 18, iters: 440, time: 0.096, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 18, iters: 540, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 18, iters: 640, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.579 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 18, iters: 740, time: 0.096, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 18, iters: 840, time: 0.097, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 18, iters: 940, time: 0.099, data: 0.001) G_GAN: 0.723 G_L1: 1.224 D_real: 0.743 D_fake: 0.649 \n",
      "(epoch: 18, iters: 1040, time: 0.094, data: 0.002) G_GAN: 0.684 G_L1: 0.001 D_real: 0.685 D_fake: 0.702 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 18, iters: 1140, time: 0.111, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 18, iters: 1240, time: 0.106, data: 0.001) G_GAN: 0.710 G_L1: 0.628 D_real: 0.712 D_fake: 0.674 \n",
      "saving the latest model (epoch 18, total_steps 40000)\n",
      "(epoch: 18, iters: 1340, time: 0.100, data: 0.001) G_GAN: 0.686 G_L1: 0.000 D_real: 0.685 D_fake: 0.709 \n",
      "(epoch: 18, iters: 1440, time: 0.101, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.696 \n",
      "(epoch: 18, iters: 1540, time: 0.113, data: 0.001) G_GAN: 0.700 G_L1: 0.764 D_real: 0.700 D_fake: 0.686 \n",
      "(epoch: 18, iters: 1640, time: 0.107, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 18, iters: 1740, time: 0.098, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 18, iters: 1840, time: 0.100, data: 0.002) G_GAN: 0.695 G_L1: 0.300 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 18, iters: 1940, time: 0.099, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 18, iters: 2040, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 18, iters: 2140, time: 0.112, data: 0.001) G_GAN: 0.716 G_L1: 0.159 D_real: 0.717 D_fake: 0.670 \n",
      "(epoch: 18, iters: 2240, time: 0.099, data: 0.001) G_GAN: 0.675 G_L1: 0.000 D_real: 0.674 D_fake: 0.712 \n",
      "End of epoch 18 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 19, iters: 60, time: 0.122, data: 0.001) G_GAN: 0.680 G_L1: 0.000 D_real: 0.680 D_fake: 0.704 \n",
      "(epoch: 19, iters: 160, time: 0.098, data: 0.001) G_GAN: 0.689 G_L1: 0.688 D_real: 0.688 D_fake: 0.695 \n",
      "(epoch: 19, iters: 260, time: 0.097, data: 0.001) G_GAN: 0.707 G_L1: 0.000 D_real: 0.710 D_fake: 0.686 \n",
      "(epoch: 19, iters: 360, time: 0.096, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 19, iters: 460, time: 0.098, data: 0.001) G_GAN: 0.690 G_L1: 0.352 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 19, iters: 560, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 19, iters: 660, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.691 \n",
      "(epoch: 19, iters: 760, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.656 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 19, iters: 860, time: 0.097, data: 0.001) G_GAN: 0.696 G_L1: 0.001 D_real: 0.696 D_fake: 0.694 \n",
      "(epoch: 19, iters: 960, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.007 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 19, iters: 1060, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.544 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 19, iters: 1160, time: 0.095, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.693 \n",
      "(epoch: 19, iters: 1260, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 1.350 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 19, iters: 1360, time: 0.106, data: 0.001) G_GAN: 0.691 G_L1: 0.479 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 19, iters: 1460, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 19, iters: 1560, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 19, iters: 1660, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.449 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 19, iters: 1760, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 19, iters: 1860, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 19, iters: 1960, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.417 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 19, iters: 2060, time: 0.093, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 19, iters: 2160, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 19, iters: 2260, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.460 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 19 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 20, iters: 80, time: 0.102, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 20, iters: 180, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 20, iters: 280, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.778 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 20, iters: 380, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 20, iters: 480, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 20, iters: 580, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.455 D_real: 0.692 D_fake: 0.692 \n",
      "(epoch: 20, iters: 680, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 20, iters: 780, time: 0.109, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 20, iters: 880, time: 0.093, data: 0.001) G_GAN: 0.694 G_L1: 0.504 D_real: 0.693 D_fake: 0.690 \n",
      "(epoch: 20, iters: 980, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 1.723 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 20, iters: 1080, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 20, iters: 1180, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.452 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 20, iters: 1280, time: 0.099, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 20, iters: 1380, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 20, iters: 1480, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.454 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 20, iters: 1580, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 20, iters: 1680, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "saving the latest model (epoch 20, total_steps 45000)\n",
      "(epoch: 20, iters: 1780, time: 0.099, data: 0.002) G_GAN: 0.692 G_L1: 0.320 D_real: 0.692 D_fake: 0.692 \n",
      "(epoch: 20, iters: 1880, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 20, iters: 1980, time: 0.100, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 20, iters: 2080, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.303 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 20, iters: 2180, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 20, iters: 2280, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "saving the model at the end of epoch 20, iters 45600\n",
      "End of epoch 20 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 21, iters: 100, time: 0.124, data: 0.264) G_GAN: 0.693 G_L1: 0.458 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 21, iters: 200, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 21, iters: 300, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 21, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.374 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 21, iters: 500, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 21, iters: 600, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 21, iters: 700, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.356 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 21, iters: 800, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 21, iters: 900, time: 0.102, data: 0.001) G_GAN: 0.699 G_L1: 0.000 D_real: 0.701 D_fake: 0.686 \n",
      "(epoch: 21, iters: 1000, time: 0.101, data: 0.001) G_GAN: 0.662 G_L1: 0.618 D_real: 0.661 D_fake: 0.727 \n",
      "(epoch: 21, iters: 1100, time: 0.099, data: 0.001) G_GAN: 0.665 G_L1: 0.000 D_real: 0.665 D_fake: 0.721 \n",
      "(epoch: 21, iters: 1200, time: 0.099, data: 0.001) G_GAN: 0.666 G_L1: 0.000 D_real: 0.666 D_fake: 0.721 \n",
      "(epoch: 21, iters: 1300, time: 0.097, data: 0.001) G_GAN: 0.674 G_L1: 0.900 D_real: 0.674 D_fake: 0.713 \n",
      "(epoch: 21, iters: 1400, time: 0.108, data: 0.002) G_GAN: 0.687 G_L1: 0.111 D_real: 0.688 D_fake: 0.704 \n",
      "(epoch: 21, iters: 1500, time: 0.097, data: 0.001) G_GAN: 0.685 G_L1: 0.000 D_real: 0.685 D_fake: 0.704 \n",
      "(epoch: 21, iters: 1600, time: 0.097, data: 0.001) G_GAN: 0.689 G_L1: 0.291 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 21, iters: 1700, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 21, iters: 1800, time: 0.096, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 21, iters: 1900, time: 0.109, data: 0.001) G_GAN: 0.692 G_L1: 0.451 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 21, iters: 2000, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 21, iters: 2100, time: 0.095, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 21, iters: 2200, time: 0.099, data: 0.002) G_GAN: 0.690 G_L1: 0.359 D_real: 0.690 D_fake: 0.697 \n",
      "End of epoch 21 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 22, iters: 20, time: 0.105, data: 0.001) G_GAN: 0.692 G_L1: 0.582 D_real: 0.693 D_fake: 0.696 \n",
      "(epoch: 22, iters: 120, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 22, iters: 220, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.399 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 22, iters: 320, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 22, iters: 420, time: 0.096, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 22, iters: 520, time: 0.095, data: 0.002) G_GAN: 0.694 G_L1: 0.451 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 22, iters: 620, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 22, iters: 720, time: 0.111, data: 0.001) G_GAN: 0.692 G_L1: 0.057 D_real: 0.692 D_fake: 0.692 \n",
      "(epoch: 22, iters: 820, time: 0.095, data: 0.001) G_GAN: 0.692 G_L1: 0.462 D_real: 0.692 D_fake: 0.692 \n",
      "(epoch: 22, iters: 920, time: 0.106, data: 0.001) G_GAN: 0.670 G_L1: 0.000 D_real: 0.671 D_fake: 0.716 \n",
      "(epoch: 22, iters: 1020, time: 0.095, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.762 D_fake: 0.665 \n",
      "(epoch: 22, iters: 1120, time: 0.098, data: 0.002) G_GAN: 0.673 G_L1: 0.924 D_real: 0.673 D_fake: 0.713 \n",
      "(epoch: 22, iters: 1220, time: 0.096, data: 0.001) G_GAN: 0.682 G_L1: 0.000 D_real: 0.682 D_fake: 0.702 \n",
      "(epoch: 22, iters: 1320, time: 0.097, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.687 D_fake: 0.700 \n",
      "(epoch: 22, iters: 1420, time: 0.097, data: 0.001) G_GAN: 0.688 G_L1: 0.482 D_real: 0.688 D_fake: 0.698 \n",
      "(epoch: 22, iters: 1520, time: 0.098, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 22, iters: 1620, time: 0.095, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.692 \n",
      "(epoch: 22, iters: 1720, time: 0.099, data: 0.002) G_GAN: 0.695 G_L1: 0.410 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 22, iters: 1820, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 22, iters: 1920, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 22, iters: 2020, time: 0.109, data: 0.002) G_GAN: 0.694 G_L1: 0.503 D_real: 0.694 D_fake: 0.691 \n",
      "(epoch: 22, iters: 2120, time: 0.107, data: 0.001) G_GAN: 0.699 G_L1: 0.000 D_real: 0.700 D_fake: 0.687 \n",
      "saving the latest model (epoch 22, total_steps 50000)\n",
      "(epoch: 22, iters: 2220, time: 0.100, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.698 \n",
      "End of epoch 22 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 23, iters: 40, time: 0.106, data: 0.001) G_GAN: 0.694 G_L1: 0.335 D_real: 0.694 D_fake: 0.682 \n",
      "(epoch: 23, iters: 140, time: 0.096, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 23, iters: 240, time: 0.096, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 23, iters: 340, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.576 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 23, iters: 440, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 23, iters: 540, time: 0.094, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 23, iters: 640, time: 0.097, data: 0.001) G_GAN: 0.691 G_L1: 0.298 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 23, iters: 740, time: 0.093, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.693 \n",
      "(epoch: 23, iters: 840, time: 0.095, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 23, iters: 940, time: 0.098, data: 0.001) G_GAN: 0.752 G_L1: 1.078 D_real: 0.735 D_fake: 0.510 \n",
      "(epoch: 23, iters: 1040, time: 0.095, data: 0.001) G_GAN: 0.695 G_L1: 0.001 D_real: 0.699 D_fake: 0.724 \n",
      "(epoch: 23, iters: 1140, time: 0.096, data: 0.001) G_GAN: 0.686 G_L1: 0.000 D_real: 0.685 D_fake: 0.659 \n",
      "(epoch: 23, iters: 1240, time: 0.095, data: 0.001) G_GAN: 0.692 G_L1: 0.679 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 23, iters: 1340, time: 0.098, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.687 D_fake: 0.699 \n",
      "(epoch: 23, iters: 1440, time: 0.099, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.692 D_fake: 0.699 \n",
      "(epoch: 23, iters: 1540, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.709 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 23, iters: 1640, time: 0.097, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.699 \n",
      "(epoch: 23, iters: 1740, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.700 \n",
      "(epoch: 23, iters: 1840, time: 0.098, data: 0.001) G_GAN: 0.690 G_L1: 0.292 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 23, iters: 1940, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 23, iters: 2040, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 23, iters: 2140, time: 0.099, data: 0.001) G_GAN: 0.699 G_L1: 0.121 D_real: 0.701 D_fake: 0.685 \n",
      "(epoch: 23, iters: 2240, time: 0.096, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.700 \n",
      "End of epoch 23 / 200 \t Time Taken: 120 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 24, iters: 60, time: 0.107, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 24, iters: 160, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.574 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 24, iters: 260, time: 0.097, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.699 D_fake: 0.694 \n",
      "(epoch: 24, iters: 360, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 24, iters: 460, time: 0.105, data: 0.001) G_GAN: 0.695 G_L1: 0.320 D_real: 0.696 D_fake: 0.696 \n",
      "(epoch: 24, iters: 560, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 24, iters: 660, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 24, iters: 760, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.598 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 24, iters: 860, time: 0.094, data: 0.001) G_GAN: 0.694 G_L1: 0.003 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 24, iters: 960, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.001 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 24, iters: 1060, time: 0.095, data: 0.002) G_GAN: 0.691 G_L1: 0.195 D_real: 0.691 D_fake: 0.697 \n",
      "(epoch: 24, iters: 1160, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 24, iters: 1260, time: 0.100, data: 0.001) G_GAN: 0.695 G_L1: 1.176 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 24, iters: 1360, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.586 D_real: 0.692 D_fake: 0.689 \n",
      "(epoch: 24, iters: 1460, time: 0.096, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 24, iters: 1560, time: 0.109, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.701 D_fake: 0.695 \n",
      "(epoch: 24, iters: 1660, time: 0.098, data: 0.001) G_GAN: 0.697 G_L1: 0.516 D_real: 0.699 D_fake: 0.694 \n",
      "(epoch: 24, iters: 1760, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 24, iters: 1860, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 24, iters: 1960, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.413 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 24, iters: 2060, time: 0.096, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 24, iters: 2160, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 24, iters: 2260, time: 0.097, data: 0.001) G_GAN: 0.690 G_L1: 0.314 D_real: 0.691 D_fake: 0.696 \n",
      "End of epoch 24 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 25, iters: 80, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 25, iters: 180, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 25, iters: 280, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 1.052 D_real: 0.693 D_fake: 0.694 \n",
      "saving the latest model (epoch 25, total_steps 55000)\n",
      "(epoch: 25, iters: 380, time: 0.108, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 25, iters: 480, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 25, iters: 580, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.466 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 25, iters: 680, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 25, iters: 780, time: 0.109, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 25, iters: 880, time: 0.095, data: 0.001) G_GAN: 0.688 G_L1: 0.669 D_real: 0.688 D_fake: 0.694 \n",
      "(epoch: 25, iters: 980, time: 0.098, data: 0.001) G_GAN: 0.696 G_L1: 1.737 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 25, iters: 1080, time: 0.107, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 25, iters: 1180, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.430 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 25, iters: 1280, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 25, iters: 1380, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 25, iters: 1480, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.488 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 25, iters: 1580, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 25, iters: 1680, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 25, iters: 1780, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.468 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 25, iters: 1880, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 25, iters: 1980, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 25, iters: 2080, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.352 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 25, iters: 2180, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 25, iters: 2280, time: 0.106, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "saving the model at the end of epoch 25, iters 57000\n",
      "End of epoch 25 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 26, iters: 100, time: 0.104, data: 0.277) G_GAN: 0.693 G_L1: 0.299 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 26, iters: 200, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 26, iters: 300, time: 0.096, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 26, iters: 400, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.412 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 26, iters: 500, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 26, iters: 600, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 26, iters: 700, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.344 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 26, iters: 800, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 26, iters: 900, time: 0.095, data: 0.001) G_GAN: 0.686 G_L1: 0.000 D_real: 0.688 D_fake: 0.698 \n",
      "(epoch: 26, iters: 1000, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.552 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 26, iters: 1100, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 26, iters: 1200, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 26, iters: 1300, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.819 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 26, iters: 1400, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.022 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 26, iters: 1500, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 26, iters: 1600, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.244 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 26, iters: 1700, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 26, iters: 1800, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 26, iters: 1900, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.449 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 26, iters: 2000, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 26, iters: 2100, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 26, iters: 2200, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.243 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 26 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 27, iters: 20, time: 0.118, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 27, iters: 120, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 27, iters: 220, time: 0.098, data: 0.001) G_GAN: 0.690 G_L1: 0.444 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 27, iters: 320, time: 0.097, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 27, iters: 420, time: 0.110, data: 0.001) G_GAN: 0.672 G_L1: 0.000 D_real: 0.672 D_fake: 0.715 \n",
      "(epoch: 27, iters: 520, time: 0.095, data: 0.001) G_GAN: 0.698 G_L1: 0.670 D_real: 0.699 D_fake: 0.687 \n",
      "(epoch: 27, iters: 620, time: 0.097, data: 0.001) G_GAN: 0.680 G_L1: 0.000 D_real: 0.679 D_fake: 0.707 \n",
      "(epoch: 27, iters: 720, time: 0.098, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.704 \n",
      "saving the latest model (epoch 27, total_steps 60000)\n",
      "(epoch: 27, iters: 820, time: 0.098, data: 0.002) G_GAN: 0.689 G_L1: 0.206 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 27, iters: 920, time: 0.097, data: 0.001) G_GAN: 0.678 G_L1: 0.000 D_real: 0.678 D_fake: 0.708 \n",
      "(epoch: 27, iters: 1020, time: 0.099, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 27, iters: 1120, time: 0.109, data: 0.001) G_GAN: 0.697 G_L1: 0.437 D_real: 0.697 D_fake: 0.691 \n",
      "(epoch: 27, iters: 1220, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 27, iters: 1320, time: 0.109, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 27, iters: 1420, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.232 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 27, iters: 1520, time: 0.097, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 27, iters: 1620, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 27, iters: 1720, time: 0.108, data: 0.001) G_GAN: 0.691 G_L1: 0.462 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 27, iters: 1820, time: 0.100, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 27, iters: 1920, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 27, iters: 2020, time: 0.098, data: 0.001) G_GAN: 0.690 G_L1: 0.399 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 27, iters: 2120, time: 0.108, data: 0.001) G_GAN: 0.715 G_L1: 0.000 D_real: 0.755 D_fake: 0.642 \n",
      "(epoch: 27, iters: 2220, time: 0.099, data: 0.002) G_GAN: 0.666 G_L1: 0.000 D_real: 0.665 D_fake: 0.724 \n",
      "End of epoch 27 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 28, iters: 40, time: 0.108, data: 0.001) G_GAN: 0.667 G_L1: 0.332 D_real: 0.667 D_fake: 0.722 \n",
      "(epoch: 28, iters: 140, time: 0.096, data: 0.002) G_GAN: 0.675 G_L1: 0.000 D_real: 0.676 D_fake: 0.713 \n",
      "(epoch: 28, iters: 240, time: 0.097, data: 0.002) G_GAN: 0.678 G_L1: 0.000 D_real: 0.673 D_fake: 0.601 \n",
      "(epoch: 28, iters: 340, time: 0.096, data: 0.001) G_GAN: 0.705 G_L1: 0.576 D_real: 0.709 D_fake: 0.695 \n",
      "(epoch: 28, iters: 440, time: 0.097, data: 0.001) G_GAN: 0.668 G_L1: 0.000 D_real: 0.670 D_fake: 0.717 \n",
      "(epoch: 28, iters: 540, time: 0.094, data: 0.001) G_GAN: 0.663 G_L1: 0.000 D_real: 0.668 D_fake: 0.728 \n",
      "(epoch: 28, iters: 640, time: 0.099, data: 0.001) G_GAN: 0.742 G_L1: 0.376 D_real: 0.741 D_fake: 0.639 \n",
      "(epoch: 28, iters: 740, time: 0.094, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 28, iters: 840, time: 0.097, data: 0.001) G_GAN: 0.672 G_L1: 0.000 D_real: 0.671 D_fake: 0.715 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 28, iters: 940, time: 0.098, data: 0.001) G_GAN: 0.677 G_L1: 1.343 D_real: 0.677 D_fake: 0.710 \n",
      "(epoch: 28, iters: 1040, time: 0.106, data: 0.001) G_GAN: 0.702 G_L1: 0.004 D_real: 0.705 D_fake: 0.701 \n",
      "(epoch: 28, iters: 1140, time: 0.097, data: 0.000) G_GAN: 0.709 G_L1: 0.002 D_real: 0.708 D_fake: 0.659 \n",
      "(epoch: 28, iters: 1240, time: 0.094, data: 0.002) G_GAN: 0.728 G_L1: 0.887 D_real: 0.733 D_fake: 0.697 \n",
      "(epoch: 28, iters: 1340, time: 0.101, data: 0.001) G_GAN: 0.680 G_L1: 0.000 D_real: 0.680 D_fake: 0.705 \n",
      "(epoch: 28, iters: 1440, time: 0.098, data: 0.001) G_GAN: 0.684 G_L1: 0.000 D_real: 0.684 D_fake: 0.699 \n",
      "(epoch: 28, iters: 1540, time: 0.099, data: 0.001) G_GAN: 0.683 G_L1: 0.590 D_real: 0.683 D_fake: 0.697 \n",
      "(epoch: 28, iters: 1640, time: 0.101, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.697 \n",
      "(epoch: 28, iters: 1740, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.676 \n",
      "(epoch: 28, iters: 1840, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.115 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 28, iters: 1940, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.696 D_fake: 0.700 \n",
      "(epoch: 28, iters: 2040, time: 0.099, data: 0.001) G_GAN: 0.686 G_L1: 0.000 D_real: 0.686 D_fake: 0.700 \n",
      "(epoch: 28, iters: 2140, time: 0.110, data: 0.001) G_GAN: 0.681 G_L1: 0.181 D_real: 0.680 D_fake: 0.706 \n",
      "(epoch: 28, iters: 2240, time: 0.098, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "End of epoch 28 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 29, iters: 60, time: 0.106, data: 0.001) G_GAN: 0.703 G_L1: 0.000 D_real: 0.702 D_fake: 0.692 \n",
      "(epoch: 29, iters: 160, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.347 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 29, iters: 260, time: 0.098, data: 0.001) G_GAN: 0.680 G_L1: 0.000 D_real: 0.680 D_fake: 0.706 \n",
      "(epoch: 29, iters: 360, time: 0.096, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.698 \n",
      "(epoch: 29, iters: 460, time: 0.096, data: 0.002) G_GAN: 0.690 G_L1: 0.300 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 29, iters: 560, time: 0.108, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.693 \n",
      "(epoch: 29, iters: 660, time: 0.100, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 29, iters: 760, time: 0.095, data: 0.001) G_GAN: 0.691 G_L1: 0.573 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 29, iters: 860, time: 0.095, data: 0.001) G_GAN: 0.682 G_L1: 0.023 D_real: 0.683 D_fake: 0.704 \n",
      "(epoch: 29, iters: 960, time: 0.096, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 29, iters: 1060, time: 0.102, data: 0.001) G_GAN: 0.690 G_L1: 0.214 D_real: 0.691 D_fake: 0.692 \n",
      "(epoch: 29, iters: 1160, time: 0.095, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "saving the latest model (epoch 29, total_steps 65000)\n",
      "(epoch: 29, iters: 1260, time: 0.099, data: 0.001) G_GAN: 0.695 G_L1: 0.779 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 29, iters: 1360, time: 0.108, data: 0.001) G_GAN: 0.692 G_L1: 0.575 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 29, iters: 1460, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 29, iters: 1560, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 29, iters: 1660, time: 0.099, data: 0.001) G_GAN: 0.695 G_L1: 0.522 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 29, iters: 1760, time: 0.110, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 29, iters: 1860, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 29, iters: 1960, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.416 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 29, iters: 2060, time: 0.095, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 29, iters: 2160, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 29, iters: 2260, time: 0.096, data: 0.002) G_GAN: 0.695 G_L1: 0.263 D_real: 0.695 D_fake: 0.691 \n",
      "End of epoch 29 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 30, iters: 80, time: 0.113, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.693 \n",
      "(epoch: 30, iters: 180, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 30, iters: 280, time: 0.097, data: 0.001) G_GAN: 0.691 G_L1: 0.530 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 30, iters: 380, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 30, iters: 480, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 30, iters: 580, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.398 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 30, iters: 680, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 30, iters: 780, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 30, iters: 880, time: 0.096, data: 0.001) G_GAN: 0.691 G_L1: 0.349 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 30, iters: 980, time: 0.109, data: 0.001) G_GAN: 0.695 G_L1: 0.230 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 30, iters: 1080, time: 0.107, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 30, iters: 1180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.399 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 30, iters: 1280, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 30, iters: 1380, time: 0.094, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 30, iters: 1480, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.545 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 30, iters: 1580, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 30, iters: 1680, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 30, iters: 1780, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.334 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 30, iters: 1880, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 30, iters: 1980, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.030 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 30, iters: 2080, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.275 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 30, iters: 2180, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 30, iters: 2280, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 30, iters 68400\n",
      "End of epoch 30 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 31, iters: 100, time: 0.119, data: 0.287) G_GAN: 0.693 G_L1: 0.378 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 31, iters: 200, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 31, iters: 300, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 31, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.374 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 31, iters: 500, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 31, iters: 600, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 31, iters: 700, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.277 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 31, iters: 800, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 31, iters: 900, time: 0.092, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 31, iters: 1000, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.773 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 31, iters: 1100, time: 0.112, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 31, iters: 1200, time: 0.096, data: 0.001) G_GAN: 0.708 G_L1: 0.000 D_real: 0.703 D_fake: 0.550 \n",
      "(epoch: 31, iters: 1300, time: 0.099, data: 0.001) G_GAN: 0.648 G_L1: 1.047 D_real: 0.648 D_fake: 0.727 \n",
      "(epoch: 31, iters: 1400, time: 0.097, data: 0.001) G_GAN: 0.697 G_L1: 0.572 D_real: 0.698 D_fake: 0.718 \n",
      "(epoch: 31, iters: 1500, time: 0.098, data: 0.002) G_GAN: 0.675 G_L1: 0.000 D_real: 0.675 D_fake: 0.704 \n",
      "(epoch: 31, iters: 1600, time: 0.098, data: 0.001) G_GAN: 0.675 G_L1: 0.202 D_real: 0.677 D_fake: 0.702 \n",
      "saving the latest model (epoch 31, total_steps 70000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 31, iters: 1700, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.707 \n",
      "(epoch: 31, iters: 1800, time: 0.096, data: 0.001) G_GAN: 0.681 G_L1: 0.000 D_real: 0.681 D_fake: 0.701 \n",
      "(epoch: 31, iters: 1900, time: 0.102, data: 0.002) G_GAN: 0.692 G_L1: 0.369 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 31, iters: 2000, time: 0.097, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 31, iters: 2100, time: 0.095, data: 0.001) G_GAN: 0.686 G_L1: 0.000 D_real: 0.686 D_fake: 0.700 \n",
      "(epoch: 31, iters: 2200, time: 0.111, data: 0.001) G_GAN: 0.696 G_L1: 0.198 D_real: 0.697 D_fake: 0.698 \n",
      "End of epoch 31 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 32, iters: 20, time: 0.105, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.697 \n",
      "(epoch: 32, iters: 120, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 32, iters: 220, time: 0.100, data: 0.001) G_GAN: 0.692 G_L1: 0.315 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 32, iters: 320, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 32, iters: 420, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 32, iters: 520, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.327 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 32, iters: 620, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 32, iters: 720, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 32, iters: 820, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.270 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 32, iters: 920, time: 0.095, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 32, iters: 1020, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 32, iters: 1120, time: 0.097, data: 0.001) G_GAN: 0.672 G_L1: 0.867 D_real: 0.673 D_fake: 0.714 \n",
      "(epoch: 32, iters: 1220, time: 0.096, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.690 \n",
      "(epoch: 32, iters: 1320, time: 0.098, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 32, iters: 1420, time: 0.099, data: 0.002) G_GAN: 0.695 G_L1: 0.476 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 32, iters: 1520, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 32, iters: 1620, time: 0.094, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 32, iters: 1720, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.361 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 32, iters: 1820, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.001 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 32, iters: 1920, time: 0.099, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 32, iters: 2020, time: 0.099, data: 0.002) G_GAN: 0.695 G_L1: 0.244 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 32, iters: 2120, time: 0.097, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 32, iters: 2220, time: 0.100, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.694 \n",
      "End of epoch 32 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 33, iters: 40, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.250 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 33, iters: 140, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 33, iters: 240, time: 0.096, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 33, iters: 340, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 33, iters: 440, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 33, iters: 540, time: 0.101, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 33, iters: 640, time: 0.096, data: 0.001) G_GAN: 0.697 G_L1: 0.460 D_real: 0.697 D_fake: 0.690 \n",
      "(epoch: 33, iters: 740, time: 0.093, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 33, iters: 840, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 33, iters: 940, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.875 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 33, iters: 1040, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 33, iters: 1140, time: 0.097, data: 0.001) G_GAN: 0.685 G_L1: 0.000 D_real: 0.685 D_fake: 0.702 \n",
      "(epoch: 33, iters: 1240, time: 0.095, data: 0.001) G_GAN: 0.695 G_L1: 0.581 D_real: 0.695 D_fake: 0.694 \n",
      "(epoch: 33, iters: 1340, time: 0.100, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 33, iters: 1440, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 33, iters: 1540, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.489 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 33, iters: 1640, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 33, iters: 1740, time: 0.098, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 33, iters: 1840, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.330 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 33, iters: 1940, time: 0.107, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 33, iters: 2040, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "saving the latest model (epoch 33, total_steps 75000)\n",
      "(epoch: 33, iters: 2140, time: 0.099, data: 0.001) G_GAN: 0.695 G_L1: 0.322 D_real: 0.696 D_fake: 0.693 \n",
      "(epoch: 33, iters: 2240, time: 0.100, data: 0.001) G_GAN: 0.676 G_L1: 0.000 D_real: 0.676 D_fake: 0.710 \n",
      "End of epoch 33 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 34, iters: 60, time: 0.113, data: 0.001) G_GAN: 0.679 G_L1: 0.000 D_real: 0.679 D_fake: 0.708 \n",
      "(epoch: 34, iters: 160, time: 0.098, data: 0.001) G_GAN: 0.688 G_L1: 0.424 D_real: 0.688 D_fake: 0.698 \n",
      "(epoch: 34, iters: 260, time: 0.097, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.689 \n",
      "(epoch: 34, iters: 360, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 34, iters: 460, time: 0.101, data: 0.001) G_GAN: 0.691 G_L1: 0.310 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 34, iters: 560, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 34, iters: 660, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 34, iters: 760, time: 0.108, data: 0.001) G_GAN: 0.696 G_L1: 0.649 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 34, iters: 860, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.009 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 34, iters: 960, time: 0.094, data: 0.002) G_GAN: 0.691 G_L1: 0.002 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 34, iters: 1060, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.401 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 34, iters: 1160, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.017 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 34, iters: 1260, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 1.377 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 34, iters: 1360, time: 0.109, data: 0.002) G_GAN: 0.694 G_L1: 0.508 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 34, iters: 1460, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 34, iters: 1560, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 34, iters: 1660, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.368 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 34, iters: 1760, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 34, iters: 1860, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 34, iters: 1960, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.389 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 34, iters: 2060, time: 0.101, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 34, iters: 2160, time: 0.099, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 34, iters: 2260, time: 0.097, data: 0.001) G_GAN: 0.690 G_L1: 0.548 D_real: 0.689 D_fake: 0.697 \n",
      "End of epoch 34 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 35, iters: 80, time: 0.105, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 35, iters: 180, time: 0.099, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.697 D_fake: 0.689 \n",
      "(epoch: 35, iters: 280, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.628 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 35, iters: 380, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 35, iters: 480, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 35, iters: 580, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.359 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 35, iters: 680, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 35, iters: 780, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 35, iters: 880, time: 0.094, data: 0.001) G_GAN: 0.692 G_L1: 0.518 D_real: 0.693 D_fake: 0.688 \n",
      "(epoch: 35, iters: 980, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 1.033 D_real: 0.693 D_fake: 0.689 \n",
      "(epoch: 35, iters: 1080, time: 0.095, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 35, iters: 1180, time: 0.108, data: 0.001) G_GAN: 0.683 G_L1: 0.446 D_real: 0.683 D_fake: 0.696 \n",
      "(epoch: 35, iters: 1280, time: 0.099, data: 0.001) G_GAN: 0.703 G_L1: 0.000 D_real: 0.704 D_fake: 0.683 \n",
      "(epoch: 35, iters: 1380, time: 0.096, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.692 D_fake: 0.697 \n",
      "(epoch: 35, iters: 1480, time: 0.097, data: 0.002) G_GAN: 0.691 G_L1: 0.477 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 35, iters: 1580, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 35, iters: 1680, time: 0.099, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 35, iters: 1780, time: 0.099, data: 0.001) G_GAN: 0.688 G_L1: 0.365 D_real: 0.688 D_fake: 0.698 \n",
      "(epoch: 35, iters: 1880, time: 0.098, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.699 \n",
      "(epoch: 35, iters: 1980, time: 0.100, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 35, iters: 2080, time: 0.095, data: 0.001) G_GAN: 0.695 G_L1: 0.335 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 35, iters: 2180, time: 0.097, data: 0.001) G_GAN: 0.719 G_L1: 0.000 D_real: 0.721 D_fake: 0.667 \n",
      "(epoch: 35, iters: 2280, time: 0.094, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.788 D_fake: 0.727 \n",
      "saving the model at the end of epoch 35, iters 79800\n",
      "End of epoch 35 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 36, iters: 100, time: 0.108, data: 0.282) G_GAN: 0.677 G_L1: 0.262 D_real: 0.678 D_fake: 0.712 \n",
      "(epoch: 36, iters: 200, time: 0.095, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.701 \n",
      "saving the latest model (epoch 36, total_steps 80000)\n",
      "(epoch: 36, iters: 300, time: 0.095, data: 0.001) G_GAN: 0.680 G_L1: 0.000 D_real: 0.680 D_fake: 0.703 \n",
      "(epoch: 36, iters: 400, time: 0.095, data: 0.002) G_GAN: 0.684 G_L1: 0.186 D_real: 0.685 D_fake: 0.703 \n",
      "(epoch: 36, iters: 500, time: 0.109, data: 0.001) G_GAN: 0.683 G_L1: 0.000 D_real: 0.683 D_fake: 0.703 \n",
      "(epoch: 36, iters: 600, time: 0.097, data: 0.002) G_GAN: 0.684 G_L1: 0.002 D_real: 0.684 D_fake: 0.703 \n",
      "(epoch: 36, iters: 700, time: 0.096, data: 0.002) G_GAN: 0.705 G_L1: 0.437 D_real: 0.705 D_fake: 0.681 \n",
      "(epoch: 36, iters: 800, time: 0.098, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 36, iters: 900, time: 0.094, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 36, iters: 1000, time: 0.100, data: 0.001) G_GAN: 0.698 G_L1: 0.429 D_real: 0.699 D_fake: 0.694 \n",
      "(epoch: 36, iters: 1100, time: 0.106, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 36, iters: 1200, time: 0.108, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 36, iters: 1300, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.628 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 36, iters: 1400, time: 0.098, data: 0.001) G_GAN: 0.696 G_L1: 0.510 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 36, iters: 1500, time: 0.113, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 36, iters: 1600, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.257 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 36, iters: 1700, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 36, iters: 1800, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 36, iters: 1900, time: 0.100, data: 0.002) G_GAN: 0.690 G_L1: 0.796 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 36, iters: 2000, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 36, iters: 2100, time: 0.094, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 36, iters: 2200, time: 0.115, data: 0.001) G_GAN: 0.691 G_L1: 0.172 D_real: 0.691 D_fake: 0.695 \n",
      "End of epoch 36 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 37, iters: 20, time: 0.105, data: 0.002) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.698 \n",
      "(epoch: 37, iters: 120, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 37, iters: 220, time: 0.097, data: 0.002) G_GAN: 0.696 G_L1: 0.244 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 37, iters: 320, time: 0.107, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 37, iters: 420, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 37, iters: 520, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.248 D_real: 0.692 D_fake: 0.696 \n",
      "(epoch: 37, iters: 620, time: 0.099, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.687 D_fake: 0.699 \n",
      "(epoch: 37, iters: 720, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 37, iters: 820, time: 0.105, data: 0.001) G_GAN: 0.697 G_L1: 0.529 D_real: 0.697 D_fake: 0.689 \n",
      "(epoch: 37, iters: 920, time: 0.094, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 37, iters: 1020, time: 0.094, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 37, iters: 1120, time: 0.099, data: 0.002) G_GAN: 0.688 G_L1: 0.629 D_real: 0.688 D_fake: 0.699 \n",
      "(epoch: 37, iters: 1220, time: 0.096, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 37, iters: 1320, time: 0.098, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.690 \n",
      "(epoch: 37, iters: 1420, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.363 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 37, iters: 1520, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 37, iters: 1620, time: 0.104, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.690 \n",
      "(epoch: 37, iters: 1720, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.403 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 37, iters: 1820, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 37, iters: 1920, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 37, iters: 2020, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.797 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 37, iters: 2120, time: 0.100, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 37, iters: 2220, time: 0.099, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.694 \n",
      "End of epoch 37 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 38, iters: 40, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.312 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 38, iters: 140, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 38, iters: 240, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 38, iters: 340, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 38, iters: 440, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 38, iters: 540, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 38, iters: 640, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.388 D_real: 0.694 D_fake: 0.693 \n",
      "saving the latest model (epoch 38, total_steps 85000)\n",
      "(epoch: 38, iters: 740, time: 0.095, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 38, iters: 840, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 38, iters: 940, time: 0.098, data: 0.002) G_GAN: 0.691 G_L1: 1.480 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 38, iters: 1040, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 38, iters: 1140, time: 0.102, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 38, iters: 1240, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.665 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 38, iters: 1340, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 38, iters: 1440, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 38, iters: 1540, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.533 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 38, iters: 1640, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 38, iters: 1740, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 38, iters: 1840, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.320 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 38, iters: 1940, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 38, iters: 2040, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 38, iters: 2140, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.322 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 38, iters: 2240, time: 0.098, data: 0.001) G_GAN: 0.647 G_L1: 0.000 D_real: 0.648 D_fake: 0.741 \n",
      "End of epoch 38 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 39, iters: 60, time: 0.105, data: 0.001) G_GAN: 0.676 G_L1: 0.000 D_real: 0.676 D_fake: 0.711 \n",
      "(epoch: 39, iters: 160, time: 0.098, data: 0.001) G_GAN: 0.687 G_L1: 0.465 D_real: 0.688 D_fake: 0.692 \n",
      "(epoch: 39, iters: 260, time: 0.108, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.698 D_fake: 0.689 \n",
      "(epoch: 39, iters: 360, time: 0.108, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 39, iters: 460, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.262 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 39, iters: 560, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 39, iters: 660, time: 0.097, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 39, iters: 760, time: 0.095, data: 0.001) G_GAN: 0.695 G_L1: 0.712 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 39, iters: 860, time: 0.095, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.689 \n",
      "(epoch: 39, iters: 960, time: 0.105, data: 0.001) G_GAN: 0.686 G_L1: 0.000 D_real: 0.686 D_fake: 0.700 \n",
      "(epoch: 39, iters: 1060, time: 0.095, data: 0.001) G_GAN: 0.692 G_L1: 0.445 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 39, iters: 1160, time: 0.095, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 39, iters: 1260, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.440 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 39, iters: 1360, time: 0.097, data: 0.002) G_GAN: 0.697 G_L1: 0.628 D_real: 0.697 D_fake: 0.690 \n",
      "(epoch: 39, iters: 1460, time: 0.094, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.690 D_fake: 0.695 \n",
      "(epoch: 39, iters: 1560, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 39, iters: 1660, time: 0.096, data: 0.001) G_GAN: 0.690 G_L1: 0.552 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 39, iters: 1760, time: 0.100, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 39, iters: 1860, time: 0.100, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 39, iters: 1960, time: 0.112, data: 0.002) G_GAN: 0.693 G_L1: 0.386 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 39, iters: 2060, time: 0.095, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 39, iters: 2160, time: 0.098, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.687 D_fake: 0.699 \n",
      "(epoch: 39, iters: 2260, time: 0.095, data: 0.002) G_GAN: 0.670 G_L1: 0.325 D_real: 0.670 D_fake: 0.717 \n",
      "End of epoch 39 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 40, iters: 80, time: 0.104, data: 0.002) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.698 \n",
      "(epoch: 40, iters: 180, time: 0.098, data: 0.002) G_GAN: 0.683 G_L1: 0.000 D_real: 0.683 D_fake: 0.702 \n",
      "(epoch: 40, iters: 280, time: 0.096, data: 0.002) G_GAN: 0.700 G_L1: 0.825 D_real: 0.700 D_fake: 0.686 \n",
      "(epoch: 40, iters: 380, time: 0.098, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.689 \n",
      "(epoch: 40, iters: 480, time: 0.097, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.699 \n",
      "(epoch: 40, iters: 580, time: 0.101, data: 0.002) G_GAN: 0.692 G_L1: 0.366 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 40, iters: 680, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 40, iters: 780, time: 0.107, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.688 \n",
      "(epoch: 40, iters: 880, time: 0.097, data: 0.001) G_GAN: 0.703 G_L1: 0.575 D_real: 0.703 D_fake: 0.683 \n",
      "(epoch: 40, iters: 980, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.678 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 40, iters: 1080, time: 0.096, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.687 D_fake: 0.699 \n",
      "saving the latest model (epoch 40, total_steps 90000)\n",
      "(epoch: 40, iters: 1180, time: 0.108, data: 0.001) G_GAN: 0.686 G_L1: 0.403 D_real: 0.686 D_fake: 0.698 \n",
      "(epoch: 40, iters: 1280, time: 0.110, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.695 \n",
      "(epoch: 40, iters: 1380, time: 0.098, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.699 D_fake: 0.689 \n",
      "(epoch: 40, iters: 1480, time: 0.109, data: 0.001) G_GAN: 0.690 G_L1: 0.416 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 40, iters: 1580, time: 0.111, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 40, iters: 1680, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 40, iters: 1780, time: 0.100, data: 0.005) G_GAN: 0.693 G_L1: 0.391 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 40, iters: 1880, time: 0.098, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.692 D_fake: 0.696 \n",
      "(epoch: 40, iters: 1980, time: 0.098, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 40, iters: 2080, time: 0.096, data: 0.002) G_GAN: 0.694 G_L1: 0.238 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 40, iters: 2180, time: 0.096, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.687 D_fake: 0.699 \n",
      "(epoch: 40, iters: 2280, time: 0.095, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "saving the model at the end of epoch 40, iters 91200\n",
      "End of epoch 40 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 41, iters: 100, time: 0.107, data: 0.281) G_GAN: 0.694 G_L1: 0.280 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 41, iters: 200, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 41, iters: 300, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 41, iters: 400, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.176 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 41, iters: 500, time: 0.099, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 41, iters: 600, time: 0.101, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.687 D_fake: 0.699 \n",
      "(epoch: 41, iters: 700, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.306 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 41, iters: 800, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 41, iters: 900, time: 0.093, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.700 D_fake: 0.686 \n",
      "(epoch: 41, iters: 1000, time: 0.108, data: 0.001) G_GAN: 0.695 G_L1: 0.390 D_real: 0.695 D_fake: 0.693 \n",
      "(epoch: 41, iters: 1100, time: 0.097, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 41, iters: 1200, time: 0.097, data: 0.003) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 41, iters: 1300, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.619 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 41, iters: 1400, time: 0.109, data: 0.001) G_GAN: 0.695 G_L1: 0.141 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 41, iters: 1500, time: 0.108, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 41, iters: 1600, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.211 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 41, iters: 1700, time: 0.102, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.695 D_fake: 0.693 \n",
      "(epoch: 41, iters: 1800, time: 0.095, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.690 \n",
      "(epoch: 41, iters: 1900, time: 0.100, data: 0.001) G_GAN: 0.691 G_L1: 0.320 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 41, iters: 2000, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 41, iters: 2100, time: 0.105, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.686 \n",
      "(epoch: 41, iters: 2200, time: 0.100, data: 0.002) G_GAN: 0.687 G_L1: 0.232 D_real: 0.688 D_fake: 0.699 \n",
      "End of epoch 41 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 42, iters: 20, time: 0.104, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 42, iters: 120, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 42, iters: 220, time: 0.109, data: 0.001) G_GAN: 0.696 G_L1: 0.380 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 42, iters: 320, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 42, iters: 420, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 42, iters: 520, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.306 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 42, iters: 620, time: 0.107, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 42, iters: 720, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 42, iters: 820, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.306 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 42, iters: 920, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 42, iters: 1020, time: 0.109, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 42, iters: 1120, time: 0.108, data: 0.001) G_GAN: 0.689 G_L1: 0.570 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 42, iters: 1220, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 42, iters: 1320, time: 0.100, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 42, iters: 1420, time: 0.110, data: 0.001) G_GAN: 0.691 G_L1: 0.412 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 42, iters: 1520, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 42, total_steps 95000)\n",
      "(epoch: 42, iters: 1620, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 42, iters: 1720, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.301 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 42, iters: 1820, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 42, iters: 1920, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 42, iters: 2020, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.472 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 42, iters: 2120, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 42, iters: 2220, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "End of epoch 42 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 43, iters: 40, time: 0.107, data: 0.003) G_GAN: 0.693 G_L1: 0.232 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 43, iters: 140, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 43, iters: 240, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 43, iters: 340, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 43, iters: 440, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 43, iters: 540, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 43, iters: 640, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.258 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 43, iters: 740, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 43, iters: 840, time: 0.108, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 43, iters: 940, time: 0.099, data: 0.001) G_GAN: 0.690 G_L1: 0.926 D_real: 0.692 D_fake: 0.710 \n",
      "(epoch: 43, iters: 1040, time: 0.107, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.699 D_fake: 0.696 \n",
      "(epoch: 43, iters: 1140, time: 0.098, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.694 D_fake: 0.682 \n",
      "(epoch: 43, iters: 1240, time: 0.097, data: 0.002) G_GAN: 0.699 G_L1: 0.677 D_real: 0.699 D_fake: 0.687 \n",
      "(epoch: 43, iters: 1340, time: 0.112, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.687 D_fake: 0.699 \n",
      "(epoch: 43, iters: 1440, time: 0.100, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.687 \n",
      "(epoch: 43, iters: 1540, time: 0.111, data: 0.001) G_GAN: 0.690 G_L1: 0.566 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 43, iters: 1640, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 43, iters: 1740, time: 0.100, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 43, iters: 1840, time: 0.102, data: 0.002) G_GAN: 0.692 G_L1: 0.297 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 43, iters: 1940, time: 0.098, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.699 D_fake: 0.697 \n",
      "(epoch: 43, iters: 2040, time: 0.101, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.689 D_fake: 0.690 \n",
      "(epoch: 43, iters: 2140, time: 0.111, data: 0.001) G_GAN: 0.687 G_L1: 0.360 D_real: 0.687 D_fake: 0.698 \n",
      "(epoch: 43, iters: 2240, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "End of epoch 43 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 44, iters: 60, time: 0.108, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.688 \n",
      "(epoch: 44, iters: 160, time: 0.102, data: 0.002) G_GAN: 0.694 G_L1: 0.429 D_real: 0.694 D_fake: 0.690 \n",
      "(epoch: 44, iters: 260, time: 0.096, data: 0.002) G_GAN: 0.683 G_L1: 0.000 D_real: 0.682 D_fake: 0.704 \n",
      "(epoch: 44, iters: 360, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 44, iters: 460, time: 0.114, data: 0.001) G_GAN: 0.688 G_L1: 0.301 D_real: 0.688 D_fake: 0.693 \n",
      "(epoch: 44, iters: 560, time: 0.096, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.694 \n",
      "(epoch: 44, iters: 660, time: 0.099, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 44, iters: 760, time: 0.099, data: 0.002) G_GAN: 0.694 G_L1: 0.499 D_real: 0.694 D_fake: 0.695 \n",
      "(epoch: 44, iters: 860, time: 0.094, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 44, iters: 960, time: 0.094, data: 0.002) G_GAN: 0.695 G_L1: 0.003 D_real: 0.695 D_fake: 0.693 \n",
      "(epoch: 44, iters: 1060, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.354 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 44, iters: 1160, time: 0.096, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.696 D_fake: 0.697 \n",
      "(epoch: 44, iters: 1260, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 1.169 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 44, iters: 1360, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.439 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 44, iters: 1460, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 44, iters: 1560, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 44, iters: 1660, time: 0.101, data: 0.001) G_GAN: 0.695 G_L1: 0.345 D_real: 0.695 D_fake: 0.693 \n",
      "(epoch: 44, iters: 1760, time: 0.097, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.690 \n",
      "(epoch: 44, iters: 1860, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 44, iters: 1960, time: 0.101, data: 0.002) G_GAN: 0.691 G_L1: 0.417 D_real: 0.691 D_fake: 0.695 \n",
      "saving the latest model (epoch 44, total_steps 100000)\n",
      "(epoch: 44, iters: 2060, time: 0.095, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 44, iters: 2160, time: 0.109, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 44, iters: 2260, time: 0.094, data: 0.001) G_GAN: 0.692 G_L1: 0.226 D_real: 0.692 D_fake: 0.697 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 44 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 45, iters: 80, time: 0.119, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 45, iters: 180, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.695 \n",
      "(epoch: 45, iters: 280, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.283 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 45, iters: 380, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 45, iters: 480, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 45, iters: 580, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.340 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 45, iters: 680, time: 0.096, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.691 \n",
      "(epoch: 45, iters: 780, time: 0.106, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 45, iters: 880, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.287 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 45, iters: 980, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.002 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 45, iters: 1080, time: 0.094, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 45, iters: 1180, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.405 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 45, iters: 1280, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 45, iters: 1380, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 45, iters: 1480, time: 0.113, data: 0.001) G_GAN: 0.693 G_L1: 0.311 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 45, iters: 1580, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 45, iters: 1680, time: 0.099, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 45, iters: 1780, time: 0.095, data: 0.001) G_GAN: 0.692 G_L1: 0.317 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 45, iters: 1880, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 45, iters: 1980, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.052 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 45, iters: 2080, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.229 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 45, iters: 2180, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 45, iters: 2280, time: 0.095, data: 0.002) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.698 \n",
      "saving the model at the end of epoch 45, iters 102600\n",
      "End of epoch 45 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 46, iters: 100, time: 0.107, data: 0.287) G_GAN: 0.691 G_L1: 0.263 D_real: 0.690 D_fake: 0.695 \n",
      "(epoch: 46, iters: 200, time: 0.096, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 46, iters: 300, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 46, iters: 400, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.226 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 46, iters: 500, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.691 \n",
      "(epoch: 46, iters: 600, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 46, iters: 700, time: 0.112, data: 0.002) G_GAN: 0.695 G_L1: 0.219 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 46, iters: 800, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 46, iters: 900, time: 0.092, data: 0.001) G_GAN: 0.686 G_L1: 0.001 D_real: 0.685 D_fake: 0.702 \n",
      "(epoch: 46, iters: 1000, time: 0.106, data: 0.002) G_GAN: 0.703 G_L1: 0.370 D_real: 0.703 D_fake: 0.687 \n",
      "(epoch: 46, iters: 1100, time: 0.098, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.691 \n",
      "(epoch: 46, iters: 1200, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 46, iters: 1300, time: 0.109, data: 0.001) G_GAN: 0.694 G_L1: 0.626 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 46, iters: 1400, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.704 \n",
      "(epoch: 46, iters: 1500, time: 0.097, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 46, iters: 1600, time: 0.097, data: 0.001) G_GAN: 0.688 G_L1: 0.143 D_real: 0.688 D_fake: 0.688 \n",
      "(epoch: 46, iters: 1700, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 46, iters: 1800, time: 0.094, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 46, iters: 1900, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.481 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 46, iters: 2000, time: 0.108, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 46, iters: 2100, time: 0.107, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.698 \n",
      "(epoch: 46, iters: 2200, time: 0.101, data: 0.001) G_GAN: 0.695 G_L1: 0.159 D_real: 0.695 D_fake: 0.691 \n",
      "End of epoch 46 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 47, iters: 20, time: 0.105, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 47, iters: 120, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "saving the latest model (epoch 47, total_steps 105000)\n",
      "(epoch: 47, iters: 220, time: 0.113, data: 0.002) G_GAN: 0.692 G_L1: 0.412 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 47, iters: 320, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 47, iters: 420, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 47, iters: 520, time: 0.094, data: 0.002) G_GAN: 0.694 G_L1: 0.194 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 47, iters: 620, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 47, iters: 720, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 47, iters: 820, time: 0.094, data: 0.001) G_GAN: 0.694 G_L1: 0.246 D_real: 0.695 D_fake: 0.693 \n",
      "(epoch: 47, iters: 920, time: 0.105, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 47, iters: 1020, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 47, iters: 1120, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.368 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 47, iters: 1220, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 47, iters: 1320, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 47, iters: 1420, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.363 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 47, iters: 1520, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 47, iters: 1620, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 47, iters: 1720, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.391 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 47, iters: 1820, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 47, iters: 1920, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.063 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 47, iters: 2020, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.350 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 47, iters: 2120, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 47, iters: 2220, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 47 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 48, iters: 40, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.267 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 48, iters: 140, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 48, iters: 240, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 48, iters: 340, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 48, iters: 440, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 48, iters: 540, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 48, iters: 640, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.378 D_real: 0.694 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 48, iters: 740, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 48, iters: 840, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 48, iters: 940, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.846 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 48, iters: 1040, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 48, iters: 1140, time: 0.096, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.711 D_fake: 0.685 \n",
      "(epoch: 48, iters: 1240, time: 0.107, data: 0.002) G_GAN: 0.695 G_L1: 0.696 D_real: 0.696 D_fake: 0.693 \n",
      "(epoch: 48, iters: 1340, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 48, iters: 1440, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 48, iters: 1540, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.505 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 48, iters: 1640, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 48, iters: 1740, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 48, iters: 1840, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.136 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 48, iters: 1940, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 48, iters: 2040, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 48, iters: 2140, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.127 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 48, iters: 2240, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 48 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 49, iters: 60, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 49, iters: 160, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.284 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 49, iters: 260, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 49, iters: 360, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 49, iters: 460, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.224 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 49, iters: 560, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 49, total_steps 110000)\n",
      "(epoch: 49, iters: 660, time: 0.113, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 49, iters: 760, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.409 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 49, iters: 860, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.151 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 49, iters: 960, time: 0.095, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.744 D_fake: 0.646 \n",
      "(epoch: 49, iters: 1060, time: 0.097, data: 0.001) G_GAN: 0.683 G_L1: 0.300 D_real: 0.683 D_fake: 0.702 \n",
      "(epoch: 49, iters: 1160, time: 0.107, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 49, iters: 1260, time: 0.109, data: 0.001) G_GAN: 0.688 G_L1: 0.023 D_real: 0.688 D_fake: 0.702 \n",
      "(epoch: 49, iters: 1360, time: 0.096, data: 0.001) G_GAN: 0.691 G_L1: 0.469 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 49, iters: 1460, time: 0.093, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 49, iters: 1560, time: 0.093, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.700 D_fake: 0.686 \n",
      "(epoch: 49, iters: 1660, time: 0.099, data: 0.001) G_GAN: 0.717 G_L1: 0.263 D_real: 0.721 D_fake: 0.666 \n",
      "(epoch: 49, iters: 1760, time: 0.096, data: 0.004) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.700 \n",
      "(epoch: 49, iters: 1860, time: 0.108, data: 0.001) G_GAN: 0.689 G_L1: 0.002 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 49, iters: 1960, time: 0.099, data: 0.001) G_GAN: 0.690 G_L1: 0.403 D_real: 0.690 D_fake: 0.695 \n",
      "(epoch: 49, iters: 2060, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 49, iters: 2160, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 49, iters: 2260, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.264 D_real: 0.694 D_fake: 0.695 \n",
      "End of epoch 49 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 50, iters: 80, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 180, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 50, iters: 280, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.424 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 380, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.688 \n",
      "(epoch: 50, iters: 480, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 50, iters: 580, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.489 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 680, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 50, iters: 780, time: 0.108, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 50, iters: 880, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.278 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 980, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 1.686 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 1080, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 1180, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.369 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 1280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 1380, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 1480, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.335 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 1580, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 1680, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 1780, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.273 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 1880, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 1980, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 2080, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.174 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 2180, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 50, iters: 2280, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 50, iters 114000\n",
      "End of epoch 50 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 51, iters: 100, time: 0.107, data: 0.287) G_GAN: 0.693 G_L1: 0.223 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 200, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 300, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 400, time: 0.112, data: 0.001) G_GAN: 0.693 G_L1: 0.227 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 500, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 600, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 700, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.242 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 800, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 900, time: 0.092, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 1000, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.272 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 51, total_steps 115000)\n",
      "(epoch: 51, iters: 1100, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 1200, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 1300, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.453 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 51, iters: 1400, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.259 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 1500, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 1600, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.203 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 1700, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 1800, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 1900, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.575 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 2000, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 2100, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 51, iters: 2200, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.226 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 51 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 52, iters: 20, time: 0.123, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 120, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 220, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.375 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 320, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 420, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 520, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.231 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 620, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 720, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 820, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.336 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 920, time: 0.095, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 52, iters: 1020, time: 0.108, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.688 D_fake: 0.699 \n",
      "(epoch: 52, iters: 1120, time: 0.101, data: 0.002) G_GAN: 0.689 G_L1: 0.384 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 52, iters: 1220, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 1320, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 52, iters: 1420, time: 0.112, data: 0.001) G_GAN: 0.693 G_L1: 0.322 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 1520, time: 0.097, data: 0.000) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 1620, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 1720, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.320 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 1820, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 1920, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 2020, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.343 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 2120, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 52, iters: 2220, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 52 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 53, iters: 40, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.257 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 53, iters: 140, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 53, iters: 240, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 53, iters: 340, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 53, iters: 440, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 53, iters: 540, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 53, iters: 640, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.231 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 53, iters: 740, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 53, iters: 840, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 53, iters: 940, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.782 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 53, iters: 1040, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 53, iters: 1140, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 53, iters: 1240, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.719 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 53, iters: 1340, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 53, iters: 1440, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 53, total_steps 120000)\n",
      "(epoch: 53, iters: 1540, time: 0.110, data: 0.001) G_GAN: 0.694 G_L1: 0.359 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 53, iters: 1640, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 53, iters: 1740, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 53, iters: 1840, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.236 D_real: 0.694 D_fake: 0.691 \n",
      "(epoch: 53, iters: 1940, time: 0.099, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.701 \n",
      "(epoch: 53, iters: 2040, time: 0.096, data: 0.001) G_GAN: 0.706 G_L1: 0.000 D_real: 0.708 D_fake: 0.679 \n",
      "(epoch: 53, iters: 2140, time: 0.099, data: 0.001) G_GAN: 0.669 G_L1: 0.277 D_real: 0.672 D_fake: 0.729 \n",
      "(epoch: 53, iters: 2240, time: 0.098, data: 0.001) G_GAN: 0.673 G_L1: 0.000 D_real: 0.673 D_fake: 0.714 \n",
      "End of epoch 53 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 54, iters: 60, time: 0.104, data: 0.001) G_GAN: 0.682 G_L1: 0.000 D_real: 0.682 D_fake: 0.706 \n",
      "(epoch: 54, iters: 160, time: 0.101, data: 0.001) G_GAN: 0.689 G_L1: 0.255 D_real: 0.689 D_fake: 0.698 \n",
      "(epoch: 54, iters: 260, time: 0.107, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.698 \n",
      "(epoch: 54, iters: 360, time: 0.096, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 54, iters: 460, time: 0.102, data: 0.001) G_GAN: 0.699 G_L1: 0.233 D_real: 0.700 D_fake: 0.687 \n",
      "(epoch: 54, iters: 560, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 54, iters: 660, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 54, iters: 760, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.421 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 54, iters: 860, time: 0.095, data: 0.001) G_GAN: 0.692 G_L1: 0.314 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 54, iters: 960, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 54, iters: 1060, time: 0.095, data: 0.001) G_GAN: 0.692 G_L1: 0.284 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 54, iters: 1160, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.061 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 54, iters: 1260, time: 0.100, data: 0.001) G_GAN: 0.692 G_L1: 0.021 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 54, iters: 1360, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.280 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 54, iters: 1460, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 54, iters: 1560, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 54, iters: 1660, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.336 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 54, iters: 1760, time: 0.096, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 54, iters: 1860, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 54, iters: 1960, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.275 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 54, iters: 2060, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 54, iters: 2160, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 54, iters: 2260, time: 0.095, data: 0.001) G_GAN: 0.695 G_L1: 0.195 D_real: 0.696 D_fake: 0.693 \n",
      "End of epoch 54 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 55, iters: 80, time: 0.110, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 55, iters: 180, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 55, iters: 280, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.400 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 55, iters: 380, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 55, iters: 480, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 55, iters: 580, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.384 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 55, iters: 680, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 55, iters: 780, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 55, iters: 880, time: 0.094, data: 0.001) G_GAN: 0.692 G_L1: 0.239 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 55, iters: 980, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.057 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 55, iters: 1080, time: 0.095, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 55, iters: 1180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.219 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 55, iters: 1280, time: 0.108, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 55, iters: 1380, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 55, iters: 1480, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.332 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 55, iters: 1580, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 55, iters: 1680, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 55, iters: 1780, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.244 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 55, iters: 1880, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 55, total_steps 125000)\n",
      "(epoch: 55, iters: 1980, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 55, iters: 2080, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.191 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 55, iters: 2180, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 55, iters: 2280, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 55, iters 125400\n",
      "End of epoch 55 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 56, iters: 100, time: 0.107, data: 0.282) G_GAN: 0.693 G_L1: 0.262 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 56, iters: 200, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.002 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 56, iters: 300, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 56, iters: 400, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.184 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 56, iters: 500, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 56, iters: 600, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 56, iters: 700, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.261 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 56, iters: 800, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 56, iters: 900, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 56, iters: 1000, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.323 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 56, iters: 1100, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 56, iters: 1200, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 56, iters: 1300, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.374 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 56, iters: 1400, time: 0.109, data: 0.002) G_GAN: 0.694 G_L1: 0.545 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 56, iters: 1500, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 56, iters: 1600, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.161 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 56, iters: 1700, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 56, iters: 1800, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 56, iters: 1900, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.330 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 56, iters: 2000, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 56, iters: 2100, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 56, iters: 2200, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.277 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 56 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 57, iters: 20, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 120, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 220, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.286 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 320, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 420, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 520, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.193 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 57, iters: 620, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 720, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 820, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.153 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 57, iters: 920, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 57, iters: 1020, time: 0.108, data: 0.002) G_GAN: 0.682 G_L1: 0.000 D_real: 0.681 D_fake: 0.707 \n",
      "(epoch: 57, iters: 1120, time: 0.115, data: 0.002) G_GAN: 0.671 G_L1: 0.421 D_real: 0.671 D_fake: 0.716 \n",
      "(epoch: 57, iters: 1220, time: 0.097, data: 0.002) G_GAN: 0.677 G_L1: 0.000 D_real: 0.677 D_fake: 0.709 \n",
      "(epoch: 57, iters: 1320, time: 0.098, data: 0.002) G_GAN: 0.680 G_L1: 0.000 D_real: 0.680 D_fake: 0.703 \n",
      "(epoch: 57, iters: 1420, time: 0.099, data: 0.002) G_GAN: 0.689 G_L1: 0.230 D_real: 0.690 D_fake: 0.698 \n",
      "(epoch: 57, iters: 1520, time: 0.097, data: 0.001) G_GAN: 0.685 G_L1: 0.000 D_real: 0.685 D_fake: 0.694 \n",
      "(epoch: 57, iters: 1620, time: 0.095, data: 0.001) G_GAN: 0.702 G_L1: 0.000 D_real: 0.702 D_fake: 0.684 \n",
      "(epoch: 57, iters: 1720, time: 0.109, data: 0.001) G_GAN: 0.690 G_L1: 0.384 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 57, iters: 1820, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 57, iters: 1920, time: 0.106, data: 0.003) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 57, iters: 2020, time: 0.100, data: 0.001) G_GAN: 0.691 G_L1: 0.698 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 57, iters: 2120, time: 0.096, data: 0.002) G_GAN: 0.698 G_L1: 0.002 D_real: 0.698 D_fake: 0.688 \n",
      "(epoch: 57, iters: 2220, time: 0.101, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.693 \n",
      "End of epoch 57 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 58, iters: 40, time: 0.116, data: 0.001) G_GAN: 0.690 G_L1: 0.248 D_real: 0.690 D_fake: 0.696 \n",
      "saving the latest model (epoch 58, total_steps 130000)\n",
      "(epoch: 58, iters: 140, time: 0.096, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 58, iters: 240, time: 0.096, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 58, iters: 340, time: 0.106, data: 0.002) G_GAN: 0.692 G_L1: 0.576 D_real: 0.691 D_fake: 0.691 \n",
      "(epoch: 58, iters: 440, time: 0.106, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.689 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 58, iters: 540, time: 0.094, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 58, iters: 640, time: 0.096, data: 0.001) G_GAN: 0.691 G_L1: 0.252 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 58, iters: 740, time: 0.094, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 58, iters: 840, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 58, iters: 940, time: 0.099, data: 0.001) G_GAN: 0.697 G_L1: 0.613 D_real: 0.697 D_fake: 0.695 \n",
      "(epoch: 58, iters: 1040, time: 0.096, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 58, iters: 1140, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 58, iters: 1240, time: 0.094, data: 0.002) G_GAN: 0.692 G_L1: 0.600 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 58, iters: 1340, time: 0.098, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.694 \n",
      "(epoch: 58, iters: 1440, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 58, iters: 1540, time: 0.100, data: 0.001) G_GAN: 0.695 G_L1: 0.356 D_real: 0.695 D_fake: 0.690 \n",
      "(epoch: 58, iters: 1640, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 58, iters: 1740, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.008 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 58, iters: 1840, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.310 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 58, iters: 1940, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 58, iters: 2040, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 58, iters: 2140, time: 0.109, data: 0.002) G_GAN: 0.695 G_L1: 0.155 D_real: 0.695 D_fake: 0.694 \n",
      "(epoch: 58, iters: 2240, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 58 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 59, iters: 60, time: 0.117, data: 0.006) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 59, iters: 160, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.265 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 59, iters: 260, time: 0.104, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 59, iters: 360, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 59, iters: 460, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.206 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 59, iters: 560, time: 0.107, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 59, iters: 660, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 59, iters: 760, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.391 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 59, iters: 860, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 59, iters: 960, time: 0.106, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 59, iters: 1060, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.118 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 59, iters: 1160, time: 0.095, data: 0.001) G_GAN: 0.685 G_L1: 0.003 D_real: 0.686 D_fake: 0.705 \n",
      "(epoch: 59, iters: 1260, time: 0.097, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.699 \n",
      "(epoch: 59, iters: 1360, time: 0.096, data: 0.001) G_GAN: 0.690 G_L1: 0.266 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 59, iters: 1460, time: 0.098, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 59, iters: 1560, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 59, iters: 1660, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.512 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 59, iters: 1760, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.013 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 59, iters: 1860, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 59, iters: 1960, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.414 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 59, iters: 2060, time: 0.109, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 59, iters: 2160, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 59, iters: 2260, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.340 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 59 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 60, iters: 80, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 180, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.758 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 380, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 480, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 60, total_steps 135000)\n",
      "(epoch: 60, iters: 580, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.331 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 60, iters: 680, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 780, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 880, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.305 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 980, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 1.659 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 1080, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 1180, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.323 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 1280, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 1380, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 1480, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.466 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 1580, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 1680, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 1780, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.395 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 1880, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 1980, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 2080, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.173 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 2180, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 60, iters: 2280, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 60, iters 136800\n",
      "End of epoch 60 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 61, iters: 100, time: 0.118, data: 0.280) G_GAN: 0.693 G_L1: 0.298 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 61, iters: 200, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 61, iters: 300, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 61, iters: 400, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.160 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 61, iters: 500, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.002 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 61, iters: 600, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 61, iters: 700, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.222 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 61, iters: 800, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 61, iters: 900, time: 0.094, data: 0.002) G_GAN: 0.692 G_L1: 0.001 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 61, iters: 1000, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.226 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 61, iters: 1100, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 61, iters: 1200, time: 0.098, data: 0.001) G_GAN: 0.704 G_L1: 0.000 D_real: 0.704 D_fake: 0.682 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 61, iters: 1300, time: 0.109, data: 0.001) G_GAN: 0.700 G_L1: 0.358 D_real: 0.700 D_fake: 0.687 \n",
      "(epoch: 61, iters: 1400, time: 0.098, data: 0.001) G_GAN: 0.701 G_L1: 0.169 D_real: 0.701 D_fake: 0.685 \n",
      "(epoch: 61, iters: 1500, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 61, iters: 1600, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.153 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 61, iters: 1700, time: 0.115, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 61, iters: 1800, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 61, iters: 1900, time: 0.098, data: 0.001) G_GAN: 0.689 G_L1: 0.229 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 61, iters: 2000, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 61, iters: 2100, time: 0.106, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 61, iters: 2200, time: 0.099, data: 0.001) G_GAN: 0.691 G_L1: 0.164 D_real: 0.691 D_fake: 0.695 \n",
      "End of epoch 61 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 62, iters: 20, time: 0.105, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 62, iters: 120, time: 0.100, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 62, iters: 220, time: 0.099, data: 0.001) G_GAN: 0.696 G_L1: 0.318 D_real: 0.696 D_fake: 0.689 \n",
      "(epoch: 62, iters: 320, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 62, iters: 420, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 62, iters: 520, time: 0.096, data: 0.002) G_GAN: 0.695 G_L1: 0.143 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 62, iters: 620, time: 0.108, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.698 \n",
      "(epoch: 62, iters: 720, time: 0.111, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 62, iters: 820, time: 0.106, data: 0.001) G_GAN: 0.695 G_L1: 0.283 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 62, iters: 920, time: 0.106, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "saving the latest model (epoch 62, total_steps 140000)\n",
      "(epoch: 62, iters: 1020, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 62, iters: 1120, time: 0.097, data: 0.002) G_GAN: 0.691 G_L1: 0.264 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 62, iters: 1220, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 62, iters: 1320, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.001 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 62, iters: 1420, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.280 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 62, iters: 1520, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 62, iters: 1620, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 62, iters: 1720, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.158 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 62, iters: 1820, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 62, iters: 1920, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.010 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 62, iters: 2020, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.595 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 62, iters: 2120, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 62, iters: 2220, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.692 D_fake: 0.682 \n",
      "End of epoch 62 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 63, iters: 40, time: 0.114, data: 0.001) G_GAN: 0.693 G_L1: 0.274 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 140, time: 0.100, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.689 \n",
      "(epoch: 63, iters: 240, time: 0.100, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.692 D_fake: 0.697 \n",
      "(epoch: 63, iters: 340, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 63, iters: 440, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 63, iters: 540, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 640, time: 0.098, data: 0.002) G_GAN: 0.696 G_L1: 0.183 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 63, iters: 740, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.695 \n",
      "(epoch: 63, iters: 840, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 940, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.749 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 1040, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 1140, time: 0.103, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.697 \n",
      "(epoch: 63, iters: 1240, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.642 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 1340, time: 0.110, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.688 \n",
      "(epoch: 63, iters: 1440, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 63, iters: 1540, time: 0.099, data: 0.002) G_GAN: 0.694 G_L1: 0.497 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 63, iters: 1640, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 63, iters: 1740, time: 0.100, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 63, iters: 1840, time: 0.110, data: 0.001) G_GAN: 0.692 G_L1: 0.311 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 63, iters: 1940, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 2040, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 63, iters: 2140, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.481 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 63, iters: 2240, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 63 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 64, iters: 60, time: 0.106, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 64, iters: 160, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.233 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 64, iters: 260, time: 0.096, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.697 D_fake: 0.692 \n",
      "(epoch: 64, iters: 360, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 64, iters: 460, time: 0.111, data: 0.001) G_GAN: 0.697 G_L1: 0.330 D_real: 0.699 D_fake: 0.700 \n",
      "(epoch: 64, iters: 560, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 64, iters: 660, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 64, iters: 760, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.384 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 64, iters: 860, time: 0.096, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 64, iters: 960, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 64, iters: 1060, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.121 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 64, iters: 1160, time: 0.105, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.693 \n",
      "(epoch: 64, iters: 1260, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.972 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 64, iters: 1360, time: 0.097, data: 0.002) G_GAN: 0.703 G_L1: 0.343 D_real: 0.704 D_fake: 0.683 \n",
      "saving the latest model (epoch 64, total_steps 145000)\n",
      "(epoch: 64, iters: 1460, time: 0.097, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.689 D_fake: 0.692 \n",
      "(epoch: 64, iters: 1560, time: 0.095, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.688 D_fake: 0.698 \n",
      "(epoch: 64, iters: 1660, time: 0.095, data: 0.001) G_GAN: 0.690 G_L1: 0.358 D_real: 0.690 D_fake: 0.692 \n",
      "(epoch: 64, iters: 1760, time: 0.096, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 64, iters: 1860, time: 0.094, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 64, iters: 1960, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.233 D_real: 0.694 D_fake: 0.692 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 64, iters: 2060, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.691 \n",
      "(epoch: 64, iters: 2160, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 64, iters: 2260, time: 0.094, data: 0.002) G_GAN: 0.692 G_L1: 0.291 D_real: 0.692 D_fake: 0.691 \n",
      "End of epoch 64 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 65, iters: 80, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 65, iters: 180, time: 0.108, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 65, iters: 280, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.383 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 65, iters: 380, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 65, iters: 480, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 65, iters: 580, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.357 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 65, iters: 680, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 65, iters: 780, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 65, iters: 880, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.299 D_real: 0.693 D_fake: 0.690 \n",
      "(epoch: 65, iters: 980, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.886 D_real: 0.694 D_fake: 0.691 \n",
      "(epoch: 65, iters: 1080, time: 0.096, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 65, iters: 1180, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.243 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 65, iters: 1280, time: 0.099, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.697 \n",
      "(epoch: 65, iters: 1380, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 65, iters: 1480, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.460 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 65, iters: 1580, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 65, iters: 1680, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 65, iters: 1780, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.326 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 65, iters: 1880, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.691 \n",
      "(epoch: 65, iters: 1980, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 65, iters: 2080, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.211 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 65, iters: 2180, time: 0.100, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 65, iters: 2280, time: 0.096, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.697 \n",
      "saving the model at the end of epoch 65, iters 148200\n",
      "End of epoch 65 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 66, iters: 100, time: 0.108, data: 0.282) G_GAN: 0.691 G_L1: 0.238 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 66, iters: 200, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 66, iters: 300, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 66, iters: 400, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.223 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 66, iters: 500, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 66, iters: 600, time: 0.101, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 66, iters: 700, time: 0.109, data: 0.002) G_GAN: 0.695 G_L1: 0.252 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 66, iters: 800, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 66, iters: 900, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 66, iters: 1000, time: 0.097, data: 0.001) G_GAN: 0.680 G_L1: 0.295 D_real: 0.680 D_fake: 0.704 \n",
      "(epoch: 66, iters: 1100, time: 0.097, data: 0.001) G_GAN: 0.682 G_L1: 0.000 D_real: 0.682 D_fake: 0.704 \n",
      "(epoch: 66, iters: 1200, time: 0.098, data: 0.001) G_GAN: 0.679 G_L1: 0.000 D_real: 0.679 D_fake: 0.707 \n",
      "(epoch: 66, iters: 1300, time: 0.096, data: 0.001) G_GAN: 0.684 G_L1: 0.308 D_real: 0.684 D_fake: 0.702 \n",
      "(epoch: 66, iters: 1400, time: 0.095, data: 0.001) G_GAN: 0.686 G_L1: 0.007 D_real: 0.686 D_fake: 0.695 \n",
      "(epoch: 66, iters: 1500, time: 0.095, data: 0.001) G_GAN: 0.691 G_L1: 0.001 D_real: 0.691 D_fake: 0.700 \n",
      "(epoch: 66, iters: 1600, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.185 D_real: 0.692 D_fake: 0.698 \n",
      "(epoch: 66, iters: 1700, time: 0.100, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.695 \n",
      "(epoch: 66, iters: 1800, time: 0.106, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.695 \n",
      "saving the latest model (epoch 66, total_steps 150000)\n",
      "(epoch: 66, iters: 1900, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.376 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 66, iters: 2000, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 66, iters: 2100, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 66, iters: 2200, time: 0.099, data: 0.001) G_GAN: 0.690 G_L1: 0.200 D_real: 0.690 D_fake: 0.693 \n",
      "End of epoch 66 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 67, iters: 20, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 67, iters: 120, time: 0.103, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 67, iters: 220, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.251 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 67, iters: 320, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 67, iters: 420, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 67, iters: 520, time: 0.095, data: 0.002) G_GAN: 0.695 G_L1: 0.160 D_real: 0.695 D_fake: 0.694 \n",
      "(epoch: 67, iters: 620, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 67, iters: 720, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 67, iters: 820, time: 0.108, data: 0.001) G_GAN: 0.694 G_L1: 0.286 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 67, iters: 920, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 67, iters: 1020, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 67, iters: 1120, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.131 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 67, iters: 1220, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 67, iters: 1320, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.691 \n",
      "(epoch: 67, iters: 1420, time: 0.097, data: 0.002) G_GAN: 0.688 G_L1: 0.199 D_real: 0.688 D_fake: 0.698 \n",
      "(epoch: 67, iters: 1520, time: 0.097, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 67, iters: 1620, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 67, iters: 1720, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.348 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 67, iters: 1820, time: 0.099, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 67, iters: 1920, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.016 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 67, iters: 2020, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.227 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 67, iters: 2120, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 67, iters: 2220, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "End of epoch 67 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 68, iters: 40, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.213 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 140, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 68, iters: 240, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 68, iters: 340, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 68, iters: 440, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 540, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 640, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.191 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 740, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 840, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 940, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.579 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 1040, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 1140, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 1240, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.547 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 1340, time: 0.108, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 68, iters: 1440, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 68, iters: 1540, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.266 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 1640, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 1740, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 1840, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.262 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 1940, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 2040, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 2140, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.078 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 68, iters: 2240, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 68, total_steps 155000)\n",
      "End of epoch 68 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 69, iters: 60, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 160, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.260 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 260, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 360, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 460, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.202 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 560, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 660, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 760, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.386 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 860, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.010 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 960, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 69, iters: 1060, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.178 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 1160, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 1260, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.635 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 1360, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.325 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 69, iters: 1460, time: 0.096, data: 0.001) G_GAN: 0.670 G_L1: 0.000 D_real: 0.670 D_fake: 0.717 \n",
      "(epoch: 69, iters: 1560, time: 0.094, data: 0.001) G_GAN: 0.682 G_L1: 0.000 D_real: 0.682 D_fake: 0.704 \n",
      "(epoch: 69, iters: 1660, time: 0.096, data: 0.001) G_GAN: 0.687 G_L1: 0.334 D_real: 0.687 D_fake: 0.699 \n",
      "(epoch: 69, iters: 1760, time: 0.098, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 69, iters: 1860, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 1960, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.424 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 69, iters: 2060, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 69, iters: 2160, time: 0.096, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 69, iters: 2260, time: 0.095, data: 0.002) G_GAN: 0.694 G_L1: 0.366 D_real: 0.694 D_fake: 0.693 \n",
      "End of epoch 69 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 70, iters: 80, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 180, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 70, iters: 280, time: 0.106, data: 0.000) G_GAN: 0.692 G_L1: 0.468 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 70, iters: 380, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 70, iters: 480, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 580, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.237 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 70, iters: 680, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 780, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 70, iters: 880, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.308 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 70, iters: 980, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 70, iters: 1080, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 70, iters: 1180, time: 0.108, data: 0.001) G_GAN: 0.692 G_L1: 0.278 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 70, iters: 1280, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 1380, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 1480, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.507 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 1580, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 1680, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 1780, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.196 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 1880, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 1980, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 2080, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.381 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 2180, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 70, iters: 2280, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 70, iters 159600\n",
      "End of epoch 70 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 71, iters: 100, time: 0.107, data: 0.290) G_GAN: 0.693 G_L1: 0.323 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 71, iters: 200, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 71, iters: 300, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 71, iters: 400, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.195 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 71, total_steps 160000)\n",
      "(epoch: 71, iters: 500, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 71, iters: 600, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 71, iters: 700, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.210 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 71, iters: 800, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 71, iters: 900, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 71, iters: 1000, time: 0.099, data: 0.001) G_GAN: 0.683 G_L1: 0.251 D_real: 0.683 D_fake: 0.704 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 71, iters: 1100, time: 0.099, data: 0.002) G_GAN: 0.686 G_L1: 0.000 D_real: 0.686 D_fake: 0.700 \n",
      "(epoch: 71, iters: 1200, time: 0.099, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 71, iters: 1300, time: 0.099, data: 0.002) G_GAN: 0.692 G_L1: 0.875 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 71, iters: 1400, time: 0.108, data: 0.001) G_GAN: 0.689 G_L1: 0.120 D_real: 0.689 D_fake: 0.698 \n",
      "(epoch: 71, iters: 1500, time: 0.099, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 71, iters: 1600, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.150 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 71, iters: 1700, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 71, iters: 1800, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 71, iters: 1900, time: 0.103, data: 0.001) G_GAN: 0.692 G_L1: 0.292 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 71, iters: 2000, time: 0.100, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.690 \n",
      "(epoch: 71, iters: 2100, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 71, iters: 2200, time: 0.100, data: 0.001) G_GAN: 0.691 G_L1: 0.254 D_real: 0.691 D_fake: 0.695 \n",
      "End of epoch 71 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 72, iters: 20, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 72, iters: 120, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 72, iters: 220, time: 0.099, data: 0.002) G_GAN: 0.694 G_L1: 0.271 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 72, iters: 320, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 72, iters: 420, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 72, iters: 520, time: 0.096, data: 0.001) G_GAN: 0.695 G_L1: 0.265 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 72, iters: 620, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 72, iters: 720, time: 0.099, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.693 \n",
      "(epoch: 72, iters: 820, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.144 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 72, iters: 920, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 72, iters: 1020, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 72, iters: 1120, time: 0.102, data: 0.001) G_GAN: 0.695 G_L1: 0.340 D_real: 0.696 D_fake: 0.699 \n",
      "(epoch: 72, iters: 1220, time: 0.099, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 72, iters: 1320, time: 0.114, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 72, iters: 1420, time: 0.098, data: 0.003) G_GAN: 0.693 G_L1: 0.399 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 72, iters: 1520, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 72, iters: 1620, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 72, iters: 1720, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.277 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 72, iters: 1820, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 72, iters: 1920, time: 0.108, data: 0.001) G_GAN: 0.694 G_L1: 0.007 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 72, iters: 2020, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.280 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 72, iters: 2120, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 72, iters: 2220, time: 0.100, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.693 \n",
      "End of epoch 72 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 73, iters: 40, time: 0.108, data: 0.002) G_GAN: 0.694 G_L1: 0.172 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 73, iters: 140, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 73, iters: 240, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 73, iters: 340, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 73, iters: 440, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 73, iters: 540, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 73, iters: 640, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.219 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 73, iters: 740, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 73, iters: 840, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "saving the latest model (epoch 73, total_steps 165000)\n",
      "(epoch: 73, iters: 940, time: 0.098, data: 0.002) G_GAN: 0.691 G_L1: 0.441 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 73, iters: 1040, time: 0.094, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.686 \n",
      "(epoch: 73, iters: 1140, time: 0.095, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 73, iters: 1240, time: 0.100, data: 0.002) G_GAN: 0.691 G_L1: 0.683 D_real: 0.692 D_fake: 0.696 \n",
      "(epoch: 73, iters: 1340, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 73, iters: 1440, time: 0.099, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 73, iters: 1540, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.403 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 73, iters: 1640, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 73, iters: 1740, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 73, iters: 1840, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.151 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 73, iters: 1940, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 73, iters: 2040, time: 0.101, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.693 \n",
      "(epoch: 73, iters: 2140, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.121 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 73, iters: 2240, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 73 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 74, iters: 60, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 74, iters: 160, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.225 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 74, iters: 260, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 74, iters: 360, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 74, iters: 460, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.228 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 74, iters: 560, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.003 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 74, iters: 660, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 74, iters: 760, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.341 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 74, iters: 860, time: 0.094, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 74, iters: 960, time: 0.098, data: 0.001) G_GAN: 0.699 G_L1: 0.001 D_real: 0.699 D_fake: 0.688 \n",
      "(epoch: 74, iters: 1060, time: 0.094, data: 0.001) G_GAN: 0.691 G_L1: 0.090 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 74, iters: 1160, time: 0.096, data: 0.001) G_GAN: 0.686 G_L1: 0.000 D_real: 0.686 D_fake: 0.700 \n",
      "(epoch: 74, iters: 1260, time: 0.100, data: 0.002) G_GAN: 0.686 G_L1: 0.000 D_real: 0.687 D_fake: 0.699 \n",
      "(epoch: 74, iters: 1360, time: 0.107, data: 0.001) G_GAN: 0.692 G_L1: 0.531 D_real: 0.692 D_fake: 0.697 \n",
      "(epoch: 74, iters: 1460, time: 0.095, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.696 \n",
      "(epoch: 74, iters: 1560, time: 0.097, data: 0.001) G_GAN: 0.708 G_L1: 0.000 D_real: 0.708 D_fake: 0.679 \n",
      "(epoch: 74, iters: 1660, time: 0.100, data: 0.002) G_GAN: 0.703 G_L1: 0.202 D_real: 0.706 D_fake: 0.681 \n",
      "(epoch: 74, iters: 1760, time: 0.098, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.692 D_fake: 0.697 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 74, iters: 1860, time: 0.108, data: 0.002) G_GAN: 0.691 G_L1: 0.001 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 74, iters: 1960, time: 0.100, data: 0.002) G_GAN: 0.692 G_L1: 0.417 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 74, iters: 2060, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 74, iters: 2160, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 74, iters: 2260, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.253 D_real: 0.694 D_fake: 0.693 \n",
      "End of epoch 74 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 75, iters: 80, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 180, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 280, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.474 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 380, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 480, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 75, iters: 580, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.278 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 75, iters: 680, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 75, iters: 780, time: 0.098, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 75, iters: 880, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.251 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 980, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 1080, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 1180, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.217 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 75, iters: 1280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 75, total_steps 170000)\n",
      "(epoch: 75, iters: 1380, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 1480, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.224 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 75, iters: 1580, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 1680, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 1780, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.184 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 1880, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 1980, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 2080, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.200 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 2180, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 75, iters: 2280, time: 0.096, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 75, iters 171000\n",
      "End of epoch 75 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 76, iters: 100, time: 0.103, data: 0.276) G_GAN: 0.693 G_L1: 0.250 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 200, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 300, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 400, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.129 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 500, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 600, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 700, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.219 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 800, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 900, time: 0.093, data: 0.002) G_GAN: 0.672 G_L1: 0.000 D_real: 0.673 D_fake: 0.715 \n",
      "(epoch: 76, iters: 1000, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.236 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 1100, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 1200, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 76, iters: 1300, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.393 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 1400, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 1500, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 1600, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.186 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 1700, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 1800, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 1900, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.439 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 2000, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 2100, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 76, iters: 2200, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.196 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 76 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 77, iters: 20, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 120, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 220, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.211 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 320, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 420, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 520, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.342 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 620, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 720, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 820, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.262 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 920, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 77, iters: 1020, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 1120, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.215 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 1220, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 1320, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 1420, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.155 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 1520, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 1620, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 1720, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.208 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 77, total_steps 175000)\n",
      "(epoch: 77, iters: 1820, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 1920, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.104 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 2020, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.305 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 2120, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 77, iters: 2220, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 77 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 78, iters: 40, time: 0.122, data: 0.002) G_GAN: 0.693 G_L1: 0.226 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 140, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 78, iters: 240, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 340, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 440, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 540, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 640, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.182 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 740, time: 0.092, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 840, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 940, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.412 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 1040, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 1140, time: 0.096, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.693 D_fake: 0.704 \n",
      "(epoch: 78, iters: 1240, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.544 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 1340, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 1440, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 1540, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.267 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 1640, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 1740, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 1840, time: 0.098, data: 0.000) G_GAN: 0.693 G_L1: 0.311 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 1940, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 2040, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 2140, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.110 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 78, iters: 2240, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 78 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 79, iters: 60, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 160, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.260 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 260, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 360, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 460, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.250 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 560, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 660, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 760, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.190 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 860, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.107 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 960, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 1060, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.147 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 1160, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 1260, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.359 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 1360, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.327 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 1460, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 1560, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 1660, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.243 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 1760, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 1860, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 1960, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.410 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 2060, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 79, iters: 2160, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 79, total_steps 180000)\n",
      "(epoch: 79, iters: 2260, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.272 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 79 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 80, iters: 80, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 180, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 280, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.233 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 380, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 480, time: 0.097, data: 0.004) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 580, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.341 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 680, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 780, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 880, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.201 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 980, time: 0.098, data: 0.002) G_GAN: 0.687 G_L1: 0.055 D_real: 0.689 D_fake: 0.713 \n",
      "(epoch: 80, iters: 1080, time: 0.096, data: 0.002) G_GAN: 0.683 G_L1: 0.000 D_real: 0.683 D_fake: 0.704 \n",
      "(epoch: 80, iters: 1180, time: 0.101, data: 0.002) G_GAN: 0.671 G_L1: 0.161 D_real: 0.671 D_fake: 0.716 \n",
      "(epoch: 80, iters: 1280, time: 0.098, data: 0.001) G_GAN: 0.678 G_L1: 0.000 D_real: 0.678 D_fake: 0.699 \n",
      "(epoch: 80, iters: 1380, time: 0.096, data: 0.001) G_GAN: 0.686 G_L1: 0.000 D_real: 0.686 D_fake: 0.700 \n",
      "(epoch: 80, iters: 1480, time: 0.097, data: 0.001) G_GAN: 0.690 G_L1: 0.445 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 80, iters: 1580, time: 0.101, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 80, iters: 1680, time: 0.098, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.697 \n",
      "(epoch: 80, iters: 1780, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.266 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 80, iters: 1880, time: 0.098, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 80, iters: 1980, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 80, iters: 2080, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.160 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 80, iters: 2180, time: 0.096, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 80, iters: 2280, time: 0.095, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "saving the model at the end of epoch 80, iters 182400\n",
      "End of epoch 80 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 81, iters: 100, time: 0.120, data: 0.278) G_GAN: 0.692 G_L1: 0.227 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 81, iters: 200, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 81, iters: 300, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 81, iters: 400, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.184 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 81, iters: 500, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 81, iters: 600, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 81, iters: 700, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.221 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 81, iters: 800, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 81, iters: 900, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 81, iters: 1000, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.439 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 81, iters: 1100, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 81, iters: 1200, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 81, iters: 1300, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.324 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 81, iters: 1400, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.017 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 81, iters: 1500, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 81, iters: 1600, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.142 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 81, iters: 1700, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 81, iters: 1800, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 81, iters: 1900, time: 0.113, data: 0.002) G_GAN: 0.693 G_L1: 0.478 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 81, iters: 2000, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 81, iters: 2100, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 81, iters: 2200, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.150 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 81 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 82, iters: 20, time: 0.117, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 120, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 220, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.240 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 320, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 82, total_steps 185000)\n",
      "(epoch: 82, iters: 420, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 520, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.244 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 620, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 720, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 820, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.219 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 920, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 1020, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 1120, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.308 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 1220, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 1320, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 1420, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.244 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 1520, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 1620, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 1720, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.192 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 1820, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 1920, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.003 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 2020, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.351 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 2120, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 82, iters: 2220, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 82 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 83, iters: 40, time: 0.122, data: 0.002) G_GAN: 0.693 G_L1: 0.244 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 140, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 240, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 340, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 440, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 540, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 640, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.214 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 740, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 840, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 940, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.660 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 1040, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 1140, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 1240, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.489 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 1340, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 1440, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 1540, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.320 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 1640, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 1740, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 1840, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.217 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 1940, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 2040, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 2140, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.125 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 83, iters: 2240, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 83 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 84, iters: 60, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 160, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.449 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 260, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 360, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 460, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.303 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 560, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 660, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 760, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.309 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 84, total_steps 190000)\n",
      "(epoch: 84, iters: 860, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 960, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 1060, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.077 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 1160, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 1260, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.278 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 1360, time: 0.096, data: 0.000) G_GAN: 0.693 G_L1: 0.509 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 1460, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 1560, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 1660, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.327 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 84, iters: 1760, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 1860, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 1960, time: 0.112, data: 0.002) G_GAN: 0.693 G_L1: 0.151 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 2060, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 2160, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 84, iters: 2260, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.292 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 84 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 85, iters: 80, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 180, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 280, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.327 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 380, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 480, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 580, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.268 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 680, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 780, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 880, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.306 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 980, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.367 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 1080, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 1180, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.225 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 1280, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 1380, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 1480, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.121 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 1580, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 1680, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 1780, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.208 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 1880, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 1980, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 2080, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.238 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 2180, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 85, iters: 2280, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 85, iters 193800\n",
      "End of epoch 85 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 86, iters: 100, time: 0.106, data: 0.279) G_GAN: 0.693 G_L1: 0.258 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 86, iters: 200, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 86, iters: 300, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 86, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.224 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 86, iters: 500, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 86, iters: 600, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 86, iters: 700, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.176 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 86, iters: 800, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 86, iters: 900, time: 0.093, data: 0.002) G_GAN: 0.692 G_L1: 0.004 D_real: 0.690 D_fake: 0.700 \n",
      "(epoch: 86, iters: 1000, time: 0.100, data: 0.001) G_GAN: 0.710 G_L1: 0.221 D_real: 0.710 D_fake: 0.677 \n",
      "(epoch: 86, iters: 1100, time: 0.101, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.701 D_fake: 0.685 \n",
      "(epoch: 86, iters: 1200, time: 0.098, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.690 \n",
      "saving the latest model (epoch 86, total_steps 195000)\n",
      "(epoch: 86, iters: 1300, time: 0.112, data: 0.002) G_GAN: 0.694 G_L1: 0.238 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 86, iters: 1400, time: 0.101, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 86, iters: 1500, time: 0.099, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 86, iters: 1600, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.184 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 86, iters: 1700, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 86, iters: 1800, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 86, iters: 1900, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.299 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 86, iters: 2000, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 86, iters: 2100, time: 0.107, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 86, iters: 2200, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.165 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 86 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 87, iters: 20, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 120, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 220, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.347 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 320, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 420, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 520, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.189 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 87, iters: 620, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 87, iters: 720, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 820, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.361 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 920, time: 0.096, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 87, iters: 1020, time: 0.112, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 1120, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.134 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 87, iters: 1220, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 1320, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 1420, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.204 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 1520, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 1620, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 1720, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.291 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 1820, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 1920, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 2020, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.360 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 2120, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 87, iters: 2220, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 87 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 88, iters: 40, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.163 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 88, iters: 140, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 240, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 340, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 440, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 540, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 640, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.234 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 740, time: 0.092, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 840, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 940, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.436 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 88, iters: 1040, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 1140, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 1240, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.600 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 1340, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 1440, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 1540, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.273 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 1640, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 88, total_steps 200000)\n",
      "(epoch: 88, iters: 1740, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 1840, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.156 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 1940, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 2040, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 2140, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.122 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 88, iters: 2240, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 88 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 89, iters: 60, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 160, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.276 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 260, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 360, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 460, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.258 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 560, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 660, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 760, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.262 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 860, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 960, time: 0.096, data: 0.005) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 1060, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.071 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 1160, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 1260, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.339 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 1360, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.240 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 1460, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 1560, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 1660, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.264 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 1760, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 1860, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 1960, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.417 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 2060, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 2160, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 89, iters: 2260, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.308 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 89 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 90, iters: 80, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 180, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.218 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 380, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 480, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 580, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.261 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 680, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 780, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 880, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.219 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 90, iters: 980, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 90, iters: 1080, time: 0.105, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 90, iters: 1180, time: 0.099, data: 0.002) G_GAN: 0.694 G_L1: 0.193 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 90, iters: 1280, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 1380, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 1480, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.335 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 90, iters: 1580, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 1680, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 90, iters: 1780, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.305 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 1880, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 1980, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 90, iters: 2080, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.212 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 90, total_steps 205000)\n",
      "(epoch: 90, iters: 2180, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 90, iters: 2280, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 90, iters 205200\n",
      "End of epoch 90 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 91, iters: 100, time: 0.106, data: 0.267) G_GAN: 0.693 G_L1: 0.250 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 200, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 300, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 400, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.320 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 500, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 600, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 700, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.180 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 91, iters: 800, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 900, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 91, iters: 1000, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.176 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 1100, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 91, iters: 1200, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 1300, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.289 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 1400, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 1500, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 1600, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.133 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 1700, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 1800, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 1900, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.352 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 2000, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 2100, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 91, iters: 2200, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.162 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 91 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 92, iters: 20, time: 0.116, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 120, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 220, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.262 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 320, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 420, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 520, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.170 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 620, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 720, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 820, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.328 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 920, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 1020, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 1120, time: 0.112, data: 0.002) G_GAN: 0.693 G_L1: 0.196 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 1220, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 1320, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 1420, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.334 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 1520, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 1620, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 1720, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.180 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 1820, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 1920, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 2020, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.336 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 2120, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 92, iters: 2220, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 92 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 93, iters: 40, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.247 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 140, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 240, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 93, total_steps 210000)\n",
      "(epoch: 93, iters: 340, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 440, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 540, time: 0.093, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 640, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.160 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 740, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 840, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 940, time: 0.099, data: 0.001) G_GAN: 0.695 G_L1: 0.332 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 93, iters: 1040, time: 0.094, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 93, iters: 1140, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 1240, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.399 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 1340, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 1440, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 1540, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.379 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 1640, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 1740, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 1840, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.131 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 1940, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 2040, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 2140, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.319 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 93, iters: 2240, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 93 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 94, iters: 60, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 160, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.261 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 260, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 360, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 460, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.244 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 94, iters: 560, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 660, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 760, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.305 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 860, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.028 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 960, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 1060, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.075 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 1160, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 1260, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.949 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 1360, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.286 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 1460, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 94, iters: 1560, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 1660, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.196 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 1760, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 1860, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 1960, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.206 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 2060, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 2160, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 94, iters: 2260, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.295 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 94 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 95, iters: 80, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 95, iters: 180, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 95, iters: 280, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.227 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 95, iters: 380, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 95, iters: 480, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 95, iters: 580, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.235 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 95, iters: 680, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 95, total_steps 215000)\n",
      "(epoch: 95, iters: 780, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 95, iters: 880, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.252 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 95, iters: 980, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 95, iters: 1080, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 95, iters: 1180, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.215 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 95, iters: 1280, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 95, iters: 1380, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 95, iters: 1480, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.290 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 95, iters: 1580, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 95, iters: 1680, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 95, iters: 1780, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.209 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 95, iters: 1880, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 95, iters: 1980, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 95, iters: 2080, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.220 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 95, iters: 2180, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 95, iters: 2280, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 95, iters 216600\n",
      "End of epoch 95 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 96, iters: 100, time: 0.105, data: 0.278) G_GAN: 0.693 G_L1: 0.342 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 200, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 300, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 400, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.148 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 500, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 600, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 700, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.236 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 800, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 900, time: 0.104, data: 0.001) G_GAN: 0.662 G_L1: 0.000 D_real: 0.646 D_fake: 0.744 \n",
      "(epoch: 96, iters: 1000, time: 0.098, data: 0.002) G_GAN: 0.700 G_L1: 0.308 D_real: 0.700 D_fake: 0.686 \n",
      "(epoch: 96, iters: 1100, time: 0.101, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.703 D_fake: 0.683 \n",
      "(epoch: 96, iters: 1200, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 96, iters: 1300, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.321 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 1400, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 1500, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 1600, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.140 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 1700, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 1800, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 1900, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.282 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 2000, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 96, iters: 2100, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 96, iters: 2200, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.125 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 96 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 97, iters: 20, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 120, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 220, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.208 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 320, time: 0.108, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 420, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 520, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.219 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 620, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 720, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 820, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.227 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 920, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 1020, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 1120, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.176 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 97, total_steps 220000)\n",
      "(epoch: 97, iters: 1220, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 1320, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 1420, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.184 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 1520, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.004 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 1620, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 1720, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.218 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 1820, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 1920, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 2020, time: 0.099, data: 0.003) G_GAN: 0.693 G_L1: 0.276 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 97, iters: 2120, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 97, iters: 2220, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 97 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 98, iters: 40, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.168 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 140, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 240, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 340, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 440, time: 0.106, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 540, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 640, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.227 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 740, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 840, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 940, time: 0.098, data: 0.002) G_GAN: 0.716 G_L1: 0.403 D_real: 0.715 D_fake: 0.668 \n",
      "(epoch: 98, iters: 1040, time: 0.094, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.699 D_fake: 0.688 \n",
      "(epoch: 98, iters: 1140, time: 0.097, data: 0.001) G_GAN: 0.713 G_L1: 0.000 D_real: 0.709 D_fake: 0.579 \n",
      "(epoch: 98, iters: 1240, time: 0.105, data: 0.001) G_GAN: 0.695 G_L1: 0.440 D_real: 0.696 D_fake: 0.708 \n",
      "(epoch: 98, iters: 1340, time: 0.097, data: 0.001) G_GAN: 0.686 G_L1: 0.000 D_real: 0.686 D_fake: 0.700 \n",
      "(epoch: 98, iters: 1440, time: 0.099, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.698 \n",
      "(epoch: 98, iters: 1540, time: 0.098, data: 0.002) G_GAN: 0.690 G_L1: 0.244 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 98, iters: 1640, time: 0.096, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 98, iters: 1740, time: 0.098, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.694 \n",
      "(epoch: 98, iters: 1840, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.157 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 98, iters: 1940, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.688 \n",
      "(epoch: 98, iters: 2040, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 98, iters: 2140, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.077 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 98, iters: 2240, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "End of epoch 98 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 99, iters: 60, time: 0.103, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 99, iters: 160, time: 0.100, data: 0.003) G_GAN: 0.692 G_L1: 0.318 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 99, iters: 260, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 99, iters: 360, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 99, iters: 460, time: 0.106, data: 0.001) G_GAN: 0.692 G_L1: 0.206 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 99, iters: 560, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 99, iters: 660, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 99, iters: 760, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.200 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 860, time: 0.107, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 99, iters: 960, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 1060, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.078 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 1160, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 1260, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 99, iters: 1360, time: 0.100, data: 0.002) G_GAN: 0.694 G_L1: 0.238 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 1460, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 1560, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 99, total_steps 225000)\n",
      "(epoch: 99, iters: 1660, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.180 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 1760, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 1860, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 1960, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.353 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 2060, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 99, iters: 2160, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 99, iters: 2260, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.300 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 99 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 100, iters: 80, time: 0.105, data: 0.000) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 100, iters: 180, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 100, iters: 280, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.235 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 100, iters: 380, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 100, iters: 480, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 100, iters: 580, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.214 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 100, iters: 680, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 100, iters: 780, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 100, iters: 880, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.388 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 100, iters: 980, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 100, iters: 1080, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 100, iters: 1180, time: 0.099, data: 0.001) G_GAN: 0.690 G_L1: 0.127 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 100, iters: 1280, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 100, iters: 1380, time: 0.096, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 100, iters: 1480, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.221 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 100, iters: 1580, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 100, iters: 1680, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 100, iters: 1780, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.353 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 100, iters: 1880, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 100, iters: 1980, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 100, iters: 2080, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.190 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 100, iters: 2180, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 100, iters: 2280, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 100, iters 228000\n",
      "End of epoch 100 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001980\n",
      "(epoch: 101, iters: 100, time: 0.121, data: 0.284) G_GAN: 0.693 G_L1: 0.160 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 101, iters: 200, time: 0.095, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 101, iters: 300, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 101, iters: 400, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.183 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 101, iters: 500, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 101, iters: 600, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 101, iters: 700, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.233 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 101, iters: 800, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 101, iters: 900, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 101, iters: 1000, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.283 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 101, iters: 1100, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 101, iters: 1200, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 101, iters: 1300, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.311 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 101, iters: 1400, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 101, iters: 1500, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 101, iters: 1600, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.138 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 101, iters: 1700, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 101, iters: 1800, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 101, iters: 1900, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.418 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 101, iters: 2000, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 101, total_steps 230000)\n",
      "(epoch: 101, iters: 2100, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 101, iters: 2200, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.119 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 101 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001960\n",
      "(epoch: 102, iters: 20, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 102, iters: 120, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 102, iters: 220, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.300 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 102, iters: 320, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 102, iters: 420, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 102, iters: 520, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.190 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 102, iters: 620, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 102, iters: 720, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 102, iters: 820, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.200 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 102, iters: 920, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 102, iters: 1020, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 102, iters: 1120, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.232 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 102, iters: 1220, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 102, iters: 1320, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 102, iters: 1420, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.167 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 102, iters: 1520, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 102, iters: 1620, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 102, iters: 1720, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.229 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 102, iters: 1820, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 102, iters: 1920, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 102, iters: 2020, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.287 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 102, iters: 2120, time: 0.100, data: 0.000) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 102, iters: 2220, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 102 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001941\n",
      "(epoch: 103, iters: 40, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.181 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 103, iters: 140, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 103, iters: 240, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 103, iters: 340, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.672 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 103, iters: 440, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 103, iters: 540, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 103, iters: 640, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.203 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 103, iters: 740, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 103, iters: 840, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 103, iters: 940, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.683 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 103, iters: 1040, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 103, iters: 1140, time: 0.097, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.694 D_fake: 0.700 \n",
      "(epoch: 103, iters: 1240, time: 0.096, data: 0.001) G_GAN: 0.696 G_L1: 0.305 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 103, iters: 1340, time: 0.111, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 103, iters: 1440, time: 0.101, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.696 \n",
      "(epoch: 103, iters: 1540, time: 0.097, data: 0.002) G_GAN: 0.691 G_L1: 0.223 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 103, iters: 1640, time: 0.096, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.686 \n",
      "(epoch: 103, iters: 1740, time: 0.111, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 103, iters: 1840, time: 0.109, data: 0.002) G_GAN: 0.692 G_L1: 0.110 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 103, iters: 1940, time: 0.100, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 103, iters: 2040, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 103, iters: 2140, time: 0.108, data: 0.002) G_GAN: 0.694 G_L1: 0.114 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 103, iters: 2240, time: 0.097, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "End of epoch 103 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001921\n",
      "(epoch: 104, iters: 60, time: 0.106, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 104, iters: 160, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.287 D_real: 0.692 D_fake: 0.694 \n",
      "saving the latest model (epoch 104, total_steps 235000)\n",
      "(epoch: 104, iters: 260, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 104, iters: 360, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 104, iters: 460, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.208 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 104, iters: 560, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 104, iters: 660, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 104, iters: 760, time: 0.099, data: 0.002) G_GAN: 0.694 G_L1: 0.252 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 104, iters: 860, time: 0.093, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 104, iters: 960, time: 0.106, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 104, iters: 1060, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.082 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 104, iters: 1160, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 104, iters: 1260, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.019 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 104, iters: 1360, time: 0.095, data: 0.002) G_GAN: 0.694 G_L1: 0.811 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 104, iters: 1460, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 104, iters: 1560, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 104, iters: 1660, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.387 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 104, iters: 1760, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 104, iters: 1860, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 104, iters: 1960, time: 0.098, data: 0.000) G_GAN: 0.693 G_L1: 0.244 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 104, iters: 2060, time: 0.096, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 104, iters: 2160, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 104, iters: 2260, time: 0.095, data: 0.001) G_GAN: 0.694 G_L1: 0.188 D_real: 0.694 D_fake: 0.693 \n",
      "End of epoch 104 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001901\n",
      "(epoch: 105, iters: 80, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 280, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.151 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 380, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 480, time: 0.096, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 105, iters: 580, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.203 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 105, iters: 680, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 780, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 880, time: 0.106, data: 0.002) G_GAN: 0.694 G_L1: 0.193 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 105, iters: 980, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 1080, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 1180, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.276 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 105, iters: 1280, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 1380, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 1480, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.575 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 1580, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 1680, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 1780, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.251 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 1880, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 1980, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 2080, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.138 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 2180, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 105, iters: 2280, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 105, iters 239400\n",
      "End of epoch 105 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0001881\n",
      "(epoch: 106, iters: 100, time: 0.104, data: 0.279) G_GAN: 0.693 G_L1: 0.217 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 200, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 300, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.220 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 500, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 600, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 106, total_steps 240000)\n",
      "(epoch: 106, iters: 700, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.253 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 800, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 900, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 1000, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.263 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 1100, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 106, iters: 1200, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 1300, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.228 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 1400, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 1500, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 1600, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.112 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 1700, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 1800, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 1900, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.414 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 2000, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 2100, time: 0.086, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 106, iters: 2200, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.132 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 106 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001861\n",
      "(epoch: 107, iters: 20, time: 0.123, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 120, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 220, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.224 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 320, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 420, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 520, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.150 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 620, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 720, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 820, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.179 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 920, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 107, iters: 1020, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 1120, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.446 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 1220, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 1320, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 1420, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.288 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 1520, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 1620, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 1720, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.229 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 1820, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 107, iters: 1920, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 2020, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.200 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 2120, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 107, iters: 2220, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 107 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001842\n",
      "(epoch: 108, iters: 40, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.238 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 140, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 240, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 340, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.573 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 440, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 540, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 640, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.148 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 740, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 840, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 108, iters: 940, time: 0.114, data: 0.001) G_GAN: 0.695 G_L1: 0.638 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 108, iters: 1040, time: 0.094, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.693 \n",
      "saving the latest model (epoch 108, total_steps 245000)\n",
      "(epoch: 108, iters: 1140, time: 0.099, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.720 D_fake: 0.673 \n",
      "(epoch: 108, iters: 1240, time: 0.096, data: 0.002) G_GAN: 0.695 G_L1: 0.346 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 108, iters: 1340, time: 0.110, data: 0.002) G_GAN: 0.683 G_L1: 0.000 D_real: 0.683 D_fake: 0.704 \n",
      "(epoch: 108, iters: 1440, time: 0.107, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.685 D_fake: 0.702 \n",
      "(epoch: 108, iters: 1540, time: 0.099, data: 0.001) G_GAN: 0.689 G_L1: 0.243 D_real: 0.689 D_fake: 0.697 \n",
      "(epoch: 108, iters: 1640, time: 0.097, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 108, iters: 1740, time: 0.111, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.694 \n",
      "(epoch: 108, iters: 1840, time: 0.110, data: 0.002) G_GAN: 0.694 G_L1: 0.199 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 108, iters: 1940, time: 0.096, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 108, iters: 2040, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 108, iters: 2140, time: 0.099, data: 0.002) G_GAN: 0.698 G_L1: 0.096 D_real: 0.699 D_fake: 0.692 \n",
      "(epoch: 108, iters: 2240, time: 0.098, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "End of epoch 108 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001822\n",
      "(epoch: 109, iters: 60, time: 0.107, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 109, iters: 160, time: 0.101, data: 0.002) G_GAN: 0.692 G_L1: 0.259 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 109, iters: 260, time: 0.109, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 109, iters: 360, time: 0.100, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.690 \n",
      "(epoch: 109, iters: 460, time: 0.101, data: 0.001) G_GAN: 0.696 G_L1: 0.255 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 109, iters: 560, time: 0.098, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 109, iters: 660, time: 0.103, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 109, iters: 760, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.284 D_real: 0.693 D_fake: 0.691 \n",
      "(epoch: 109, iters: 860, time: 0.094, data: 0.002) G_GAN: 0.696 G_L1: 0.001 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 109, iters: 960, time: 0.095, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 109, iters: 1060, time: 0.098, data: 0.002) G_GAN: 0.691 G_L1: 0.068 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 109, iters: 1160, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 109, iters: 1260, time: 0.109, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 109, iters: 1360, time: 0.100, data: 0.002) G_GAN: 0.694 G_L1: 0.256 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 109, iters: 1460, time: 0.096, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 109, iters: 1560, time: 0.097, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 109, iters: 1660, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.438 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 109, iters: 1760, time: 0.100, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 109, iters: 1860, time: 0.108, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 109, iters: 1960, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.405 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 109, iters: 2060, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 109, iters: 2160, time: 0.107, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 109, iters: 2260, time: 0.104, data: 0.001) G_GAN: 0.692 G_L1: 0.258 D_real: 0.692 D_fake: 0.693 \n",
      "End of epoch 109 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001802\n",
      "(epoch: 110, iters: 80, time: 0.115, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 180, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 110, iters: 280, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.300 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 110, iters: 380, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 110, iters: 480, time: 0.100, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 110, iters: 580, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.264 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 110, iters: 680, time: 0.101, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.695 D_fake: 0.692 \n",
      "(epoch: 110, iters: 780, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 880, time: 0.095, data: 0.001) G_GAN: 0.695 G_L1: 0.249 D_real: 0.695 D_fake: 0.690 \n",
      "(epoch: 110, iters: 980, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.696 \n",
      "(epoch: 110, iters: 1080, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 110, iters: 1180, time: 0.099, data: 0.002) G_GAN: 0.694 G_L1: 0.233 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 110, iters: 1280, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 110, iters: 1380, time: 0.097, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 110, iters: 1480, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.144 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 110, total_steps 250000)\n",
      "(epoch: 110, iters: 1580, time: 0.107, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 110, iters: 1680, time: 0.110, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.691 \n",
      "(epoch: 110, iters: 1780, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.244 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 110, iters: 1880, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 1980, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 110, iters: 2080, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.224 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 110, iters: 2180, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 110, iters: 2280, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "saving the model at the end of epoch 110, iters 250800\n",
      "End of epoch 110 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001782\n",
      "(epoch: 111, iters: 100, time: 0.106, data: 0.301) G_GAN: 0.694 G_L1: 0.291 D_real: 0.694 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 111, iters: 200, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 111, iters: 300, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 400, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.166 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 500, time: 0.096, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 111, iters: 600, time: 0.100, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 111, iters: 700, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.166 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 800, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 900, time: 0.092, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.690 \n",
      "(epoch: 111, iters: 1000, time: 0.097, data: 0.001) G_GAN: 0.694 G_L1: 0.302 D_real: 0.695 D_fake: 0.694 \n",
      "(epoch: 111, iters: 1100, time: 0.109, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 111, iters: 1200, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 111, iters: 1300, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 1.070 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 1400, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 111, iters: 1500, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 1600, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.112 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 1700, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 1800, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 1900, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.246 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 2000, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 111, iters: 2100, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 111, iters: 2200, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.122 D_real: 0.693 D_fake: 0.694 \n",
      "End of epoch 111 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001762\n",
      "(epoch: 112, iters: 20, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 120, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 220, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.232 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 320, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 420, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 112, iters: 520, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.139 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 620, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 720, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 820, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.318 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 920, time: 0.093, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.692 \n",
      "(epoch: 112, iters: 1020, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 112, iters: 1120, time: 0.111, data: 0.003) G_GAN: 0.693 G_L1: 0.281 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 112, iters: 1220, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 1320, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 1420, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.169 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 112, iters: 1520, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 1620, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 1720, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.153 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 1820, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 1920, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 112, total_steps 255000)\n",
      "(epoch: 112, iters: 2020, time: 0.112, data: 0.001) G_GAN: 0.693 G_L1: 0.443 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 2120, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 112, iters: 2220, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 112 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001743\n",
      "(epoch: 113, iters: 40, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.220 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 140, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 240, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 340, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 440, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 540, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 640, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.189 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 740, time: 0.092, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 840, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 940, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.667 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 1040, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 1140, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 1240, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.539 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 1340, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 1440, time: 0.112, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 1540, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.245 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 1640, time: 0.113, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 1740, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 1840, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.171 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 1940, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 2040, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 2140, time: 0.112, data: 0.002) G_GAN: 0.693 G_L1: 0.116 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 113, iters: 2240, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 113 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001723\n",
      "(epoch: 114, iters: 60, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 160, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.175 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 260, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 360, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 460, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.214 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 560, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 660, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 760, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.202 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 860, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 114, iters: 960, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 1060, time: 0.097, data: 0.003) G_GAN: 0.693 G_L1: 0.084 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 1160, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 1260, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.186 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 1360, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.324 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 1460, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 1560, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 1660, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.174 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 1760, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 1860, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 1960, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.155 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 2060, time: 0.106, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 2160, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 114, iters: 2260, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.174 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 114 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001703\n",
      "(epoch: 115, iters: 80, time: 0.116, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 115, total_steps 260000)\n",
      "(epoch: 115, iters: 180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 280, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.200 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 380, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 480, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 580, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.257 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 680, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 780, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 880, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.165 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 980, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.871 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 1080, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 1180, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.201 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 1280, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 1380, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 1480, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.304 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 1580, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 1680, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 1780, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.374 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 1880, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 1980, time: 0.113, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 2080, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.204 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 2180, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 115, iters: 2280, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 115, iters 262200\n",
      "End of epoch 115 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0001683\n",
      "(epoch: 116, iters: 100, time: 0.107, data: 0.287) G_GAN: 0.693 G_L1: 0.167 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 200, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 300, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 400, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.118 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 500, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 600, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 700, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.210 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 800, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 900, time: 0.092, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 116, iters: 1000, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.262 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 1100, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 1200, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 1300, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.240 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 1400, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 1500, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 1600, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.206 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 1700, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 1800, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 1900, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.264 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 2000, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 116, iters: 2100, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 116, iters: 2200, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.129 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 116 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001663\n",
      "(epoch: 117, iters: 20, time: 0.116, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 120, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 220, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.181 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 320, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 420, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 520, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.272 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 117, total_steps 265000)\n",
      "(epoch: 117, iters: 620, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 720, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 820, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.188 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 920, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 1020, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 1120, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.159 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 1220, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 1320, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 1420, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.156 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 1520, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 117, iters: 1620, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 1720, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.201 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 1820, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 1920, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.003 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 2020, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.323 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 2120, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 117, iters: 2220, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 117 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001644\n",
      "(epoch: 118, iters: 40, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.257 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 140, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 240, time: 0.101, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 340, time: 0.116, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 440, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 540, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 640, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.185 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 740, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 840, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 940, time: 0.099, data: 0.002) G_GAN: 0.698 G_L1: 0.262 D_real: 0.697 D_fake: 0.691 \n",
      "(epoch: 118, iters: 1040, time: 0.096, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 118, iters: 1140, time: 0.097, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.694 \n",
      "(epoch: 118, iters: 1240, time: 0.095, data: 0.001) G_GAN: 0.697 G_L1: 0.538 D_real: 0.697 D_fake: 0.690 \n",
      "(epoch: 118, iters: 1340, time: 0.109, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.691 \n",
      "(epoch: 118, iters: 1440, time: 0.111, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 118, iters: 1540, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.253 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 1640, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.694 \n",
      "(epoch: 118, iters: 1740, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 118, iters: 1840, time: 0.100, data: 0.002) G_GAN: 0.692 G_L1: 0.188 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 118, iters: 1940, time: 0.100, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 118, iters: 2040, time: 0.110, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.692 \n",
      "(epoch: 118, iters: 2140, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.090 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 118, iters: 2240, time: 0.099, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "End of epoch 118 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001624\n",
      "(epoch: 119, iters: 60, time: 0.105, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 119, iters: 160, time: 0.098, data: 0.002) G_GAN: 0.691 G_L1: 0.224 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 119, iters: 260, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.691 \n",
      "(epoch: 119, iters: 360, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 119, iters: 460, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.259 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 119, iters: 560, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 119, iters: 660, time: 0.100, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 119, iters: 760, time: 0.096, data: 0.001) G_GAN: 0.695 G_L1: 0.279 D_real: 0.695 D_fake: 0.691 \n",
      "(epoch: 119, iters: 860, time: 0.104, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 119, iters: 960, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "saving the latest model (epoch 119, total_steps 270000)\n",
      "(epoch: 119, iters: 1060, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.086 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 1160, time: 0.107, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 119, iters: 1260, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.753 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 1360, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.244 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 1460, time: 0.106, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 119, iters: 1560, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 1660, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.242 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 1760, time: 0.109, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 119, iters: 1860, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 119, iters: 1960, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.400 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 119, iters: 2060, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 119, iters: 2160, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 119, iters: 2260, time: 0.094, data: 0.002) G_GAN: 0.694 G_L1: 0.172 D_real: 0.694 D_fake: 0.693 \n",
      "End of epoch 119 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001604\n",
      "(epoch: 120, iters: 80, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 180, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 120, iters: 280, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.165 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 380, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 480, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 120, iters: 580, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.316 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 680, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 780, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 880, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.194 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 980, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 1080, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 1180, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.141 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 1280, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 1380, time: 0.102, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 1480, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.289 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 1580, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 1680, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 1780, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.211 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 1880, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 1980, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 2080, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.172 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 2180, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 120, iters: 2280, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 120, iters 273600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 120 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001584\n",
      "(epoch: 121, iters: 100, time: 0.120, data: 0.280) G_GAN: 0.693 G_L1: 0.258 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 200, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 300, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.192 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 500, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 600, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 700, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.169 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 800, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 900, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 1000, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.249 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 1100, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 1200, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 1300, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.361 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 1400, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 121, total_steps 275000)\n",
      "(epoch: 121, iters: 1500, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 1600, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.096 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 1700, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 1800, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 1900, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.601 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 2000, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 2100, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 121, iters: 2200, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.131 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 121 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001564\n",
      "(epoch: 122, iters: 20, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 120, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 220, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.218 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 320, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 420, time: 0.110, data: 0.006) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 520, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.184 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 620, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 720, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 820, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.227 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 920, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 1020, time: 0.112, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 1120, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.225 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 1220, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 1320, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 1420, time: 0.114, data: 0.002) G_GAN: 0.693 G_L1: 0.149 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 1520, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 1620, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 1720, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.159 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 1820, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 1920, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 2020, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.212 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 2120, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 122, iters: 2220, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 122 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001545\n",
      "(epoch: 123, iters: 40, time: 0.118, data: 0.002) G_GAN: 0.693 G_L1: 0.238 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 140, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 240, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 340, time: 0.099, data: 0.000) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 440, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 540, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 640, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.182 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 740, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 840, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 940, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.202 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 1040, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 1140, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 1240, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.358 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 1340, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 1440, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 1540, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.178 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 1640, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 1740, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.002 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 1840, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.270 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 123, total_steps 280000)\n",
      "(epoch: 123, iters: 1940, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 2040, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 2140, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.194 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 123, iters: 2240, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 123 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001525\n",
      "(epoch: 124, iters: 60, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 160, time: 0.112, data: 0.002) G_GAN: 0.693 G_L1: 0.182 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 260, time: 0.097, data: 0.000) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 360, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 460, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.177 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 560, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 124, iters: 660, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 760, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.239 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 860, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 960, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 1060, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.194 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 1160, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.022 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 1260, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.282 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 1360, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.245 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 1460, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 1560, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 1660, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.219 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 1760, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 1860, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 1960, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.095 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 2060, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 2160, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 124, iters: 2260, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.197 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 124 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001505\n",
      "(epoch: 125, iters: 80, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 180, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 280, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.218 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 380, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 480, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 580, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.184 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 680, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 780, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 880, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.217 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 980, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 1080, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 1180, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.180 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 1280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 1380, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 1480, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.277 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 1580, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 1680, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 1780, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.155 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 1880, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 1980, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 2080, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.144 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 2180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 125, iters: 2280, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 125, total_steps 285000)\n",
      "saving the model at the end of epoch 125, iters 285000\n",
      "End of epoch 125 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0001485\n",
      "(epoch: 126, iters: 100, time: 0.115, data: 0.284) G_GAN: 0.693 G_L1: 0.171 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 200, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 300, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 400, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.146 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 500, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 600, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 700, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.146 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 800, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 900, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 1000, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.251 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 1100, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 1200, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 1300, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.286 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 1400, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 1500, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 1600, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.139 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 1700, time: 0.114, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 1800, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 1900, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.249 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 2000, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 2100, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 126, iters: 2200, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.106 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 126 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001465\n",
      "(epoch: 127, iters: 20, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 120, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 220, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.205 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 320, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 420, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 520, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.131 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 620, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 720, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 820, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.222 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 920, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 1020, time: 0.108, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 1120, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.159 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 1220, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 127, iters: 1320, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 1420, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.132 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 1520, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 1620, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 1720, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.148 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 1820, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 1920, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 2020, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.196 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 2120, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 127, iters: 2220, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 127 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001446\n",
      "(epoch: 128, iters: 40, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.211 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 140, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 240, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 340, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 440, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 128, total_steps 290000)\n",
      "(epoch: 128, iters: 540, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 640, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.191 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 740, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 840, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 940, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.236 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 1040, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 1140, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 1240, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.378 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 1340, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 1440, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 1540, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.250 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 1640, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 1740, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 1840, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.130 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 1940, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 2040, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 128, iters: 2140, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.112 D_real: 0.692 D_fake: 0.692 \n",
      "(epoch: 128, iters: 2240, time: 0.098, data: 0.002) G_GAN: 0.649 G_L1: 0.000 D_real: 0.648 D_fake: 0.570 \n",
      "End of epoch 128 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001426\n",
      "(epoch: 129, iters: 60, time: 0.106, data: 0.001) G_GAN: 0.664 G_L1: 0.000 D_real: 0.664 D_fake: 0.719 \n",
      "(epoch: 129, iters: 160, time: 0.100, data: 0.001) G_GAN: 0.659 G_L1: 0.179 D_real: 0.659 D_fake: 0.729 \n",
      "(epoch: 129, iters: 260, time: 0.098, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.681 D_fake: 0.710 \n",
      "(epoch: 129, iters: 360, time: 0.096, data: 0.002) G_GAN: 0.671 G_L1: 0.000 D_real: 0.671 D_fake: 0.715 \n",
      "(epoch: 129, iters: 460, time: 0.098, data: 0.002) G_GAN: 0.674 G_L1: 0.169 D_real: 0.675 D_fake: 0.706 \n",
      "(epoch: 129, iters: 560, time: 0.096, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.681 D_fake: 0.707 \n",
      "(epoch: 129, iters: 660, time: 0.112, data: 0.001) G_GAN: 0.680 G_L1: 0.000 D_real: 0.680 D_fake: 0.707 \n",
      "(epoch: 129, iters: 760, time: 0.097, data: 0.002) G_GAN: 0.683 G_L1: 0.153 D_real: 0.683 D_fake: 0.703 \n",
      "(epoch: 129, iters: 860, time: 0.096, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.699 \n",
      "(epoch: 129, iters: 960, time: 0.096, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.689 \n",
      "(epoch: 129, iters: 1060, time: 0.095, data: 0.001) G_GAN: 0.688 G_L1: 0.052 D_real: 0.688 D_fake: 0.694 \n",
      "(epoch: 129, iters: 1160, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 129, iters: 1260, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.024 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 129, iters: 1360, time: 0.096, data: 0.002) G_GAN: 0.691 G_L1: 0.208 D_real: 0.691 D_fake: 0.696 \n",
      "(epoch: 129, iters: 1460, time: 0.094, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.696 \n",
      "(epoch: 129, iters: 1560, time: 0.096, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.705 D_fake: 0.681 \n",
      "(epoch: 129, iters: 1660, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.194 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 129, iters: 1760, time: 0.107, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.679 \n",
      "(epoch: 129, iters: 1860, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 129, iters: 1960, time: 0.101, data: 0.002) G_GAN: 0.692 G_L1: 0.090 D_real: 0.692 D_fake: 0.695 \n",
      "(epoch: 129, iters: 2060, time: 0.094, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.694 \n",
      "(epoch: 129, iters: 2160, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 129, iters: 2260, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.240 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 129 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001406\n",
      "(epoch: 130, iters: 80, time: 0.108, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 130, iters: 180, time: 0.113, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.695 \n",
      "(epoch: 130, iters: 280, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.205 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 130, iters: 380, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 130, iters: 480, time: 0.096, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 130, iters: 580, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.436 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 130, iters: 680, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 130, iters: 780, time: 0.097, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 130, iters: 880, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.146 D_real: 0.693 D_fake: 0.692 \n",
      "saving the latest model (epoch 130, total_steps 295000)\n",
      "(epoch: 130, iters: 980, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 130, iters: 1080, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 130, iters: 1180, time: 0.099, data: 0.002) G_GAN: 0.695 G_L1: 0.144 D_real: 0.695 D_fake: 0.693 \n",
      "(epoch: 130, iters: 1280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 130, iters: 1380, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 130, iters: 1480, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.259 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 130, iters: 1580, time: 0.099, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 130, iters: 1680, time: 0.103, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 130, iters: 1780, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.225 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 130, iters: 1880, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 130, iters: 1980, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 130, iters: 2080, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.167 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 130, iters: 2180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 130, iters: 2280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "saving the model at the end of epoch 130, iters 296400\n",
      "End of epoch 130 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0001386\n",
      "(epoch: 131, iters: 100, time: 0.119, data: 0.283) G_GAN: 0.694 G_L1: 0.204 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 131, iters: 200, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 300, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 400, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.137 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 131, iters: 500, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 600, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 131, iters: 700, time: 0.104, data: 0.002) G_GAN: 0.692 G_L1: 0.129 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 131, iters: 800, time: 0.099, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 131, iters: 900, time: 0.093, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.688 \n",
      "(epoch: 131, iters: 1000, time: 0.101, data: 0.001) G_GAN: 0.695 G_L1: 0.257 D_real: 0.695 D_fake: 0.695 \n",
      "(epoch: 131, iters: 1100, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 131, iters: 1200, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 1300, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.178 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 131, iters: 1400, time: 0.109, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 131, iters: 1500, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 1600, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.185 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 131, iters: 1700, time: 0.110, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 131, iters: 1800, time: 0.095, data: 0.005) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 1900, time: 0.100, data: 0.003) G_GAN: 0.693 G_L1: 0.299 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 2000, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 2100, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 131, iters: 2200, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.177 D_real: 0.693 D_fake: 0.694 \n",
      "End of epoch 131 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001366\n",
      "(epoch: 132, iters: 20, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 132, iters: 120, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 220, time: 0.099, data: 0.001) G_GAN: 0.694 G_L1: 0.253 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 132, iters: 320, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 132, iters: 420, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 132, iters: 520, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.187 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 620, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 720, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 820, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.173 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 132, iters: 920, time: 0.109, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.691 \n",
      "(epoch: 132, iters: 1020, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.695 \n",
      "(epoch: 132, iters: 1120, time: 0.101, data: 0.002) G_GAN: 0.692 G_L1: 0.162 D_real: 0.692 D_fake: 0.694 \n",
      "(epoch: 132, iters: 1220, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 132, iters: 1320, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 132, total_steps 300000)\n",
      "(epoch: 132, iters: 1420, time: 0.097, data: 0.001) G_GAN: 0.692 G_L1: 0.155 D_real: 0.692 D_fake: 0.693 \n",
      "(epoch: 132, iters: 1520, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.003 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 1620, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 1720, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.183 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 132, iters: 1820, time: 0.099, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 132, iters: 1920, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 2020, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.185 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 132, iters: 2120, time: 0.108, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.692 \n",
      "(epoch: 132, iters: 2220, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "End of epoch 132 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001347\n",
      "(epoch: 133, iters: 40, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.220 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 140, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 240, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 340, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 440, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.692 \n",
      "(epoch: 133, iters: 540, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 640, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.192 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 740, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 840, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 940, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.268 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 1040, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 1140, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 1240, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.390 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 1340, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 1440, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 1540, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.215 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 1640, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 1740, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 1840, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.104 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 1940, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 2040, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 133, iters: 2140, time: 0.112, data: 0.002) G_GAN: 0.693 G_L1: 0.131 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 133, iters: 2240, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 133 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001327\n",
      "(epoch: 134, iters: 60, time: 0.114, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 160, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.227 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 134, iters: 260, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 360, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 460, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.207 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 560, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 660, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 760, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.164 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 860, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 960, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 1060, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.044 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 1160, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 1260, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.398 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 1360, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.252 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 1460, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 1560, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 1660, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.129 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 1760, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 134, total_steps 305000)\n",
      "(epoch: 134, iters: 1860, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 1960, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.079 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 2060, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 2160, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 134, iters: 2260, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.179 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 134 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001307\n",
      "(epoch: 135, iters: 80, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 180, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 280, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.209 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 380, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 480, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 580, time: 0.114, data: 0.002) G_GAN: 0.693 G_L1: 0.207 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 680, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 780, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 880, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.166 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 980, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 1080, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 1180, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.127 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 1280, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 1380, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 1480, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.152 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 1580, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 1680, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 1780, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.190 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 1880, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 1980, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 2080, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.162 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 2180, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 135, iters: 2280, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 135, iters 307800\n",
      "End of epoch 135 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001287\n",
      "(epoch: 136, iters: 100, time: 0.117, data: 0.298) G_GAN: 0.693 G_L1: 0.170 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 200, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 300, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 400, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.138 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 500, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 600, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 700, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.141 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 800, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 900, time: 0.091, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 1000, time: 0.109, data: 0.002) G_GAN: 0.694 G_L1: 0.159 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 1100, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 1200, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 1300, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.190 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 1400, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 1500, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 1600, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.138 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 1700, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 1800, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 1900, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.190 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 2000, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 2100, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 136, iters: 2200, time: 0.113, data: 0.001) G_GAN: 0.693 G_L1: 0.165 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 136, total_steps 310000)\n",
      "End of epoch 136 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001267\n",
      "(epoch: 137, iters: 20, time: 0.121, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 120, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 220, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.214 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 320, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 420, time: 0.107, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 520, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.144 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 620, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 720, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 820, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.191 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 137, iters: 920, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 1020, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 1120, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.165 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 1220, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 1320, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 1420, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.150 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 1520, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 1620, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 1720, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.179 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 1820, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 1920, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 2020, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.331 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 2120, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 137, iters: 2220, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 137 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001248\n",
      "(epoch: 138, iters: 40, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.178 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 140, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 240, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 340, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 440, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 540, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 640, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.137 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 740, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 840, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 940, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.483 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 1040, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 1140, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 1240, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.407 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 1340, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 1440, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 1540, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.189 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 1640, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 1740, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 1840, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.167 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 1940, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 2040, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 2140, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.120 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 138, iters: 2240, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 138 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001228\n",
      "(epoch: 139, iters: 60, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 160, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.185 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 260, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 360, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 139, total_steps 315000)\n",
      "(epoch: 139, iters: 460, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.157 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 560, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 660, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 760, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.246 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 860, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 960, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 1060, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.051 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 1160, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 1260, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 1360, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.260 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 1460, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 1560, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 1660, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.194 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 1760, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 1860, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 1960, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.121 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 2060, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 2160, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 139, iters: 2260, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.191 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 139 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001208\n",
      "(epoch: 140, iters: 80, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 180, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.106 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 380, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 480, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 580, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.273 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 680, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 780, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 880, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.261 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 980, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 1080, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 1180, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.221 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 1280, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 1380, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 1480, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.165 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 1580, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 140, iters: 1680, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 1780, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.181 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 1880, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 1980, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 2080, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.147 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 2180, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 140, iters: 2280, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 140, iters 319200\n",
      "End of epoch 140 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001188\n",
      "(epoch: 141, iters: 100, time: 0.107, data: 0.274) G_GAN: 0.693 G_L1: 0.341 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 200, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 300, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 400, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.152 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 500, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 600, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 700, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.125 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 800, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 141, total_steps 320000)\n",
      "(epoch: 141, iters: 900, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 1000, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.142 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 1100, time: 0.097, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 1200, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 1300, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.428 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 1400, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 1500, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 1600, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.175 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 1700, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 1800, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 1900, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.233 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 2000, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 2100, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 141, iters: 2200, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.136 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 141 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0001168\n",
      "(epoch: 142, iters: 20, time: 0.120, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 120, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 220, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.255 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 320, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 420, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 520, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.128 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 620, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 720, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 820, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.135 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 920, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 1020, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 1120, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.132 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 1220, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 1320, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 1420, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.117 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 1520, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 1620, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 1720, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.150 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 1820, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 1920, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 2020, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.106 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 2120, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 142, iters: 2220, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 142 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001149\n",
      "(epoch: 143, iters: 40, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.165 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 140, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 240, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 340, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 440, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 540, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 640, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.147 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 740, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 840, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 940, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.245 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 1040, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 1140, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 1240, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.243 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 143, total_steps 325000)\n",
      "(epoch: 143, iters: 1340, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 1440, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 1540, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.213 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 1640, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 1740, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 1840, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.075 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 1940, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 2040, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 143, iters: 2140, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.121 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 143, iters: 2240, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "End of epoch 143 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001129\n",
      "(epoch: 144, iters: 60, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 160, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.163 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 260, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 360, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 460, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.157 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 560, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 660, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 760, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.222 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 860, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 960, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 1060, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.125 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 1160, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 1260, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 1360, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.236 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 1460, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 1560, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 1660, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.190 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 1760, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 1860, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 1960, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.085 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 2060, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 2160, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 144, iters: 2260, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.264 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 144 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001109\n",
      "(epoch: 145, iters: 80, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 180, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 280, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.178 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 380, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 480, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 580, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.216 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 680, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 780, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 880, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.201 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 980, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 1080, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 1180, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.140 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 1280, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 1380, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 1480, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.237 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 1580, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 1680, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 145, total_steps 330000)\n",
      "(epoch: 145, iters: 1780, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.200 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 1880, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 1980, time: 0.112, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 2080, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.176 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 2180, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 145, iters: 2280, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 145, iters 330600\n",
      "End of epoch 145 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0001089\n",
      "(epoch: 146, iters: 100, time: 0.105, data: 0.291) G_GAN: 0.693 G_L1: 0.176 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 200, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 300, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 400, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.111 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 500, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 600, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 700, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.136 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 800, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 900, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 1000, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.150 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 1100, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 1200, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 1300, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.263 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 1400, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 1500, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 1600, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.132 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 1700, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 1800, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 1900, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.305 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 2000, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 2100, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 146, iters: 2200, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.191 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 146 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001069\n",
      "(epoch: 147, iters: 20, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 120, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 220, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.208 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 320, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 420, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 147, iters: 520, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.120 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 620, time: 0.098, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 720, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 820, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.117 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 920, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 1020, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 1120, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.101 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 1220, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 1320, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 1420, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.145 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 1520, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 1620, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 1720, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.214 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 1820, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 1920, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 2020, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.113 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 147, iters: 2120, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 147, total_steps 335000)\n",
      "(epoch: 147, iters: 2220, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 147 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001050\n",
      "(epoch: 148, iters: 40, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.174 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 140, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 240, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 340, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 440, time: 0.095, data: 0.000) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 540, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 640, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.218 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 740, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 840, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 940, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.653 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 1040, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 1140, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 1240, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.358 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 1340, time: 0.113, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 1440, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 1540, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.178 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 1640, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 1740, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 1840, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.038 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 1940, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 2040, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 2140, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.087 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 148, iters: 2240, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 148 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001030\n",
      "(epoch: 149, iters: 60, time: 0.117, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 160, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.226 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 260, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 360, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 460, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.155 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 560, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 660, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 760, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.158 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 860, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 960, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 1060, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.036 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 1160, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 1260, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.171 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 1360, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.202 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 1460, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 1560, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 1660, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.118 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 1760, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 1860, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 1960, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.103 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 2060, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 2160, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 149, iters: 2260, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.195 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 149 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001010\n",
      "(epoch: 150, iters: 80, time: 0.115, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 180, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 280, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.099 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 150, total_steps 340000)\n",
      "(epoch: 150, iters: 380, time: 0.112, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 480, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 580, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.199 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 680, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 780, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 880, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.208 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 980, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 1080, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 150, iters: 1180, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.167 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 1280, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 1380, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 1480, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.110 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 1580, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 1680, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 1780, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.160 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 1880, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 1980, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 2080, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.165 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 2180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 150, iters: 2280, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 150, iters 342000\n",
      "End of epoch 150 / 200 \t Time Taken: 127 sec\n",
      "learning rate = 0.0000990\n",
      "(epoch: 151, iters: 100, time: 0.108, data: 0.292) G_GAN: 0.693 G_L1: 0.185 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 200, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 300, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 400, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.138 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 500, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 600, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 700, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.128 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 800, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 900, time: 0.092, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 1000, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.230 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 1100, time: 0.113, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 1200, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 1300, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.158 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 1400, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.056 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 1500, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 1600, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.210 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 1700, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 1800, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 1900, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.359 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 2000, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 2100, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 151, iters: 2200, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.114 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 151 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0000970\n",
      "(epoch: 152, iters: 20, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 120, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 220, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.207 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 320, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 420, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 520, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.118 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 620, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 720, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 152, total_steps 345000)\n",
      "(epoch: 152, iters: 820, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.192 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 920, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 1020, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 1120, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.259 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 1220, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 1320, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 1420, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.145 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 1520, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 1620, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 1720, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.182 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 1820, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 1920, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 2020, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.289 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 2120, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 152, iters: 2220, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 152 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000950\n",
      "(epoch: 153, iters: 40, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.148 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 140, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 240, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 340, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 440, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 540, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 640, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.178 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 740, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 840, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 940, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.158 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 1040, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 1140, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 1240, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.360 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 1340, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 1440, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 1540, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.178 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 1640, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 1740, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 153, iters: 1840, time: 0.112, data: 0.002) G_GAN: 0.693 G_L1: 0.168 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 1940, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 2040, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 2140, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.141 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 153, iters: 2240, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 153 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000931\n",
      "(epoch: 154, iters: 60, time: 0.114, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 160, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.223 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 260, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 360, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 460, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.156 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 560, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 660, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 760, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.177 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 860, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 960, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 1060, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.037 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 1160, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 154, total_steps 350000)\n",
      "(epoch: 154, iters: 1260, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.090 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 1360, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.387 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 1460, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 1560, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 1660, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.258 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 1760, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 1860, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 1960, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.081 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 2060, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 2160, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 154, iters: 2260, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.219 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 154 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000911\n",
      "(epoch: 155, iters: 80, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 180, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 280, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.110 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 380, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 480, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 580, time: 0.112, data: 0.001) G_GAN: 0.693 G_L1: 0.206 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 680, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 780, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 880, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.148 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 980, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 1080, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 1180, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.155 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 1280, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 1380, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 1480, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.106 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 1580, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 1680, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 1780, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.145 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 1880, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 1980, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 2080, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.127 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 2180, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 155, iters: 2280, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 155, iters 353400\n",
      "End of epoch 155 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000891\n",
      "(epoch: 156, iters: 100, time: 0.107, data: 0.280) G_GAN: 0.693 G_L1: 0.133 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 200, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 300, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.158 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 500, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 600, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 700, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.120 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 800, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 900, time: 0.092, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 1000, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.189 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 1100, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 1200, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 1300, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.307 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 1400, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 1500, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 1600, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.130 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 156, total_steps 355000)\n",
      "(epoch: 156, iters: 1700, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 1800, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 1900, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.212 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 2000, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 2100, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 156, iters: 2200, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.147 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 156 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000871\n",
      "(epoch: 157, iters: 20, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 157, iters: 120, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 220, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.229 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 320, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 420, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 520, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.109 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 620, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 720, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 820, time: 0.092, data: 0.002) G_GAN: 0.693 G_L1: 0.189 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 920, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 1020, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 1120, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.106 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 1220, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 1320, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 1420, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.163 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 1520, time: 0.113, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 1620, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 1720, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.195 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 1820, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 1920, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 2020, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.225 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 2120, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 157, iters: 2220, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 157 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000851\n",
      "(epoch: 158, iters: 40, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.205 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 140, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 240, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 340, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.566 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 440, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 540, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 640, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.169 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 740, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 840, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 940, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.302 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 1040, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 1140, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 1240, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.376 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 1340, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 1440, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 1540, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.227 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 1640, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 1740, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 1840, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.111 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 1940, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 2040, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 158, total_steps 360000)\n",
      "(epoch: 158, iters: 2140, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.088 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 158, iters: 2240, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 158 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000832\n",
      "(epoch: 159, iters: 60, time: 0.114, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 160, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.181 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 260, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 360, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 460, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.160 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 560, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 660, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 760, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.189 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 860, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 960, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 1060, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.091 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 1160, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 1260, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 1360, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.201 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 1460, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 1560, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 1660, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.133 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 1760, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 1860, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 1960, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.191 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 2060, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 2160, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 159, iters: 2260, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.199 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 159 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000812\n",
      "(epoch: 160, iters: 80, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 280, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.161 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 380, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 480, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 580, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.215 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 680, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 780, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 160, iters: 880, time: 0.096, data: 0.003) G_GAN: 0.693 G_L1: 0.164 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 980, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 1080, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 1180, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.101 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 1280, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 1380, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 1480, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.134 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 1580, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 1680, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 1780, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.203 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 1880, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 1980, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 2080, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.195 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 2180, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 160, iters: 2280, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 160, iters 364800\n",
      "End of epoch 160 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000792\n",
      "(epoch: 161, iters: 100, time: 0.107, data: 0.288) G_GAN: 0.693 G_L1: 0.287 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 200, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 161, total_steps 365000)\n",
      "(epoch: 161, iters: 300, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 400, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.110 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 500, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 600, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 700, time: 0.113, data: 0.002) G_GAN: 0.693 G_L1: 0.146 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 800, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 900, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 1000, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.181 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 1100, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 1200, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 1300, time: 0.112, data: 0.001) G_GAN: 0.693 G_L1: 0.247 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 1400, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 1500, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 1600, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.136 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 1700, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 1800, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 1900, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.291 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 2000, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 2100, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 161, iters: 2200, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.121 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 161 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000772\n",
      "(epoch: 162, iters: 20, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 120, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 220, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.179 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 320, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 420, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 520, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.152 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 620, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 720, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 820, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.123 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 920, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 1020, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 1120, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.226 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 1220, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 1320, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 1420, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.145 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 1520, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 1620, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 1720, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.120 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 1820, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 1920, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.087 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 2020, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.189 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 2120, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 162, iters: 2220, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 162 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000752\n",
      "(epoch: 163, iters: 40, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.116 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 140, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 240, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 340, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 440, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 540, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 640, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.132 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 163, total_steps 370000)\n",
      "(epoch: 163, iters: 740, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 840, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 940, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.169 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 1040, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 1140, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 1240, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.312 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 1340, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 1440, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 163, iters: 1540, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.242 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 1640, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 1740, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 1840, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.074 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 1940, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 2040, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 2140, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.080 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 163, iters: 2240, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 163 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000733\n",
      "(epoch: 164, iters: 60, time: 0.119, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 160, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.185 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 260, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 360, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 460, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.150 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 560, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 660, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 760, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.177 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 860, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 960, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 1060, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.055 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 1160, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 1260, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 1360, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.196 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 1460, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 1560, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 1660, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.157 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 1760, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 1860, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 1960, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.083 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 2060, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 2160, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 164, iters: 2260, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.259 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 164 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000713\n",
      "(epoch: 165, iters: 80, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 180, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.088 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 380, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 480, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 580, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.209 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 680, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 780, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 880, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.178 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 980, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 1080, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 165, total_steps 375000)\n",
      "(epoch: 165, iters: 1180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.142 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 1280, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 1380, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 1480, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.134 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 1580, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 1680, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 1780, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.160 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 1880, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 1980, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 2080, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.212 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 2180, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 165, iters: 2280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 165, iters 376200\n",
      "End of epoch 165 / 200 \t Time Taken: 127 sec\n",
      "learning rate = 0.0000693\n",
      "(epoch: 166, iters: 100, time: 0.108, data: 0.283) G_GAN: 0.693 G_L1: 0.319 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 200, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 300, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 400, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.128 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 500, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 600, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 700, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.093 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 800, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 900, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 1000, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.191 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 1100, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 1200, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 1300, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.224 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 1400, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 1500, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 1600, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.115 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 1700, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 1800, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 1900, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.279 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 2000, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 166, iters: 2100, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 166, iters: 2200, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.114 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 166 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000673\n",
      "(epoch: 167, iters: 20, time: 0.114, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 120, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 220, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.176 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 320, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 420, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 520, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.130 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 620, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 720, time: 0.107, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 820, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.165 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 920, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 1020, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 1120, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.137 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 1220, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 1320, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 1420, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.119 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 1520, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 167, total_steps 380000)\n",
      "(epoch: 167, iters: 1620, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 1720, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.174 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 1820, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 1920, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.045 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 2020, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.185 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 2120, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 167, iters: 2220, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 167 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000653\n",
      "(epoch: 168, iters: 40, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.166 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 140, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 240, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 340, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 440, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 540, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 640, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.131 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 740, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 840, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 940, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.196 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 1040, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 1140, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 1240, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.285 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 1340, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 1440, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 1540, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.182 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 1640, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 1740, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 1840, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.090 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 1940, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 2040, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 2140, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.087 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 168, iters: 2240, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 168 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000634\n",
      "(epoch: 169, iters: 60, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 160, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.187 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 260, time: 0.097, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 360, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 460, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.162 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 560, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 660, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 760, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.168 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 860, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 960, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 1060, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.087 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 1160, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 1260, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 1360, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.241 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 1460, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 1560, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 1660, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.167 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 1760, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 1860, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 1960, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.064 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 169, total_steps 385000)\n",
      "(epoch: 169, iters: 2060, time: 0.092, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 2160, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 169, iters: 2260, time: 0.104, data: 0.003) G_GAN: 0.693 G_L1: 0.177 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 169 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000614\n",
      "(epoch: 170, iters: 80, time: 0.113, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 180, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 280, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.076 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 380, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 170, iters: 480, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 580, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.196 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 680, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 780, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 880, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.197 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 980, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 1080, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 1180, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.112 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 1280, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 1380, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 1480, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.173 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 1580, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 1680, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 1780, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.213 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 1880, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 1980, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 2080, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.182 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 2180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 170, iters: 2280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 170, iters 387600\n",
      "End of epoch 170 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000594\n",
      "(epoch: 171, iters: 100, time: 0.107, data: 0.284) G_GAN: 0.693 G_L1: 0.137 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 200, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 300, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 400, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.114 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 500, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 600, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 700, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.146 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 800, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 900, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 1000, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.141 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 1100, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 1200, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 1300, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.204 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 1400, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 1500, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 1600, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.100 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 1700, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 1800, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 1900, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.216 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 2000, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 2100, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 171, iters: 2200, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.111 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 171 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000574\n",
      "(epoch: 172, iters: 20, time: 0.117, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 120, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 172, total_steps 390000)\n",
      "(epoch: 172, iters: 220, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.205 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 320, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 420, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 520, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.114 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 620, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 720, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 820, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.105 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 920, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 1020, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 1120, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.181 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 1220, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 1320, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 1420, time: 0.113, data: 0.002) G_GAN: 0.693 G_L1: 0.100 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 1520, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 1620, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 1720, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.135 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 1820, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 1920, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 2020, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.166 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 2120, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 172, iters: 2220, time: 0.112, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 172 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000554\n",
      "(epoch: 173, iters: 40, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.145 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 140, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 240, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 340, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.575 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 440, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 540, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 640, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.146 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 740, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 840, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 940, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.226 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 1040, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 173, iters: 1140, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 1240, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.245 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 1340, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 1440, time: 0.116, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 1540, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.170 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 1640, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 1740, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 1840, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.101 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 1940, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 2040, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 2140, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.124 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 173, iters: 2240, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 173 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000535\n",
      "(epoch: 174, iters: 60, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 160, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.140 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 260, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 360, time: 0.102, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 460, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.154 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 560, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 174, total_steps 395000)\n",
      "(epoch: 174, iters: 660, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 760, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.192 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 860, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 960, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 1060, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.066 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 1160, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 1260, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 1360, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.175 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 1460, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 1560, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 1660, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.172 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 1760, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 1860, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 1960, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.112 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 2060, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 2160, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 174, iters: 2260, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.147 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 174 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000515\n",
      "(epoch: 175, iters: 80, time: 0.116, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 180, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.124 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 380, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 480, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 580, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.265 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 680, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 780, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 880, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.263 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 980, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 1080, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 1180, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.088 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 1280, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 1380, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 1480, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.107 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 1580, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 1680, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 1780, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.164 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 1880, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 1980, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 2080, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.217 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 2180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 175, iters: 2280, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 175, iters 399000\n",
      "End of epoch 175 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000495\n",
      "(epoch: 176, iters: 100, time: 0.105, data: 0.284) G_GAN: 0.693 G_L1: 0.184 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 200, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 300, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 400, time: 0.098, data: 0.003) G_GAN: 0.693 G_L1: 0.167 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 500, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 600, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 700, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.117 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 800, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 900, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 1000, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.198 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 176, total_steps 400000)\n",
      "(epoch: 176, iters: 1100, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 1200, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 1300, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.215 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 1400, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 1500, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 1600, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.121 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 176, iters: 1700, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 1800, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 1900, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.188 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 2000, time: 0.109, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 2100, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 176, iters: 2200, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.093 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 176 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000475\n",
      "(epoch: 177, iters: 20, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 120, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 220, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.250 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 320, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 420, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 520, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.150 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 620, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 720, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 820, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.110 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 920, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 1020, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 1120, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.069 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 1220, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 1320, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 1420, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.156 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 1520, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 1620, time: 0.112, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 1720, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.150 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 1820, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 1920, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 2020, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.141 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 2120, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 177, iters: 2220, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 177 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000455\n",
      "(epoch: 178, iters: 40, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.128 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 140, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 240, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 340, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.568 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 440, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 540, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 640, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.133 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 740, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 840, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 940, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.243 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 1040, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 1140, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 1240, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.255 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 1340, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 1440, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 178, total_steps 405000)\n",
      "(epoch: 178, iters: 1540, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.192 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 1640, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 1740, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 1840, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.054 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 1940, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 2040, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 2140, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.081 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 178, iters: 2240, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 178 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000436\n",
      "(epoch: 179, iters: 60, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 160, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.149 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 260, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 360, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 460, time: 0.111, data: 0.001) G_GAN: 0.693 G_L1: 0.151 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 560, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 660, time: 0.113, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 760, time: 0.103, data: 0.001) G_GAN: 0.693 G_L1: 0.184 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 860, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 960, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 1060, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.095 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 1160, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 1260, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 1360, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.200 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 1460, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 1560, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 1660, time: 0.099, data: 0.003) G_GAN: 0.693 G_L1: 0.132 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 1760, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 1860, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 1960, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.092 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 2060, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 2160, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 179, iters: 2260, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.146 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 179 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 180, iters: 80, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 180, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 280, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.089 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 380, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 480, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 580, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.190 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 680, time: 0.098, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 780, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 880, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.143 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 980, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 1080, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 1180, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.104 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 1280, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 1380, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 1480, time: 0.097, data: 0.003) G_GAN: 0.693 G_L1: 0.093 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 1580, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 1680, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 1780, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.149 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 1880, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 180, total_steps 410000)\n",
      "(epoch: 180, iters: 1980, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 2080, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.145 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 2180, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 180, iters: 2280, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 180, iters 410400\n",
      "End of epoch 180 / 200 \t Time Taken: 127 sec\n",
      "learning rate = 0.0000396\n",
      "(epoch: 181, iters: 100, time: 0.107, data: 0.281) G_GAN: 0.693 G_L1: 0.208 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 200, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 300, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 400, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.131 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 500, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 600, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 700, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.113 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 800, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 900, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 1000, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.136 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 1100, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 1200, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 1300, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.180 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 1400, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 1500, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 1600, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.097 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 1700, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 1800, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 1900, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.223 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 2000, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 2100, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 181, iters: 2200, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.101 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 181 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000376\n",
      "(epoch: 182, iters: 20, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 120, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 220, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.169 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 320, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 420, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 520, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.152 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 620, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 720, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 820, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.098 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 920, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 1020, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 1120, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.098 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 1220, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 1320, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 1420, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.099 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 1520, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 1620, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 1720, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.128 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 1820, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 1920, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 2020, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.105 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 2120, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 182, iters: 2220, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 182 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000356\n",
      "(epoch: 183, iters: 40, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.119 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 183, total_steps 415000)\n",
      "(epoch: 183, iters: 140, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 240, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 340, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.507 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 440, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 540, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 640, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.165 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 183, iters: 740, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 840, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 940, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.246 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 1040, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 1140, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 1240, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.336 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 1340, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 1440, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 1540, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.215 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 1640, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 1740, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 1840, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.059 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 1940, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 2040, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 2140, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.049 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 183, iters: 2240, time: 0.113, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 183 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000337\n",
      "(epoch: 184, iters: 60, time: 0.119, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 160, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.200 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 260, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 360, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 460, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.171 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 560, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 660, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 760, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.215 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 860, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 960, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 1060, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.023 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 1160, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 1260, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.002 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 1360, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.193 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 1460, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 1560, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 1660, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.135 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 1760, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 1860, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 1960, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.125 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 2060, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 2160, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 184, iters: 2260, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.202 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 184 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000317\n",
      "(epoch: 185, iters: 80, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 180, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 280, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.115 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 380, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 480, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 185, total_steps 420000)\n",
      "(epoch: 185, iters: 580, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.208 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 680, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 780, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 880, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.179 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 980, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 1080, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 1180, time: 0.115, data: 0.001) G_GAN: 0.693 G_L1: 0.118 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 1280, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 1380, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 1480, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.145 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 1580, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 1680, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 1780, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.176 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 1880, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 1980, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 2080, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.113 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 2180, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 185, iters: 2280, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 185, iters 421800\n",
      "End of epoch 185 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0000297\n",
      "(epoch: 186, iters: 100, time: 0.110, data: 0.279) G_GAN: 0.693 G_L1: 0.155 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 200, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 300, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 400, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.135 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 500, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 600, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 700, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.131 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 800, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 900, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 1000, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.192 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 1100, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 1200, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 1300, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.151 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 186, iters: 1400, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 1500, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 1600, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.105 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 1700, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 1800, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 1900, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.382 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 2000, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 2100, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 186, iters: 2200, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.086 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 186 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000277\n",
      "(epoch: 187, iters: 20, time: 0.107, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 120, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 220, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.181 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 320, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 420, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 520, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.092 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 620, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 720, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 820, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.093 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 920, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 187, total_steps 425000)\n",
      "(epoch: 187, iters: 1020, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 1120, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.144 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 1220, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 1320, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 1420, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.107 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 1520, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 1620, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 1720, time: 0.112, data: 0.002) G_GAN: 0.693 G_L1: 0.136 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 1820, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 1920, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 2020, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.193 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 2120, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 187, iters: 2220, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 187 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000257\n",
      "(epoch: 188, iters: 40, time: 0.115, data: 0.002) G_GAN: 0.693 G_L1: 0.157 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 140, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 240, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 340, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.407 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 440, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 540, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 640, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.124 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 740, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 840, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 940, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.203 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 1040, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 1140, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 1240, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.283 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 1340, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 1440, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 1540, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.167 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 1640, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 1740, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 1840, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.060 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 1940, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 2040, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 2140, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.090 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 188, iters: 2240, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 188 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000238\n",
      "(epoch: 189, iters: 60, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 160, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.157 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 260, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 360, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 460, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.162 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 560, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 660, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 760, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.149 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 860, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 960, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 1060, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.029 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 1160, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 1260, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 1360, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.221 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 189, total_steps 430000)\n",
      "(epoch: 189, iters: 1460, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 1560, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 1660, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.135 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 1760, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 1860, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 1960, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.099 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 189, iters: 2060, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 2160, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 189, iters: 2260, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.182 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 189 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000218\n",
      "(epoch: 190, iters: 80, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 180, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 280, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.090 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 380, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 480, time: 0.100, data: 0.003) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 580, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.164 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 680, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 780, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 880, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.138 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 980, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 1080, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 1180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.101 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 1280, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 1380, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 1480, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.135 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 1580, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 1680, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 1780, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.148 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 1880, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 1980, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 2080, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.146 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 2180, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 190, iters: 2280, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 190, iters 433200\n",
      "End of epoch 190 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000198\n",
      "(epoch: 191, iters: 100, time: 0.108, data: 0.273) G_GAN: 0.693 G_L1: 0.205 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 200, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 300, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 400, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.094 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 500, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 600, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 700, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.152 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 800, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 900, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 1000, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.156 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 1100, time: 0.112, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 1200, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 1300, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.215 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 1400, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 1500, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 1600, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.118 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 1700, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 1800, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 191, total_steps 435000)\n",
      "(epoch: 191, iters: 1900, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.274 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 2000, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 2100, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 191, iters: 2200, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.089 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 191 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000178\n",
      "(epoch: 192, iters: 20, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 120, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 220, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.176 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 320, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 420, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 520, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.172 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 620, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 720, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 820, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.103 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 920, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 1020, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 1120, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.135 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 1220, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 1320, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 1420, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.110 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 1520, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 1620, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 1720, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.210 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 1820, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 1920, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 2020, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.197 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 2120, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 192, iters: 2220, time: 0.115, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 192 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000158\n",
      "(epoch: 193, iters: 40, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.139 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 140, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 240, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 193, iters: 340, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.577 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 440, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 540, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 640, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.114 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 740, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 840, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 940, time: 0.113, data: 0.002) G_GAN: 0.693 G_L1: 0.370 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 1040, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 1140, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 1240, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.321 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 1340, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 1440, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 1540, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.212 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 1640, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 1740, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 1840, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.080 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 1940, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 2040, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 2140, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.113 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 193, iters: 2240, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 193, total_steps 440000)\n",
      "End of epoch 193 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000139\n",
      "(epoch: 194, iters: 60, time: 0.105, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 160, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.198 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 260, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 360, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 460, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.148 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 560, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 660, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 760, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.201 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 860, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 960, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 1060, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.036 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 1160, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 1260, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.001 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 1360, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.170 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 1460, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 1560, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 1660, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.160 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 1760, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 1860, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 1960, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.070 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 2060, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 2160, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 194, iters: 2260, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.171 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 194 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000119\n",
      "(epoch: 195, iters: 80, time: 0.116, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 180, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 280, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.097 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 380, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 480, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 580, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.169 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 680, time: 0.102, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 780, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 880, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.185 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 980, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 1080, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 1180, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.138 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 1280, time: 0.113, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 1380, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 1480, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.127 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 1580, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 1680, time: 0.111, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 1780, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.175 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 1880, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 1980, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 2080, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.143 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 2180, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 195, iters: 2280, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 195, iters 444600\n",
      "End of epoch 195 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0000099\n",
      "(epoch: 196, iters: 100, time: 0.106, data: 0.274) G_GAN: 0.693 G_L1: 0.146 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 200, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 300, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 400, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.159 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 196, total_steps 445000)\n",
      "(epoch: 196, iters: 500, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 600, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 700, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.131 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 800, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 900, time: 0.092, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 196, iters: 1000, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.148 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 1100, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 1200, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 1300, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.142 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 1400, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 1500, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 1600, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.123 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 1700, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 1800, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 1900, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.218 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 2000, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 2100, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 196, iters: 2200, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.117 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 196 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000079\n",
      "(epoch: 197, iters: 20, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 120, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 220, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.178 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 320, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 420, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 520, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.128 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 620, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 720, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 820, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.129 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 920, time: 0.106, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 1020, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 1120, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.146 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 1220, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 1320, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 1420, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.101 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 1520, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 1620, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 1720, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.157 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 1820, time: 0.103, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 1920, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 2020, time: 0.112, data: 0.002) G_GAN: 0.693 G_L1: 0.127 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 2120, time: 0.099, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 197, iters: 2220, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 197 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000059\n",
      "(epoch: 198, iters: 40, time: 0.119, data: 0.002) G_GAN: 0.693 G_L1: 0.168 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 140, time: 0.108, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 240, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 340, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.576 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 440, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 540, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 640, time: 0.104, data: 0.002) G_GAN: 0.693 G_L1: 0.132 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 740, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 840, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 198, total_steps 450000)\n",
      "(epoch: 198, iters: 940, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.200 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 1040, time: 0.110, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 1140, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 1240, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.277 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 1340, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 1440, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 1540, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.198 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 1640, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 1740, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 1840, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.070 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 1940, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 2040, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 2140, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.104 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 198, iters: 2240, time: 0.109, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 198 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000040\n",
      "(epoch: 199, iters: 60, time: 0.104, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 160, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.149 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 260, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 360, time: 0.115, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 460, time: 0.112, data: 0.002) G_GAN: 0.693 G_L1: 0.143 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 560, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 660, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 760, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.132 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 860, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 960, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 1060, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.032 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 1160, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 1260, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 1360, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.199 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 1460, time: 0.106, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 1560, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 1660, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.186 D_real: 0.693 D_fake: 0.693 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 199, iters: 1760, time: 0.101, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 1860, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 1960, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.079 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 2060, time: 0.094, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 2160, time: 0.097, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 199, iters: 2260, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.196 D_real: 0.693 D_fake: 0.693 \n",
      "End of epoch 199 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000020\n",
      "(epoch: 200, iters: 80, time: 0.105, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 180, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 280, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.085 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 380, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 480, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 580, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.146 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 680, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 780, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 880, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.175 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 980, time: 0.098, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 1080, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 1180, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.123 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 1280, time: 0.099, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the latest model (epoch 200, total_steps 455000)\n",
      "(epoch: 200, iters: 1380, time: 0.114, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 1480, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.158 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 1580, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 1680, time: 0.100, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 1780, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.192 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 1880, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 1980, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 2080, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.137 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 2180, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "(epoch: 200, iters: 2280, time: 0.095, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.693 \n",
      "saving the model at the end of epoch 200, iters 456000\n",
      "End of epoch 200 / 200 \t Time Taken: 127 sec\n",
      "learning rate = 0.0000000\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 2280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with xavier\n",
      "initialize network with xavier\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "DataParallel(\n",
      "  (module): UnetGenerator(\n",
      "    (model): UnetSkipConnectionBlock(\n",
      "      (model): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): UnetSkipConnectionBlock(\n",
      "          (model): Sequential(\n",
      "            (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "            (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (3): UnetSkipConnectionBlock(\n",
      "              (model): Sequential(\n",
      "                (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (3): UnetSkipConnectionBlock(\n",
      "                  (model): Sequential(\n",
      "                    (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                    (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (3): UnetSkipConnectionBlock(\n",
      "                      (model): Sequential(\n",
      "                        (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                        (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                        (3): UnetSkipConnectionBlock(\n",
      "                          (model): Sequential(\n",
      "                            (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                            (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                            (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                            (3): UnetSkipConnectionBlock(\n",
      "                              (model): Sequential(\n",
      "                                (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                                (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                                (3): UnetSkipConnectionBlock(\n",
      "                                  (model): Sequential(\n",
      "                                    (0): LeakyReLU(negative_slope=0.2, inplace)\n",
      "                                    (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                    (2): ReLU(inplace)\n",
      "                                    (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                                  )\n",
      "                                )\n",
      "                                (4): ReLU(inplace)\n",
      "                                (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                                (7): Dropout(p=0.5)\n",
      "                              )\n",
      "                            )\n",
      "                            (4): ReLU(inplace)\n",
      "                            (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                            (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                            (7): Dropout(p=0.5)\n",
      "                          )\n",
      "                        )\n",
      "                        (4): ReLU(inplace)\n",
      "                        (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                        (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                        (7): Dropout(p=0.5)\n",
      "                      )\n",
      "                    )\n",
      "                    (4): ReLU(inplace)\n",
      "                    (5): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                )\n",
      "                (4): ReLU(inplace)\n",
      "                (5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (4): ReLU(inplace)\n",
      "            (5): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): ReLU(inplace)\n",
      "        (3): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "        (4): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "DataParallel(\n",
      "  (module): NLayerDiscriminator(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (3): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (5): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (6): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (7): LeakyReLU(negative_slope=0.2, inplace)\n",
      "      (8): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "      (9): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network D] Total number of parameters : 2.767 M\n",
      "-----------------------------------------------\n",
      "(epoch: 1, iters: 100, time: 0.123, data: 0.271) G_GAN: 0.600 G_L1: 6.697 D_real: 0.572 D_fake: 0.817 \n",
      "(epoch: 1, iters: 200, time: 0.097, data: 0.001) G_GAN: 0.653 G_L1: 0.179 D_real: 0.696 D_fake: 0.687 \n",
      "(epoch: 1, iters: 300, time: 0.095, data: 0.005) G_GAN: 0.690 G_L1: 0.053 D_real: 0.690 D_fake: 0.693 \n",
      "(epoch: 1, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.769 G_L1: 1.906 D_real: 0.666 D_fake: 0.630 \n",
      "(epoch: 1, iters: 500, time: 0.099, data: 0.001) G_GAN: 0.708 G_L1: 0.124 D_real: 0.688 D_fake: 0.698 \n",
      "(epoch: 1, iters: 600, time: 0.103, data: 0.001) G_GAN: 0.691 G_L1: 0.067 D_real: 0.698 D_fake: 0.689 \n",
      "(epoch: 1, iters: 700, time: 0.109, data: 0.001) G_GAN: 0.698 G_L1: 2.270 D_real: 0.691 D_fake: 0.604 \n",
      "(epoch: 1, iters: 800, time: 0.097, data: 0.001) G_GAN: 0.723 G_L1: 0.096 D_real: 0.733 D_fake: 0.655 \n",
      "(epoch: 1, iters: 900, time: 0.092, data: 0.001) G_GAN: 0.710 G_L1: 0.000 D_real: 0.710 D_fake: 0.677 \n",
      "(epoch: 1, iters: 1000, time: 0.114, data: 0.001) G_GAN: 0.732 G_L1: 2.267 D_real: 0.626 D_fake: 0.657 \n",
      "(epoch: 1, iters: 1100, time: 0.109, data: 0.001) G_GAN: 0.735 G_L1: 0.069 D_real: 0.736 D_fake: 0.652 \n",
      "(epoch: 1, iters: 1200, time: 0.099, data: 0.001) G_GAN: 0.730 G_L1: 0.007 D_real: 0.732 D_fake: 0.658 \n",
      "(epoch: 1, iters: 1300, time: 0.099, data: 0.001) G_GAN: 0.744 G_L1: 3.100 D_real: 0.597 D_fake: 0.649 \n",
      "(epoch: 1, iters: 1400, time: 0.109, data: 0.001) G_GAN: 0.754 G_L1: 0.006 D_real: 0.761 D_fake: 0.630 \n",
      "(epoch: 1, iters: 1500, time: 0.098, data: 0.001) G_GAN: 0.721 G_L1: 0.001 D_real: 0.722 D_fake: 0.665 \n",
      "(epoch: 1, iters: 1600, time: 0.108, data: 0.001) G_GAN: 0.746 G_L1: 1.704 D_real: 0.626 D_fake: 0.646 \n",
      "(epoch: 1, iters: 1700, time: 0.098, data: 0.002) G_GAN: 0.757 G_L1: 0.034 D_real: 0.764 D_fake: 0.627 \n",
      "(epoch: 1, iters: 1800, time: 0.096, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.706 D_fake: 0.675 \n",
      "(epoch: 1, iters: 1900, time: 0.099, data: 0.002) G_GAN: 0.773 G_L1: 4.076 D_real: 0.589 D_fake: 0.627 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 1, iters: 2000, time: 0.097, data: 0.001) G_GAN: 0.766 G_L1: 0.001 D_real: 0.775 D_fake: 0.620 \n",
      "(epoch: 1, iters: 2100, time: 0.105, data: 0.001) G_GAN: 0.720 G_L1: 0.000 D_real: 0.716 D_fake: 0.667 \n",
      "(epoch: 1, iters: 2200, time: 0.098, data: 0.001) G_GAN: 0.766 G_L1: 1.972 D_real: 0.636 D_fake: 0.628 \n",
      "End of epoch 1 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 20, time: 0.108, data: 0.001) G_GAN: 0.718 G_L1: 0.020 D_real: 0.737 D_fake: 0.653 \n",
      "(epoch: 2, iters: 120, time: 0.100, data: 0.002) G_GAN: 0.690 G_L1: 0.007 D_real: 0.687 D_fake: 0.701 \n",
      "(epoch: 2, iters: 220, time: 0.106, data: 0.005) G_GAN: 0.783 G_L1: 3.205 D_real: 0.609 D_fake: 0.615 \n",
      "(epoch: 2, iters: 320, time: 0.096, data: 0.001) G_GAN: 0.745 G_L1: 0.002 D_real: 0.753 D_fake: 0.639 \n",
      "(epoch: 2, iters: 420, time: 0.096, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.695 D_fake: 0.688 \n",
      "(epoch: 2, iters: 520, time: 0.105, data: 0.001) G_GAN: 0.784 G_L1: 1.603 D_real: 0.645 D_fake: 0.608 \n",
      "(epoch: 2, iters: 620, time: 0.108, data: 0.002) G_GAN: 0.682 G_L1: 0.005 D_real: 0.690 D_fake: 0.697 \n",
      "(epoch: 2, iters: 720, time: 0.109, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
      "(epoch: 2, iters: 820, time: 0.095, data: 0.002) G_GAN: 0.787 G_L1: 2.187 D_real: 0.623 D_fake: 0.603 \n",
      "(epoch: 2, iters: 920, time: 0.094, data: 0.001) G_GAN: 0.757 G_L1: 0.000 D_real: 0.586 D_fake: 0.827 \n",
      "(epoch: 2, iters: 1020, time: 0.097, data: 0.001) G_GAN: 0.673 G_L1: 0.004 D_real: 0.669 D_fake: 0.718 \n",
      "(epoch: 2, iters: 1120, time: 0.098, data: 0.001) G_GAN: 0.777 G_L1: 1.007 D_real: 0.666 D_fake: 0.625 \n",
      "(epoch: 2, iters: 1220, time: 0.097, data: 0.001) G_GAN: 0.677 G_L1: 0.000 D_real: 0.684 D_fake: 0.707 \n",
      "(epoch: 2, iters: 1320, time: 0.098, data: 0.001) G_GAN: 0.699 G_L1: 0.000 D_real: 0.702 D_fake: 0.685 \n",
      "(epoch: 2, iters: 1420, time: 0.098, data: 0.001) G_GAN: 0.750 G_L1: 2.201 D_real: 0.602 D_fake: 0.634 \n",
      "(epoch: 2, iters: 1520, time: 0.097, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.744 D_fake: 0.645 \n",
      "(epoch: 2, iters: 1620, time: 0.099, data: 0.001) G_GAN: 0.671 G_L1: 0.000 D_real: 0.675 D_fake: 0.707 \n",
      "(epoch: 2, iters: 1720, time: 0.099, data: 0.001) G_GAN: 0.825 G_L1: 3.386 D_real: 0.638 D_fake: 0.591 \n",
      "(epoch: 2, iters: 1820, time: 0.098, data: 0.001) G_GAN: 0.712 G_L1: 0.001 D_real: 0.726 D_fake: 0.663 \n",
      "(epoch: 2, iters: 1920, time: 0.098, data: 0.001) G_GAN: 0.694 G_L1: 0.002 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 2, iters: 2020, time: 0.097, data: 0.001) G_GAN: 0.817 G_L1: 1.903 D_real: 0.667 D_fake: 0.583 \n",
      "(epoch: 2, iters: 2120, time: 0.109, data: 0.001) G_GAN: 0.699 G_L1: 0.000 D_real: 0.720 D_fake: 0.670 \n",
      "(epoch: 2, iters: 2220, time: 0.098, data: 0.001) G_GAN: 0.703 G_L1: 0.004 D_real: 0.704 D_fake: 0.684 \n",
      "End of epoch 2 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 3, iters: 40, time: 0.105, data: 0.001) G_GAN: 0.736 G_L1: 1.545 D_real: 0.616 D_fake: 0.654 \n",
      "(epoch: 3, iters: 140, time: 0.097, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.759 D_fake: 0.633 \n",
      "(epoch: 3, iters: 240, time: 0.096, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.729 D_fake: 0.659 \n",
      "(epoch: 3, iters: 340, time: 0.107, data: 0.001) G_GAN: 0.742 G_L1: 0.576 D_real: 0.640 D_fake: 0.645 \n",
      "(epoch: 3, iters: 440, time: 0.105, data: 0.001) G_GAN: 0.757 G_L1: 0.000 D_real: 0.765 D_fake: 0.628 \n",
      "saving the latest model (epoch 3, total_steps 5000)\n",
      "(epoch: 3, iters: 540, time: 0.096, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.725 D_fake: 0.663 \n",
      "(epoch: 3, iters: 640, time: 0.096, data: 0.001) G_GAN: 0.786 G_L1: 3.338 D_real: 0.605 D_fake: 0.613 \n",
      "(epoch: 3, iters: 740, time: 0.096, data: 0.001) G_GAN: 0.765 G_L1: 0.000 D_real: 0.773 D_fake: 0.621 \n",
      "(epoch: 3, iters: 840, time: 0.095, data: 0.001) G_GAN: 0.711 G_L1: 0.000 D_real: 0.722 D_fake: 0.666 \n",
      "(epoch: 3, iters: 940, time: 0.111, data: 0.001) G_GAN: 0.797 G_L1: 1.224 D_real: 0.664 D_fake: 0.606 \n",
      "(epoch: 3, iters: 1040, time: 0.097, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.735 D_fake: 0.654 \n",
      "(epoch: 3, iters: 1140, time: 0.098, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.719 D_fake: 0.668 \n",
      "(epoch: 3, iters: 1240, time: 0.095, data: 0.001) G_GAN: 0.778 G_L1: 2.557 D_real: 0.614 D_fake: 0.620 \n",
      "(epoch: 3, iters: 1340, time: 0.112, data: 0.001) G_GAN: 0.756 G_L1: 0.000 D_real: 0.766 D_fake: 0.629 \n",
      "(epoch: 3, iters: 1440, time: 0.098, data: 0.002) G_GAN: 0.677 G_L1: 0.001 D_real: 0.681 D_fake: 0.706 \n",
      "(epoch: 3, iters: 1540, time: 0.107, data: 0.001) G_GAN: 0.752 G_L1: 1.958 D_real: 0.602 D_fake: 0.641 \n",
      "(epoch: 3, iters: 1640, time: 0.096, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.737 D_fake: 0.652 \n",
      "(epoch: 3, iters: 1740, time: 0.099, data: 0.001) G_GAN: 0.682 G_L1: 0.000 D_real: 0.692 D_fake: 0.687 \n",
      "(epoch: 3, iters: 1840, time: 0.098, data: 0.002) G_GAN: 0.724 G_L1: 0.312 D_real: 0.642 D_fake: 0.665 \n",
      "(epoch: 3, iters: 1940, time: 0.096, data: 0.001) G_GAN: 0.671 G_L1: 0.000 D_real: 0.677 D_fake: 0.711 \n",
      "(epoch: 3, iters: 2040, time: 0.110, data: 0.001) G_GAN: 0.684 G_L1: 0.000 D_real: 0.685 D_fake: 0.701 \n",
      "(epoch: 3, iters: 2140, time: 0.098, data: 0.002) G_GAN: 0.735 G_L1: 0.787 D_real: 0.634 D_fake: 0.676 \n",
      "(epoch: 3, iters: 2240, time: 0.097, data: 0.001) G_GAN: 0.758 G_L1: 0.001 D_real: 0.758 D_fake: 0.634 \n",
      "End of epoch 3 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 4, iters: 60, time: 0.104, data: 0.001) G_GAN: 0.703 G_L1: 0.000 D_real: 0.706 D_fake: 0.672 \n",
      "(epoch: 4, iters: 160, time: 0.098, data: 0.001) G_GAN: 0.738 G_L1: 3.187 D_real: 0.566 D_fake: 0.632 \n",
      "(epoch: 4, iters: 260, time: 0.096, data: 0.001) G_GAN: 0.759 G_L1: 0.001 D_real: 0.766 D_fake: 0.626 \n",
      "(epoch: 4, iters: 360, time: 0.096, data: 0.001) G_GAN: 0.709 G_L1: 0.000 D_real: 0.712 D_fake: 0.655 \n",
      "(epoch: 4, iters: 460, time: 0.098, data: 0.001) G_GAN: 0.782 G_L1: 2.600 D_real: 0.610 D_fake: 0.616 \n",
      "(epoch: 4, iters: 560, time: 0.108, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.762 D_fake: 0.630 \n",
      "(epoch: 4, iters: 660, time: 0.099, data: 0.002) G_GAN: 0.664 G_L1: 0.000 D_real: 0.639 D_fake: 0.733 \n",
      "(epoch: 4, iters: 760, time: 0.096, data: 0.001) G_GAN: 0.767 G_L1: 2.399 D_real: 0.614 D_fake: 0.609 \n",
      "(epoch: 4, iters: 860, time: 0.105, data: 0.001) G_GAN: 0.790 G_L1: 0.000 D_real: 0.768 D_fake: 0.528 \n",
      "(epoch: 4, iters: 960, time: 0.096, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.688 D_fake: 0.707 \n",
      "(epoch: 4, iters: 1060, time: 0.095, data: 0.001) G_GAN: 0.744 G_L1: 0.087 D_real: 0.719 D_fake: 0.645 \n",
      "(epoch: 4, iters: 1160, time: 0.094, data: 0.002) G_GAN: 0.768 G_L1: 0.000 D_real: 0.769 D_fake: 0.623 \n",
      "(epoch: 4, iters: 1260, time: 0.107, data: 0.001) G_GAN: 0.682 G_L1: 0.001 D_real: 0.625 D_fake: 0.808 \n",
      "(epoch: 4, iters: 1360, time: 0.109, data: 0.001) G_GAN: 0.763 G_L1: 4.502 D_real: 0.556 D_fake: 0.631 \n",
      "(epoch: 4, iters: 1460, time: 0.097, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.744 D_fake: 0.645 \n",
      "(epoch: 4, iters: 1560, time: 0.097, data: 0.001) G_GAN: 0.711 G_L1: 0.000 D_real: 0.711 D_fake: 0.676 \n",
      "(epoch: 4, iters: 1660, time: 0.095, data: 0.001) G_GAN: 0.752 G_L1: 1.973 D_real: 0.604 D_fake: 0.635 \n",
      "(epoch: 4, iters: 1760, time: 0.098, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.640 \n",
      "(epoch: 4, iters: 1860, time: 0.098, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.705 D_fake: 0.668 \n",
      "(epoch: 4, iters: 1960, time: 0.097, data: 0.001) G_GAN: 0.783 G_L1: 0.417 D_real: 0.687 D_fake: 0.620 \n",
      "(epoch: 4, iters: 2060, time: 0.095, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.744 D_fake: 0.645 \n",
      "(epoch: 4, iters: 2160, time: 0.096, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.685 D_fake: 0.702 \n",
      "(epoch: 4, iters: 2260, time: 0.095, data: 0.001) G_GAN: 0.726 G_L1: 3.017 D_real: 0.562 D_fake: 0.663 \n",
      "End of epoch 4 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 5, iters: 80, time: 0.103, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.746 D_fake: 0.649 \n",
      "(epoch: 5, iters: 180, time: 0.099, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.729 D_fake: 0.659 \n",
      "(epoch: 5, iters: 280, time: 0.097, data: 0.001) G_GAN: 0.741 G_L1: 1.052 D_real: 0.624 D_fake: 0.645 \n",
      "(epoch: 5, iters: 380, time: 0.097, data: 0.001) G_GAN: 0.759 G_L1: 0.000 D_real: 0.773 D_fake: 0.621 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 5, iters: 480, time: 0.108, data: 0.001) G_GAN: 0.699 G_L1: 0.000 D_real: 0.700 D_fake: 0.687 \n",
      "(epoch: 5, iters: 580, time: 0.113, data: 0.002) G_GAN: 0.757 G_L1: 4.208 D_real: 0.555 D_fake: 0.638 \n",
      "(epoch: 5, iters: 680, time: 0.099, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.767 D_fake: 0.625 \n",
      "(epoch: 5, iters: 780, time: 0.096, data: 0.001) G_GAN: 0.719 G_L1: 0.000 D_real: 0.720 D_fake: 0.653 \n",
      "(epoch: 5, iters: 880, time: 0.094, data: 0.001) G_GAN: 0.828 G_L1: 3.483 D_real: 0.607 D_fake: 0.508 \n",
      "saving the latest model (epoch 5, total_steps 10000)\n",
      "(epoch: 5, iters: 980, time: 0.097, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.761 D_fake: 0.631 \n",
      "(epoch: 5, iters: 1080, time: 0.097, data: 0.001) G_GAN: 0.708 G_L1: 0.000 D_real: 0.709 D_fake: 0.677 \n",
      "(epoch: 5, iters: 1180, time: 0.107, data: 0.001) G_GAN: 0.766 G_L1: 0.978 D_real: 0.643 D_fake: 0.626 \n",
      "(epoch: 5, iters: 1280, time: 0.097, data: 0.001) G_GAN: 0.753 G_L1: 0.000 D_real: 0.758 D_fake: 0.634 \n",
      "(epoch: 5, iters: 1380, time: 0.105, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.732 D_fake: 0.639 \n",
      "(epoch: 5, iters: 1480, time: 0.096, data: 0.001) G_GAN: 0.770 G_L1: 1.681 D_real: 0.623 D_fake: 0.626 \n",
      "(epoch: 5, iters: 1580, time: 0.096, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.731 D_fake: 0.657 \n",
      "(epoch: 5, iters: 1680, time: 0.098, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.770 D_fake: 0.707 \n",
      "(epoch: 5, iters: 1780, time: 0.096, data: 0.001) G_GAN: 0.798 G_L1: 3.487 D_real: 0.591 D_fake: 0.620 \n",
      "(epoch: 5, iters: 1880, time: 0.100, data: 0.001) G_GAN: 0.712 G_L1: 0.000 D_real: 0.721 D_fake: 0.668 \n",
      "(epoch: 5, iters: 1980, time: 0.097, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.686 D_fake: 0.701 \n",
      "(epoch: 5, iters: 2080, time: 0.095, data: 0.001) G_GAN: 0.782 G_L1: 2.663 D_real: 0.604 D_fake: 0.507 \n",
      "(epoch: 5, iters: 2180, time: 0.099, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.765 D_fake: 0.647 \n",
      "(epoch: 5, iters: 2280, time: 0.097, data: 0.000) G_GAN: 0.727 G_L1: 0.000 D_real: 0.735 D_fake: 0.656 \n",
      "saving the model at the end of epoch 5, iters 11400\n",
      "End of epoch 5 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 6, iters: 100, time: 0.108, data: 0.305) G_GAN: 0.752 G_L1: 2.739 D_real: 0.578 D_fake: 0.631 \n",
      "(epoch: 6, iters: 200, time: 0.099, data: 0.001) G_GAN: 0.724 G_L1: 0.000 D_real: 0.730 D_fake: 0.659 \n",
      "(epoch: 6, iters: 300, time: 0.107, data: 0.001) G_GAN: 0.679 G_L1: 0.000 D_real: 0.680 D_fake: 0.707 \n",
      "(epoch: 6, iters: 400, time: 0.097, data: 0.002) G_GAN: 0.751 G_L1: 1.900 D_real: 0.593 D_fake: 0.642 \n",
      "(epoch: 6, iters: 500, time: 0.100, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.766 D_fake: 0.627 \n",
      "(epoch: 6, iters: 600, time: 0.098, data: 0.001) G_GAN: 0.715 G_L1: 0.000 D_real: 0.718 D_fake: 0.671 \n",
      "(epoch: 6, iters: 700, time: 0.105, data: 0.001) G_GAN: 0.812 G_L1: 2.269 D_real: 0.638 D_fake: 0.605 \n",
      "(epoch: 6, iters: 800, time: 0.098, data: 0.001) G_GAN: 0.758 G_L1: 0.000 D_real: 0.769 D_fake: 0.625 \n",
      "(epoch: 6, iters: 900, time: 0.094, data: 0.001) G_GAN: 0.677 G_L1: 0.000 D_real: 0.685 D_fake: 0.705 \n",
      "(epoch: 6, iters: 1000, time: 0.099, data: 0.001) G_GAN: 0.766 G_L1: 2.064 D_real: 0.613 D_fake: 0.630 \n",
      "(epoch: 6, iters: 1100, time: 0.108, data: 0.001) G_GAN: 0.782 G_L1: 0.000 D_real: 0.785 D_fake: 0.611 \n",
      "(epoch: 6, iters: 1200, time: 0.097, data: 0.001) G_GAN: 0.713 G_L1: 0.000 D_real: 0.716 D_fake: 0.672 \n",
      "(epoch: 6, iters: 1300, time: 0.098, data: 0.001) G_GAN: 0.757 G_L1: 3.100 D_real: 0.570 D_fake: 0.640 \n",
      "(epoch: 6, iters: 1400, time: 0.098, data: 0.001) G_GAN: 0.766 G_L1: 0.000 D_real: 0.777 D_fake: 0.613 \n",
      "(epoch: 6, iters: 1500, time: 0.108, data: 0.001) G_GAN: 0.703 G_L1: 0.000 D_real: 0.704 D_fake: 0.684 \n",
      "(epoch: 6, iters: 1600, time: 0.095, data: 0.001) G_GAN: 0.773 G_L1: 1.704 D_real: 0.622 D_fake: 0.624 \n",
      "(epoch: 6, iters: 1700, time: 0.098, data: 0.001) G_GAN: 0.713 G_L1: 0.000 D_real: 0.732 D_fake: 0.667 \n",
      "(epoch: 6, iters: 1800, time: 0.095, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.749 D_fake: 0.640 \n",
      "(epoch: 6, iters: 1900, time: 0.098, data: 0.001) G_GAN: 0.819 G_L1: 4.005 D_real: 0.589 D_fake: 0.580 \n",
      "(epoch: 6, iters: 2000, time: 0.097, data: 0.001) G_GAN: 0.749 G_L1: 0.000 D_real: 0.762 D_fake: 0.630 \n",
      "(epoch: 6, iters: 2100, time: 0.095, data: 0.001) G_GAN: 0.662 G_L1: 0.000 D_real: 0.657 D_fake: 0.732 \n",
      "(epoch: 6, iters: 2200, time: 0.100, data: 0.001) G_GAN: 0.756 G_L1: 1.935 D_real: 0.609 D_fake: 0.624 \n",
      "End of epoch 6 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 7, iters: 20, time: 0.115, data: 0.001) G_GAN: 0.756 G_L1: 0.000 D_real: 0.759 D_fake: 0.632 \n",
      "(epoch: 7, iters: 120, time: 0.097, data: 0.001) G_GAN: 0.752 G_L1: 0.000 D_real: 0.753 D_fake: 0.641 \n",
      "(epoch: 7, iters: 220, time: 0.097, data: 0.001) G_GAN: 0.751 G_L1: 3.205 D_real: 0.572 D_fake: 0.641 \n",
      "(epoch: 7, iters: 320, time: 0.108, data: 0.001) G_GAN: 0.751 G_L1: 0.000 D_real: 0.755 D_fake: 0.638 \n",
      "(epoch: 7, iters: 420, time: 0.110, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.728 D_fake: 0.660 \n",
      "(epoch: 7, iters: 520, time: 0.107, data: 0.001) G_GAN: 0.755 G_L1: 1.603 D_real: 0.605 D_fake: 0.638 \n",
      "(epoch: 7, iters: 620, time: 0.113, data: 0.001) G_GAN: 0.757 G_L1: 0.000 D_real: 0.761 D_fake: 0.632 \n",
      "(epoch: 7, iters: 720, time: 0.099, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.699 D_fake: 0.689 \n",
      "(epoch: 7, iters: 820, time: 0.097, data: 0.001) G_GAN: 0.753 G_L1: 2.187 D_real: 0.588 D_fake: 0.640 \n",
      "(epoch: 7, iters: 920, time: 0.095, data: 0.001) G_GAN: 0.712 G_L1: 0.000 D_real: 0.716 D_fake: 0.672 \n",
      "(epoch: 7, iters: 1020, time: 0.098, data: 0.001) G_GAN: 0.703 G_L1: 0.000 D_real: 0.705 D_fake: 0.683 \n",
      "(epoch: 7, iters: 1120, time: 0.099, data: 0.001) G_GAN: 0.756 G_L1: 1.002 D_real: 0.627 D_fake: 0.636 \n",
      "(epoch: 7, iters: 1220, time: 0.096, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.747 D_fake: 0.644 \n",
      "(epoch: 7, iters: 1320, time: 0.099, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.728 D_fake: 0.660 \n",
      "saving the latest model (epoch 7, total_steps 15000)\n",
      "(epoch: 7, iters: 1420, time: 0.097, data: 0.001) G_GAN: 0.743 G_L1: 2.201 D_real: 0.582 D_fake: 0.650 \n",
      "(epoch: 7, iters: 1520, time: 0.098, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.752 D_fake: 0.644 \n",
      "(epoch: 7, iters: 1620, time: 0.095, data: 0.001) G_GAN: 0.720 G_L1: 0.000 D_real: 0.721 D_fake: 0.647 \n",
      "(epoch: 7, iters: 1720, time: 0.101, data: 0.001) G_GAN: 0.755 G_L1: 3.384 D_real: 0.561 D_fake: 0.644 \n",
      "(epoch: 7, iters: 1820, time: 0.098, data: 0.001) G_GAN: 0.753 G_L1: 0.000 D_real: 0.769 D_fake: 0.624 \n",
      "(epoch: 7, iters: 1920, time: 0.097, data: 0.001) G_GAN: 0.734 G_L1: 0.000 D_real: 0.734 D_fake: 0.656 \n",
      "(epoch: 7, iters: 2020, time: 0.099, data: 0.002) G_GAN: 0.762 G_L1: 1.903 D_real: 0.605 D_fake: 0.633 \n",
      "(epoch: 7, iters: 2120, time: 0.107, data: 0.001) G_GAN: 0.764 G_L1: 0.000 D_real: 0.772 D_fake: 0.603 \n",
      "(epoch: 7, iters: 2220, time: 0.099, data: 0.001) G_GAN: 0.653 G_L1: 0.000 D_real: 0.655 D_fake: 0.689 \n",
      "End of epoch 7 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 8, iters: 40, time: 0.117, data: 0.001) G_GAN: 0.743 G_L1: 1.545 D_real: 0.603 D_fake: 0.649 \n",
      "(epoch: 8, iters: 140, time: 0.096, data: 0.001) G_GAN: 0.753 G_L1: 0.000 D_real: 0.757 D_fake: 0.634 \n",
      "(epoch: 8, iters: 240, time: 0.096, data: 0.001) G_GAN: 0.743 G_L1: 0.000 D_real: 0.744 D_fake: 0.639 \n",
      "(epoch: 8, iters: 340, time: 0.107, data: 0.001) G_GAN: 0.746 G_L1: 0.576 D_real: 0.642 D_fake: 0.646 \n",
      "(epoch: 8, iters: 440, time: 0.097, data: 0.001) G_GAN: 0.753 G_L1: 0.000 D_real: 0.756 D_fake: 0.635 \n",
      "(epoch: 8, iters: 540, time: 0.095, data: 0.001) G_GAN: 0.720 G_L1: 0.000 D_real: 0.725 D_fake: 0.662 \n",
      "(epoch: 8, iters: 640, time: 0.106, data: 0.001) G_GAN: 0.759 G_L1: 3.338 D_real: 0.568 D_fake: 0.635 \n",
      "(epoch: 8, iters: 740, time: 0.094, data: 0.001) G_GAN: 0.752 G_L1: 0.000 D_real: 0.754 D_fake: 0.637 \n",
      "(epoch: 8, iters: 840, time: 0.095, data: 0.001) G_GAN: 0.743 G_L1: 0.000 D_real: 0.746 D_fake: 0.630 \n",
      "(epoch: 8, iters: 940, time: 0.099, data: 0.002) G_GAN: 0.779 G_L1: 1.224 D_real: 0.638 D_fake: 0.620 \n",
      "(epoch: 8, iters: 1040, time: 0.103, data: 0.001) G_GAN: 0.752 G_L1: 0.000 D_real: 0.749 D_fake: 0.626 \n",
      "(epoch: 8, iters: 1140, time: 0.107, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.727 D_fake: 0.657 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 8, iters: 1240, time: 0.094, data: 0.001) G_GAN: 0.735 G_L1: 2.557 D_real: 0.568 D_fake: 0.656 \n",
      "(epoch: 8, iters: 1340, time: 0.109, data: 0.001) G_GAN: 0.771 G_L1: 0.000 D_real: 0.774 D_fake: 0.620 \n",
      "(epoch: 8, iters: 1440, time: 0.108, data: 0.001) G_GAN: 0.721 G_L1: 0.000 D_real: 0.725 D_fake: 0.668 \n",
      "(epoch: 8, iters: 1540, time: 0.099, data: 0.001) G_GAN: 0.762 G_L1: 1.958 D_real: 0.600 D_fake: 0.632 \n",
      "(epoch: 8, iters: 1640, time: 0.098, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.735 D_fake: 0.653 \n",
      "(epoch: 8, iters: 1740, time: 0.100, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.706 D_fake: 0.667 \n",
      "(epoch: 8, iters: 1840, time: 0.098, data: 0.001) G_GAN: 0.730 G_L1: 0.311 D_real: 0.637 D_fake: 0.662 \n",
      "(epoch: 8, iters: 1940, time: 0.098, data: 0.001) G_GAN: 0.763 G_L1: 0.000 D_real: 0.767 D_fake: 0.626 \n",
      "(epoch: 8, iters: 2040, time: 0.108, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.730 D_fake: 0.664 \n",
      "(epoch: 8, iters: 2140, time: 0.099, data: 0.001) G_GAN: 0.777 G_L1: 0.787 D_real: 0.649 D_fake: 0.625 \n",
      "(epoch: 8, iters: 2240, time: 0.097, data: 0.001) G_GAN: 0.710 G_L1: 0.000 D_real: 0.729 D_fake: 0.645 \n",
      "End of epoch 8 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 9, iters: 60, time: 0.107, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.719 D_fake: 0.664 \n",
      "(epoch: 9, iters: 160, time: 0.098, data: 0.001) G_GAN: 0.755 G_L1: 3.185 D_real: 0.571 D_fake: 0.639 \n",
      "(epoch: 9, iters: 260, time: 0.097, data: 0.001) G_GAN: 0.767 G_L1: 0.000 D_real: 0.783 D_fake: 0.643 \n",
      "(epoch: 9, iters: 360, time: 0.106, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.732 D_fake: 0.649 \n",
      "(epoch: 9, iters: 460, time: 0.098, data: 0.001) G_GAN: 0.767 G_L1: 2.593 D_real: 0.592 D_fake: 0.644 \n",
      "(epoch: 9, iters: 560, time: 0.097, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.739 D_fake: 0.651 \n",
      "(epoch: 9, iters: 660, time: 0.099, data: 0.001) G_GAN: 0.710 G_L1: 0.000 D_real: 0.712 D_fake: 0.664 \n",
      "(epoch: 9, iters: 760, time: 0.095, data: 0.001) G_GAN: 0.789 G_L1: 2.399 D_real: 0.607 D_fake: 0.611 \n",
      "(epoch: 9, iters: 860, time: 0.093, data: 0.001) G_GAN: 0.712 G_L1: 0.000 D_real: 0.709 D_fake: 0.680 \n",
      "(epoch: 9, iters: 960, time: 0.095, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.727 D_fake: 0.661 \n",
      "(epoch: 9, iters: 1060, time: 0.107, data: 0.001) G_GAN: 0.746 G_L1: 0.087 D_real: 0.710 D_fake: 0.640 \n",
      "(epoch: 9, iters: 1160, time: 0.095, data: 0.001) G_GAN: 0.734 G_L1: 0.000 D_real: 0.735 D_fake: 0.653 \n",
      "(epoch: 9, iters: 1260, time: 0.099, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.746 D_fake: 0.643 \n",
      "(epoch: 9, iters: 1360, time: 0.110, data: 0.001) G_GAN: 0.754 G_L1: 4.502 D_real: 0.539 D_fake: 0.643 \n",
      "(epoch: 9, iters: 1460, time: 0.097, data: 0.001) G_GAN: 0.744 G_L1: 0.000 D_real: 0.745 D_fake: 0.647 \n",
      "(epoch: 9, iters: 1560, time: 0.096, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.729 D_fake: 0.653 \n",
      "(epoch: 9, iters: 1660, time: 0.111, data: 0.001) G_GAN: 0.743 G_L1: 1.973 D_real: 0.591 D_fake: 0.647 \n",
      "(epoch: 9, iters: 1760, time: 0.098, data: 0.001) G_GAN: 0.743 G_L1: 0.000 D_real: 0.744 D_fake: 0.645 \n",
      "saving the latest model (epoch 9, total_steps 20000)\n",
      "(epoch: 9, iters: 1860, time: 0.099, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.733 D_fake: 0.656 \n",
      "(epoch: 9, iters: 1960, time: 0.113, data: 0.001) G_GAN: 0.768 G_L1: 0.417 D_real: 0.664 D_fake: 0.625 \n",
      "(epoch: 9, iters: 2060, time: 0.094, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.742 D_fake: 0.631 \n",
      "(epoch: 9, iters: 2160, time: 0.100, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.729 D_fake: 0.656 \n",
      "(epoch: 9, iters: 2260, time: 0.096, data: 0.001) G_GAN: 0.763 G_L1: 3.017 D_real: 0.579 D_fake: 0.625 \n",
      "End of epoch 9 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 10, iters: 80, time: 0.102, data: 0.001) G_GAN: 0.759 G_L1: 0.000 D_real: 0.762 D_fake: 0.630 \n",
      "(epoch: 10, iters: 180, time: 0.097, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.692 \n",
      "(epoch: 10, iters: 280, time: 0.097, data: 0.001) G_GAN: 0.768 G_L1: 1.052 D_real: 0.639 D_fake: 0.629 \n",
      "(epoch: 10, iters: 380, time: 0.098, data: 0.001) G_GAN: 0.768 G_L1: 0.000 D_real: 0.773 D_fake: 0.630 \n",
      "(epoch: 10, iters: 480, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.698 D_fake: 0.683 \n",
      "(epoch: 10, iters: 580, time: 0.097, data: 0.001) G_GAN: 0.762 G_L1: 4.208 D_real: 0.539 D_fake: 0.634 \n",
      "(epoch: 10, iters: 680, time: 0.097, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.748 D_fake: 0.643 \n",
      "(epoch: 10, iters: 780, time: 0.091, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.685 D_fake: 0.712 \n",
      "(epoch: 10, iters: 880, time: 0.097, data: 0.001) G_GAN: 0.863 G_L1: 3.483 D_real: 0.618 D_fake: 0.559 \n",
      "(epoch: 10, iters: 980, time: 0.096, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.705 D_fake: 0.682 \n",
      "(epoch: 10, iters: 1080, time: 0.096, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.528 D_fake: 0.895 \n",
      "(epoch: 10, iters: 1180, time: 0.098, data: 0.001) G_GAN: 0.768 G_L1: 0.978 D_real: 0.642 D_fake: 0.635 \n",
      "(epoch: 10, iters: 1280, time: 0.097, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.754 D_fake: 0.631 \n",
      "(epoch: 10, iters: 1380, time: 0.097, data: 0.001) G_GAN: 0.674 G_L1: 0.000 D_real: 0.675 D_fake: 0.713 \n",
      "(epoch: 10, iters: 1480, time: 0.097, data: 0.002) G_GAN: 0.771 G_L1: 1.681 D_real: 0.615 D_fake: 0.636 \n",
      "(epoch: 10, iters: 1580, time: 0.107, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.746 D_fake: 0.642 \n",
      "(epoch: 10, iters: 1680, time: 0.097, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.738 D_fake: 0.654 \n",
      "(epoch: 10, iters: 1780, time: 0.096, data: 0.001) G_GAN: 0.779 G_L1: 3.487 D_real: 0.574 D_fake: 0.623 \n",
      "(epoch: 10, iters: 1880, time: 0.110, data: 0.001) G_GAN: 0.749 G_L1: 0.000 D_real: 0.756 D_fake: 0.636 \n",
      "(epoch: 10, iters: 1980, time: 0.100, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.728 D_fake: 0.661 \n",
      "(epoch: 10, iters: 2080, time: 0.096, data: 0.002) G_GAN: 0.795 G_L1: 2.663 D_real: 0.602 D_fake: 0.610 \n",
      "(epoch: 10, iters: 2180, time: 0.099, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.749 D_fake: 0.642 \n",
      "(epoch: 10, iters: 2280, time: 0.096, data: 0.001) G_GAN: 0.705 G_L1: 0.000 D_real: 0.710 D_fake: 0.678 \n",
      "saving the model at the end of epoch 10, iters 22800\n",
      "End of epoch 10 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 11, iters: 100, time: 0.106, data: 0.281) G_GAN: 0.768 G_L1: 2.739 D_real: 0.582 D_fake: 0.626 \n",
      "(epoch: 11, iters: 200, time: 0.109, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.746 D_fake: 0.621 \n",
      "(epoch: 11, iters: 300, time: 0.095, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.703 D_fake: 0.678 \n",
      "(epoch: 11, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.719 G_L1: 1.900 D_real: 0.559 D_fake: 0.675 \n",
      "(epoch: 11, iters: 500, time: 0.098, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.760 D_fake: 0.632 \n",
      "(epoch: 11, iters: 600, time: 0.110, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.738 D_fake: 0.663 \n",
      "(epoch: 11, iters: 700, time: 0.097, data: 0.001) G_GAN: 0.801 G_L1: 2.269 D_real: 0.620 D_fake: 0.602 \n",
      "(epoch: 11, iters: 800, time: 0.109, data: 0.001) G_GAN: 0.773 G_L1: 0.000 D_real: 0.788 D_fake: 0.614 \n",
      "(epoch: 11, iters: 900, time: 0.103, data: 0.001) G_GAN: 1.043 G_L1: 0.000 D_real: 2.133 D_fake: 0.341 \n",
      "(epoch: 11, iters: 1000, time: 0.099, data: 0.002) G_GAN: 0.742 G_L1: 2.064 D_real: 0.584 D_fake: 0.651 \n",
      "(epoch: 11, iters: 1100, time: 0.098, data: 0.001) G_GAN: 0.749 G_L1: 0.000 D_real: 0.754 D_fake: 0.637 \n",
      "(epoch: 11, iters: 1200, time: 0.097, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.642 \n",
      "(epoch: 11, iters: 1300, time: 0.098, data: 0.001) G_GAN: 0.745 G_L1: 3.100 D_real: 0.569 D_fake: 0.639 \n",
      "(epoch: 11, iters: 1400, time: 0.097, data: 0.001) G_GAN: 0.774 G_L1: 0.000 D_real: 0.777 D_fake: 0.617 \n",
      "(epoch: 11, iters: 1500, time: 0.097, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.739 D_fake: 0.637 \n",
      "(epoch: 11, iters: 1600, time: 0.108, data: 0.001) G_GAN: 0.736 G_L1: 1.704 D_real: 0.593 D_fake: 0.646 \n",
      "(epoch: 11, iters: 1700, time: 0.110, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.763 D_fake: 0.630 \n",
      "(epoch: 11, iters: 1800, time: 0.097, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.740 D_fake: 0.640 \n",
      "(epoch: 11, iters: 1900, time: 0.099, data: 0.001) G_GAN: 0.777 G_L1: 4.005 D_real: 0.563 D_fake: 0.624 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 11, iters: 2000, time: 0.097, data: 0.001) G_GAN: 0.784 G_L1: 0.000 D_real: 0.788 D_fake: 0.595 \n",
      "(epoch: 11, iters: 2100, time: 0.094, data: 0.001) G_GAN: 0.679 G_L1: 0.000 D_real: 0.674 D_fake: 0.714 \n",
      "(epoch: 11, iters: 2200, time: 0.096, data: 0.001) G_GAN: 0.725 G_L1: 1.935 D_real: 0.559 D_fake: 0.502 \n",
      "saving the latest model (epoch 11, total_steps 25000)\n",
      "End of epoch 11 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 12, iters: 20, time: 0.106, data: 0.001) G_GAN: 0.757 G_L1: 0.000 D_real: 0.764 D_fake: 0.635 \n",
      "(epoch: 12, iters: 120, time: 0.098, data: 0.001) G_GAN: 0.712 G_L1: 0.000 D_real: 0.714 D_fake: 0.673 \n",
      "(epoch: 12, iters: 220, time: 0.098, data: 0.001) G_GAN: 0.766 G_L1: 3.205 D_real: 0.575 D_fake: 0.643 \n",
      "(epoch: 12, iters: 320, time: 0.109, data: 0.001) G_GAN: 0.753 G_L1: 0.000 D_real: 0.756 D_fake: 0.636 \n",
      "(epoch: 12, iters: 420, time: 0.096, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.728 D_fake: 0.661 \n",
      "(epoch: 12, iters: 520, time: 0.096, data: 0.001) G_GAN: 0.737 G_L1: 1.603 D_real: 0.593 D_fake: 0.654 \n",
      "(epoch: 12, iters: 620, time: 0.097, data: 0.001) G_GAN: 0.736 G_L1: 0.000 D_real: 0.736 D_fake: 0.658 \n",
      "(epoch: 12, iters: 720, time: 0.098, data: 0.001) G_GAN: 0.719 G_L1: 0.000 D_real: 0.721 D_fake: 0.667 \n",
      "(epoch: 12, iters: 820, time: 0.098, data: 0.001) G_GAN: 0.740 G_L1: 2.187 D_real: 0.584 D_fake: 0.633 \n",
      "(epoch: 12, iters: 920, time: 0.094, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.694 D_fake: 0.677 \n",
      "(epoch: 12, iters: 1020, time: 0.095, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.725 D_fake: 0.665 \n",
      "(epoch: 12, iters: 1120, time: 0.097, data: 0.001) G_GAN: 0.772 G_L1: 1.002 D_real: 0.634 D_fake: 0.632 \n",
      "(epoch: 12, iters: 1220, time: 0.097, data: 0.001) G_GAN: 0.761 G_L1: 0.000 D_real: 0.763 D_fake: 0.630 \n",
      "(epoch: 12, iters: 1320, time: 0.096, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.701 D_fake: 0.689 \n",
      "(epoch: 12, iters: 1420, time: 0.095, data: 0.001) G_GAN: 0.746 G_L1: 2.201 D_real: 0.588 D_fake: 0.647 \n",
      "(epoch: 12, iters: 1520, time: 0.108, data: 0.001) G_GAN: 0.734 G_L1: 0.000 D_real: 0.738 D_fake: 0.652 \n",
      "(epoch: 12, iters: 1620, time: 0.103, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.724 D_fake: 0.664 \n",
      "(epoch: 12, iters: 1720, time: 0.111, data: 0.001) G_GAN: 0.768 G_L1: 3.384 D_real: 0.569 D_fake: 0.635 \n",
      "(epoch: 12, iters: 1820, time: 0.101, data: 0.001) G_GAN: 0.772 G_L1: 0.000 D_real: 0.785 D_fake: 0.632 \n",
      "(epoch: 12, iters: 1920, time: 0.098, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.724 D_fake: 0.627 \n",
      "(epoch: 12, iters: 2020, time: 0.096, data: 0.001) G_GAN: 0.762 G_L1: 1.903 D_real: 0.602 D_fake: 0.633 \n",
      "(epoch: 12, iters: 2120, time: 0.098, data: 0.001) G_GAN: 0.788 G_L1: 0.000 D_real: 0.800 D_fake: 0.600 \n",
      "(epoch: 12, iters: 2220, time: 0.100, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.739 D_fake: 0.650 \n",
      "End of epoch 12 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 13, iters: 40, time: 0.104, data: 0.002) G_GAN: 0.746 G_L1: 1.545 D_real: 0.605 D_fake: 0.645 \n",
      "(epoch: 13, iters: 140, time: 0.106, data: 0.001) G_GAN: 0.760 G_L1: 0.000 D_real: 0.761 D_fake: 0.631 \n",
      "(epoch: 13, iters: 240, time: 0.096, data: 0.001) G_GAN: 0.714 G_L1: 0.000 D_real: 0.719 D_fake: 0.634 \n",
      "(epoch: 13, iters: 340, time: 0.095, data: 0.002) G_GAN: 0.743 G_L1: 0.576 D_real: 0.632 D_fake: 0.647 \n",
      "(epoch: 13, iters: 440, time: 0.103, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.743 D_fake: 0.639 \n",
      "(epoch: 13, iters: 540, time: 0.096, data: 0.001) G_GAN: 0.717 G_L1: 0.000 D_real: 0.718 D_fake: 0.670 \n",
      "(epoch: 13, iters: 640, time: 0.095, data: 0.002) G_GAN: 0.765 G_L1: 3.338 D_real: 0.571 D_fake: 0.632 \n",
      "(epoch: 13, iters: 740, time: 0.096, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.745 D_fake: 0.623 \n",
      "(epoch: 13, iters: 840, time: 0.093, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.720 D_fake: 0.669 \n",
      "(epoch: 13, iters: 940, time: 0.104, data: 0.001) G_GAN: 0.827 G_L1: 1.224 D_real: 0.669 D_fake: 0.575 \n",
      "(epoch: 13, iters: 1040, time: 0.096, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.752 D_fake: 0.639 \n",
      "(epoch: 13, iters: 1140, time: 0.109, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.750 D_fake: 0.650 \n",
      "(epoch: 13, iters: 1240, time: 0.106, data: 0.001) G_GAN: 0.828 G_L1: 2.557 D_real: 0.636 D_fake: 0.606 \n",
      "(epoch: 13, iters: 1340, time: 0.098, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.751 D_fake: 0.640 \n",
      "(epoch: 13, iters: 1440, time: 0.100, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.726 D_fake: 0.663 \n",
      "(epoch: 13, iters: 1540, time: 0.099, data: 0.001) G_GAN: 0.786 G_L1: 1.958 D_real: 0.616 D_fake: 0.613 \n",
      "(epoch: 13, iters: 1640, time: 0.098, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.744 D_fake: 0.647 \n",
      "(epoch: 13, iters: 1740, time: 0.098, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.733 D_fake: 0.657 \n",
      "(epoch: 13, iters: 1840, time: 0.100, data: 0.002) G_GAN: 0.746 G_L1: 0.311 D_real: 0.650 D_fake: 0.646 \n",
      "(epoch: 13, iters: 1940, time: 0.101, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.769 D_fake: 0.625 \n",
      "(epoch: 13, iters: 2040, time: 0.109, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.730 D_fake: 0.658 \n",
      "(epoch: 13, iters: 2140, time: 0.099, data: 0.002) G_GAN: 0.764 G_L1: 0.787 D_real: 0.644 D_fake: 0.623 \n",
      "(epoch: 13, iters: 2240, time: 0.097, data: 0.001) G_GAN: 0.715 G_L1: 0.000 D_real: 0.716 D_fake: 0.672 \n",
      "End of epoch 13 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 14, iters: 60, time: 0.105, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.732 D_fake: 0.627 \n",
      "(epoch: 14, iters: 160, time: 0.109, data: 0.001) G_GAN: 0.746 G_L1: 3.185 D_real: 0.555 D_fake: 0.634 \n",
      "(epoch: 14, iters: 260, time: 0.100, data: 0.001) G_GAN: 0.812 G_L1: 0.000 D_real: 0.823 D_fake: 0.583 \n",
      "(epoch: 14, iters: 360, time: 0.095, data: 0.001) G_GAN: 0.734 G_L1: 0.000 D_real: 0.735 D_fake: 0.629 \n",
      "saving the latest model (epoch 14, total_steps 30000)\n",
      "(epoch: 14, iters: 460, time: 0.099, data: 0.002) G_GAN: 0.750 G_L1: 2.593 D_real: 0.577 D_fake: 0.640 \n",
      "(epoch: 14, iters: 560, time: 0.108, data: 0.001) G_GAN: 0.763 G_L1: 0.000 D_real: 0.770 D_fake: 0.625 \n",
      "(epoch: 14, iters: 660, time: 0.095, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.720 D_fake: 0.672 \n",
      "(epoch: 14, iters: 760, time: 0.097, data: 0.001) G_GAN: 0.757 G_L1: 2.399 D_real: 0.586 D_fake: 0.637 \n",
      "(epoch: 14, iters: 860, time: 0.096, data: 0.001) G_GAN: 0.666 G_L1: 0.000 D_real: 0.665 D_fake: 0.724 \n",
      "(epoch: 14, iters: 960, time: 0.106, data: 0.001) G_GAN: 0.868 G_L1: 0.000 D_real: 0.829 D_fake: 0.622 \n",
      "(epoch: 14, iters: 1060, time: 0.095, data: 0.002) G_GAN: 0.723 G_L1: 0.087 D_real: 0.663 D_fake: 0.668 \n",
      "(epoch: 14, iters: 1160, time: 0.097, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.762 D_fake: 0.644 \n",
      "(epoch: 14, iters: 1260, time: 0.098, data: 0.003) G_GAN: 0.736 G_L1: 0.000 D_real: 0.736 D_fake: 0.633 \n",
      "(epoch: 14, iters: 1360, time: 0.096, data: 0.001) G_GAN: 0.751 G_L1: 4.502 D_real: 0.521 D_fake: 0.666 \n",
      "(epoch: 14, iters: 1460, time: 0.095, data: 0.001) G_GAN: 0.753 G_L1: 0.000 D_real: 0.757 D_fake: 0.634 \n",
      "(epoch: 14, iters: 1560, time: 0.096, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.731 D_fake: 0.646 \n",
      "(epoch: 14, iters: 1660, time: 0.097, data: 0.001) G_GAN: 0.762 G_L1: 1.973 D_real: 0.605 D_fake: 0.630 \n",
      "(epoch: 14, iters: 1760, time: 0.099, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.731 D_fake: 0.657 \n",
      "(epoch: 14, iters: 1860, time: 0.100, data: 0.001) G_GAN: 0.721 G_L1: 0.000 D_real: 0.723 D_fake: 0.659 \n",
      "(epoch: 14, iters: 1960, time: 0.097, data: 0.001) G_GAN: 0.774 G_L1: 0.417 D_real: 0.675 D_fake: 0.626 \n",
      "(epoch: 14, iters: 2060, time: 0.093, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.738 D_fake: 0.651 \n",
      "(epoch: 14, iters: 2160, time: 0.109, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.709 D_fake: 0.680 \n",
      "(epoch: 14, iters: 2260, time: 0.094, data: 0.001) G_GAN: 0.767 G_L1: 3.017 D_real: 0.581 D_fake: 0.629 \n",
      "End of epoch 14 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 15, iters: 80, time: 0.104, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.727 D_fake: 0.662 \n",
      "(epoch: 15, iters: 180, time: 0.099, data: 0.001) G_GAN: 0.719 G_L1: 0.000 D_real: 0.724 D_fake: 0.665 \n",
      "(epoch: 15, iters: 280, time: 0.097, data: 0.001) G_GAN: 0.760 G_L1: 1.052 D_real: 0.632 D_fake: 0.640 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 15, iters: 380, time: 0.096, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.763 D_fake: 0.637 \n",
      "(epoch: 15, iters: 480, time: 0.099, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.761 D_fake: 0.542 \n",
      "(epoch: 15, iters: 580, time: 0.098, data: 0.002) G_GAN: 0.773 G_L1: 4.208 D_real: 0.545 D_fake: 0.623 \n",
      "(epoch: 15, iters: 680, time: 0.096, data: 0.001) G_GAN: 0.755 G_L1: 0.000 D_real: 0.759 D_fake: 0.640 \n",
      "(epoch: 15, iters: 780, time: 0.097, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.739 D_fake: 0.629 \n",
      "(epoch: 15, iters: 880, time: 0.096, data: 0.001) G_GAN: 0.764 G_L1: 3.483 D_real: 0.564 D_fake: 0.639 \n",
      "(epoch: 15, iters: 980, time: 0.096, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.751 D_fake: 0.640 \n",
      "(epoch: 15, iters: 1080, time: 0.097, data: 0.001) G_GAN: 0.711 G_L1: 0.000 D_real: 0.711 D_fake: 0.676 \n",
      "(epoch: 15, iters: 1180, time: 0.097, data: 0.002) G_GAN: 0.747 G_L1: 0.978 D_real: 0.626 D_fake: 0.643 \n",
      "(epoch: 15, iters: 1280, time: 0.098, data: 0.001) G_GAN: 0.807 G_L1: 0.000 D_real: 0.841 D_fake: 0.569 \n",
      "(epoch: 15, iters: 1380, time: 0.095, data: 0.001) G_GAN: 0.665 G_L1: 0.000 D_real: 0.662 D_fake: 0.727 \n",
      "(epoch: 15, iters: 1480, time: 0.107, data: 0.001) G_GAN: 0.731 G_L1: 1.681 D_real: 0.581 D_fake: 0.660 \n",
      "(epoch: 15, iters: 1580, time: 0.098, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.750 D_fake: 0.641 \n",
      "(epoch: 15, iters: 1680, time: 0.099, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.734 D_fake: 0.655 \n",
      "(epoch: 15, iters: 1780, time: 0.105, data: 0.001) G_GAN: 0.742 G_L1: 3.487 D_real: 0.549 D_fake: 0.651 \n",
      "(epoch: 15, iters: 1880, time: 0.112, data: 0.001) G_GAN: 0.774 G_L1: 0.000 D_real: 0.777 D_fake: 0.620 \n",
      "(epoch: 15, iters: 1980, time: 0.098, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.736 D_fake: 0.668 \n",
      "(epoch: 15, iters: 2080, time: 0.095, data: 0.001) G_GAN: 0.728 G_L1: 2.663 D_real: 0.556 D_fake: 0.662 \n",
      "(epoch: 15, iters: 2180, time: 0.107, data: 0.001) G_GAN: 0.758 G_L1: 0.000 D_real: 0.772 D_fake: 0.662 \n",
      "(epoch: 15, iters: 2280, time: 0.097, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.748 D_fake: 0.637 \n",
      "saving the model at the end of epoch 15, iters 34200\n",
      "End of epoch 15 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 16, iters: 100, time: 0.120, data: 0.282) G_GAN: 0.773 G_L1: 2.739 D_real: 0.592 D_fake: 0.637 \n",
      "(epoch: 16, iters: 200, time: 0.096, data: 0.001) G_GAN: 0.753 G_L1: 0.000 D_real: 0.755 D_fake: 0.636 \n",
      "(epoch: 16, iters: 300, time: 0.096, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.732 D_fake: 0.660 \n",
      "(epoch: 16, iters: 400, time: 0.108, data: 0.001) G_GAN: 0.733 G_L1: 1.900 D_real: 0.581 D_fake: 0.658 \n",
      "(epoch: 16, iters: 500, time: 0.098, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.731 D_fake: 0.658 \n",
      "(epoch: 16, iters: 600, time: 0.098, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.697 D_fake: 0.691 \n",
      "(epoch: 16, iters: 700, time: 0.098, data: 0.001) G_GAN: 0.767 G_L1: 2.269 D_real: 0.597 D_fake: 0.627 \n",
      "(epoch: 16, iters: 800, time: 0.111, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.751 D_fake: 0.638 \n",
      "saving the latest model (epoch 16, total_steps 35000)\n",
      "(epoch: 16, iters: 900, time: 0.103, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.733 D_fake: 0.660 \n",
      "(epoch: 16, iters: 1000, time: 0.101, data: 0.001) G_GAN: 0.760 G_L1: 2.064 D_real: 0.597 D_fake: 0.665 \n",
      "(epoch: 16, iters: 1100, time: 0.102, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.753 D_fake: 0.602 \n",
      "(epoch: 16, iters: 1200, time: 0.099, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.729 D_fake: 0.643 \n",
      "(epoch: 16, iters: 1300, time: 0.100, data: 0.002) G_GAN: 0.793 G_L1: 3.100 D_real: 0.599 D_fake: 0.693 \n",
      "(epoch: 16, iters: 1400, time: 0.098, data: 0.001) G_GAN: 0.763 G_L1: 0.000 D_real: 0.769 D_fake: 0.627 \n",
      "(epoch: 16, iters: 1500, time: 0.107, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.729 D_fake: 0.670 \n",
      "(epoch: 16, iters: 1600, time: 0.096, data: 0.001) G_GAN: 0.753 G_L1: 1.704 D_real: 0.607 D_fake: 0.670 \n",
      "(epoch: 16, iters: 1700, time: 0.110, data: 0.001) G_GAN: 0.789 G_L1: 0.000 D_real: 0.792 D_fake: 0.606 \n",
      "(epoch: 16, iters: 1800, time: 0.094, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.731 D_fake: 0.645 \n",
      "(epoch: 16, iters: 1900, time: 0.097, data: 0.001) G_GAN: 0.743 G_L1: 4.005 D_real: 0.540 D_fake: 0.638 \n",
      "(epoch: 16, iters: 2000, time: 0.098, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.755 D_fake: 0.631 \n",
      "(epoch: 16, iters: 2100, time: 0.095, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.699 \n",
      "(epoch: 16, iters: 2200, time: 0.099, data: 0.001) G_GAN: 0.748 G_L1: 1.935 D_real: 0.583 D_fake: 0.645 \n",
      "End of epoch 16 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 17, iters: 20, time: 0.116, data: 0.001) G_GAN: 0.759 G_L1: 0.000 D_real: 0.762 D_fake: 0.630 \n",
      "(epoch: 17, iters: 120, time: 0.098, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.730 D_fake: 0.657 \n",
      "(epoch: 17, iters: 220, time: 0.099, data: 0.001) G_GAN: 0.821 G_L1: 3.205 D_real: 0.608 D_fake: 0.576 \n",
      "(epoch: 17, iters: 320, time: 0.095, data: 0.001) G_GAN: 0.756 G_L1: 0.000 D_real: 0.763 D_fake: 0.630 \n",
      "(epoch: 17, iters: 420, time: 0.096, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.712 D_fake: 0.676 \n",
      "(epoch: 17, iters: 520, time: 0.096, data: 0.001) G_GAN: 0.734 G_L1: 1.603 D_real: 0.587 D_fake: 0.659 \n",
      "(epoch: 17, iters: 620, time: 0.099, data: 0.001) G_GAN: 0.711 G_L1: 0.000 D_real: 0.715 D_fake: 0.674 \n",
      "(epoch: 17, iters: 720, time: 0.101, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.738 D_fake: 0.652 \n",
      "(epoch: 17, iters: 820, time: 0.094, data: 0.001) G_GAN: 0.739 G_L1: 2.187 D_real: 0.574 D_fake: 0.653 \n",
      "(epoch: 17, iters: 920, time: 0.094, data: 0.001) G_GAN: 0.682 G_L1: 0.000 D_real: 0.707 D_fake: 0.426 \n",
      "(epoch: 17, iters: 1020, time: 0.097, data: 0.001) G_GAN: 0.718 G_L1: 0.000 D_real: 0.692 D_fake: 0.699 \n",
      "(epoch: 17, iters: 1120, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 1.002 D_real: 0.543 D_fake: 0.518 \n",
      "(epoch: 17, iters: 1220, time: 0.098, data: 0.001) G_GAN: 0.793 G_L1: 0.000 D_real: 0.807 D_fake: 0.554 \n",
      "(epoch: 17, iters: 1320, time: 0.097, data: 0.001) G_GAN: 0.718 G_L1: 0.000 D_real: 0.719 D_fake: 0.669 \n",
      "(epoch: 17, iters: 1420, time: 0.110, data: 0.000) G_GAN: 0.734 G_L1: 2.201 D_real: 0.563 D_fake: 0.642 \n",
      "(epoch: 17, iters: 1520, time: 0.098, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.744 D_fake: 0.647 \n",
      "(epoch: 17, iters: 1620, time: 0.094, data: 0.001) G_GAN: 0.669 G_L1: 0.000 D_real: 0.705 D_fake: 0.623 \n",
      "(epoch: 17, iters: 1720, time: 0.101, data: 0.001) G_GAN: 0.769 G_L1: 3.384 D_real: 0.569 D_fake: 0.628 \n",
      "(epoch: 17, iters: 1820, time: 0.099, data: 0.001) G_GAN: 0.771 G_L1: 0.000 D_real: 0.777 D_fake: 0.619 \n",
      "(epoch: 17, iters: 1920, time: 0.097, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.738 D_fake: 0.652 \n",
      "(epoch: 17, iters: 2020, time: 0.111, data: 0.002) G_GAN: 0.764 G_L1: 1.903 D_real: 0.605 D_fake: 0.630 \n",
      "(epoch: 17, iters: 2120, time: 0.097, data: 0.001) G_GAN: 0.818 G_L1: 0.000 D_real: 0.839 D_fake: 0.573 \n",
      "(epoch: 17, iters: 2220, time: 0.099, data: 0.001) G_GAN: 0.625 G_L1: 0.000 D_real: 0.612 D_fake: 0.767 \n",
      "End of epoch 17 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 18, iters: 40, time: 0.104, data: 0.002) G_GAN: 0.738 G_L1: 1.545 D_real: 0.594 D_fake: 0.653 \n",
      "(epoch: 18, iters: 140, time: 0.096, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.738 D_fake: 0.652 \n",
      "(epoch: 18, iters: 240, time: 0.094, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.735 D_fake: 0.654 \n",
      "(epoch: 18, iters: 340, time: 0.108, data: 0.001) G_GAN: 0.728 G_L1: 0.576 D_real: 0.615 D_fake: 0.654 \n",
      "(epoch: 18, iters: 440, time: 0.106, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.735 D_fake: 0.655 \n",
      "(epoch: 18, iters: 540, time: 0.093, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.732 D_fake: 0.657 \n",
      "(epoch: 18, iters: 640, time: 0.096, data: 0.001) G_GAN: 0.745 G_L1: 3.338 D_real: 0.547 D_fake: 0.647 \n",
      "(epoch: 18, iters: 740, time: 0.107, data: 0.001) G_GAN: 0.761 G_L1: 0.000 D_real: 0.762 D_fake: 0.630 \n",
      "(epoch: 18, iters: 840, time: 0.096, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.753 D_fake: 0.623 \n",
      "(epoch: 18, iters: 940, time: 0.098, data: 0.001) G_GAN: 0.788 G_L1: 1.224 D_real: 0.663 D_fake: 0.660 \n",
      "(epoch: 18, iters: 1040, time: 0.098, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.739 D_fake: 0.652 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 18, iters: 1140, time: 0.097, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.723 D_fake: 0.685 \n",
      "(epoch: 18, iters: 1240, time: 0.096, data: 0.001) G_GAN: 0.816 G_L1: 2.557 D_real: 0.644 D_fake: 0.652 \n",
      "saving the latest model (epoch 18, total_steps 40000)\n",
      "(epoch: 18, iters: 1340, time: 0.098, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.738 D_fake: 0.638 \n",
      "(epoch: 18, iters: 1440, time: 0.100, data: 0.001) G_GAN: 0.764 G_L1: 0.000 D_real: 0.765 D_fake: 0.628 \n",
      "(epoch: 18, iters: 1540, time: 0.100, data: 0.001) G_GAN: 0.765 G_L1: 1.958 D_real: 0.602 D_fake: 0.639 \n",
      "(epoch: 18, iters: 1640, time: 0.098, data: 0.001) G_GAN: 0.755 G_L1: 0.000 D_real: 0.757 D_fake: 0.626 \n",
      "(epoch: 18, iters: 1740, time: 0.108, data: 0.001) G_GAN: 0.717 G_L1: 0.000 D_real: 0.723 D_fake: 0.613 \n",
      "(epoch: 18, iters: 1840, time: 0.099, data: 0.002) G_GAN: 0.735 G_L1: 0.311 D_real: 0.641 D_fake: 0.655 \n",
      "(epoch: 18, iters: 1940, time: 0.099, data: 0.001) G_GAN: 0.772 G_L1: 0.000 D_real: 0.773 D_fake: 0.621 \n",
      "(epoch: 18, iters: 2040, time: 0.098, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.755 D_fake: 0.649 \n",
      "(epoch: 18, iters: 2140, time: 0.097, data: 0.002) G_GAN: 0.804 G_L1: 0.787 D_real: 0.678 D_fake: 0.595 \n",
      "(epoch: 18, iters: 2240, time: 0.099, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.754 D_fake: 0.639 \n",
      "End of epoch 18 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 19, iters: 60, time: 0.119, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.727 D_fake: 0.662 \n",
      "(epoch: 19, iters: 160, time: 0.097, data: 0.002) G_GAN: 0.739 G_L1: 3.185 D_real: 0.551 D_fake: 0.653 \n",
      "(epoch: 19, iters: 260, time: 0.099, data: 0.001) G_GAN: 0.785 G_L1: 0.000 D_real: 0.790 D_fake: 0.610 \n",
      "(epoch: 19, iters: 360, time: 0.097, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.726 D_fake: 0.663 \n",
      "(epoch: 19, iters: 460, time: 0.099, data: 0.001) G_GAN: 0.774 G_L1: 2.593 D_real: 0.593 D_fake: 0.653 \n",
      "(epoch: 19, iters: 560, time: 0.100, data: 0.001) G_GAN: 0.751 G_L1: 0.000 D_real: 0.753 D_fake: 0.626 \n",
      "(epoch: 19, iters: 660, time: 0.110, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.736 D_fake: 0.655 \n",
      "(epoch: 19, iters: 760, time: 0.096, data: 0.001) G_GAN: 0.745 G_L1: 2.399 D_real: 0.577 D_fake: 0.648 \n",
      "(epoch: 19, iters: 860, time: 0.095, data: 0.001) G_GAN: 0.618 G_L1: 0.000 D_real: 0.726 D_fake: 0.597 \n",
      "(epoch: 19, iters: 960, time: 0.095, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.743 D_fake: 0.619 \n",
      "(epoch: 19, iters: 1060, time: 0.094, data: 0.002) G_GAN: 0.733 G_L1: 0.087 D_real: 0.680 D_fake: 0.657 \n",
      "(epoch: 19, iters: 1160, time: 0.094, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.761 D_fake: 0.622 \n",
      "(epoch: 19, iters: 1260, time: 0.098, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.733 D_fake: 0.654 \n",
      "(epoch: 19, iters: 1360, time: 0.099, data: 0.001) G_GAN: 0.749 G_L1: 4.502 D_real: 0.522 D_fake: 0.644 \n",
      "(epoch: 19, iters: 1460, time: 0.095, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.749 D_fake: 0.642 \n",
      "(epoch: 19, iters: 1560, time: 0.107, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.729 D_fake: 0.661 \n",
      "(epoch: 19, iters: 1660, time: 0.098, data: 0.001) G_GAN: 0.743 G_L1: 1.973 D_real: 0.577 D_fake: 0.641 \n",
      "(epoch: 19, iters: 1760, time: 0.099, data: 0.001) G_GAN: 0.755 G_L1: 0.000 D_real: 0.756 D_fake: 0.638 \n",
      "(epoch: 19, iters: 1860, time: 0.097, data: 0.001) G_GAN: 0.712 G_L1: 0.000 D_real: 0.718 D_fake: 0.671 \n",
      "(epoch: 19, iters: 1960, time: 0.097, data: 0.001) G_GAN: 0.759 G_L1: 0.417 D_real: 0.650 D_fake: 0.635 \n",
      "(epoch: 19, iters: 2060, time: 0.104, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.721 D_fake: 0.654 \n",
      "(epoch: 19, iters: 2160, time: 0.111, data: 0.001) G_GAN: 0.714 G_L1: 0.000 D_real: 0.700 D_fake: 0.692 \n",
      "(epoch: 19, iters: 2260, time: 0.094, data: 0.001) G_GAN: 0.783 G_L1: 3.017 D_real: 0.573 D_fake: 0.629 \n",
      "End of epoch 19 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 20, iters: 80, time: 0.105, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.733 D_fake: 0.662 \n",
      "(epoch: 20, iters: 180, time: 0.097, data: 0.001) G_GAN: 0.719 G_L1: 0.000 D_real: 0.720 D_fake: 0.669 \n",
      "(epoch: 20, iters: 280, time: 0.098, data: 0.001) G_GAN: 0.758 G_L1: 1.052 D_real: 0.627 D_fake: 0.633 \n",
      "(epoch: 20, iters: 380, time: 0.098, data: 0.001) G_GAN: 0.763 G_L1: 0.000 D_real: 0.768 D_fake: 0.649 \n",
      "(epoch: 20, iters: 480, time: 0.099, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.725 D_fake: 0.665 \n",
      "(epoch: 20, iters: 580, time: 0.102, data: 0.002) G_GAN: 0.757 G_L1: 4.208 D_real: 0.537 D_fake: 0.627 \n",
      "(epoch: 20, iters: 680, time: 0.098, data: 0.001) G_GAN: 0.753 G_L1: 0.000 D_real: 0.760 D_fake: 0.587 \n",
      "(epoch: 20, iters: 780, time: 0.094, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.728 D_fake: 0.661 \n",
      "(epoch: 20, iters: 880, time: 0.094, data: 0.001) G_GAN: 0.778 G_L1: 3.483 D_real: 0.561 D_fake: 0.624 \n",
      "(epoch: 20, iters: 980, time: 0.097, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.752 D_fake: 0.639 \n",
      "(epoch: 20, iters: 1080, time: 0.096, data: 0.001) G_GAN: 0.714 G_L1: 0.000 D_real: 0.716 D_fake: 0.658 \n",
      "(epoch: 20, iters: 1180, time: 0.099, data: 0.002) G_GAN: 0.763 G_L1: 0.978 D_real: 0.634 D_fake: 0.631 \n",
      "(epoch: 20, iters: 1280, time: 0.104, data: 0.001) G_GAN: 0.799 G_L1: 0.000 D_real: 0.817 D_fake: 0.565 \n",
      "(epoch: 20, iters: 1380, time: 0.095, data: 0.001) G_GAN: 0.709 G_L1: 0.000 D_real: 0.710 D_fake: 0.686 \n",
      "(epoch: 20, iters: 1480, time: 0.099, data: 0.001) G_GAN: 0.744 G_L1: 1.681 D_real: 0.592 D_fake: 0.655 \n",
      "(epoch: 20, iters: 1580, time: 0.095, data: 0.001) G_GAN: 0.734 G_L1: 0.000 D_real: 0.735 D_fake: 0.654 \n",
      "(epoch: 20, iters: 1680, time: 0.098, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.732 D_fake: 0.656 \n",
      "saving the latest model (epoch 20, total_steps 45000)\n",
      "(epoch: 20, iters: 1780, time: 0.097, data: 0.001) G_GAN: 0.739 G_L1: 3.487 D_real: 0.551 D_fake: 0.651 \n",
      "(epoch: 20, iters: 1880, time: 0.108, data: 0.001) G_GAN: 0.749 G_L1: 0.000 D_real: 0.750 D_fake: 0.643 \n",
      "(epoch: 20, iters: 1980, time: 0.097, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.740 D_fake: 0.624 \n",
      "(epoch: 20, iters: 2080, time: 0.108, data: 0.001) G_GAN: 0.744 G_L1: 2.663 D_real: 0.566 D_fake: 0.647 \n",
      "(epoch: 20, iters: 2180, time: 0.096, data: 0.001) G_GAN: 0.788 G_L1: 0.000 D_real: 0.788 D_fake: 0.610 \n",
      "(epoch: 20, iters: 2280, time: 0.108, data: 0.001) G_GAN: 0.707 G_L1: 0.000 D_real: 0.700 D_fake: 0.705 \n",
      "saving the model at the end of epoch 20, iters 45600\n",
      "End of epoch 20 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 21, iters: 100, time: 0.108, data: 0.287) G_GAN: 0.763 G_L1: 2.739 D_real: 0.579 D_fake: 0.633 \n",
      "(epoch: 21, iters: 200, time: 0.096, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.747 D_fake: 0.645 \n",
      "(epoch: 21, iters: 300, time: 0.097, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.727 D_fake: 0.663 \n",
      "(epoch: 21, iters: 400, time: 0.096, data: 0.002) G_GAN: 0.730 G_L1: 1.900 D_real: 0.578 D_fake: 0.660 \n",
      "(epoch: 21, iters: 500, time: 0.099, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.752 D_fake: 0.640 \n",
      "(epoch: 21, iters: 600, time: 0.109, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.737 D_fake: 0.653 \n",
      "(epoch: 21, iters: 700, time: 0.097, data: 0.001) G_GAN: 0.772 G_L1: 2.269 D_real: 0.600 D_fake: 0.647 \n",
      "(epoch: 21, iters: 800, time: 0.098, data: 0.001) G_GAN: 0.763 G_L1: 0.000 D_real: 0.766 D_fake: 0.629 \n",
      "(epoch: 21, iters: 900, time: 0.094, data: 0.001) G_GAN: 0.521 G_L1: 0.000 D_real: 0.657 D_fake: 0.382 \n",
      "(epoch: 21, iters: 1000, time: 0.101, data: 0.001) G_GAN: 0.799 G_L1: 2.064 D_real: 0.619 D_fake: 0.649 \n",
      "(epoch: 21, iters: 1100, time: 0.097, data: 0.001) G_GAN: 0.763 G_L1: 0.000 D_real: 0.763 D_fake: 0.630 \n",
      "(epoch: 21, iters: 1200, time: 0.099, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.731 D_fake: 0.659 \n",
      "(epoch: 21, iters: 1300, time: 0.099, data: 0.002) G_GAN: 0.735 G_L1: 3.100 D_real: 0.540 D_fake: 0.638 \n",
      "(epoch: 21, iters: 1400, time: 0.098, data: 0.001) G_GAN: 0.774 G_L1: 0.000 D_real: 0.806 D_fake: 0.672 \n",
      "(epoch: 21, iters: 1500, time: 0.095, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.733 D_fake: 0.662 \n",
      "(epoch: 21, iters: 1600, time: 0.109, data: 0.001) G_GAN: 0.718 G_L1: 1.704 D_real: 0.567 D_fake: 0.672 \n",
      "(epoch: 21, iters: 1700, time: 0.097, data: 0.002) G_GAN: 0.799 G_L1: 0.000 D_real: 0.804 D_fake: 0.597 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 21, iters: 1800, time: 0.096, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.731 D_fake: 0.628 \n",
      "(epoch: 21, iters: 1900, time: 0.098, data: 0.001) G_GAN: 0.742 G_L1: 4.005 D_real: 0.534 D_fake: 0.645 \n",
      "(epoch: 21, iters: 2000, time: 0.098, data: 0.001) G_GAN: 0.756 G_L1: 0.000 D_real: 0.760 D_fake: 0.624 \n",
      "(epoch: 21, iters: 2100, time: 0.093, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.730 D_fake: 0.659 \n",
      "(epoch: 21, iters: 2200, time: 0.098, data: 0.001) G_GAN: 0.728 G_L1: 1.935 D_real: 0.572 D_fake: 0.632 \n",
      "End of epoch 21 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 22, iters: 20, time: 0.115, data: 0.001) G_GAN: 0.753 G_L1: 0.000 D_real: 0.781 D_fake: 0.715 \n",
      "(epoch: 22, iters: 120, time: 0.098, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.730 D_fake: 0.660 \n",
      "(epoch: 22, iters: 220, time: 0.099, data: 0.001) G_GAN: 0.767 G_L1: 3.205 D_real: 0.561 D_fake: 0.641 \n",
      "(epoch: 22, iters: 320, time: 0.109, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.748 D_fake: 0.644 \n",
      "(epoch: 22, iters: 420, time: 0.108, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.730 D_fake: 0.659 \n",
      "(epoch: 22, iters: 520, time: 0.095, data: 0.001) G_GAN: 0.753 G_L1: 1.603 D_real: 0.598 D_fake: 0.644 \n",
      "(epoch: 22, iters: 620, time: 0.111, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.744 D_fake: 0.642 \n",
      "(epoch: 22, iters: 720, time: 0.097, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.729 D_fake: 0.662 \n",
      "(epoch: 22, iters: 820, time: 0.106, data: 0.001) G_GAN: 0.750 G_L1: 2.187 D_real: 0.580 D_fake: 0.643 \n",
      "(epoch: 22, iters: 920, time: 0.094, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.751 D_fake: 0.641 \n",
      "(epoch: 22, iters: 1020, time: 0.096, data: 0.001) G_GAN: 0.714 G_L1: 0.000 D_real: 0.717 D_fake: 0.673 \n",
      "(epoch: 22, iters: 1120, time: 0.100, data: 0.001) G_GAN: 0.751 G_L1: 1.002 D_real: 0.623 D_fake: 0.642 \n",
      "(epoch: 22, iters: 1220, time: 0.099, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.742 D_fake: 0.656 \n",
      "(epoch: 22, iters: 1320, time: 0.099, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.739 D_fake: 0.652 \n",
      "(epoch: 22, iters: 1420, time: 0.098, data: 0.001) G_GAN: 0.736 G_L1: 2.201 D_real: 0.568 D_fake: 0.657 \n",
      "(epoch: 22, iters: 1520, time: 0.096, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.747 D_fake: 0.630 \n",
      "(epoch: 22, iters: 1620, time: 0.108, data: 0.001) G_GAN: 0.734 G_L1: 0.000 D_real: 0.737 D_fake: 0.655 \n",
      "(epoch: 22, iters: 1720, time: 0.099, data: 0.002) G_GAN: 0.773 G_L1: 3.384 D_real: 0.561 D_fake: 0.627 \n",
      "(epoch: 22, iters: 1820, time: 0.099, data: 0.001) G_GAN: 0.773 G_L1: 0.000 D_real: 0.779 D_fake: 0.618 \n",
      "(epoch: 22, iters: 1920, time: 0.098, data: 0.001) G_GAN: 0.672 G_L1: 0.000 D_real: 0.689 D_fake: 0.646 \n",
      "(epoch: 22, iters: 2020, time: 0.100, data: 0.002) G_GAN: 0.785 G_L1: 1.903 D_real: 0.610 D_fake: 0.613 \n",
      "(epoch: 22, iters: 2120, time: 0.097, data: 0.001) G_GAN: 0.752 G_L1: 0.000 D_real: 0.777 D_fake: 0.955 \n",
      "saving the latest model (epoch 22, total_steps 50000)\n",
      "(epoch: 22, iters: 2220, time: 0.101, data: 0.001) G_GAN: 0.654 G_L1: 0.000 D_real: 0.648 D_fake: 0.742 \n",
      "End of epoch 22 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 23, iters: 40, time: 0.111, data: 0.002) G_GAN: 0.745 G_L1: 1.545 D_real: 0.587 D_fake: 0.648 \n",
      "(epoch: 23, iters: 140, time: 0.098, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.762 D_fake: 0.631 \n",
      "(epoch: 23, iters: 240, time: 0.109, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.716 D_fake: 0.674 \n",
      "(epoch: 23, iters: 340, time: 0.097, data: 0.001) G_GAN: 0.732 G_L1: 0.576 D_real: 0.627 D_fake: 0.659 \n",
      "(epoch: 23, iters: 440, time: 0.106, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.731 D_fake: 0.659 \n",
      "(epoch: 23, iters: 540, time: 0.095, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.734 D_fake: 0.656 \n",
      "(epoch: 23, iters: 640, time: 0.096, data: 0.001) G_GAN: 0.771 G_L1: 3.338 D_real: 0.572 D_fake: 0.624 \n",
      "(epoch: 23, iters: 740, time: 0.095, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.755 D_fake: 0.639 \n",
      "(epoch: 23, iters: 840, time: 0.097, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.733 D_fake: 0.653 \n",
      "(epoch: 23, iters: 940, time: 0.099, data: 0.001) G_GAN: 0.763 G_L1: 1.224 D_real: 0.626 D_fake: 0.629 \n",
      "(epoch: 23, iters: 1040, time: 0.094, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.761 D_fake: 0.631 \n",
      "(epoch: 23, iters: 1140, time: 0.099, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.732 D_fake: 0.658 \n",
      "(epoch: 23, iters: 1240, time: 0.093, data: 0.002) G_GAN: 0.803 G_L1: 2.557 D_real: 0.612 D_fake: 0.622 \n",
      "(epoch: 23, iters: 1340, time: 0.100, data: 0.001) G_GAN: 0.752 G_L1: 0.000 D_real: 0.754 D_fake: 0.644 \n",
      "(epoch: 23, iters: 1440, time: 0.101, data: 0.001) G_GAN: 0.753 G_L1: 0.000 D_real: 0.755 D_fake: 0.653 \n",
      "(epoch: 23, iters: 1540, time: 0.099, data: 0.001) G_GAN: 0.765 G_L1: 1.958 D_real: 0.601 D_fake: 0.630 \n",
      "(epoch: 23, iters: 1640, time: 0.099, data: 0.001) G_GAN: 0.758 G_L1: 0.000 D_real: 0.761 D_fake: 0.633 \n",
      "(epoch: 23, iters: 1740, time: 0.098, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.643 \n",
      "(epoch: 23, iters: 1840, time: 0.097, data: 0.001) G_GAN: 0.758 G_L1: 0.311 D_real: 0.664 D_fake: 0.632 \n",
      "(epoch: 23, iters: 1940, time: 0.098, data: 0.001) G_GAN: 0.766 G_L1: 0.000 D_real: 0.770 D_fake: 0.625 \n",
      "(epoch: 23, iters: 2040, time: 0.099, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.744 D_fake: 0.654 \n",
      "(epoch: 23, iters: 2140, time: 0.108, data: 0.001) G_GAN: 0.793 G_L1: 0.787 D_real: 0.667 D_fake: 0.632 \n",
      "(epoch: 23, iters: 2240, time: 0.097, data: 0.001) G_GAN: 0.633 G_L1: 0.000 D_real: 0.639 D_fake: 0.546 \n",
      "End of epoch 23 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 24, iters: 60, time: 0.105, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.727 D_fake: 0.673 \n",
      "(epoch: 24, iters: 160, time: 0.098, data: 0.001) G_GAN: 0.747 G_L1: 3.185 D_real: 0.558 D_fake: 0.647 \n",
      "(epoch: 24, iters: 260, time: 0.110, data: 0.001) G_GAN: 0.794 G_L1: 0.000 D_real: 0.802 D_fake: 0.601 \n",
      "(epoch: 24, iters: 360, time: 0.103, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.736 D_fake: 0.653 \n",
      "(epoch: 24, iters: 460, time: 0.112, data: 0.002) G_GAN: 0.776 G_L1: 2.593 D_real: 0.607 D_fake: 0.620 \n",
      "(epoch: 24, iters: 560, time: 0.099, data: 0.001) G_GAN: 0.761 G_L1: 0.000 D_real: 0.764 D_fake: 0.629 \n",
      "(epoch: 24, iters: 660, time: 0.107, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.733 D_fake: 0.657 \n",
      "(epoch: 24, iters: 760, time: 0.096, data: 0.001) G_GAN: 0.767 G_L1: 2.399 D_real: 0.582 D_fake: 0.633 \n",
      "(epoch: 24, iters: 860, time: 0.095, data: 0.001) G_GAN: 0.771 G_L1: 0.000 D_real: 0.774 D_fake: 0.624 \n",
      "(epoch: 24, iters: 960, time: 0.096, data: 0.001) G_GAN: 0.643 G_L1: 0.000 D_real: 1.055 D_fake: 0.486 \n",
      "(epoch: 24, iters: 1060, time: 0.094, data: 0.001) G_GAN: 0.725 G_L1: 0.087 D_real: 0.668 D_fake: 0.667 \n",
      "(epoch: 24, iters: 1160, time: 0.093, data: 0.001) G_GAN: 0.752 G_L1: 0.000 D_real: 0.761 D_fake: 0.632 \n",
      "(epoch: 24, iters: 1260, time: 0.096, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.736 D_fake: 0.655 \n",
      "(epoch: 24, iters: 1360, time: 0.094, data: 0.001) G_GAN: 0.740 G_L1: 4.502 D_real: 0.512 D_fake: 0.660 \n",
      "(epoch: 24, iters: 1460, time: 0.096, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.743 D_fake: 0.648 \n",
      "(epoch: 24, iters: 1560, time: 0.098, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.736 D_fake: 0.644 \n",
      "(epoch: 24, iters: 1660, time: 0.095, data: 0.001) G_GAN: 0.736 G_L1: 1.973 D_real: 0.579 D_fake: 0.655 \n",
      "(epoch: 24, iters: 1760, time: 0.097, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.739 D_fake: 0.655 \n",
      "(epoch: 24, iters: 1860, time: 0.098, data: 0.001) G_GAN: 0.718 G_L1: 0.000 D_real: 0.722 D_fake: 0.658 \n",
      "(epoch: 24, iters: 1960, time: 0.114, data: 0.002) G_GAN: 0.733 G_L1: 0.417 D_real: 0.629 D_fake: 0.594 \n",
      "(epoch: 24, iters: 2060, time: 0.105, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.744 D_fake: 0.642 \n",
      "(epoch: 24, iters: 2160, time: 0.098, data: 0.001) G_GAN: 0.663 G_L1: 0.000 D_real: 0.678 D_fake: 0.659 \n",
      "(epoch: 24, iters: 2260, time: 0.095, data: 0.001) G_GAN: 0.819 G_L1: 3.017 D_real: 0.602 D_fake: 0.587 \n",
      "End of epoch 24 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 25, iters: 80, time: 0.103, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.723 D_fake: 0.656 \n",
      "(epoch: 25, iters: 180, time: 0.097, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.728 D_fake: 0.662 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 25, iters: 280, time: 0.107, data: 0.001) G_GAN: 0.746 G_L1: 1.052 D_real: 0.615 D_fake: 0.645 \n",
      "saving the latest model (epoch 25, total_steps 55000)\n",
      "(epoch: 25, iters: 380, time: 0.108, data: 0.001) G_GAN: 0.765 G_L1: 0.000 D_real: 0.766 D_fake: 0.628 \n",
      "(epoch: 25, iters: 480, time: 0.097, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.746 D_fake: 0.648 \n",
      "(epoch: 25, iters: 580, time: 0.099, data: 0.001) G_GAN: 0.755 G_L1: 4.208 D_real: 0.533 D_fake: 0.628 \n",
      "(epoch: 25, iters: 680, time: 0.098, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.751 D_fake: 0.640 \n",
      "(epoch: 25, iters: 780, time: 0.096, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.747 D_fake: 0.632 \n",
      "(epoch: 25, iters: 880, time: 0.094, data: 0.001) G_GAN: 0.776 G_L1: 3.483 D_real: 0.554 D_fake: 0.608 \n",
      "(epoch: 25, iters: 980, time: 0.108, data: 0.001) G_GAN: 0.761 G_L1: 0.000 D_real: 0.772 D_fake: 0.660 \n",
      "(epoch: 25, iters: 1080, time: 0.096, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.708 D_fake: 0.598 \n",
      "(epoch: 25, iters: 1180, time: 0.098, data: 0.002) G_GAN: 0.786 G_L1: 0.978 D_real: 0.652 D_fake: 0.608 \n",
      "(epoch: 25, iters: 1280, time: 0.097, data: 0.001) G_GAN: 0.770 G_L1: 0.000 D_real: 0.773 D_fake: 0.624 \n",
      "(epoch: 25, iters: 1380, time: 0.096, data: 0.001) G_GAN: 0.734 G_L1: 0.000 D_real: 0.735 D_fake: 0.655 \n",
      "(epoch: 25, iters: 1480, time: 0.109, data: 0.001) G_GAN: 0.755 G_L1: 1.681 D_real: 0.599 D_fake: 0.658 \n",
      "(epoch: 25, iters: 1580, time: 0.095, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.754 D_fake: 0.650 \n",
      "(epoch: 25, iters: 1680, time: 0.097, data: 0.001) G_GAN: 0.755 G_L1: 0.000 D_real: 0.757 D_fake: 0.636 \n",
      "(epoch: 25, iters: 1780, time: 0.106, data: 0.001) G_GAN: 0.755 G_L1: 3.487 D_real: 0.542 D_fake: 0.639 \n",
      "(epoch: 25, iters: 1880, time: 0.110, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.745 D_fake: 0.646 \n",
      "(epoch: 25, iters: 1980, time: 0.106, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.735 D_fake: 0.656 \n",
      "(epoch: 25, iters: 2080, time: 0.095, data: 0.001) G_GAN: 0.732 G_L1: 2.663 D_real: 0.549 D_fake: 0.663 \n",
      "(epoch: 25, iters: 2180, time: 0.108, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.745 D_fake: 0.647 \n",
      "(epoch: 25, iters: 2280, time: 0.096, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.735 D_fake: 0.657 \n",
      "saving the model at the end of epoch 25, iters 57000\n",
      "End of epoch 25 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 26, iters: 100, time: 0.106, data: 0.284) G_GAN: 0.755 G_L1: 2.739 D_real: 0.570 D_fake: 0.644 \n",
      "(epoch: 26, iters: 200, time: 0.096, data: 0.001) G_GAN: 0.736 G_L1: 0.000 D_real: 0.738 D_fake: 0.654 \n",
      "(epoch: 26, iters: 300, time: 0.107, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.733 D_fake: 0.657 \n",
      "(epoch: 26, iters: 400, time: 0.096, data: 0.001) G_GAN: 0.727 G_L1: 1.900 D_real: 0.580 D_fake: 0.666 \n",
      "(epoch: 26, iters: 500, time: 0.098, data: 0.001) G_GAN: 0.684 G_L1: 0.000 D_real: 0.734 D_fake: 0.531 \n",
      "(epoch: 26, iters: 600, time: 0.098, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.751 D_fake: 0.640 \n",
      "(epoch: 26, iters: 700, time: 0.097, data: 0.001) G_GAN: 0.881 G_L1: 2.269 D_real: 0.702 D_fake: 0.588 \n",
      "(epoch: 26, iters: 800, time: 0.101, data: 0.001) G_GAN: 0.756 G_L1: 0.000 D_real: 0.758 D_fake: 0.639 \n",
      "(epoch: 26, iters: 900, time: 0.093, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.692 D_fake: 0.703 \n",
      "(epoch: 26, iters: 1000, time: 0.098, data: 0.001) G_GAN: 0.774 G_L1: 2.064 D_real: 0.595 D_fake: 0.634 \n",
      "(epoch: 26, iters: 1100, time: 0.099, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.755 D_fake: 0.637 \n",
      "(epoch: 26, iters: 1200, time: 0.098, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.728 D_fake: 0.637 \n",
      "(epoch: 26, iters: 1300, time: 0.110, data: 0.001) G_GAN: 0.751 G_L1: 3.100 D_real: 0.568 D_fake: 0.641 \n",
      "(epoch: 26, iters: 1400, time: 0.096, data: 0.001) G_GAN: 0.783 G_L1: 0.000 D_real: 0.787 D_fake: 0.611 \n",
      "(epoch: 26, iters: 1500, time: 0.096, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.738 D_fake: 0.653 \n",
      "(epoch: 26, iters: 1600, time: 0.108, data: 0.001) G_GAN: 0.749 G_L1: 1.704 D_real: 0.594 D_fake: 0.643 \n",
      "(epoch: 26, iters: 1700, time: 0.099, data: 0.002) G_GAN: 0.779 G_L1: 0.000 D_real: 0.781 D_fake: 0.615 \n",
      "(epoch: 26, iters: 1800, time: 0.096, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.733 D_fake: 0.657 \n",
      "(epoch: 26, iters: 1900, time: 0.098, data: 0.002) G_GAN: 0.725 G_L1: 4.005 D_real: 0.525 D_fake: 0.641 \n",
      "(epoch: 26, iters: 2000, time: 0.098, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.755 D_fake: 0.638 \n",
      "(epoch: 26, iters: 2100, time: 0.095, data: 0.002) G_GAN: 0.663 G_L1: 0.000 D_real: 0.685 D_fake: 0.619 \n",
      "(epoch: 26, iters: 2200, time: 0.098, data: 0.001) G_GAN: 0.743 G_L1: 1.935 D_real: 0.587 D_fake: 0.648 \n",
      "End of epoch 26 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 27, iters: 20, time: 0.117, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.743 D_fake: 0.648 \n",
      "(epoch: 27, iters: 120, time: 0.098, data: 0.001) G_GAN: 0.724 G_L1: 0.000 D_real: 0.726 D_fake: 0.663 \n",
      "(epoch: 27, iters: 220, time: 0.097, data: 0.001) G_GAN: 0.756 G_L1: 3.205 D_real: 0.560 D_fake: 0.637 \n",
      "(epoch: 27, iters: 320, time: 0.097, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.750 D_fake: 0.643 \n",
      "(epoch: 27, iters: 420, time: 0.106, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.712 D_fake: 0.676 \n",
      "(epoch: 27, iters: 520, time: 0.094, data: 0.002) G_GAN: 0.741 G_L1: 1.603 D_real: 0.591 D_fake: 0.651 \n",
      "(epoch: 27, iters: 620, time: 0.096, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.741 D_fake: 0.649 \n",
      "(epoch: 27, iters: 720, time: 0.097, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.742 D_fake: 0.648 \n",
      "saving the latest model (epoch 27, total_steps 60000)\n",
      "(epoch: 27, iters: 820, time: 0.095, data: 0.002) G_GAN: 0.744 G_L1: 2.187 D_real: 0.567 D_fake: 0.649 \n",
      "(epoch: 27, iters: 920, time: 0.095, data: 0.002) G_GAN: 0.768 G_L1: 0.000 D_real: 0.772 D_fake: 0.626 \n",
      "(epoch: 27, iters: 1020, time: 0.107, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.733 D_fake: 0.650 \n",
      "(epoch: 27, iters: 1120, time: 0.108, data: 0.002) G_GAN: 0.752 G_L1: 1.002 D_real: 0.619 D_fake: 0.641 \n",
      "(epoch: 27, iters: 1220, time: 0.096, data: 0.001) G_GAN: 0.783 G_L1: 0.000 D_real: 0.843 D_fake: 0.572 \n",
      "(epoch: 27, iters: 1320, time: 0.097, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.730 D_fake: 0.633 \n",
      "(epoch: 27, iters: 1420, time: 0.109, data: 0.001) G_GAN: 0.733 G_L1: 2.201 D_real: 0.568 D_fake: 0.658 \n",
      "(epoch: 27, iters: 1520, time: 0.100, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.752 D_fake: 0.640 \n",
      "(epoch: 27, iters: 1620, time: 0.111, data: 0.001) G_GAN: 0.717 G_L1: 0.000 D_real: 0.719 D_fake: 0.670 \n",
      "(epoch: 27, iters: 1720, time: 0.099, data: 0.001) G_GAN: 0.762 G_L1: 3.384 D_real: 0.558 D_fake: 0.637 \n",
      "(epoch: 27, iters: 1820, time: 0.096, data: 0.001) G_GAN: 0.778 G_L1: 0.000 D_real: 0.782 D_fake: 0.621 \n",
      "(epoch: 27, iters: 1920, time: 0.099, data: 0.002) G_GAN: 0.590 G_L1: 0.000 D_real: 0.570 D_fake: 0.695 \n",
      "(epoch: 27, iters: 2020, time: 0.099, data: 0.002) G_GAN: 0.772 G_L1: 1.903 D_real: 0.608 D_fake: 0.643 \n",
      "(epoch: 27, iters: 2120, time: 0.097, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.807 D_fake: 0.705 \n",
      "(epoch: 27, iters: 2220, time: 0.100, data: 0.001) G_GAN: 0.638 G_L1: 0.000 D_real: 0.617 D_fake: 0.762 \n",
      "End of epoch 27 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 28, iters: 40, time: 0.105, data: 0.001) G_GAN: 0.662 G_L1: 1.545 D_real: 0.533 D_fake: 0.746 \n",
      "(epoch: 28, iters: 140, time: 0.095, data: 0.001) G_GAN: 0.736 G_L1: 0.000 D_real: 0.738 D_fake: 0.648 \n",
      "(epoch: 28, iters: 240, time: 0.095, data: 0.001) G_GAN: 0.743 G_L1: 0.000 D_real: 0.744 D_fake: 0.581 \n",
      "(epoch: 28, iters: 340, time: 0.106, data: 0.001) G_GAN: 0.743 G_L1: 0.576 D_real: 0.637 D_fake: 0.645 \n",
      "(epoch: 28, iters: 440, time: 0.099, data: 0.001) G_GAN: 0.736 G_L1: 0.000 D_real: 0.737 D_fake: 0.616 \n",
      "(epoch: 28, iters: 540, time: 0.095, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.738 D_fake: 0.652 \n",
      "(epoch: 28, iters: 640, time: 0.107, data: 0.001) G_GAN: 0.751 G_L1: 3.338 D_real: 0.549 D_fake: 0.641 \n",
      "(epoch: 28, iters: 740, time: 0.095, data: 0.001) G_GAN: 0.760 G_L1: 0.000 D_real: 0.763 D_fake: 0.605 \n",
      "(epoch: 28, iters: 840, time: 0.097, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.715 D_fake: 0.677 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 28, iters: 940, time: 0.097, data: 0.001) G_GAN: 0.806 G_L1: 1.224 D_real: 0.658 D_fake: 0.596 \n",
      "(epoch: 28, iters: 1040, time: 0.097, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.750 D_fake: 0.641 \n",
      "(epoch: 28, iters: 1140, time: 0.096, data: 0.001) G_GAN: 0.734 G_L1: 0.000 D_real: 0.734 D_fake: 0.657 \n",
      "(epoch: 28, iters: 1240, time: 0.096, data: 0.002) G_GAN: 0.832 G_L1: 2.557 D_real: 0.644 D_fake: 0.571 \n",
      "(epoch: 28, iters: 1340, time: 0.099, data: 0.001) G_GAN: 0.744 G_L1: 0.000 D_real: 0.747 D_fake: 0.657 \n",
      "(epoch: 28, iters: 1440, time: 0.104, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.746 D_fake: 0.665 \n",
      "(epoch: 28, iters: 1540, time: 0.104, data: 0.001) G_GAN: 0.765 G_L1: 1.958 D_real: 0.602 D_fake: 0.629 \n",
      "(epoch: 28, iters: 1640, time: 0.096, data: 0.001) G_GAN: 0.756 G_L1: 0.000 D_real: 0.759 D_fake: 0.642 \n",
      "(epoch: 28, iters: 1740, time: 0.098, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.750 D_fake: 0.646 \n",
      "(epoch: 28, iters: 1840, time: 0.099, data: 0.001) G_GAN: 0.760 G_L1: 0.311 D_real: 0.659 D_fake: 0.635 \n",
      "(epoch: 28, iters: 1940, time: 0.097, data: 0.001) G_GAN: 0.764 G_L1: 0.000 D_real: 0.770 D_fake: 0.625 \n",
      "(epoch: 28, iters: 2040, time: 0.097, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.748 D_fake: 0.651 \n",
      "(epoch: 28, iters: 2140, time: 0.097, data: 0.001) G_GAN: 0.774 G_L1: 0.787 D_real: 0.656 D_fake: 0.683 \n",
      "(epoch: 28, iters: 2240, time: 0.097, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.718 D_fake: 0.671 \n",
      "End of epoch 28 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 29, iters: 60, time: 0.107, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.732 D_fake: 0.661 \n",
      "(epoch: 29, iters: 160, time: 0.109, data: 0.001) G_GAN: 0.732 G_L1: 3.185 D_real: 0.533 D_fake: 0.660 \n",
      "(epoch: 29, iters: 260, time: 0.099, data: 0.001) G_GAN: 0.787 G_L1: 0.000 D_real: 0.800 D_fake: 0.595 \n",
      "(epoch: 29, iters: 360, time: 0.099, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.724 D_fake: 0.649 \n",
      "(epoch: 29, iters: 460, time: 0.100, data: 0.001) G_GAN: 0.773 G_L1: 2.593 D_real: 0.601 D_fake: 0.656 \n",
      "(epoch: 29, iters: 560, time: 0.100, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.758 D_fake: 0.654 \n",
      "(epoch: 29, iters: 660, time: 0.097, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.738 D_fake: 0.648 \n",
      "(epoch: 29, iters: 760, time: 0.097, data: 0.001) G_GAN: 0.747 G_L1: 2.399 D_real: 0.580 D_fake: 0.627 \n",
      "(epoch: 29, iters: 860, time: 0.094, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.760 D_fake: 0.635 \n",
      "(epoch: 29, iters: 960, time: 0.096, data: 0.001) G_GAN: 0.761 G_L1: 0.000 D_real: 0.769 D_fake: 0.637 \n",
      "(epoch: 29, iters: 1060, time: 0.095, data: 0.001) G_GAN: 0.722 G_L1: 0.087 D_real: 0.662 D_fake: 0.670 \n",
      "(epoch: 29, iters: 1160, time: 0.106, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.757 D_fake: 0.627 \n",
      "saving the latest model (epoch 29, total_steps 65000)\n",
      "(epoch: 29, iters: 1260, time: 0.097, data: 0.001) G_GAN: 0.703 G_L1: 0.000 D_real: 0.699 D_fake: 0.610 \n",
      "(epoch: 29, iters: 1360, time: 0.096, data: 0.002) G_GAN: 0.743 G_L1: 4.502 D_real: 0.520 D_fake: 0.651 \n",
      "(epoch: 29, iters: 1460, time: 0.095, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.737 D_fake: 0.654 \n",
      "(epoch: 29, iters: 1560, time: 0.098, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.736 D_fake: 0.654 \n",
      "(epoch: 29, iters: 1660, time: 0.107, data: 0.002) G_GAN: 0.780 G_L1: 1.973 D_real: 0.609 D_fake: 0.655 \n",
      "(epoch: 29, iters: 1760, time: 0.099, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.757 D_fake: 0.639 \n",
      "(epoch: 29, iters: 1860, time: 0.110, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.747 D_fake: 0.651 \n",
      "(epoch: 29, iters: 1960, time: 0.102, data: 0.002) G_GAN: 0.754 G_L1: 0.417 D_real: 0.654 D_fake: 0.644 \n",
      "(epoch: 29, iters: 2060, time: 0.101, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.741 D_fake: 0.651 \n",
      "(epoch: 29, iters: 2160, time: 0.097, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.702 D_fake: 0.690 \n",
      "(epoch: 29, iters: 2260, time: 0.096, data: 0.001) G_GAN: 0.756 G_L1: 3.017 D_real: 0.532 D_fake: 0.662 \n",
      "End of epoch 29 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 30, iters: 80, time: 0.103, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.754 D_fake: 0.602 \n",
      "(epoch: 30, iters: 180, time: 0.098, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.745 D_fake: 0.643 \n",
      "(epoch: 30, iters: 280, time: 0.097, data: 0.001) G_GAN: 0.750 G_L1: 1.052 D_real: 0.621 D_fake: 0.645 \n",
      "(epoch: 30, iters: 380, time: 0.099, data: 0.002) G_GAN: 0.769 G_L1: 0.000 D_real: 0.777 D_fake: 0.631 \n",
      "(epoch: 30, iters: 480, time: 0.096, data: 0.001) G_GAN: 0.715 G_L1: 0.000 D_real: 0.717 D_fake: 0.676 \n",
      "(epoch: 30, iters: 580, time: 0.097, data: 0.002) G_GAN: 0.762 G_L1: 4.208 D_real: 0.541 D_fake: 0.633 \n",
      "(epoch: 30, iters: 680, time: 0.098, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.757 D_fake: 0.634 \n",
      "(epoch: 30, iters: 780, time: 0.095, data: 0.003) G_GAN: 0.716 G_L1: 0.000 D_real: 0.717 D_fake: 0.674 \n",
      "(epoch: 30, iters: 880, time: 0.094, data: 0.002) G_GAN: 0.858 G_L1: 3.483 D_real: 0.609 D_fake: 0.526 \n",
      "(epoch: 30, iters: 980, time: 0.095, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.719 D_fake: 0.673 \n",
      "(epoch: 30, iters: 1080, time: 0.095, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.676 D_fake: 0.683 \n",
      "(epoch: 30, iters: 1180, time: 0.098, data: 0.001) G_GAN: 0.777 G_L1: 0.978 D_real: 0.646 D_fake: 0.618 \n",
      "(epoch: 30, iters: 1280, time: 0.097, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.749 D_fake: 0.642 \n",
      "(epoch: 30, iters: 1380, time: 0.096, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.714 D_fake: 0.675 \n",
      "(epoch: 30, iters: 1480, time: 0.106, data: 0.001) G_GAN: 0.740 G_L1: 1.681 D_real: 0.585 D_fake: 0.651 \n",
      "(epoch: 30, iters: 1580, time: 0.096, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.742 D_fake: 0.648 \n",
      "(epoch: 30, iters: 1680, time: 0.099, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.746 D_fake: 0.645 \n",
      "(epoch: 30, iters: 1780, time: 0.108, data: 0.001) G_GAN: 0.752 G_L1: 3.487 D_real: 0.556 D_fake: 0.636 \n",
      "(epoch: 30, iters: 1880, time: 0.098, data: 0.001) G_GAN: 0.753 G_L1: 0.000 D_real: 0.755 D_fake: 0.638 \n",
      "(epoch: 30, iters: 1980, time: 0.099, data: 0.001) G_GAN: 0.736 G_L1: 0.000 D_real: 0.737 D_fake: 0.653 \n",
      "(epoch: 30, iters: 2080, time: 0.097, data: 0.001) G_GAN: 0.727 G_L1: 2.663 D_real: 0.544 D_fake: 0.665 \n",
      "(epoch: 30, iters: 2180, time: 0.099, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.745 D_fake: 0.642 \n",
      "(epoch: 30, iters: 2280, time: 0.095, data: 0.001) G_GAN: 0.676 G_L1: 0.000 D_real: 0.680 D_fake: 0.606 \n",
      "saving the model at the end of epoch 30, iters 68400\n",
      "End of epoch 30 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 31, iters: 100, time: 0.108, data: 0.276) G_GAN: 0.744 G_L1: 2.739 D_real: 0.562 D_fake: 0.651 \n",
      "(epoch: 31, iters: 200, time: 0.095, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.731 D_fake: 0.651 \n",
      "(epoch: 31, iters: 300, time: 0.096, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.726 D_fake: 0.664 \n",
      "(epoch: 31, iters: 400, time: 0.099, data: 0.001) G_GAN: 0.729 G_L1: 1.900 D_real: 0.575 D_fake: 0.662 \n",
      "(epoch: 31, iters: 500, time: 0.108, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.742 D_fake: 0.649 \n",
      "(epoch: 31, iters: 600, time: 0.104, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.737 D_fake: 0.653 \n",
      "(epoch: 31, iters: 700, time: 0.107, data: 0.001) G_GAN: 0.749 G_L1: 2.269 D_real: 0.578 D_fake: 0.644 \n",
      "(epoch: 31, iters: 800, time: 0.104, data: 0.001) G_GAN: 0.751 G_L1: 0.000 D_real: 0.753 D_fake: 0.641 \n",
      "(epoch: 31, iters: 900, time: 0.092, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.745 D_fake: 0.651 \n",
      "(epoch: 31, iters: 1000, time: 0.098, data: 0.001) G_GAN: 0.744 G_L1: 2.064 D_real: 0.568 D_fake: 0.650 \n",
      "(epoch: 31, iters: 1100, time: 0.107, data: 0.001) G_GAN: 0.758 G_L1: 0.000 D_real: 0.763 D_fake: 0.647 \n",
      "(epoch: 31, iters: 1200, time: 0.098, data: 0.001) G_GAN: 0.734 G_L1: 0.000 D_real: 0.736 D_fake: 0.599 \n",
      "(epoch: 31, iters: 1300, time: 0.097, data: 0.001) G_GAN: 0.744 G_L1: 3.100 D_real: 0.547 D_fake: 0.651 \n",
      "(epoch: 31, iters: 1400, time: 0.099, data: 0.001) G_GAN: 0.766 G_L1: 0.000 D_real: 0.773 D_fake: 0.632 \n",
      "(epoch: 31, iters: 1500, time: 0.098, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.725 D_fake: 0.666 \n",
      "(epoch: 31, iters: 1600, time: 0.098, data: 0.001) G_GAN: 0.738 G_L1: 1.704 D_real: 0.582 D_fake: 0.634 \n",
      "saving the latest model (epoch 31, total_steps 70000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 31, iters: 1700, time: 0.100, data: 0.001) G_GAN: 0.778 G_L1: 0.000 D_real: 0.783 D_fake: 0.614 \n",
      "(epoch: 31, iters: 1800, time: 0.096, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.741 D_fake: 0.651 \n",
      "(epoch: 31, iters: 1900, time: 0.109, data: 0.001) G_GAN: 0.721 G_L1: 4.005 D_real: 0.515 D_fake: 0.674 \n",
      "(epoch: 31, iters: 2000, time: 0.099, data: 0.001) G_GAN: 0.757 G_L1: 0.000 D_real: 0.758 D_fake: 0.635 \n",
      "(epoch: 31, iters: 2100, time: 0.097, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.741 D_fake: 0.650 \n",
      "(epoch: 31, iters: 2200, time: 0.100, data: 0.002) G_GAN: 0.706 G_L1: 1.935 D_real: 0.547 D_fake: 0.692 \n",
      "End of epoch 31 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 32, iters: 20, time: 0.114, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.744 D_fake: 0.649 \n",
      "(epoch: 32, iters: 120, time: 0.097, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.744 D_fake: 0.659 \n",
      "(epoch: 32, iters: 220, time: 0.109, data: 0.001) G_GAN: 0.745 G_L1: 3.205 D_real: 0.548 D_fake: 0.652 \n",
      "(epoch: 32, iters: 320, time: 0.097, data: 0.001) G_GAN: 0.751 G_L1: 0.000 D_real: 0.752 D_fake: 0.639 \n",
      "(epoch: 32, iters: 420, time: 0.096, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.738 D_fake: 0.653 \n",
      "(epoch: 32, iters: 520, time: 0.107, data: 0.001) G_GAN: 0.778 G_L1: 1.603 D_real: 0.630 D_fake: 0.653 \n",
      "(epoch: 32, iters: 620, time: 0.109, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.643 \n",
      "(epoch: 32, iters: 720, time: 0.098, data: 0.001) G_GAN: 0.744 G_L1: 0.000 D_real: 0.747 D_fake: 0.645 \n",
      "(epoch: 32, iters: 820, time: 0.095, data: 0.001) G_GAN: 0.792 G_L1: 2.187 D_real: 0.614 D_fake: 0.607 \n",
      "(epoch: 32, iters: 920, time: 0.095, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.733 D_fake: 0.659 \n",
      "(epoch: 32, iters: 1020, time: 0.097, data: 0.001) G_GAN: 0.674 G_L1: 0.000 D_real: 0.697 D_fake: 0.629 \n",
      "(epoch: 32, iters: 1120, time: 0.099, data: 0.001) G_GAN: 0.760 G_L1: 1.002 D_real: 0.632 D_fake: 0.635 \n",
      "(epoch: 32, iters: 1220, time: 0.098, data: 0.001) G_GAN: 0.788 G_L1: 0.000 D_real: 0.790 D_fake: 0.608 \n",
      "(epoch: 32, iters: 1320, time: 0.099, data: 0.001) G_GAN: 0.743 G_L1: 0.000 D_real: 0.745 D_fake: 0.646 \n",
      "(epoch: 32, iters: 1420, time: 0.097, data: 0.001) G_GAN: 0.755 G_L1: 2.201 D_real: 0.595 D_fake: 0.617 \n",
      "(epoch: 32, iters: 1520, time: 0.098, data: 0.001) G_GAN: 0.758 G_L1: 0.000 D_real: 0.759 D_fake: 0.636 \n",
      "(epoch: 32, iters: 1620, time: 0.096, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.729 D_fake: 0.660 \n",
      "(epoch: 32, iters: 1720, time: 0.101, data: 0.002) G_GAN: 0.756 G_L1: 3.384 D_real: 0.559 D_fake: 0.639 \n",
      "(epoch: 32, iters: 1820, time: 0.100, data: 0.001) G_GAN: 0.763 G_L1: 0.000 D_real: 0.769 D_fake: 0.631 \n",
      "(epoch: 32, iters: 1920, time: 0.095, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.717 D_fake: 0.667 \n",
      "(epoch: 32, iters: 2020, time: 0.099, data: 0.001) G_GAN: 0.798 G_L1: 1.903 D_real: 0.628 D_fake: 0.603 \n",
      "(epoch: 32, iters: 2120, time: 0.098, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.777 D_fake: 0.560 \n",
      "(epoch: 32, iters: 2220, time: 0.102, data: 0.001) G_GAN: 0.627 G_L1: 0.000 D_real: 0.620 D_fake: 0.670 \n",
      "End of epoch 32 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 33, iters: 40, time: 0.103, data: 0.001) G_GAN: 0.754 G_L1: 1.545 D_real: 0.609 D_fake: 0.643 \n",
      "(epoch: 33, iters: 140, time: 0.096, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.733 D_fake: 0.641 \n",
      "(epoch: 33, iters: 240, time: 0.097, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.742 D_fake: 0.650 \n",
      "(epoch: 33, iters: 340, time: 0.106, data: 0.001) G_GAN: 0.749 G_L1: 0.576 D_real: 0.633 D_fake: 0.643 \n",
      "(epoch: 33, iters: 440, time: 0.098, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.733 D_fake: 0.658 \n",
      "(epoch: 33, iters: 540, time: 0.094, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.732 D_fake: 0.660 \n",
      "(epoch: 33, iters: 640, time: 0.096, data: 0.002) G_GAN: 0.742 G_L1: 3.338 D_real: 0.548 D_fake: 0.650 \n",
      "(epoch: 33, iters: 740, time: 0.094, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.748 D_fake: 0.643 \n",
      "(epoch: 33, iters: 840, time: 0.105, data: 0.001) G_GAN: 0.709 G_L1: 0.000 D_real: 0.716 D_fake: 0.627 \n",
      "(epoch: 33, iters: 940, time: 0.100, data: 0.001) G_GAN: 0.792 G_L1: 1.224 D_real: 0.648 D_fake: 0.609 \n",
      "(epoch: 33, iters: 1040, time: 0.094, data: 0.001) G_GAN: 0.718 G_L1: 0.000 D_real: 0.729 D_fake: 0.661 \n",
      "(epoch: 33, iters: 1140, time: 0.107, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.734 D_fake: 0.623 \n",
      "(epoch: 33, iters: 1240, time: 0.096, data: 0.001) G_GAN: 0.877 G_L1: 2.557 D_real: 0.658 D_fake: 0.539 \n",
      "(epoch: 33, iters: 1340, time: 0.098, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.750 D_fake: 0.642 \n",
      "(epoch: 33, iters: 1440, time: 0.112, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.735 D_fake: 0.656 \n",
      "(epoch: 33, iters: 1540, time: 0.099, data: 0.001) G_GAN: 0.784 G_L1: 1.958 D_real: 0.595 D_fake: 0.615 \n",
      "(epoch: 33, iters: 1640, time: 0.098, data: 0.001) G_GAN: 0.756 G_L1: 0.000 D_real: 0.761 D_fake: 0.640 \n",
      "(epoch: 33, iters: 1740, time: 0.098, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.729 D_fake: 0.673 \n",
      "(epoch: 33, iters: 1840, time: 0.098, data: 0.001) G_GAN: 0.745 G_L1: 0.311 D_real: 0.657 D_fake: 0.659 \n",
      "(epoch: 33, iters: 1940, time: 0.099, data: 0.001) G_GAN: 0.753 G_L1: 0.000 D_real: 0.755 D_fake: 0.636 \n",
      "(epoch: 33, iters: 2040, time: 0.098, data: 0.001) G_GAN: 0.752 G_L1: 0.000 D_real: 0.753 D_fake: 0.639 \n",
      "saving the latest model (epoch 33, total_steps 75000)\n",
      "(epoch: 33, iters: 2140, time: 0.099, data: 0.001) G_GAN: 0.775 G_L1: 0.787 D_real: 0.655 D_fake: 0.702 \n",
      "(epoch: 33, iters: 2240, time: 0.098, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.726 D_fake: 0.664 \n",
      "End of epoch 33 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 34, iters: 60, time: 0.118, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.692 D_fake: 0.699 \n",
      "(epoch: 34, iters: 160, time: 0.096, data: 0.002) G_GAN: 0.742 G_L1: 3.185 D_real: 0.548 D_fake: 0.651 \n",
      "(epoch: 34, iters: 260, time: 0.098, data: 0.002) G_GAN: 0.800 G_L1: 0.000 D_real: 0.806 D_fake: 0.596 \n",
      "(epoch: 34, iters: 360, time: 0.096, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.737 D_fake: 0.653 \n",
      "(epoch: 34, iters: 460, time: 0.098, data: 0.001) G_GAN: 0.766 G_L1: 2.593 D_real: 0.588 D_fake: 0.650 \n",
      "(epoch: 34, iters: 560, time: 0.098, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.760 D_fake: 0.615 \n",
      "(epoch: 34, iters: 660, time: 0.098, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.753 D_fake: 0.639 \n",
      "(epoch: 34, iters: 760, time: 0.099, data: 0.002) G_GAN: 0.741 G_L1: 2.399 D_real: 0.562 D_fake: 0.652 \n",
      "(epoch: 34, iters: 860, time: 0.094, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.752 D_fake: 0.602 \n",
      "(epoch: 34, iters: 960, time: 0.098, data: 0.002) G_GAN: 0.768 G_L1: 0.000 D_real: 0.946 D_fake: 0.507 \n",
      "(epoch: 34, iters: 1060, time: 0.095, data: 0.001) G_GAN: 0.737 G_L1: 0.087 D_real: 0.676 D_fake: 0.657 \n",
      "(epoch: 34, iters: 1160, time: 0.095, data: 0.001) G_GAN: 0.759 G_L1: 0.000 D_real: 0.760 D_fake: 0.642 \n",
      "(epoch: 34, iters: 1260, time: 0.097, data: 0.001) G_GAN: 0.715 G_L1: 0.000 D_real: 0.717 D_fake: 0.672 \n",
      "(epoch: 34, iters: 1360, time: 0.104, data: 0.001) G_GAN: 0.741 G_L1: 4.502 D_real: 0.510 D_fake: 0.653 \n",
      "(epoch: 34, iters: 1460, time: 0.107, data: 0.001) G_GAN: 0.749 G_L1: 0.000 D_real: 0.752 D_fake: 0.617 \n",
      "(epoch: 34, iters: 1560, time: 0.106, data: 0.001) G_GAN: 0.719 G_L1: 0.000 D_real: 0.720 D_fake: 0.669 \n",
      "(epoch: 34, iters: 1660, time: 0.096, data: 0.001) G_GAN: 0.746 G_L1: 1.973 D_real: 0.586 D_fake: 0.647 \n",
      "(epoch: 34, iters: 1760, time: 0.110, data: 0.001) G_GAN: 0.782 G_L1: 0.000 D_real: 0.793 D_fake: 0.644 \n",
      "(epoch: 34, iters: 1860, time: 0.109, data: 0.001) G_GAN: 0.734 G_L1: 0.000 D_real: 0.735 D_fake: 0.651 \n",
      "(epoch: 34, iters: 1960, time: 0.119, data: 0.001) G_GAN: 0.752 G_L1: 0.417 D_real: 0.644 D_fake: 0.639 \n",
      "(epoch: 34, iters: 2060, time: 0.093, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.741 D_fake: 0.650 \n",
      "(epoch: 34, iters: 2160, time: 0.095, data: 0.001) G_GAN: 0.717 G_L1: 0.000 D_real: 0.719 D_fake: 0.665 \n",
      "(epoch: 34, iters: 2260, time: 0.094, data: 0.001) G_GAN: 0.767 G_L1: 3.017 D_real: 0.579 D_fake: 0.626 \n",
      "End of epoch 34 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 35, iters: 80, time: 0.104, data: 0.001) G_GAN: 0.752 G_L1: 0.000 D_real: 0.754 D_fake: 0.635 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 35, iters: 180, time: 0.097, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.727 D_fake: 0.663 \n",
      "(epoch: 35, iters: 280, time: 0.109, data: 0.001) G_GAN: 0.756 G_L1: 1.052 D_real: 0.609 D_fake: 0.631 \n",
      "(epoch: 35, iters: 380, time: 0.097, data: 0.001) G_GAN: 0.771 G_L1: 0.000 D_real: 0.775 D_fake: 0.645 \n",
      "(epoch: 35, iters: 480, time: 0.096, data: 0.001) G_GAN: 0.736 G_L1: 0.000 D_real: 0.739 D_fake: 0.656 \n",
      "(epoch: 35, iters: 580, time: 0.099, data: 0.001) G_GAN: 0.754 G_L1: 4.208 D_real: 0.534 D_fake: 0.640 \n",
      "(epoch: 35, iters: 680, time: 0.100, data: 0.002) G_GAN: 0.678 G_L1: 0.000 D_real: 0.678 D_fake: 0.712 \n",
      "(epoch: 35, iters: 780, time: 0.095, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.735 D_fake: 0.660 \n",
      "(epoch: 35, iters: 880, time: 0.094, data: 0.002) G_GAN: 0.788 G_L1: 3.483 D_real: 0.563 D_fake: 0.617 \n",
      "(epoch: 35, iters: 980, time: 0.107, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.758 D_fake: 0.636 \n",
      "(epoch: 35, iters: 1080, time: 0.106, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.728 D_fake: 0.662 \n",
      "(epoch: 35, iters: 1180, time: 0.098, data: 0.001) G_GAN: 0.760 G_L1: 0.978 D_real: 0.632 D_fake: 0.658 \n",
      "(epoch: 35, iters: 1280, time: 0.098, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.769 D_fake: 0.626 \n",
      "(epoch: 35, iters: 1380, time: 0.096, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.734 D_fake: 0.658 \n",
      "(epoch: 35, iters: 1480, time: 0.098, data: 0.001) G_GAN: 0.763 G_L1: 1.681 D_real: 0.601 D_fake: 0.646 \n",
      "(epoch: 35, iters: 1580, time: 0.097, data: 0.001) G_GAN: 0.752 G_L1: 0.000 D_real: 0.754 D_fake: 0.638 \n",
      "(epoch: 35, iters: 1680, time: 0.098, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.757 D_fake: 0.636 \n",
      "(epoch: 35, iters: 1780, time: 0.096, data: 0.001) G_GAN: 0.758 G_L1: 3.487 D_real: 0.559 D_fake: 0.635 \n",
      "(epoch: 35, iters: 1880, time: 0.110, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.745 D_fake: 0.666 \n",
      "(epoch: 35, iters: 1980, time: 0.110, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.742 D_fake: 0.648 \n",
      "(epoch: 35, iters: 2080, time: 0.096, data: 0.001) G_GAN: 0.742 G_L1: 2.663 D_real: 0.566 D_fake: 0.604 \n",
      "(epoch: 35, iters: 2180, time: 0.098, data: 0.001) G_GAN: 0.736 G_L1: 0.000 D_real: 0.765 D_fake: 0.571 \n",
      "(epoch: 35, iters: 2280, time: 0.097, data: 0.001) G_GAN: 0.704 G_L1: 0.000 D_real: 0.707 D_fake: 0.677 \n",
      "saving the model at the end of epoch 35, iters 79800\n",
      "End of epoch 35 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 36, iters: 100, time: 0.105, data: 0.287) G_GAN: 0.817 G_L1: 2.739 D_real: 0.611 D_fake: 0.587 \n",
      "(epoch: 36, iters: 200, time: 0.096, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.670 D_fake: 0.743 \n",
      "saving the latest model (epoch 36, total_steps 80000)\n",
      "(epoch: 36, iters: 300, time: 0.097, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.738 D_fake: 0.652 \n",
      "(epoch: 36, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.744 G_L1: 1.900 D_real: 0.586 D_fake: 0.648 \n",
      "(epoch: 36, iters: 500, time: 0.109, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.741 D_fake: 0.650 \n",
      "(epoch: 36, iters: 600, time: 0.099, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.731 D_fake: 0.658 \n",
      "(epoch: 36, iters: 700, time: 0.099, data: 0.001) G_GAN: 0.793 G_L1: 2.269 D_real: 0.617 D_fake: 0.609 \n",
      "(epoch: 36, iters: 800, time: 0.099, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.747 D_fake: 0.647 \n",
      "(epoch: 36, iters: 900, time: 0.094, data: 0.001) G_GAN: 0.593 G_L1: 0.000 D_real: 0.584 D_fake: 0.788 \n",
      "(epoch: 36, iters: 1000, time: 0.100, data: 0.001) G_GAN: 0.787 G_L1: 2.064 D_real: 0.610 D_fake: 0.621 \n",
      "(epoch: 36, iters: 1100, time: 0.098, data: 0.001) G_GAN: 0.786 G_L1: 0.000 D_real: 0.788 D_fake: 0.622 \n",
      "(epoch: 36, iters: 1200, time: 0.097, data: 0.001) G_GAN: 0.708 G_L1: 0.000 D_real: 0.710 D_fake: 0.677 \n",
      "(epoch: 36, iters: 1300, time: 0.107, data: 0.001) G_GAN: 0.797 G_L1: 3.100 D_real: 0.596 D_fake: 0.601 \n",
      "(epoch: 36, iters: 1400, time: 0.100, data: 0.001) G_GAN: 0.806 G_L1: 0.000 D_real: 0.811 D_fake: 0.647 \n",
      "(epoch: 36, iters: 1500, time: 0.097, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.735 D_fake: 0.656 \n",
      "(epoch: 36, iters: 1600, time: 0.096, data: 0.002) G_GAN: 0.745 G_L1: 1.704 D_real: 0.593 D_fake: 0.647 \n",
      "(epoch: 36, iters: 1700, time: 0.108, data: 0.001) G_GAN: 0.775 G_L1: 0.000 D_real: 0.777 D_fake: 0.619 \n",
      "(epoch: 36, iters: 1800, time: 0.097, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.742 D_fake: 0.631 \n",
      "(epoch: 36, iters: 1900, time: 0.099, data: 0.002) G_GAN: 0.781 G_L1: 4.005 D_real: 0.554 D_fake: 0.626 \n",
      "(epoch: 36, iters: 2000, time: 0.098, data: 0.001) G_GAN: 0.755 G_L1: 0.000 D_real: 0.755 D_fake: 0.638 \n",
      "(epoch: 36, iters: 2100, time: 0.096, data: 0.001) G_GAN: 0.706 G_L1: 0.000 D_real: 0.707 D_fake: 0.639 \n",
      "(epoch: 36, iters: 2200, time: 0.109, data: 0.001) G_GAN: 0.698 G_L1: 1.935 D_real: 0.533 D_fake: 0.701 \n",
      "End of epoch 36 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 37, iters: 20, time: 0.106, data: 0.001) G_GAN: 0.769 G_L1: 0.000 D_real: 0.772 D_fake: 0.620 \n",
      "(epoch: 37, iters: 120, time: 0.097, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.709 D_fake: 0.691 \n",
      "(epoch: 37, iters: 220, time: 0.098, data: 0.002) G_GAN: 0.738 G_L1: 3.205 D_real: 0.537 D_fake: 0.619 \n",
      "(epoch: 37, iters: 320, time: 0.097, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.742 D_fake: 0.638 \n",
      "(epoch: 37, iters: 420, time: 0.098, data: 0.001) G_GAN: 0.715 G_L1: 0.000 D_real: 0.716 D_fake: 0.672 \n",
      "(epoch: 37, iters: 520, time: 0.107, data: 0.002) G_GAN: 0.761 G_L1: 1.603 D_real: 0.602 D_fake: 0.632 \n",
      "(epoch: 37, iters: 620, time: 0.097, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.747 D_fake: 0.641 \n",
      "(epoch: 37, iters: 720, time: 0.097, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.742 D_fake: 0.648 \n",
      "(epoch: 37, iters: 820, time: 0.095, data: 0.001) G_GAN: 0.769 G_L1: 2.187 D_real: 0.591 D_fake: 0.627 \n",
      "(epoch: 37, iters: 920, time: 0.096, data: 0.001) G_GAN: 0.665 G_L1: 0.000 D_real: 0.693 D_fake: 0.527 \n",
      "(epoch: 37, iters: 1020, time: 0.097, data: 0.001) G_GAN: 0.709 G_L1: 0.000 D_real: 0.711 D_fake: 0.672 \n",
      "(epoch: 37, iters: 1120, time: 0.097, data: 0.001) G_GAN: 0.755 G_L1: 1.002 D_real: 0.616 D_fake: 0.639 \n",
      "(epoch: 37, iters: 1220, time: 0.097, data: 0.001) G_GAN: 0.777 G_L1: 0.000 D_real: 0.781 D_fake: 0.615 \n",
      "(epoch: 37, iters: 1320, time: 0.097, data: 0.001) G_GAN: 0.714 G_L1: 0.000 D_real: 0.715 D_fake: 0.668 \n",
      "(epoch: 37, iters: 1420, time: 0.110, data: 0.001) G_GAN: 0.718 G_L1: 2.201 D_real: 0.554 D_fake: 0.678 \n",
      "(epoch: 37, iters: 1520, time: 0.098, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.742 D_fake: 0.649 \n",
      "(epoch: 37, iters: 1620, time: 0.093, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.701 D_fake: 0.685 \n",
      "(epoch: 37, iters: 1720, time: 0.112, data: 0.002) G_GAN: 0.775 G_L1: 3.384 D_real: 0.561 D_fake: 0.623 \n",
      "(epoch: 37, iters: 1820, time: 0.096, data: 0.001) G_GAN: 0.777 G_L1: 0.000 D_real: 0.780 D_fake: 0.617 \n",
      "(epoch: 37, iters: 1920, time: 0.096, data: 0.001) G_GAN: 0.734 G_L1: 0.000 D_real: 0.738 D_fake: 0.617 \n",
      "(epoch: 37, iters: 2020, time: 0.100, data: 0.001) G_GAN: 0.757 G_L1: 1.903 D_real: 0.595 D_fake: 0.638 \n",
      "(epoch: 37, iters: 2120, time: 0.097, data: 0.002) G_GAN: 0.795 G_L1: 0.000 D_real: 0.801 D_fake: 0.604 \n",
      "(epoch: 37, iters: 2220, time: 0.099, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.702 D_fake: 0.687 \n",
      "End of epoch 37 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 38, iters: 40, time: 0.123, data: 0.001) G_GAN: 0.733 G_L1: 1.545 D_real: 0.578 D_fake: 0.668 \n",
      "(epoch: 38, iters: 140, time: 0.109, data: 0.001) G_GAN: 0.758 G_L1: 0.000 D_real: 0.760 D_fake: 0.634 \n",
      "(epoch: 38, iters: 240, time: 0.097, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.740 D_fake: 0.661 \n",
      "(epoch: 38, iters: 340, time: 0.095, data: 0.001) G_GAN: 0.749 G_L1: 0.576 D_real: 0.623 D_fake: 0.645 \n",
      "(epoch: 38, iters: 440, time: 0.103, data: 0.001) G_GAN: 0.744 G_L1: 0.000 D_real: 0.745 D_fake: 0.636 \n",
      "(epoch: 38, iters: 540, time: 0.096, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.732 D_fake: 0.665 \n",
      "(epoch: 38, iters: 640, time: 0.096, data: 0.002) G_GAN: 0.760 G_L1: 3.338 D_real: 0.559 D_fake: 0.666 \n",
      "saving the latest model (epoch 38, total_steps 85000)\n",
      "(epoch: 38, iters: 740, time: 0.104, data: 0.001) G_GAN: 0.760 G_L1: 0.000 D_real: 0.762 D_fake: 0.631 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 38, iters: 840, time: 0.106, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.737 D_fake: 0.654 \n",
      "(epoch: 38, iters: 940, time: 0.103, data: 0.001) G_GAN: 0.788 G_L1: 1.224 D_real: 0.637 D_fake: 0.609 \n",
      "(epoch: 38, iters: 1040, time: 0.096, data: 0.001) G_GAN: 0.755 G_L1: 0.000 D_real: 0.762 D_fake: 0.632 \n",
      "(epoch: 38, iters: 1140, time: 0.098, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.740 D_fake: 0.650 \n",
      "(epoch: 38, iters: 1240, time: 0.105, data: 0.001) G_GAN: 0.787 G_L1: 2.557 D_real: 0.597 D_fake: 0.622 \n",
      "(epoch: 38, iters: 1340, time: 0.098, data: 0.003) G_GAN: 0.772 G_L1: 0.000 D_real: 0.774 D_fake: 0.621 \n",
      "(epoch: 38, iters: 1440, time: 0.110, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.745 D_fake: 0.646 \n",
      "(epoch: 38, iters: 1540, time: 0.098, data: 0.002) G_GAN: 0.757 G_L1: 1.958 D_real: 0.592 D_fake: 0.638 \n",
      "(epoch: 38, iters: 1640, time: 0.097, data: 0.001) G_GAN: 0.751 G_L1: 0.000 D_real: 0.755 D_fake: 0.638 \n",
      "(epoch: 38, iters: 1740, time: 0.097, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.737 D_fake: 0.654 \n",
      "(epoch: 38, iters: 1840, time: 0.097, data: 0.001) G_GAN: 0.762 G_L1: 0.311 D_real: 0.674 D_fake: 0.603 \n",
      "(epoch: 38, iters: 1940, time: 0.097, data: 0.001) G_GAN: 0.760 G_L1: 0.000 D_real: 0.771 D_fake: 0.625 \n",
      "(epoch: 38, iters: 2040, time: 0.108, data: 0.001) G_GAN: 0.743 G_L1: 0.000 D_real: 0.746 D_fake: 0.644 \n",
      "(epoch: 38, iters: 2140, time: 0.098, data: 0.001) G_GAN: 0.797 G_L1: 0.787 D_real: 0.660 D_fake: 0.640 \n",
      "(epoch: 38, iters: 2240, time: 0.098, data: 0.002) G_GAN: 0.772 G_L1: 0.000 D_real: 0.765 D_fake: 0.629 \n",
      "End of epoch 38 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 39, iters: 60, time: 0.105, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.714 D_fake: 0.675 \n",
      "(epoch: 39, iters: 160, time: 0.098, data: 0.001) G_GAN: 0.777 G_L1: 3.185 D_real: 0.574 D_fake: 0.622 \n",
      "(epoch: 39, iters: 260, time: 0.101, data: 0.001) G_GAN: 0.775 G_L1: 0.000 D_real: 0.780 D_fake: 0.617 \n",
      "(epoch: 39, iters: 360, time: 0.095, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.731 D_fake: 0.645 \n",
      "(epoch: 39, iters: 460, time: 0.098, data: 0.001) G_GAN: 0.768 G_L1: 2.593 D_real: 0.586 D_fake: 0.646 \n",
      "(epoch: 39, iters: 560, time: 0.096, data: 0.001) G_GAN: 0.755 G_L1: 0.000 D_real: 0.759 D_fake: 0.635 \n",
      "(epoch: 39, iters: 660, time: 0.110, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.720 D_fake: 0.671 \n",
      "(epoch: 39, iters: 760, time: 0.097, data: 0.002) G_GAN: 0.758 G_L1: 2.399 D_real: 0.585 D_fake: 0.636 \n",
      "(epoch: 39, iters: 860, time: 0.096, data: 0.002) G_GAN: 0.775 G_L1: 0.000 D_real: 0.782 D_fake: 0.611 \n",
      "(epoch: 39, iters: 960, time: 0.105, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.727 D_fake: 0.663 \n",
      "(epoch: 39, iters: 1060, time: 0.093, data: 0.002) G_GAN: 0.765 G_L1: 0.087 D_real: 0.709 D_fake: 0.566 \n",
      "(epoch: 39, iters: 1160, time: 0.107, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.763 D_fake: 0.627 \n",
      "(epoch: 39, iters: 1260, time: 0.106, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.701 D_fake: 0.648 \n",
      "(epoch: 39, iters: 1360, time: 0.097, data: 0.002) G_GAN: 0.786 G_L1: 4.502 D_real: 0.531 D_fake: 0.621 \n",
      "(epoch: 39, iters: 1460, time: 0.096, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.761 D_fake: 0.619 \n",
      "(epoch: 39, iters: 1560, time: 0.095, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.718 D_fake: 0.666 \n",
      "(epoch: 39, iters: 1660, time: 0.096, data: 0.001) G_GAN: 0.769 G_L1: 1.973 D_real: 0.599 D_fake: 0.644 \n",
      "(epoch: 39, iters: 1760, time: 0.097, data: 0.001) G_GAN: 0.781 G_L1: 0.000 D_real: 0.784 D_fake: 0.615 \n",
      "(epoch: 39, iters: 1860, time: 0.108, data: 0.001) G_GAN: 0.724 G_L1: 0.000 D_real: 0.726 D_fake: 0.658 \n",
      "(epoch: 39, iters: 1960, time: 0.098, data: 0.001) G_GAN: 0.772 G_L1: 0.417 D_real: 0.660 D_fake: 0.624 \n",
      "(epoch: 39, iters: 2060, time: 0.094, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.747 D_fake: 0.630 \n",
      "(epoch: 39, iters: 2160, time: 0.098, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.728 D_fake: 0.662 \n",
      "(epoch: 39, iters: 2260, time: 0.103, data: 0.001) G_GAN: 0.822 G_L1: 3.017 D_real: 0.610 D_fake: 0.681 \n",
      "End of epoch 39 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 40, iters: 80, time: 0.113, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.745 D_fake: 0.623 \n",
      "(epoch: 40, iters: 180, time: 0.097, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.732 D_fake: 0.658 \n",
      "(epoch: 40, iters: 280, time: 0.107, data: 0.001) G_GAN: 0.747 G_L1: 1.052 D_real: 0.617 D_fake: 0.646 \n",
      "(epoch: 40, iters: 380, time: 0.099, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.788 D_fake: 0.601 \n",
      "(epoch: 40, iters: 480, time: 0.098, data: 0.001) G_GAN: 0.736 G_L1: 0.000 D_real: 0.738 D_fake: 0.652 \n",
      "(epoch: 40, iters: 580, time: 0.098, data: 0.001) G_GAN: 0.759 G_L1: 4.208 D_real: 0.535 D_fake: 0.636 \n",
      "(epoch: 40, iters: 680, time: 0.110, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.751 D_fake: 0.641 \n",
      "(epoch: 40, iters: 780, time: 0.096, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.741 D_fake: 0.651 \n",
      "(epoch: 40, iters: 880, time: 0.094, data: 0.001) G_GAN: 0.858 G_L1: 3.483 D_real: 0.590 D_fake: 0.533 \n",
      "(epoch: 40, iters: 980, time: 0.098, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.756 D_fake: 0.639 \n",
      "(epoch: 40, iters: 1080, time: 0.094, data: 0.001) G_GAN: 0.676 G_L1: 0.000 D_real: 0.674 D_fake: 0.715 \n",
      "saving the latest model (epoch 40, total_steps 90000)\n",
      "(epoch: 40, iters: 1180, time: 0.100, data: 0.002) G_GAN: 0.738 G_L1: 0.978 D_real: 0.613 D_fake: 0.653 \n",
      "(epoch: 40, iters: 1280, time: 0.098, data: 0.001) G_GAN: 0.775 G_L1: 0.000 D_real: 0.813 D_fake: 0.668 \n",
      "(epoch: 40, iters: 1380, time: 0.095, data: 0.001) G_GAN: 0.706 G_L1: 0.000 D_real: 0.709 D_fake: 0.692 \n",
      "(epoch: 40, iters: 1480, time: 0.109, data: 0.002) G_GAN: 0.742 G_L1: 1.681 D_real: 0.585 D_fake: 0.651 \n",
      "(epoch: 40, iters: 1580, time: 0.095, data: 0.002) G_GAN: 0.783 G_L1: 0.000 D_real: 0.788 D_fake: 0.612 \n",
      "(epoch: 40, iters: 1680, time: 0.099, data: 0.001) G_GAN: 0.755 G_L1: 0.000 D_real: 0.763 D_fake: 0.666 \n",
      "(epoch: 40, iters: 1780, time: 0.098, data: 0.002) G_GAN: 0.753 G_L1: 3.487 D_real: 0.543 D_fake: 0.640 \n",
      "(epoch: 40, iters: 1880, time: 0.100, data: 0.001) G_GAN: 0.751 G_L1: 0.000 D_real: 0.754 D_fake: 0.648 \n",
      "(epoch: 40, iters: 1980, time: 0.099, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.739 D_fake: 0.608 \n",
      "(epoch: 40, iters: 2080, time: 0.098, data: 0.000) G_GAN: 0.745 G_L1: 2.663 D_real: 0.556 D_fake: 0.654 \n",
      "(epoch: 40, iters: 2180, time: 0.099, data: 0.001) G_GAN: 0.765 G_L1: 0.000 D_real: 0.767 D_fake: 0.627 \n",
      "(epoch: 40, iters: 2280, time: 0.108, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.742 D_fake: 0.649 \n",
      "saving the model at the end of epoch 40, iters 91200\n",
      "End of epoch 40 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 41, iters: 100, time: 0.106, data: 0.277) G_GAN: 0.753 G_L1: 2.739 D_real: 0.566 D_fake: 0.643 \n",
      "(epoch: 41, iters: 200, time: 0.096, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.739 D_fake: 0.653 \n",
      "(epoch: 41, iters: 300, time: 0.096, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.740 D_fake: 0.650 \n",
      "(epoch: 41, iters: 400, time: 0.098, data: 0.001) G_GAN: 0.704 G_L1: 1.900 D_real: 0.544 D_fake: 0.611 \n",
      "(epoch: 41, iters: 500, time: 0.098, data: 0.001) G_GAN: 0.769 G_L1: 0.000 D_real: 0.772 D_fake: 0.645 \n",
      "(epoch: 41, iters: 600, time: 0.099, data: 0.001) G_GAN: 0.744 G_L1: 0.000 D_real: 0.746 D_fake: 0.645 \n",
      "(epoch: 41, iters: 700, time: 0.098, data: 0.001) G_GAN: 0.967 G_L1: 2.269 D_real: 0.763 D_fake: 0.649 \n",
      "(epoch: 41, iters: 800, time: 0.096, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.738 D_fake: 0.654 \n",
      "(epoch: 41, iters: 900, time: 0.094, data: 0.001) G_GAN: 0.669 G_L1: 0.000 D_real: 0.663 D_fake: 0.737 \n",
      "(epoch: 41, iters: 1000, time: 0.097, data: 0.001) G_GAN: 0.880 G_L1: 2.064 D_real: 0.679 D_fake: 0.722 \n",
      "(epoch: 41, iters: 1100, time: 0.099, data: 0.001) G_GAN: 0.761 G_L1: 0.000 D_real: 0.773 D_fake: 0.609 \n",
      "(epoch: 41, iters: 1200, time: 0.097, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.731 D_fake: 0.655 \n",
      "(epoch: 41, iters: 1300, time: 0.098, data: 0.001) G_GAN: 0.794 G_L1: 3.100 D_real: 0.601 D_fake: 0.691 \n",
      "(epoch: 41, iters: 1400, time: 0.100, data: 0.002) G_GAN: 0.779 G_L1: 0.000 D_real: 0.783 D_fake: 0.614 \n",
      "(epoch: 41, iters: 1500, time: 0.098, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.733 D_fake: 0.649 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 41, iters: 1600, time: 0.098, data: 0.001) G_GAN: 0.743 G_L1: 1.704 D_real: 0.586 D_fake: 0.631 \n",
      "(epoch: 41, iters: 1700, time: 0.115, data: 0.001) G_GAN: 0.796 G_L1: 0.000 D_real: 0.801 D_fake: 0.599 \n",
      "(epoch: 41, iters: 1800, time: 0.094, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.732 D_fake: 0.658 \n",
      "(epoch: 41, iters: 1900, time: 0.098, data: 0.001) G_GAN: 0.751 G_L1: 4.005 D_real: 0.532 D_fake: 0.639 \n",
      "(epoch: 41, iters: 2000, time: 0.094, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.764 D_fake: 0.631 \n",
      "(epoch: 41, iters: 2100, time: 0.094, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.694 D_fake: 0.670 \n",
      "(epoch: 41, iters: 2200, time: 0.099, data: 0.001) G_GAN: 0.745 G_L1: 1.935 D_real: 0.570 D_fake: 0.653 \n",
      "End of epoch 41 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 42, iters: 20, time: 0.123, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.756 D_fake: 0.640 \n",
      "(epoch: 42, iters: 120, time: 0.097, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.716 D_fake: 0.672 \n",
      "(epoch: 42, iters: 220, time: 0.096, data: 0.002) G_GAN: 0.777 G_L1: 3.205 D_real: 0.566 D_fake: 0.621 \n",
      "(epoch: 42, iters: 320, time: 0.097, data: 0.001) G_GAN: 0.751 G_L1: 0.000 D_real: 0.754 D_fake: 0.640 \n",
      "(epoch: 42, iters: 420, time: 0.097, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.727 D_fake: 0.650 \n",
      "(epoch: 42, iters: 520, time: 0.095, data: 0.001) G_GAN: 0.739 G_L1: 1.603 D_real: 0.590 D_fake: 0.646 \n",
      "(epoch: 42, iters: 620, time: 0.096, data: 0.001) G_GAN: 0.743 G_L1: 0.000 D_real: 0.744 D_fake: 0.647 \n",
      "(epoch: 42, iters: 720, time: 0.097, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.731 D_fake: 0.670 \n",
      "(epoch: 42, iters: 820, time: 0.107, data: 0.001) G_GAN: 0.754 G_L1: 2.187 D_real: 0.590 D_fake: 0.647 \n",
      "(epoch: 42, iters: 920, time: 0.095, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.737 D_fake: 0.542 \n",
      "(epoch: 42, iters: 1020, time: 0.097, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.733 D_fake: 0.658 \n",
      "(epoch: 42, iters: 1120, time: 0.097, data: 0.002) G_GAN: 0.720 G_L1: 1.002 D_real: 0.594 D_fake: 0.673 \n",
      "(epoch: 42, iters: 1220, time: 0.097, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.750 D_fake: 0.642 \n",
      "(epoch: 42, iters: 1320, time: 0.097, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.725 D_fake: 0.659 \n",
      "(epoch: 42, iters: 1420, time: 0.107, data: 0.001) G_GAN: 0.723 G_L1: 2.201 D_real: 0.554 D_fake: 0.675 \n",
      "(epoch: 42, iters: 1520, time: 0.111, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.757 D_fake: 0.640 \n",
      "saving the latest model (epoch 42, total_steps 95000)\n",
      "(epoch: 42, iters: 1620, time: 0.097, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.736 D_fake: 0.652 \n",
      "(epoch: 42, iters: 1720, time: 0.098, data: 0.001) G_GAN: 0.766 G_L1: 3.384 D_real: 0.561 D_fake: 0.626 \n",
      "(epoch: 42, iters: 1820, time: 0.110, data: 0.001) G_GAN: 0.781 G_L1: 0.000 D_real: 0.787 D_fake: 0.635 \n",
      "(epoch: 42, iters: 1920, time: 0.109, data: 0.006) G_GAN: 0.727 G_L1: 0.000 D_real: 0.732 D_fake: 0.634 \n",
      "(epoch: 42, iters: 2020, time: 0.100, data: 0.002) G_GAN: 0.764 G_L1: 1.903 D_real: 0.600 D_fake: 0.631 \n",
      "(epoch: 42, iters: 2120, time: 0.099, data: 0.001) G_GAN: 0.772 G_L1: 0.000 D_real: 0.781 D_fake: 0.618 \n",
      "(epoch: 42, iters: 2220, time: 0.098, data: 0.002) G_GAN: 0.666 G_L1: 0.000 D_real: 0.661 D_fake: 0.729 \n",
      "End of epoch 42 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 43, iters: 40, time: 0.119, data: 0.001) G_GAN: 0.757 G_L1: 1.545 D_real: 0.603 D_fake: 0.638 \n",
      "(epoch: 43, iters: 140, time: 0.098, data: 0.001) G_GAN: 0.755 G_L1: 0.000 D_real: 0.758 D_fake: 0.650 \n",
      "(epoch: 43, iters: 240, time: 0.099, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.751 D_fake: 0.608 \n",
      "(epoch: 43, iters: 340, time: 0.095, data: 0.002) G_GAN: 0.745 G_L1: 0.576 D_real: 0.637 D_fake: 0.645 \n",
      "(epoch: 43, iters: 440, time: 0.106, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.748 D_fake: 0.644 \n",
      "(epoch: 43, iters: 540, time: 0.094, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.738 D_fake: 0.652 \n",
      "(epoch: 43, iters: 640, time: 0.095, data: 0.001) G_GAN: 0.751 G_L1: 3.338 D_real: 0.543 D_fake: 0.633 \n",
      "(epoch: 43, iters: 740, time: 0.094, data: 0.002) G_GAN: 0.773 G_L1: 0.000 D_real: 0.789 D_fake: 0.610 \n",
      "(epoch: 43, iters: 840, time: 0.098, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.737 D_fake: 0.638 \n",
      "(epoch: 43, iters: 940, time: 0.111, data: 0.001) G_GAN: 0.849 G_L1: 1.224 D_real: 0.678 D_fake: 0.565 \n",
      "(epoch: 43, iters: 1040, time: 0.096, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.740 D_fake: 0.651 \n",
      "(epoch: 43, iters: 1140, time: 0.096, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.721 D_fake: 0.662 \n",
      "(epoch: 43, iters: 1240, time: 0.095, data: 0.002) G_GAN: 0.824 G_L1: 2.557 D_real: 0.618 D_fake: 0.645 \n",
      "(epoch: 43, iters: 1340, time: 0.099, data: 0.001) G_GAN: 0.757 G_L1: 0.000 D_real: 0.757 D_fake: 0.636 \n",
      "(epoch: 43, iters: 1440, time: 0.098, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.749 D_fake: 0.659 \n",
      "(epoch: 43, iters: 1540, time: 0.101, data: 0.002) G_GAN: 0.767 G_L1: 1.958 D_real: 0.593 D_fake: 0.628 \n",
      "(epoch: 43, iters: 1640, time: 0.098, data: 0.001) G_GAN: 0.743 G_L1: 0.000 D_real: 0.747 D_fake: 0.642 \n",
      "(epoch: 43, iters: 1740, time: 0.100, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.729 D_fake: 0.664 \n",
      "(epoch: 43, iters: 1840, time: 0.099, data: 0.001) G_GAN: 0.752 G_L1: 0.311 D_real: 0.654 D_fake: 0.635 \n",
      "(epoch: 43, iters: 1940, time: 0.099, data: 0.003) G_GAN: 0.770 G_L1: 0.000 D_real: 0.774 D_fake: 0.620 \n",
      "(epoch: 43, iters: 2040, time: 0.098, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.731 D_fake: 0.658 \n",
      "(epoch: 43, iters: 2140, time: 0.107, data: 0.001) G_GAN: 0.764 G_L1: 0.787 D_real: 0.642 D_fake: 0.644 \n",
      "(epoch: 43, iters: 2240, time: 0.097, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.745 D_fake: 0.636 \n",
      "End of epoch 43 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 44, iters: 60, time: 0.120, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.681 D_fake: 0.701 \n",
      "(epoch: 44, iters: 160, time: 0.097, data: 0.002) G_GAN: 0.755 G_L1: 3.185 D_real: 0.554 D_fake: 0.633 \n",
      "(epoch: 44, iters: 260, time: 0.096, data: 0.002) G_GAN: 0.781 G_L1: 0.000 D_real: 0.788 D_fake: 0.618 \n",
      "(epoch: 44, iters: 360, time: 0.096, data: 0.001) G_GAN: 0.744 G_L1: 0.000 D_real: 0.746 D_fake: 0.661 \n",
      "(epoch: 44, iters: 460, time: 0.099, data: 0.001) G_GAN: 0.788 G_L1: 2.593 D_real: 0.597 D_fake: 0.611 \n",
      "(epoch: 44, iters: 560, time: 0.097, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.751 D_fake: 0.649 \n",
      "(epoch: 44, iters: 660, time: 0.098, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.732 D_fake: 0.659 \n",
      "(epoch: 44, iters: 760, time: 0.096, data: 0.001) G_GAN: 0.755 G_L1: 2.399 D_real: 0.570 D_fake: 0.642 \n",
      "(epoch: 44, iters: 860, time: 0.095, data: 0.001) G_GAN: 0.781 G_L1: 0.000 D_real: 0.786 D_fake: 0.615 \n",
      "(epoch: 44, iters: 960, time: 0.107, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.716 D_fake: 0.677 \n",
      "(epoch: 44, iters: 1060, time: 0.096, data: 0.001) G_GAN: 0.726 G_L1: 0.087 D_real: 0.668 D_fake: 0.674 \n",
      "(epoch: 44, iters: 1160, time: 0.095, data: 0.003) G_GAN: 0.753 G_L1: 0.000 D_real: 0.754 D_fake: 0.602 \n",
      "(epoch: 44, iters: 1260, time: 0.110, data: 0.001) G_GAN: 0.703 G_L1: 0.000 D_real: 0.703 D_fake: 0.687 \n",
      "(epoch: 44, iters: 1360, time: 0.105, data: 0.002) G_GAN: 0.781 G_L1: 4.502 D_real: 0.541 D_fake: 0.627 \n",
      "(epoch: 44, iters: 1460, time: 0.095, data: 0.001) G_GAN: 0.753 G_L1: 0.000 D_real: 0.756 D_fake: 0.637 \n",
      "(epoch: 44, iters: 1560, time: 0.098, data: 0.001) G_GAN: 0.724 G_L1: 0.000 D_real: 0.726 D_fake: 0.618 \n",
      "(epoch: 44, iters: 1660, time: 0.107, data: 0.002) G_GAN: 0.778 G_L1: 1.973 D_real: 0.609 D_fake: 0.619 \n",
      "(epoch: 44, iters: 1760, time: 0.098, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.763 D_fake: 0.644 \n",
      "(epoch: 44, iters: 1860, time: 0.100, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.733 D_fake: 0.651 \n",
      "(epoch: 44, iters: 1960, time: 0.110, data: 0.001) G_GAN: 0.771 G_L1: 0.417 D_real: 0.659 D_fake: 0.634 \n",
      "saving the latest model (epoch 44, total_steps 100000)\n",
      "(epoch: 44, iters: 2060, time: 0.094, data: 0.001) G_GAN: 0.718 G_L1: 0.000 D_real: 0.715 D_fake: 0.679 \n",
      "(epoch: 44, iters: 2160, time: 0.100, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.711 D_fake: 0.667 \n",
      "(epoch: 44, iters: 2260, time: 0.105, data: 0.001) G_GAN: 0.852 G_L1: 3.017 D_real: 0.626 D_fake: 0.562 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 44 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 45, iters: 80, time: 0.117, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.703 D_fake: 0.696 \n",
      "(epoch: 45, iters: 180, time: 0.099, data: 0.001) G_GAN: 0.736 G_L1: 0.000 D_real: 0.738 D_fake: 0.653 \n",
      "(epoch: 45, iters: 280, time: 0.096, data: 0.002) G_GAN: 0.755 G_L1: 1.052 D_real: 0.624 D_fake: 0.638 \n",
      "(epoch: 45, iters: 380, time: 0.099, data: 0.001) G_GAN: 0.780 G_L1: 0.000 D_real: 0.785 D_fake: 0.612 \n",
      "(epoch: 45, iters: 480, time: 0.097, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.722 D_fake: 0.666 \n",
      "(epoch: 45, iters: 580, time: 0.099, data: 0.001) G_GAN: 0.764 G_L1: 4.208 D_real: 0.536 D_fake: 0.617 \n",
      "(epoch: 45, iters: 680, time: 0.100, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.745 D_fake: 0.641 \n",
      "(epoch: 45, iters: 780, time: 0.095, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.732 D_fake: 0.651 \n",
      "(epoch: 45, iters: 880, time: 0.093, data: 0.001) G_GAN: 0.823 G_L1: 3.483 D_real: 0.588 D_fake: 0.680 \n",
      "(epoch: 45, iters: 980, time: 0.096, data: 0.002) G_GAN: 0.770 G_L1: 0.000 D_real: 0.774 D_fake: 0.638 \n",
      "(epoch: 45, iters: 1080, time: 0.094, data: 0.001) G_GAN: 0.702 G_L1: 0.000 D_real: 0.711 D_fake: 0.631 \n",
      "(epoch: 45, iters: 1180, time: 0.097, data: 0.001) G_GAN: 0.769 G_L1: 0.978 D_real: 0.634 D_fake: 0.627 \n",
      "(epoch: 45, iters: 1280, time: 0.103, data: 0.002) G_GAN: 0.794 G_L1: 0.000 D_real: 0.833 D_fake: 0.584 \n",
      "(epoch: 45, iters: 1380, time: 0.096, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.701 D_fake: 0.684 \n",
      "(epoch: 45, iters: 1480, time: 0.097, data: 0.001) G_GAN: 0.749 G_L1: 1.681 D_real: 0.589 D_fake: 0.645 \n",
      "(epoch: 45, iters: 1580, time: 0.108, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.756 D_fake: 0.637 \n",
      "(epoch: 45, iters: 1680, time: 0.100, data: 0.004) G_GAN: 0.745 G_L1: 0.000 D_real: 0.747 D_fake: 0.644 \n",
      "(epoch: 45, iters: 1780, time: 0.096, data: 0.002) G_GAN: 0.758 G_L1: 3.487 D_real: 0.543 D_fake: 0.638 \n",
      "(epoch: 45, iters: 1880, time: 0.100, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.762 D_fake: 0.633 \n",
      "(epoch: 45, iters: 1980, time: 0.097, data: 0.001) G_GAN: 0.743 G_L1: 0.000 D_real: 0.745 D_fake: 0.644 \n",
      "(epoch: 45, iters: 2080, time: 0.104, data: 0.001) G_GAN: 0.753 G_L1: 2.663 D_real: 0.563 D_fake: 0.643 \n",
      "(epoch: 45, iters: 2180, time: 0.106, data: 0.001) G_GAN: 0.768 G_L1: 0.000 D_real: 0.770 D_fake: 0.636 \n",
      "(epoch: 45, iters: 2280, time: 0.096, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.735 D_fake: 0.656 \n",
      "saving the model at the end of epoch 45, iters 102600\n",
      "End of epoch 45 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 46, iters: 100, time: 0.105, data: 0.289) G_GAN: 0.752 G_L1: 2.739 D_real: 0.568 D_fake: 0.644 \n",
      "(epoch: 46, iters: 200, time: 0.094, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.732 D_fake: 0.617 \n",
      "(epoch: 46, iters: 300, time: 0.107, data: 0.001) G_GAN: 0.712 G_L1: 0.000 D_real: 0.716 D_fake: 0.679 \n",
      "(epoch: 46, iters: 400, time: 0.098, data: 0.002) G_GAN: 0.679 G_L1: 1.900 D_real: 0.523 D_fake: 0.722 \n",
      "(epoch: 46, iters: 500, time: 0.106, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.759 D_fake: 0.631 \n",
      "(epoch: 46, iters: 600, time: 0.097, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.752 D_fake: 0.627 \n",
      "(epoch: 46, iters: 700, time: 0.097, data: 0.001) G_GAN: 0.878 G_L1: 2.269 D_real: 0.702 D_fake: 0.648 \n",
      "(epoch: 46, iters: 800, time: 0.098, data: 0.001) G_GAN: 0.734 G_L1: 0.000 D_real: 0.744 D_fake: 0.651 \n",
      "(epoch: 46, iters: 900, time: 0.104, data: 0.001) G_GAN: 0.650 G_L1: 0.000 D_real: 0.646 D_fake: 0.618 \n",
      "(epoch: 46, iters: 1000, time: 0.101, data: 0.001) G_GAN: 0.791 G_L1: 2.064 D_real: 0.595 D_fake: 0.617 \n",
      "(epoch: 46, iters: 1100, time: 0.102, data: 0.001) G_GAN: 0.768 G_L1: 0.000 D_real: 0.774 D_fake: 0.656 \n",
      "(epoch: 46, iters: 1200, time: 0.096, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.731 D_fake: 0.659 \n",
      "(epoch: 46, iters: 1300, time: 0.109, data: 0.001) G_GAN: 0.795 G_L1: 3.100 D_real: 0.586 D_fake: 0.606 \n",
      "(epoch: 46, iters: 1400, time: 0.100, data: 0.001) G_GAN: 0.772 G_L1: 0.000 D_real: 0.775 D_fake: 0.644 \n",
      "(epoch: 46, iters: 1500, time: 0.107, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.737 D_fake: 0.655 \n",
      "(epoch: 46, iters: 1600, time: 0.097, data: 0.005) G_GAN: 0.739 G_L1: 1.704 D_real: 0.584 D_fake: 0.649 \n",
      "(epoch: 46, iters: 1700, time: 0.100, data: 0.001) G_GAN: 0.784 G_L1: 0.000 D_real: 0.789 D_fake: 0.609 \n",
      "(epoch: 46, iters: 1800, time: 0.096, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.726 D_fake: 0.664 \n",
      "(epoch: 46, iters: 1900, time: 0.097, data: 0.001) G_GAN: 0.737 G_L1: 4.005 D_real: 0.521 D_fake: 0.658 \n",
      "(epoch: 46, iters: 2000, time: 0.098, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.755 D_fake: 0.638 \n",
      "(epoch: 46, iters: 2100, time: 0.094, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.681 D_fake: 0.689 \n",
      "(epoch: 46, iters: 2200, time: 0.101, data: 0.001) G_GAN: 0.730 G_L1: 1.935 D_real: 0.561 D_fake: 0.669 \n",
      "End of epoch 46 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 47, iters: 20, time: 0.107, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.752 D_fake: 0.645 \n",
      "(epoch: 47, iters: 120, time: 0.099, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.724 D_fake: 0.666 \n",
      "saving the latest model (epoch 47, total_steps 105000)\n",
      "(epoch: 47, iters: 220, time: 0.098, data: 0.001) G_GAN: 0.774 G_L1: 3.205 D_real: 0.555 D_fake: 0.608 \n",
      "(epoch: 47, iters: 320, time: 0.108, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.759 D_fake: 0.643 \n",
      "(epoch: 47, iters: 420, time: 0.099, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.730 D_fake: 0.659 \n",
      "(epoch: 47, iters: 520, time: 0.096, data: 0.001) G_GAN: 0.748 G_L1: 1.603 D_real: 0.596 D_fake: 0.636 \n",
      "(epoch: 47, iters: 620, time: 0.099, data: 0.001) G_GAN: 0.759 G_L1: 0.000 D_real: 0.762 D_fake: 0.636 \n",
      "(epoch: 47, iters: 720, time: 0.099, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.723 D_fake: 0.667 \n",
      "(epoch: 47, iters: 820, time: 0.096, data: 0.001) G_GAN: 0.755 G_L1: 2.187 D_real: 0.576 D_fake: 0.648 \n",
      "(epoch: 47, iters: 920, time: 0.095, data: 0.001) G_GAN: 0.668 G_L1: 0.000 D_real: 0.669 D_fake: 0.723 \n",
      "(epoch: 47, iters: 1020, time: 0.095, data: 0.001) G_GAN: 0.710 G_L1: 0.000 D_real: 0.715 D_fake: 0.646 \n",
      "(epoch: 47, iters: 1120, time: 0.098, data: 0.001) G_GAN: 0.726 G_L1: 1.002 D_real: 0.584 D_fake: 0.674 \n",
      "(epoch: 47, iters: 1220, time: 0.098, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.751 D_fake: 0.615 \n",
      "(epoch: 47, iters: 1320, time: 0.098, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.708 D_fake: 0.680 \n",
      "(epoch: 47, iters: 1420, time: 0.096, data: 0.002) G_GAN: 0.740 G_L1: 2.201 D_real: 0.579 D_fake: 0.660 \n",
      "(epoch: 47, iters: 1520, time: 0.097, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.748 D_fake: 0.644 \n",
      "(epoch: 47, iters: 1620, time: 0.096, data: 0.001) G_GAN: 0.751 G_L1: 0.000 D_real: 0.762 D_fake: 0.652 \n",
      "(epoch: 47, iters: 1720, time: 0.109, data: 0.002) G_GAN: 0.765 G_L1: 3.384 D_real: 0.559 D_fake: 0.632 \n",
      "(epoch: 47, iters: 1820, time: 0.099, data: 0.001) G_GAN: 0.780 G_L1: 0.000 D_real: 0.785 D_fake: 0.624 \n",
      "(epoch: 47, iters: 1920, time: 0.097, data: 0.001) G_GAN: 0.705 G_L1: 0.000 D_real: 0.710 D_fake: 0.568 \n",
      "(epoch: 47, iters: 2020, time: 0.111, data: 0.001) G_GAN: 0.760 G_L1: 1.903 D_real: 0.593 D_fake: 0.635 \n",
      "(epoch: 47, iters: 2120, time: 0.098, data: 0.001) G_GAN: 0.786 G_L1: 0.000 D_real: 0.797 D_fake: 0.563 \n",
      "(epoch: 47, iters: 2220, time: 0.107, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.716 D_fake: 0.510 \n",
      "End of epoch 47 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 48, iters: 40, time: 0.105, data: 0.001) G_GAN: 0.770 G_L1: 1.545 D_real: 0.607 D_fake: 0.648 \n",
      "(epoch: 48, iters: 140, time: 0.097, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.643 \n",
      "(epoch: 48, iters: 240, time: 0.098, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.733 D_fake: 0.657 \n",
      "(epoch: 48, iters: 340, time: 0.095, data: 0.002) G_GAN: 0.733 G_L1: 0.576 D_real: 0.621 D_fake: 0.644 \n",
      "(epoch: 48, iters: 440, time: 0.094, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.743 D_fake: 0.648 \n",
      "(epoch: 48, iters: 540, time: 0.094, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.732 D_fake: 0.662 \n",
      "(epoch: 48, iters: 640, time: 0.100, data: 0.001) G_GAN: 0.792 G_L1: 3.338 D_real: 0.577 D_fake: 0.611 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 48, iters: 740, time: 0.092, data: 0.001) G_GAN: 0.751 G_L1: 0.000 D_real: 0.758 D_fake: 0.634 \n",
      "(epoch: 48, iters: 840, time: 0.095, data: 0.001) G_GAN: 0.724 G_L1: 0.000 D_real: 0.726 D_fake: 0.641 \n",
      "(epoch: 48, iters: 940, time: 0.098, data: 0.001) G_GAN: 0.778 G_L1: 1.224 D_real: 0.632 D_fake: 0.618 \n",
      "(epoch: 48, iters: 1040, time: 0.094, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.750 D_fake: 0.647 \n",
      "(epoch: 48, iters: 1140, time: 0.096, data: 0.001) G_GAN: 0.760 G_L1: 0.000 D_real: 0.762 D_fake: 0.631 \n",
      "(epoch: 48, iters: 1240, time: 0.095, data: 0.001) G_GAN: 0.825 G_L1: 2.557 D_real: 0.609 D_fake: 0.588 \n",
      "(epoch: 48, iters: 1340, time: 0.097, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.749 D_fake: 0.643 \n",
      "(epoch: 48, iters: 1440, time: 0.100, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.744 D_fake: 0.667 \n",
      "(epoch: 48, iters: 1540, time: 0.099, data: 0.001) G_GAN: 0.776 G_L1: 1.958 D_real: 0.604 D_fake: 0.622 \n",
      "(epoch: 48, iters: 1640, time: 0.099, data: 0.001) G_GAN: 0.758 G_L1: 0.000 D_real: 0.761 D_fake: 0.633 \n",
      "(epoch: 48, iters: 1740, time: 0.097, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.748 D_fake: 0.651 \n",
      "(epoch: 48, iters: 1840, time: 0.097, data: 0.001) G_GAN: 0.752 G_L1: 0.311 D_real: 0.644 D_fake: 0.638 \n",
      "(epoch: 48, iters: 1940, time: 0.107, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.768 D_fake: 0.585 \n",
      "(epoch: 48, iters: 2040, time: 0.109, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.739 D_fake: 0.654 \n",
      "(epoch: 48, iters: 2140, time: 0.100, data: 0.001) G_GAN: 0.780 G_L1: 0.787 D_real: 0.655 D_fake: 0.629 \n",
      "(epoch: 48, iters: 2240, time: 0.108, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.745 D_fake: 0.648 \n",
      "End of epoch 48 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 49, iters: 60, time: 0.105, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.735 D_fake: 0.657 \n",
      "(epoch: 49, iters: 160, time: 0.099, data: 0.001) G_GAN: 0.750 G_L1: 3.185 D_real: 0.543 D_fake: 0.646 \n",
      "(epoch: 49, iters: 260, time: 0.103, data: 0.001) G_GAN: 0.749 G_L1: 0.000 D_real: 0.752 D_fake: 0.643 \n",
      "(epoch: 49, iters: 360, time: 0.097, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.744 D_fake: 0.647 \n",
      "(epoch: 49, iters: 460, time: 0.098, data: 0.001) G_GAN: 0.788 G_L1: 2.593 D_real: 0.593 D_fake: 0.610 \n",
      "(epoch: 49, iters: 560, time: 0.097, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.750 D_fake: 0.645 \n",
      "saving the latest model (epoch 49, total_steps 110000)\n",
      "(epoch: 49, iters: 660, time: 0.100, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.725 D_fake: 0.666 \n",
      "(epoch: 49, iters: 760, time: 0.098, data: 0.001) G_GAN: 0.743 G_L1: 2.399 D_real: 0.571 D_fake: 0.651 \n",
      "(epoch: 49, iters: 860, time: 0.096, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.754 D_fake: 0.641 \n",
      "(epoch: 49, iters: 960, time: 0.096, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.731 D_fake: 0.643 \n",
      "(epoch: 49, iters: 1060, time: 0.098, data: 0.002) G_GAN: 0.730 G_L1: 0.087 D_real: 0.668 D_fake: 0.598 \n",
      "(epoch: 49, iters: 1160, time: 0.094, data: 0.001) G_GAN: 0.759 G_L1: 0.000 D_real: 0.764 D_fake: 0.634 \n",
      "(epoch: 49, iters: 1260, time: 0.098, data: 0.002) G_GAN: 0.702 G_L1: 0.000 D_real: 0.703 D_fake: 0.693 \n",
      "(epoch: 49, iters: 1360, time: 0.098, data: 0.002) G_GAN: 0.781 G_L1: 4.502 D_real: 0.539 D_fake: 0.645 \n",
      "(epoch: 49, iters: 1460, time: 0.096, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.751 D_fake: 0.639 \n",
      "(epoch: 49, iters: 1560, time: 0.095, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.731 D_fake: 0.664 \n",
      "(epoch: 49, iters: 1660, time: 0.097, data: 0.001) G_GAN: 0.744 G_L1: 1.973 D_real: 0.573 D_fake: 0.647 \n",
      "(epoch: 49, iters: 1760, time: 0.100, data: 0.001) G_GAN: 0.758 G_L1: 0.000 D_real: 0.762 D_fake: 0.637 \n",
      "(epoch: 49, iters: 1860, time: 0.099, data: 0.001) G_GAN: 0.720 G_L1: 0.000 D_real: 0.722 D_fake: 0.667 \n",
      "(epoch: 49, iters: 1960, time: 0.099, data: 0.001) G_GAN: 0.761 G_L1: 0.417 D_real: 0.649 D_fake: 0.605 \n",
      "(epoch: 49, iters: 2060, time: 0.094, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.743 D_fake: 0.649 \n",
      "(epoch: 49, iters: 2160, time: 0.096, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.710 D_fake: 0.665 \n",
      "(epoch: 49, iters: 2260, time: 0.094, data: 0.002) G_GAN: 0.813 G_L1: 3.017 D_real: 0.601 D_fake: 0.651 \n",
      "End of epoch 49 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 50, iters: 80, time: 0.112, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.734 D_fake: 0.657 \n",
      "(epoch: 50, iters: 180, time: 0.097, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.736 D_fake: 0.654 \n",
      "(epoch: 50, iters: 280, time: 0.097, data: 0.002) G_GAN: 0.761 G_L1: 1.052 D_real: 0.623 D_fake: 0.608 \n",
      "(epoch: 50, iters: 380, time: 0.099, data: 0.001) G_GAN: 0.753 G_L1: 0.000 D_real: 0.755 D_fake: 0.639 \n",
      "(epoch: 50, iters: 480, time: 0.097, data: 0.001) G_GAN: 0.712 G_L1: 0.000 D_real: 0.714 D_fake: 0.674 \n",
      "(epoch: 50, iters: 580, time: 0.100, data: 0.001) G_GAN: 0.751 G_L1: 4.208 D_real: 0.530 D_fake: 0.644 \n",
      "(epoch: 50, iters: 680, time: 0.099, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.752 D_fake: 0.646 \n",
      "(epoch: 50, iters: 780, time: 0.097, data: 0.001) G_GAN: 0.743 G_L1: 0.000 D_real: 0.748 D_fake: 0.636 \n",
      "(epoch: 50, iters: 880, time: 0.093, data: 0.002) G_GAN: 0.743 G_L1: 3.483 D_real: 0.541 D_fake: 0.645 \n",
      "(epoch: 50, iters: 980, time: 0.108, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.739 D_fake: 0.653 \n",
      "(epoch: 50, iters: 1080, time: 0.095, data: 0.001) G_GAN: 0.704 G_L1: 0.000 D_real: 0.705 D_fake: 0.683 \n",
      "(epoch: 50, iters: 1180, time: 0.111, data: 0.001) G_GAN: 0.757 G_L1: 0.978 D_real: 0.614 D_fake: 0.638 \n",
      "(epoch: 50, iters: 1280, time: 0.098, data: 0.002) G_GAN: 0.781 G_L1: 0.000 D_real: 0.833 D_fake: 0.686 \n",
      "(epoch: 50, iters: 1380, time: 0.103, data: 0.001) G_GAN: 0.685 G_L1: 0.000 D_real: 0.638 D_fake: 0.758 \n",
      "(epoch: 50, iters: 1480, time: 0.097, data: 0.001) G_GAN: 0.756 G_L1: 1.681 D_real: 0.592 D_fake: 0.665 \n",
      "(epoch: 50, iters: 1580, time: 0.096, data: 0.001) G_GAN: 0.743 G_L1: 0.000 D_real: 0.746 D_fake: 0.626 \n",
      "(epoch: 50, iters: 1680, time: 0.098, data: 0.001) G_GAN: 0.749 G_L1: 0.000 D_real: 0.750 D_fake: 0.641 \n",
      "(epoch: 50, iters: 1780, time: 0.112, data: 0.002) G_GAN: 0.746 G_L1: 3.487 D_real: 0.549 D_fake: 0.648 \n",
      "(epoch: 50, iters: 1880, time: 0.098, data: 0.001) G_GAN: 0.743 G_L1: 0.000 D_real: 0.758 D_fake: 0.563 \n",
      "(epoch: 50, iters: 1980, time: 0.098, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.728 D_fake: 0.662 \n",
      "(epoch: 50, iters: 2080, time: 0.108, data: 0.002) G_GAN: 0.715 G_L1: 2.663 D_real: 0.520 D_fake: 0.688 \n",
      "(epoch: 50, iters: 2180, time: 0.096, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.745 D_fake: 0.666 \n",
      "(epoch: 50, iters: 2280, time: 0.096, data: 0.001) G_GAN: 0.679 G_L1: 0.000 D_real: 0.683 D_fake: 0.689 \n",
      "saving the model at the end of epoch 50, iters 114000\n",
      "End of epoch 50 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 51, iters: 100, time: 0.108, data: 0.267) G_GAN: 0.773 G_L1: 2.739 D_real: 0.592 D_fake: 0.624 \n",
      "(epoch: 51, iters: 200, time: 0.097, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.739 D_fake: 0.640 \n",
      "(epoch: 51, iters: 300, time: 0.096, data: 0.001) G_GAN: 0.721 G_L1: 0.000 D_real: 0.724 D_fake: 0.635 \n",
      "(epoch: 51, iters: 400, time: 0.099, data: 0.001) G_GAN: 0.740 G_L1: 1.900 D_real: 0.580 D_fake: 0.653 \n",
      "(epoch: 51, iters: 500, time: 0.097, data: 0.001) G_GAN: 0.753 G_L1: 0.000 D_real: 0.757 D_fake: 0.636 \n",
      "(epoch: 51, iters: 600, time: 0.111, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.750 D_fake: 0.641 \n",
      "(epoch: 51, iters: 700, time: 0.100, data: 0.001) G_GAN: 0.825 G_L1: 2.269 D_real: 0.622 D_fake: 0.590 \n",
      "(epoch: 51, iters: 800, time: 0.098, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.729 D_fake: 0.664 \n",
      "(epoch: 51, iters: 900, time: 0.093, data: 0.001) G_GAN: 0.714 G_L1: 0.000 D_real: 0.715 D_fake: 0.678 \n",
      "(epoch: 51, iters: 1000, time: 0.099, data: 0.001) G_GAN: 0.758 G_L1: 2.064 D_real: 0.581 D_fake: 0.635 \n",
      "saving the latest model (epoch 51, total_steps 115000)\n",
      "(epoch: 51, iters: 1100, time: 0.097, data: 0.001) G_GAN: 0.776 G_L1: 0.000 D_real: 0.778 D_fake: 0.617 \n",
      "(epoch: 51, iters: 1200, time: 0.096, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.739 D_fake: 0.652 \n",
      "(epoch: 51, iters: 1300, time: 0.107, data: 0.002) G_GAN: 0.824 G_L1: 3.100 D_real: 0.599 D_fake: 0.583 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 51, iters: 1400, time: 0.112, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.748 D_fake: 0.644 \n",
      "(epoch: 51, iters: 1500, time: 0.098, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.724 D_fake: 0.608 \n",
      "(epoch: 51, iters: 1600, time: 0.097, data: 0.001) G_GAN: 0.756 G_L1: 1.704 D_real: 0.595 D_fake: 0.637 \n",
      "(epoch: 51, iters: 1700, time: 0.102, data: 0.001) G_GAN: 0.787 G_L1: 0.000 D_real: 0.793 D_fake: 0.632 \n",
      "(epoch: 51, iters: 1800, time: 0.096, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.729 D_fake: 0.661 \n",
      "(epoch: 51, iters: 1900, time: 0.099, data: 0.001) G_GAN: 0.732 G_L1: 4.005 D_real: 0.515 D_fake: 0.656 \n",
      "(epoch: 51, iters: 2000, time: 0.097, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.757 D_fake: 0.623 \n",
      "(epoch: 51, iters: 2100, time: 0.098, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.731 D_fake: 0.660 \n",
      "(epoch: 51, iters: 2200, time: 0.099, data: 0.002) G_GAN: 0.757 G_L1: 1.935 D_real: 0.586 D_fake: 0.639 \n",
      "End of epoch 51 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 52, iters: 20, time: 0.106, data: 0.001) G_GAN: 0.771 G_L1: 0.000 D_real: 0.776 D_fake: 0.570 \n",
      "(epoch: 52, iters: 120, time: 0.095, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.734 D_fake: 0.655 \n",
      "(epoch: 52, iters: 220, time: 0.100, data: 0.001) G_GAN: 0.763 G_L1: 3.205 D_real: 0.558 D_fake: 0.659 \n",
      "(epoch: 52, iters: 320, time: 0.108, data: 0.001) G_GAN: 0.763 G_L1: 0.000 D_real: 0.766 D_fake: 0.629 \n",
      "(epoch: 52, iters: 420, time: 0.096, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.724 D_fake: 0.665 \n",
      "(epoch: 52, iters: 520, time: 0.097, data: 0.001) G_GAN: 0.783 G_L1: 1.603 D_real: 0.626 D_fake: 0.687 \n",
      "(epoch: 52, iters: 620, time: 0.098, data: 0.001) G_GAN: 0.753 G_L1: 0.000 D_real: 0.756 D_fake: 0.651 \n",
      "(epoch: 52, iters: 720, time: 0.098, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.732 D_fake: 0.657 \n",
      "(epoch: 52, iters: 820, time: 0.095, data: 0.001) G_GAN: 0.776 G_L1: 2.187 D_real: 0.588 D_fake: 0.630 \n",
      "(epoch: 52, iters: 920, time: 0.095, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.729 D_fake: 0.665 \n",
      "(epoch: 52, iters: 1020, time: 0.098, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.694 D_fake: 0.698 \n",
      "(epoch: 52, iters: 1120, time: 0.097, data: 0.002) G_GAN: 0.791 G_L1: 1.002 D_real: 0.657 D_fake: 0.606 \n",
      "(epoch: 52, iters: 1220, time: 0.097, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.741 D_fake: 0.650 \n",
      "(epoch: 52, iters: 1320, time: 0.111, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.722 D_fake: 0.662 \n",
      "(epoch: 52, iters: 1420, time: 0.098, data: 0.001) G_GAN: 0.768 G_L1: 2.201 D_real: 0.592 D_fake: 0.628 \n",
      "(epoch: 52, iters: 1520, time: 0.100, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.642 \n",
      "(epoch: 52, iters: 1620, time: 0.098, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.745 D_fake: 0.653 \n",
      "(epoch: 52, iters: 1720, time: 0.099, data: 0.001) G_GAN: 0.762 G_L1: 3.384 D_real: 0.552 D_fake: 0.638 \n",
      "(epoch: 52, iters: 1820, time: 0.099, data: 0.001) G_GAN: 0.768 G_L1: 0.000 D_real: 0.771 D_fake: 0.624 \n",
      "(epoch: 52, iters: 1920, time: 0.097, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.743 D_fake: 0.576 \n",
      "(epoch: 52, iters: 2020, time: 0.098, data: 0.001) G_GAN: 0.751 G_L1: 1.903 D_real: 0.589 D_fake: 0.643 \n",
      "(epoch: 52, iters: 2120, time: 0.098, data: 0.001) G_GAN: 0.819 G_L1: 0.000 D_real: 0.838 D_fake: 0.612 \n",
      "(epoch: 52, iters: 2220, time: 0.099, data: 0.002) G_GAN: 0.659 G_L1: 0.000 D_real: 0.652 D_fake: 0.742 \n",
      "End of epoch 52 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 53, iters: 40, time: 0.105, data: 0.001) G_GAN: 0.767 G_L1: 1.545 D_real: 0.601 D_fake: 0.631 \n",
      "(epoch: 53, iters: 140, time: 0.095, data: 0.001) G_GAN: 0.777 G_L1: 0.000 D_real: 0.784 D_fake: 0.620 \n",
      "(epoch: 53, iters: 240, time: 0.097, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.739 D_fake: 0.652 \n",
      "(epoch: 53, iters: 340, time: 0.097, data: 0.002) G_GAN: 0.775 G_L1: 0.576 D_real: 0.654 D_fake: 0.623 \n",
      "(epoch: 53, iters: 440, time: 0.095, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.734 D_fake: 0.657 \n",
      "(epoch: 53, iters: 540, time: 0.093, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.746 D_fake: 0.645 \n",
      "(epoch: 53, iters: 640, time: 0.099, data: 0.002) G_GAN: 0.756 G_L1: 3.338 D_real: 0.555 D_fake: 0.646 \n",
      "(epoch: 53, iters: 740, time: 0.094, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.766 D_fake: 0.623 \n",
      "(epoch: 53, iters: 840, time: 0.106, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.733 D_fake: 0.649 \n",
      "(epoch: 53, iters: 940, time: 0.108, data: 0.001) G_GAN: 0.793 G_L1: 1.224 D_real: 0.634 D_fake: 0.610 \n",
      "(epoch: 53, iters: 1040, time: 0.095, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.753 D_fake: 0.644 \n",
      "(epoch: 53, iters: 1140, time: 0.098, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.746 D_fake: 0.646 \n",
      "(epoch: 53, iters: 1240, time: 0.095, data: 0.001) G_GAN: 0.822 G_L1: 2.557 D_real: 0.617 D_fake: 0.649 \n",
      "(epoch: 53, iters: 1340, time: 0.103, data: 0.002) G_GAN: 0.810 G_L1: 0.000 D_real: 0.838 D_fake: 0.657 \n",
      "(epoch: 53, iters: 1440, time: 0.098, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.735 D_fake: 0.673 \n",
      "saving the latest model (epoch 53, total_steps 120000)\n",
      "(epoch: 53, iters: 1540, time: 0.101, data: 0.002) G_GAN: 0.754 G_L1: 1.958 D_real: 0.581 D_fake: 0.651 \n",
      "(epoch: 53, iters: 1640, time: 0.095, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.737 D_fake: 0.654 \n",
      "(epoch: 53, iters: 1740, time: 0.110, data: 0.001) G_GAN: 0.720 G_L1: 0.000 D_real: 0.722 D_fake: 0.666 \n",
      "(epoch: 53, iters: 1840, time: 0.106, data: 0.002) G_GAN: 0.739 G_L1: 0.311 D_real: 0.642 D_fake: 0.653 \n",
      "(epoch: 53, iters: 1940, time: 0.100, data: 0.001) G_GAN: 0.744 G_L1: 0.000 D_real: 0.745 D_fake: 0.646 \n",
      "(epoch: 53, iters: 2040, time: 0.100, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.728 D_fake: 0.662 \n",
      "(epoch: 53, iters: 2140, time: 0.109, data: 0.001) G_GAN: 0.772 G_L1: 0.787 D_real: 0.649 D_fake: 0.653 \n",
      "(epoch: 53, iters: 2240, time: 0.097, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.724 D_fake: 0.648 \n",
      "End of epoch 53 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 54, iters: 60, time: 0.104, data: 0.001) G_GAN: 0.708 G_L1: 0.000 D_real: 0.706 D_fake: 0.669 \n",
      "(epoch: 54, iters: 160, time: 0.098, data: 0.001) G_GAN: 0.744 G_L1: 3.185 D_real: 0.551 D_fake: 0.652 \n",
      "(epoch: 54, iters: 260, time: 0.109, data: 0.003) G_GAN: 0.832 G_L1: 0.000 D_real: 0.871 D_fake: 0.579 \n",
      "(epoch: 54, iters: 360, time: 0.096, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.755 D_fake: 0.637 \n",
      "(epoch: 54, iters: 460, time: 0.101, data: 0.001) G_GAN: 0.783 G_L1: 2.593 D_real: 0.596 D_fake: 0.611 \n",
      "(epoch: 54, iters: 560, time: 0.097, data: 0.001) G_GAN: 0.771 G_L1: 0.000 D_real: 0.788 D_fake: 0.618 \n",
      "(epoch: 54, iters: 660, time: 0.099, data: 0.001) G_GAN: 0.706 G_L1: 0.000 D_real: 0.706 D_fake: 0.685 \n",
      "(epoch: 54, iters: 760, time: 0.098, data: 0.002) G_GAN: 0.716 G_L1: 2.399 D_real: 0.551 D_fake: 0.677 \n",
      "(epoch: 54, iters: 860, time: 0.096, data: 0.003) G_GAN: 0.748 G_L1: 0.000 D_real: 0.759 D_fake: 0.554 \n",
      "(epoch: 54, iters: 960, time: 0.096, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.700 D_fake: 0.645 \n",
      "(epoch: 54, iters: 1060, time: 0.095, data: 0.002) G_GAN: 0.731 G_L1: 0.087 D_real: 0.676 D_fake: 0.657 \n",
      "(epoch: 54, iters: 1160, time: 0.092, data: 0.001) G_GAN: 0.768 G_L1: 0.000 D_real: 0.775 D_fake: 0.622 \n",
      "(epoch: 54, iters: 1260, time: 0.099, data: 0.001) G_GAN: 0.708 G_L1: 0.000 D_real: 0.709 D_fake: 0.668 \n",
      "(epoch: 54, iters: 1360, time: 0.097, data: 0.001) G_GAN: 0.739 G_L1: 4.502 D_real: 0.517 D_fake: 0.654 \n",
      "(epoch: 54, iters: 1460, time: 0.096, data: 0.002) G_GAN: 0.798 G_L1: 0.000 D_real: 0.810 D_fake: 0.630 \n",
      "(epoch: 54, iters: 1560, time: 0.098, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.717 D_fake: 0.671 \n",
      "(epoch: 54, iters: 1660, time: 0.095, data: 0.001) G_GAN: 0.762 G_L1: 1.973 D_real: 0.584 D_fake: 0.634 \n",
      "(epoch: 54, iters: 1760, time: 0.098, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.744 D_fake: 0.647 \n",
      "(epoch: 54, iters: 1860, time: 0.097, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.730 D_fake: 0.652 \n",
      "(epoch: 54, iters: 1960, time: 0.098, data: 0.001) G_GAN: 0.754 G_L1: 0.417 D_real: 0.642 D_fake: 0.641 \n",
      "(epoch: 54, iters: 2060, time: 0.094, data: 0.001) G_GAN: 0.724 G_L1: 0.000 D_real: 0.725 D_fake: 0.666 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 54, iters: 2160, time: 0.098, data: 0.001) G_GAN: 0.614 G_L1: 0.000 D_real: 0.675 D_fake: 0.652 \n",
      "(epoch: 54, iters: 2260, time: 0.096, data: 0.001) G_GAN: 0.875 G_L1: 3.017 D_real: 0.635 D_fake: 0.612 \n",
      "End of epoch 54 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 55, iters: 80, time: 0.103, data: 0.001) G_GAN: 0.713 G_L1: 0.000 D_real: 0.721 D_fake: 0.671 \n",
      "(epoch: 55, iters: 180, time: 0.097, data: 0.001) G_GAN: 0.721 G_L1: 0.000 D_real: 0.724 D_fake: 0.683 \n",
      "(epoch: 55, iters: 280, time: 0.098, data: 0.001) G_GAN: 0.760 G_L1: 1.052 D_real: 0.616 D_fake: 0.638 \n",
      "(epoch: 55, iters: 380, time: 0.098, data: 0.001) G_GAN: 0.758 G_L1: 0.000 D_real: 0.771 D_fake: 0.674 \n",
      "(epoch: 55, iters: 480, time: 0.106, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 55, iters: 580, time: 0.098, data: 0.001) G_GAN: 0.749 G_L1: 4.208 D_real: 0.532 D_fake: 0.644 \n",
      "(epoch: 55, iters: 680, time: 0.098, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.748 D_fake: 0.635 \n",
      "(epoch: 55, iters: 780, time: 0.107, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.729 D_fake: 0.660 \n",
      "(epoch: 55, iters: 880, time: 0.105, data: 0.001) G_GAN: 0.760 G_L1: 3.483 D_real: 0.536 D_fake: 0.494 \n",
      "(epoch: 55, iters: 980, time: 0.108, data: 0.001) G_GAN: 0.703 G_L1: 0.000 D_real: 0.707 D_fake: 0.684 \n",
      "(epoch: 55, iters: 1080, time: 0.094, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.710 D_fake: 0.678 \n",
      "(epoch: 55, iters: 1180, time: 0.108, data: 0.001) G_GAN: 0.743 G_L1: 0.978 D_real: 0.615 D_fake: 0.655 \n",
      "(epoch: 55, iters: 1280, time: 0.098, data: 0.002) G_GAN: 0.837 G_L1: 0.000 D_real: 0.846 D_fake: 0.567 \n",
      "(epoch: 55, iters: 1380, time: 0.095, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.724 D_fake: 0.667 \n",
      "(epoch: 55, iters: 1480, time: 0.096, data: 0.001) G_GAN: 0.742 G_L1: 1.681 D_real: 0.584 D_fake: 0.647 \n",
      "(epoch: 55, iters: 1580, time: 0.098, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.768 D_fake: 0.647 \n",
      "(epoch: 55, iters: 1680, time: 0.097, data: 0.001) G_GAN: 0.752 G_L1: 0.000 D_real: 0.754 D_fake: 0.642 \n",
      "(epoch: 55, iters: 1780, time: 0.097, data: 0.001) G_GAN: 0.750 G_L1: 3.487 D_real: 0.550 D_fake: 0.644 \n",
      "(epoch: 55, iters: 1880, time: 0.099, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.749 D_fake: 0.644 \n",
      "saving the latest model (epoch 55, total_steps 125000)\n",
      "(epoch: 55, iters: 1980, time: 0.100, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.736 D_fake: 0.655 \n",
      "(epoch: 55, iters: 2080, time: 0.096, data: 0.001) G_GAN: 0.739 G_L1: 2.663 D_real: 0.535 D_fake: 0.659 \n",
      "(epoch: 55, iters: 2180, time: 0.110, data: 0.001) G_GAN: 0.712 G_L1: 0.000 D_real: 0.733 D_fake: 0.553 \n",
      "(epoch: 55, iters: 2280, time: 0.096, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.752 D_fake: 0.642 \n",
      "saving the model at the end of epoch 55, iters 125400\n",
      "End of epoch 55 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 56, iters: 100, time: 0.104, data: 0.284) G_GAN: 0.831 G_L1: 2.739 D_real: 0.616 D_fake: 0.578 \n",
      "(epoch: 56, iters: 200, time: 0.097, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.743 D_fake: 0.651 \n",
      "(epoch: 56, iters: 300, time: 0.106, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.724 D_fake: 0.668 \n",
      "(epoch: 56, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.730 G_L1: 1.900 D_real: 0.565 D_fake: 0.599 \n",
      "(epoch: 56, iters: 500, time: 0.100, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.735 D_fake: 0.654 \n",
      "(epoch: 56, iters: 600, time: 0.108, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.743 D_fake: 0.644 \n",
      "(epoch: 56, iters: 700, time: 0.098, data: 0.001) G_GAN: 0.885 G_L1: 2.269 D_real: 0.663 D_fake: 0.548 \n",
      "(epoch: 56, iters: 800, time: 0.097, data: 0.002) G_GAN: 0.775 G_L1: 0.000 D_real: 0.781 D_fake: 0.618 \n",
      "(epoch: 56, iters: 900, time: 0.092, data: 0.002) G_GAN: 0.686 G_L1: 0.000 D_real: 0.712 D_fake: 0.337 \n",
      "(epoch: 56, iters: 1000, time: 0.098, data: 0.002) G_GAN: 0.813 G_L1: 2.064 D_real: 0.610 D_fake: 0.619 \n",
      "(epoch: 56, iters: 1100, time: 0.097, data: 0.001) G_GAN: 0.757 G_L1: 0.000 D_real: 0.762 D_fake: 0.630 \n",
      "(epoch: 56, iters: 1200, time: 0.109, data: 0.001) G_GAN: 0.718 G_L1: 0.000 D_real: 0.720 D_fake: 0.669 \n",
      "(epoch: 56, iters: 1300, time: 0.096, data: 0.002) G_GAN: 0.742 G_L1: 3.100 D_real: 0.543 D_fake: 0.692 \n",
      "(epoch: 56, iters: 1400, time: 0.099, data: 0.002) G_GAN: 0.778 G_L1: 0.000 D_real: 0.780 D_fake: 0.618 \n",
      "(epoch: 56, iters: 1500, time: 0.095, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.721 D_fake: 0.670 \n",
      "(epoch: 56, iters: 1600, time: 0.096, data: 0.002) G_GAN: 0.824 G_L1: 1.704 D_real: 0.655 D_fake: 0.584 \n",
      "(epoch: 56, iters: 1700, time: 0.097, data: 0.002) G_GAN: 0.778 G_L1: 0.000 D_real: 0.782 D_fake: 0.635 \n",
      "(epoch: 56, iters: 1800, time: 0.096, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.728 D_fake: 0.662 \n",
      "(epoch: 56, iters: 1900, time: 0.100, data: 0.002) G_GAN: 0.757 G_L1: 4.005 D_real: 0.527 D_fake: 0.651 \n",
      "(epoch: 56, iters: 2000, time: 0.097, data: 0.001) G_GAN: 0.760 G_L1: 0.000 D_real: 0.763 D_fake: 0.633 \n",
      "(epoch: 56, iters: 2100, time: 0.095, data: 0.001) G_GAN: 0.523 G_L1: 0.000 D_real: 0.625 D_fake: 0.657 \n",
      "(epoch: 56, iters: 2200, time: 0.108, data: 0.001) G_GAN: 0.745 G_L1: 1.935 D_real: 0.569 D_fake: 0.630 \n",
      "End of epoch 56 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 57, iters: 20, time: 0.108, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.742 D_fake: 0.659 \n",
      "(epoch: 57, iters: 120, time: 0.110, data: 0.001) G_GAN: 0.720 G_L1: 0.000 D_real: 0.722 D_fake: 0.667 \n",
      "(epoch: 57, iters: 220, time: 0.097, data: 0.001) G_GAN: 0.774 G_L1: 3.205 D_real: 0.564 D_fake: 0.657 \n",
      "(epoch: 57, iters: 320, time: 0.097, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.738 D_fake: 0.641 \n",
      "(epoch: 57, iters: 420, time: 0.109, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.701 D_fake: 0.679 \n",
      "(epoch: 57, iters: 520, time: 0.096, data: 0.001) G_GAN: 0.766 G_L1: 1.603 D_real: 0.604 D_fake: 0.621 \n",
      "(epoch: 57, iters: 620, time: 0.099, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.643 \n",
      "(epoch: 57, iters: 720, time: 0.099, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.731 D_fake: 0.659 \n",
      "(epoch: 57, iters: 820, time: 0.094, data: 0.002) G_GAN: 0.786 G_L1: 2.187 D_real: 0.611 D_fake: 0.611 \n",
      "(epoch: 57, iters: 920, time: 0.096, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.694 D_fake: 0.696 \n",
      "(epoch: 57, iters: 1020, time: 0.108, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.696 D_fake: 0.668 \n",
      "(epoch: 57, iters: 1120, time: 0.112, data: 0.001) G_GAN: 0.708 G_L1: 1.002 D_real: 0.578 D_fake: 0.683 \n",
      "(epoch: 57, iters: 1220, time: 0.109, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.730 D_fake: 0.656 \n",
      "(epoch: 57, iters: 1320, time: 0.100, data: 0.001) G_GAN: 0.715 G_L1: 0.000 D_real: 0.717 D_fake: 0.672 \n",
      "(epoch: 57, iters: 1420, time: 0.098, data: 0.001) G_GAN: 0.731 G_L1: 2.201 D_real: 0.575 D_fake: 0.611 \n",
      "(epoch: 57, iters: 1520, time: 0.099, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.739 D_fake: 0.661 \n",
      "(epoch: 57, iters: 1620, time: 0.097, data: 0.001) G_GAN: 0.709 G_L1: 0.000 D_real: 0.712 D_fake: 0.676 \n",
      "(epoch: 57, iters: 1720, time: 0.099, data: 0.001) G_GAN: 0.763 G_L1: 3.384 D_real: 0.549 D_fake: 0.642 \n",
      "(epoch: 57, iters: 1820, time: 0.100, data: 0.001) G_GAN: 0.765 G_L1: 0.000 D_real: 0.769 D_fake: 0.632 \n",
      "(epoch: 57, iters: 1920, time: 0.097, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.729 D_fake: 0.576 \n",
      "(epoch: 57, iters: 2020, time: 0.097, data: 0.001) G_GAN: 0.750 G_L1: 1.903 D_real: 0.586 D_fake: 0.645 \n",
      "(epoch: 57, iters: 2120, time: 0.096, data: 0.002) G_GAN: 0.854 G_L1: 0.000 D_real: 0.889 D_fake: 0.607 \n",
      "(epoch: 57, iters: 2220, time: 0.100, data: 0.001) G_GAN: 0.665 G_L1: 0.000 D_real: 0.664 D_fake: 0.726 \n",
      "End of epoch 57 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 58, iters: 40, time: 0.107, data: 0.002) G_GAN: 0.736 G_L1: 1.545 D_real: 0.572 D_fake: 0.671 \n",
      "saving the latest model (epoch 58, total_steps 130000)\n",
      "(epoch: 58, iters: 140, time: 0.096, data: 0.001) G_GAN: 0.773 G_L1: 0.000 D_real: 0.780 D_fake: 0.614 \n",
      "(epoch: 58, iters: 240, time: 0.099, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.739 D_fake: 0.662 \n",
      "(epoch: 58, iters: 340, time: 0.096, data: 0.002) G_GAN: 0.748 G_L1: 0.576 D_real: 0.634 D_fake: 0.658 \n",
      "(epoch: 58, iters: 440, time: 0.096, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.727 D_fake: 0.665 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 58, iters: 540, time: 0.093, data: 0.001) G_GAN: 0.713 G_L1: 0.000 D_real: 0.714 D_fake: 0.675 \n",
      "(epoch: 58, iters: 640, time: 0.096, data: 0.002) G_GAN: 0.775 G_L1: 3.338 D_real: 0.566 D_fake: 0.625 \n",
      "(epoch: 58, iters: 740, time: 0.096, data: 0.001) G_GAN: 0.777 G_L1: 0.000 D_real: 0.796 D_fake: 0.661 \n",
      "(epoch: 58, iters: 840, time: 0.095, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.729 D_fake: 0.645 \n",
      "(epoch: 58, iters: 940, time: 0.101, data: 0.002) G_GAN: 0.743 G_L1: 1.224 D_real: 0.604 D_fake: 0.649 \n",
      "(epoch: 58, iters: 1040, time: 0.095, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.737 D_fake: 0.656 \n",
      "(epoch: 58, iters: 1140, time: 0.110, data: 0.001) G_GAN: 0.736 G_L1: 0.000 D_real: 0.737 D_fake: 0.652 \n",
      "(epoch: 58, iters: 1240, time: 0.095, data: 0.001) G_GAN: 0.825 G_L1: 2.557 D_real: 0.610 D_fake: 0.587 \n",
      "(epoch: 58, iters: 1340, time: 0.098, data: 0.001) G_GAN: 0.765 G_L1: 0.000 D_real: 0.766 D_fake: 0.629 \n",
      "(epoch: 58, iters: 1440, time: 0.102, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.767 D_fake: 0.629 \n",
      "(epoch: 58, iters: 1540, time: 0.097, data: 0.001) G_GAN: 0.766 G_L1: 1.958 D_real: 0.589 D_fake: 0.654 \n",
      "(epoch: 58, iters: 1640, time: 0.100, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.756 D_fake: 0.644 \n",
      "(epoch: 58, iters: 1740, time: 0.100, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.756 D_fake: 0.646 \n",
      "(epoch: 58, iters: 1840, time: 0.111, data: 0.002) G_GAN: 0.751 G_L1: 0.311 D_real: 0.642 D_fake: 0.642 \n",
      "(epoch: 58, iters: 1940, time: 0.099, data: 0.001) G_GAN: 0.766 G_L1: 0.000 D_real: 0.768 D_fake: 0.632 \n",
      "(epoch: 58, iters: 2040, time: 0.110, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.734 D_fake: 0.656 \n",
      "(epoch: 58, iters: 2140, time: 0.100, data: 0.001) G_GAN: 0.791 G_L1: 0.787 D_real: 0.660 D_fake: 0.608 \n",
      "(epoch: 58, iters: 2240, time: 0.108, data: 0.001) G_GAN: 0.708 G_L1: 0.000 D_real: 0.709 D_fake: 0.682 \n",
      "End of epoch 58 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 59, iters: 60, time: 0.117, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.741 D_fake: 0.652 \n",
      "(epoch: 59, iters: 160, time: 0.101, data: 0.001) G_GAN: 0.740 G_L1: 3.185 D_real: 0.531 D_fake: 0.665 \n",
      "(epoch: 59, iters: 260, time: 0.095, data: 0.002) G_GAN: 0.774 G_L1: 0.000 D_real: 0.783 D_fake: 0.642 \n",
      "(epoch: 59, iters: 360, time: 0.097, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.737 D_fake: 0.659 \n",
      "(epoch: 59, iters: 460, time: 0.098, data: 0.002) G_GAN: 0.769 G_L1: 2.593 D_real: 0.575 D_fake: 0.657 \n",
      "(epoch: 59, iters: 560, time: 0.106, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.756 D_fake: 0.639 \n",
      "(epoch: 59, iters: 660, time: 0.098, data: 0.001) G_GAN: 0.743 G_L1: 0.000 D_real: 0.745 D_fake: 0.638 \n",
      "(epoch: 59, iters: 760, time: 0.097, data: 0.001) G_GAN: 0.745 G_L1: 2.399 D_real: 0.569 D_fake: 0.655 \n",
      "(epoch: 59, iters: 860, time: 0.096, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.757 D_fake: 0.640 \n",
      "(epoch: 59, iters: 960, time: 0.107, data: 0.001) G_GAN: 0.808 G_L1: 0.000 D_real: 0.851 D_fake: 0.581 \n",
      "(epoch: 59, iters: 1060, time: 0.095, data: 0.001) G_GAN: 0.759 G_L1: 0.087 D_real: 0.699 D_fake: 0.631 \n",
      "(epoch: 59, iters: 1160, time: 0.095, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.738 D_fake: 0.655 \n",
      "(epoch: 59, iters: 1260, time: 0.098, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.707 D_fake: 0.691 \n",
      "(epoch: 59, iters: 1360, time: 0.098, data: 0.001) G_GAN: 0.746 G_L1: 4.502 D_real: 0.511 D_fake: 0.626 \n",
      "(epoch: 59, iters: 1460, time: 0.098, data: 0.001) G_GAN: 0.777 G_L1: 0.000 D_real: 0.786 D_fake: 0.614 \n",
      "(epoch: 59, iters: 1560, time: 0.094, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.714 D_fake: 0.705 \n",
      "(epoch: 59, iters: 1660, time: 0.098, data: 0.001) G_GAN: 0.751 G_L1: 1.973 D_real: 0.579 D_fake: 0.642 \n",
      "(epoch: 59, iters: 1760, time: 0.099, data: 0.001) G_GAN: 0.781 G_L1: 0.000 D_real: 0.785 D_fake: 0.614 \n",
      "(epoch: 59, iters: 1860, time: 0.110, data: 0.001) G_GAN: 0.719 G_L1: 0.000 D_real: 0.720 D_fake: 0.671 \n",
      "(epoch: 59, iters: 1960, time: 0.118, data: 0.002) G_GAN: 0.750 G_L1: 0.417 D_real: 0.646 D_fake: 0.645 \n",
      "(epoch: 59, iters: 2060, time: 0.106, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.732 D_fake: 0.629 \n",
      "(epoch: 59, iters: 2160, time: 0.098, data: 0.001) G_GAN: 0.662 G_L1: 0.000 D_real: 0.669 D_fake: 0.720 \n",
      "(epoch: 59, iters: 2260, time: 0.095, data: 0.001) G_GAN: 0.769 G_L1: 3.017 D_real: 0.561 D_fake: 0.631 \n",
      "End of epoch 59 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 60, iters: 80, time: 0.103, data: 0.001) G_GAN: 0.749 G_L1: 0.000 D_real: 0.750 D_fake: 0.643 \n",
      "(epoch: 60, iters: 180, time: 0.097, data: 0.001) G_GAN: 0.662 G_L1: 0.000 D_real: 0.622 D_fake: 0.775 \n",
      "(epoch: 60, iters: 280, time: 0.099, data: 0.002) G_GAN: 0.764 G_L1: 1.052 D_real: 0.620 D_fake: 0.632 \n",
      "(epoch: 60, iters: 380, time: 0.099, data: 0.001) G_GAN: 0.788 G_L1: 0.000 D_real: 0.790 D_fake: 0.601 \n",
      "(epoch: 60, iters: 480, time: 0.109, data: 0.001) G_GAN: 0.714 G_L1: 0.000 D_real: 0.717 D_fake: 0.674 \n",
      "saving the latest model (epoch 60, total_steps 135000)\n",
      "(epoch: 60, iters: 580, time: 0.098, data: 0.001) G_GAN: 0.758 G_L1: 4.208 D_real: 0.533 D_fake: 0.632 \n",
      "(epoch: 60, iters: 680, time: 0.097, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.744 D_fake: 0.648 \n",
      "(epoch: 60, iters: 780, time: 0.095, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.737 D_fake: 0.643 \n",
      "(epoch: 60, iters: 880, time: 0.093, data: 0.002) G_GAN: 0.783 G_L1: 3.483 D_real: 0.533 D_fake: 0.639 \n",
      "(epoch: 60, iters: 980, time: 0.106, data: 0.001) G_GAN: 0.771 G_L1: 0.000 D_real: 0.775 D_fake: 0.641 \n",
      "(epoch: 60, iters: 1080, time: 0.097, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.708 D_fake: 0.680 \n",
      "(epoch: 60, iters: 1180, time: 0.111, data: 0.001) G_GAN: 0.771 G_L1: 0.978 D_real: 0.638 D_fake: 0.617 \n",
      "(epoch: 60, iters: 1280, time: 0.114, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.759 D_fake: 0.633 \n",
      "(epoch: 60, iters: 1380, time: 0.108, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.730 D_fake: 0.660 \n",
      "(epoch: 60, iters: 1480, time: 0.097, data: 0.002) G_GAN: 0.742 G_L1: 1.681 D_real: 0.586 D_fake: 0.654 \n",
      "(epoch: 60, iters: 1580, time: 0.097, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.741 D_fake: 0.650 \n",
      "(epoch: 60, iters: 1680, time: 0.098, data: 0.001) G_GAN: 0.749 G_L1: 0.000 D_real: 0.751 D_fake: 0.624 \n",
      "(epoch: 60, iters: 1780, time: 0.096, data: 0.001) G_GAN: 0.741 G_L1: 3.487 D_real: 0.535 D_fake: 0.652 \n",
      "(epoch: 60, iters: 1880, time: 0.097, data: 0.001) G_GAN: 0.759 G_L1: 0.000 D_real: 0.761 D_fake: 0.634 \n",
      "(epoch: 60, iters: 1980, time: 0.099, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.740 D_fake: 0.651 \n",
      "(epoch: 60, iters: 2080, time: 0.098, data: 0.002) G_GAN: 0.715 G_L1: 2.663 D_real: 0.522 D_fake: 0.686 \n",
      "(epoch: 60, iters: 2180, time: 0.097, data: 0.001) G_GAN: 0.761 G_L1: 0.000 D_real: 0.766 D_fake: 0.619 \n",
      "(epoch: 60, iters: 2280, time: 0.096, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.731 D_fake: 0.659 \n",
      "saving the model at the end of epoch 60, iters 136800\n",
      "End of epoch 60 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 61, iters: 100, time: 0.115, data: 0.286) G_GAN: 0.785 G_L1: 2.739 D_real: 0.579 D_fake: 0.648 \n",
      "(epoch: 61, iters: 200, time: 0.096, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.745 D_fake: 0.655 \n",
      "(epoch: 61, iters: 300, time: 0.095, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.747 D_fake: 0.644 \n",
      "(epoch: 61, iters: 400, time: 0.108, data: 0.002) G_GAN: 0.734 G_L1: 1.900 D_real: 0.574 D_fake: 0.660 \n",
      "(epoch: 61, iters: 500, time: 0.108, data: 0.001) G_GAN: 0.744 G_L1: 0.000 D_real: 0.746 D_fake: 0.645 \n",
      "(epoch: 61, iters: 600, time: 0.111, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.736 D_fake: 0.654 \n",
      "(epoch: 61, iters: 700, time: 0.098, data: 0.001) G_GAN: 0.792 G_L1: 2.269 D_real: 0.605 D_fake: 0.610 \n",
      "(epoch: 61, iters: 800, time: 0.098, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.759 D_fake: 0.637 \n",
      "(epoch: 61, iters: 900, time: 0.096, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.689 D_fake: 0.809 \n",
      "(epoch: 61, iters: 1000, time: 0.097, data: 0.002) G_GAN: 0.783 G_L1: 2.064 D_real: 0.592 D_fake: 0.620 \n",
      "(epoch: 61, iters: 1100, time: 0.099, data: 0.002) G_GAN: 0.776 G_L1: 0.000 D_real: 0.781 D_fake: 0.626 \n",
      "(epoch: 61, iters: 1200, time: 0.097, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.728 D_fake: 0.645 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 61, iters: 1300, time: 0.098, data: 0.002) G_GAN: 0.801 G_L1: 3.100 D_real: 0.585 D_fake: 0.602 \n",
      "(epoch: 61, iters: 1400, time: 0.098, data: 0.002) G_GAN: 0.802 G_L1: 0.000 D_real: 0.822 D_fake: 0.586 \n",
      "(epoch: 61, iters: 1500, time: 0.108, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.728 D_fake: 0.656 \n",
      "(epoch: 61, iters: 1600, time: 0.099, data: 0.002) G_GAN: 0.774 G_L1: 1.704 D_real: 0.610 D_fake: 0.651 \n",
      "(epoch: 61, iters: 1700, time: 0.101, data: 0.001) G_GAN: 0.772 G_L1: 0.000 D_real: 0.774 D_fake: 0.621 \n",
      "(epoch: 61, iters: 1800, time: 0.096, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.734 D_fake: 0.637 \n",
      "(epoch: 61, iters: 1900, time: 0.099, data: 0.001) G_GAN: 0.753 G_L1: 4.005 D_real: 0.528 D_fake: 0.647 \n",
      "(epoch: 61, iters: 2000, time: 0.113, data: 0.001) G_GAN: 0.755 G_L1: 0.000 D_real: 0.757 D_fake: 0.605 \n",
      "(epoch: 61, iters: 2100, time: 0.095, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.720 D_fake: 0.690 \n",
      "(epoch: 61, iters: 2200, time: 0.098, data: 0.001) G_GAN: 0.737 G_L1: 1.935 D_real: 0.557 D_fake: 0.660 \n",
      "End of epoch 61 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 62, iters: 20, time: 0.114, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.741 D_fake: 0.661 \n",
      "(epoch: 62, iters: 120, time: 0.098, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.712 D_fake: 0.676 \n",
      "(epoch: 62, iters: 220, time: 0.095, data: 0.001) G_GAN: 0.738 G_L1: 3.205 D_real: 0.537 D_fake: 0.663 \n",
      "(epoch: 62, iters: 320, time: 0.095, data: 0.001) G_GAN: 0.772 G_L1: 0.000 D_real: 0.777 D_fake: 0.601 \n",
      "(epoch: 62, iters: 420, time: 0.096, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.703 D_fake: 0.669 \n",
      "(epoch: 62, iters: 520, time: 0.105, data: 0.001) G_GAN: 0.737 G_L1: 1.603 D_real: 0.578 D_fake: 0.656 \n",
      "(epoch: 62, iters: 620, time: 0.096, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.733 D_fake: 0.666 \n",
      "(epoch: 62, iters: 720, time: 0.097, data: 0.001) G_GAN: 0.736 G_L1: 0.000 D_real: 0.738 D_fake: 0.685 \n",
      "(epoch: 62, iters: 820, time: 0.106, data: 0.001) G_GAN: 0.745 G_L1: 2.187 D_real: 0.571 D_fake: 0.619 \n",
      "(epoch: 62, iters: 920, time: 0.094, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.731 D_fake: 0.653 \n",
      "saving the latest model (epoch 62, total_steps 140000)\n",
      "(epoch: 62, iters: 1020, time: 0.097, data: 0.002) G_GAN: 0.678 G_L1: 0.000 D_real: 0.679 D_fake: 0.710 \n",
      "(epoch: 62, iters: 1120, time: 0.097, data: 0.001) G_GAN: 0.773 G_L1: 1.002 D_real: 0.634 D_fake: 0.623 \n",
      "(epoch: 62, iters: 1220, time: 0.097, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.735 D_fake: 0.653 \n",
      "(epoch: 62, iters: 1320, time: 0.097, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.735 D_fake: 0.682 \n",
      "(epoch: 62, iters: 1420, time: 0.098, data: 0.002) G_GAN: 1.103 G_L1: 2.201 D_real: 1.010 D_fake: 0.332 \n",
      "(epoch: 62, iters: 1520, time: 0.098, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.736 D_fake: 0.655 \n",
      "(epoch: 62, iters: 1620, time: 0.094, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.742 D_fake: 0.648 \n",
      "(epoch: 62, iters: 1720, time: 0.099, data: 0.001) G_GAN: 0.743 G_L1: 3.384 D_real: 0.532 D_fake: 0.637 \n",
      "(epoch: 62, iters: 1820, time: 0.099, data: 0.001) G_GAN: 0.801 G_L1: 0.000 D_real: 0.813 D_fake: 0.587 \n",
      "(epoch: 62, iters: 1920, time: 0.097, data: 0.001) G_GAN: 0.717 G_L1: 0.000 D_real: 0.721 D_fake: 0.676 \n",
      "(epoch: 62, iters: 2020, time: 0.100, data: 0.001) G_GAN: 0.772 G_L1: 1.903 D_real: 0.603 D_fake: 0.626 \n",
      "(epoch: 62, iters: 2120, time: 0.097, data: 0.001) G_GAN: 0.794 G_L1: 0.000 D_real: 0.809 D_fake: 0.654 \n",
      "(epoch: 62, iters: 2220, time: 0.100, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.718 D_fake: 0.673 \n",
      "End of epoch 62 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 63, iters: 40, time: 0.116, data: 0.001) G_GAN: 0.742 G_L1: 1.545 D_real: 0.594 D_fake: 0.674 \n",
      "(epoch: 63, iters: 140, time: 0.106, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.760 D_fake: 0.644 \n",
      "(epoch: 63, iters: 240, time: 0.095, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.730 D_fake: 0.610 \n",
      "(epoch: 63, iters: 340, time: 0.096, data: 0.002) G_GAN: 0.741 G_L1: 0.576 D_real: 0.626 D_fake: 0.652 \n",
      "(epoch: 63, iters: 440, time: 0.093, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.747 D_fake: 0.631 \n",
      "(epoch: 63, iters: 540, time: 0.094, data: 0.002) G_GAN: 0.010 G_L1: 0.000 D_real: 0.310 D_fake: 0.649 \n",
      "(epoch: 63, iters: 640, time: 0.103, data: 0.001) G_GAN: 0.778 G_L1: 3.338 D_real: 0.568 D_fake: 0.619 \n",
      "(epoch: 63, iters: 740, time: 0.093, data: 0.001) G_GAN: 0.769 G_L1: 0.000 D_real: 0.772 D_fake: 0.622 \n",
      "(epoch: 63, iters: 840, time: 0.108, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.730 D_fake: 0.660 \n",
      "(epoch: 63, iters: 940, time: 0.114, data: 0.001) G_GAN: 0.770 G_L1: 1.224 D_real: 0.621 D_fake: 0.625 \n",
      "(epoch: 63, iters: 1040, time: 0.105, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.767 D_fake: 0.629 \n",
      "(epoch: 63, iters: 1140, time: 0.096, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.742 D_fake: 0.644 \n",
      "(epoch: 63, iters: 1240, time: 0.094, data: 0.002) G_GAN: 0.820 G_L1: 2.557 D_real: 0.607 D_fake: 0.591 \n",
      "(epoch: 63, iters: 1340, time: 0.098, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.751 D_fake: 0.651 \n",
      "(epoch: 63, iters: 1440, time: 0.098, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.765 D_fake: 0.628 \n",
      "(epoch: 63, iters: 1540, time: 0.097, data: 0.002) G_GAN: 0.770 G_L1: 1.958 D_real: 0.585 D_fake: 0.626 \n",
      "(epoch: 63, iters: 1640, time: 0.097, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.644 \n",
      "(epoch: 63, iters: 1740, time: 0.098, data: 0.003) G_GAN: 0.716 G_L1: 0.000 D_real: 0.718 D_fake: 0.673 \n",
      "(epoch: 63, iters: 1840, time: 0.097, data: 0.002) G_GAN: 0.743 G_L1: 0.311 D_real: 0.653 D_fake: 0.658 \n",
      "(epoch: 63, iters: 1940, time: 0.097, data: 0.001) G_GAN: 0.753 G_L1: 0.000 D_real: 0.757 D_fake: 0.638 \n",
      "(epoch: 63, iters: 2040, time: 0.100, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.734 D_fake: 0.645 \n",
      "(epoch: 63, iters: 2140, time: 0.097, data: 0.001) G_GAN: 0.796 G_L1: 0.787 D_real: 0.659 D_fake: 0.603 \n",
      "(epoch: 63, iters: 2240, time: 0.098, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.750 D_fake: 0.580 \n",
      "End of epoch 63 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 64, iters: 60, time: 0.109, data: 0.001) G_GAN: 0.717 G_L1: 0.000 D_real: 0.718 D_fake: 0.674 \n",
      "(epoch: 64, iters: 160, time: 0.100, data: 0.000) G_GAN: 0.745 G_L1: 3.185 D_real: 0.537 D_fake: 0.651 \n",
      "(epoch: 64, iters: 260, time: 0.111, data: 0.001) G_GAN: 0.826 G_L1: 0.000 D_real: 0.841 D_fake: 0.578 \n",
      "(epoch: 64, iters: 360, time: 0.095, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.742 D_fake: 0.649 \n",
      "(epoch: 64, iters: 460, time: 0.110, data: 0.001) G_GAN: 0.793 G_L1: 2.593 D_real: 0.592 D_fake: 0.607 \n",
      "(epoch: 64, iters: 560, time: 0.113, data: 0.001) G_GAN: 0.749 G_L1: 0.000 D_real: 0.751 D_fake: 0.643 \n",
      "(epoch: 64, iters: 660, time: 0.096, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.726 D_fake: 0.665 \n",
      "(epoch: 64, iters: 760, time: 0.096, data: 0.001) G_GAN: 0.760 G_L1: 2.399 D_real: 0.581 D_fake: 0.634 \n",
      "(epoch: 64, iters: 860, time: 0.094, data: 0.002) G_GAN: 0.768 G_L1: 0.000 D_real: 0.775 D_fake: 0.622 \n",
      "(epoch: 64, iters: 960, time: 0.097, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.719 D_fake: 0.635 \n",
      "(epoch: 64, iters: 1060, time: 0.099, data: 0.001) G_GAN: 0.696 G_L1: 0.087 D_real: 0.641 D_fake: 0.651 \n",
      "(epoch: 64, iters: 1160, time: 0.095, data: 0.001) G_GAN: 0.776 G_L1: 0.000 D_real: 0.778 D_fake: 0.614 \n",
      "(epoch: 64, iters: 1260, time: 0.096, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.755 D_fake: 0.640 \n",
      "(epoch: 64, iters: 1360, time: 0.097, data: 0.001) G_GAN: 0.740 G_L1: 4.502 D_real: 0.517 D_fake: 0.628 \n",
      "saving the latest model (epoch 64, total_steps 145000)\n",
      "(epoch: 64, iters: 1460, time: 0.097, data: 0.001) G_GAN: 0.770 G_L1: 0.000 D_real: 0.775 D_fake: 0.633 \n",
      "(epoch: 64, iters: 1560, time: 0.107, data: 0.001) G_GAN: 0.721 G_L1: 0.000 D_real: 0.724 D_fake: 0.647 \n",
      "(epoch: 64, iters: 1660, time: 0.097, data: 0.001) G_GAN: 0.744 G_L1: 1.973 D_real: 0.565 D_fake: 0.649 \n",
      "(epoch: 64, iters: 1760, time: 0.098, data: 0.002) G_GAN: 0.768 G_L1: 0.000 D_real: 0.772 D_fake: 0.642 \n",
      "(epoch: 64, iters: 1860, time: 0.101, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.740 D_fake: 0.616 \n",
      "(epoch: 64, iters: 1960, time: 0.108, data: 0.002) G_GAN: 0.743 G_L1: 0.417 D_real: 0.634 D_fake: 0.650 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 64, iters: 2060, time: 0.094, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.700 D_fake: 0.691 \n",
      "(epoch: 64, iters: 2160, time: 0.098, data: 0.001) G_GAN: 0.759 G_L1: 0.000 D_real: 0.761 D_fake: 0.639 \n",
      "(epoch: 64, iters: 2260, time: 0.105, data: 0.001) G_GAN: 0.792 G_L1: 3.017 D_real: 0.566 D_fake: 0.619 \n",
      "End of epoch 64 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 65, iters: 80, time: 0.114, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.733 D_fake: 0.658 \n",
      "(epoch: 65, iters: 180, time: 0.099, data: 0.001) G_GAN: 0.715 G_L1: 0.000 D_real: 0.720 D_fake: 0.670 \n",
      "(epoch: 65, iters: 280, time: 0.096, data: 0.002) G_GAN: 0.731 G_L1: 1.052 D_real: 0.589 D_fake: 0.677 \n",
      "(epoch: 65, iters: 380, time: 0.098, data: 0.001) G_GAN: 0.777 G_L1: 0.000 D_real: 0.780 D_fake: 0.617 \n",
      "(epoch: 65, iters: 480, time: 0.098, data: 0.001) G_GAN: 0.641 G_L1: 0.000 D_real: 0.613 D_fake: 0.820 \n",
      "(epoch: 65, iters: 580, time: 0.107, data: 0.001) G_GAN: 0.760 G_L1: 4.208 D_real: 0.534 D_fake: 0.636 \n",
      "(epoch: 65, iters: 680, time: 0.097, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.757 D_fake: 0.613 \n",
      "(epoch: 65, iters: 780, time: 0.097, data: 0.001) G_GAN: 0.736 G_L1: 0.000 D_real: 0.738 D_fake: 0.639 \n",
      "(epoch: 65, iters: 880, time: 0.104, data: 0.001) G_GAN: 0.753 G_L1: 3.483 D_real: 0.544 D_fake: 0.685 \n",
      "(epoch: 65, iters: 980, time: 0.099, data: 0.001) G_GAN: 0.755 G_L1: 0.000 D_real: 0.757 D_fake: 0.633 \n",
      "(epoch: 65, iters: 1080, time: 0.097, data: 0.001) G_GAN: 0.707 G_L1: 0.000 D_real: 0.707 D_fake: 0.683 \n",
      "(epoch: 65, iters: 1180, time: 0.098, data: 0.002) G_GAN: 0.790 G_L1: 0.978 D_real: 0.644 D_fake: 0.611 \n",
      "(epoch: 65, iters: 1280, time: 0.100, data: 0.001) G_GAN: 0.833 G_L1: 0.000 D_real: 0.862 D_fake: 0.543 \n",
      "(epoch: 65, iters: 1380, time: 0.097, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.722 D_fake: 0.668 \n",
      "(epoch: 65, iters: 1480, time: 0.097, data: 0.001) G_GAN: 0.768 G_L1: 1.681 D_real: 0.601 D_fake: 0.629 \n",
      "(epoch: 65, iters: 1580, time: 0.108, data: 0.001) G_GAN: 0.757 G_L1: 0.000 D_real: 0.760 D_fake: 0.647 \n",
      "(epoch: 65, iters: 1680, time: 0.097, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.743 D_fake: 0.649 \n",
      "(epoch: 65, iters: 1780, time: 0.096, data: 0.002) G_GAN: 0.752 G_L1: 3.487 D_real: 0.538 D_fake: 0.632 \n",
      "(epoch: 65, iters: 1880, time: 0.096, data: 0.001) G_GAN: 0.755 G_L1: 0.000 D_real: 0.757 D_fake: 0.646 \n",
      "(epoch: 65, iters: 1980, time: 0.108, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.742 D_fake: 0.592 \n",
      "(epoch: 65, iters: 2080, time: 0.097, data: 0.001) G_GAN: 0.776 G_L1: 2.663 D_real: 0.572 D_fake: 0.625 \n",
      "(epoch: 65, iters: 2180, time: 0.098, data: 0.001) G_GAN: 0.786 G_L1: 0.000 D_real: 0.795 D_fake: 0.583 \n",
      "(epoch: 65, iters: 2280, time: 0.108, data: 0.001) G_GAN: 0.772 G_L1: 0.000 D_real: 0.777 D_fake: 0.652 \n",
      "saving the model at the end of epoch 65, iters 148200\n",
      "End of epoch 65 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 66, iters: 100, time: 0.106, data: 0.279) G_GAN: 0.816 G_L1: 2.739 D_real: 0.608 D_fake: 0.591 \n",
      "(epoch: 66, iters: 200, time: 0.096, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.732 D_fake: 0.627 \n",
      "(epoch: 66, iters: 300, time: 0.096, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.736 D_fake: 0.655 \n",
      "(epoch: 66, iters: 400, time: 0.096, data: 0.001) G_GAN: 0.744 G_L1: 1.900 D_real: 0.572 D_fake: 0.647 \n",
      "(epoch: 66, iters: 500, time: 0.097, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.700 D_fake: 0.688 \n",
      "(epoch: 66, iters: 600, time: 0.098, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.757 D_fake: 0.636 \n",
      "(epoch: 66, iters: 700, time: 0.097, data: 0.002) G_GAN: 0.957 G_L1: 2.269 D_real: 0.719 D_fake: 0.495 \n",
      "(epoch: 66, iters: 800, time: 0.109, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.761 D_fake: 0.635 \n",
      "(epoch: 66, iters: 900, time: 0.104, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.718 D_fake: 0.635 \n",
      "(epoch: 66, iters: 1000, time: 0.099, data: 0.002) G_GAN: 0.781 G_L1: 2.064 D_real: 0.593 D_fake: 0.621 \n",
      "(epoch: 66, iters: 1100, time: 0.097, data: 0.001) G_GAN: 0.770 G_L1: 0.000 D_real: 0.773 D_fake: 0.623 \n",
      "(epoch: 66, iters: 1200, time: 0.096, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.726 D_fake: 0.663 \n",
      "(epoch: 66, iters: 1300, time: 0.099, data: 0.002) G_GAN: 0.779 G_L1: 3.100 D_real: 0.572 D_fake: 0.654 \n",
      "(epoch: 66, iters: 1400, time: 0.096, data: 0.002) G_GAN: 0.787 G_L1: 0.000 D_real: 0.792 D_fake: 0.602 \n",
      "(epoch: 66, iters: 1500, time: 0.095, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.726 D_fake: 0.666 \n",
      "(epoch: 66, iters: 1600, time: 0.108, data: 0.001) G_GAN: 0.751 G_L1: 1.704 D_real: 0.591 D_fake: 0.642 \n",
      "(epoch: 66, iters: 1700, time: 0.100, data: 0.001) G_GAN: 0.775 G_L1: 0.000 D_real: 0.778 D_fake: 0.619 \n",
      "(epoch: 66, iters: 1800, time: 0.096, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.726 D_fake: 0.658 \n",
      "saving the latest model (epoch 66, total_steps 150000)\n",
      "(epoch: 66, iters: 1900, time: 0.110, data: 0.001) G_GAN: 0.757 G_L1: 4.005 D_real: 0.534 D_fake: 0.649 \n",
      "(epoch: 66, iters: 2000, time: 0.100, data: 0.001) G_GAN: 0.764 G_L1: 0.000 D_real: 0.766 D_fake: 0.629 \n",
      "(epoch: 66, iters: 2100, time: 0.096, data: 0.001) G_GAN: 0.664 G_L1: 0.000 D_real: 0.692 D_fake: 0.650 \n",
      "(epoch: 66, iters: 2200, time: 0.106, data: 0.001) G_GAN: 0.739 G_L1: 1.935 D_real: 0.567 D_fake: 0.657 \n",
      "End of epoch 66 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 67, iters: 20, time: 0.108, data: 0.002) G_GAN: 0.766 G_L1: 0.000 D_real: 0.769 D_fake: 0.627 \n",
      "(epoch: 67, iters: 120, time: 0.098, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.684 D_fake: 0.705 \n",
      "(epoch: 67, iters: 220, time: 0.101, data: 0.002) G_GAN: 0.773 G_L1: 3.205 D_real: 0.559 D_fake: 0.600 \n",
      "(epoch: 67, iters: 320, time: 0.097, data: 0.001) G_GAN: 0.763 G_L1: 0.000 D_real: 0.767 D_fake: 0.619 \n",
      "(epoch: 67, iters: 420, time: 0.096, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.730 D_fake: 0.660 \n",
      "(epoch: 67, iters: 520, time: 0.097, data: 0.001) G_GAN: 0.756 G_L1: 1.603 D_real: 0.590 D_fake: 0.642 \n",
      "(epoch: 67, iters: 620, time: 0.098, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.750 D_fake: 0.716 \n",
      "(epoch: 67, iters: 720, time: 0.098, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.713 D_fake: 0.675 \n",
      "(epoch: 67, iters: 820, time: 0.097, data: 0.002) G_GAN: 0.804 G_L1: 2.187 D_real: 0.597 D_fake: 0.605 \n",
      "(epoch: 67, iters: 920, time: 0.094, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.747 D_fake: 0.652 \n",
      "(epoch: 67, iters: 1020, time: 0.099, data: 0.001) G_GAN: 0.720 G_L1: 0.000 D_real: 0.724 D_fake: 0.667 \n",
      "(epoch: 67, iters: 1120, time: 0.098, data: 0.002) G_GAN: 0.784 G_L1: 1.002 D_real: 0.635 D_fake: 0.614 \n",
      "(epoch: 67, iters: 1220, time: 0.096, data: 0.002) G_GAN: 0.861 G_L1: 0.000 D_real: 0.930 D_fake: 0.522 \n",
      "(epoch: 67, iters: 1320, time: 0.097, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.732 D_fake: 0.639 \n",
      "(epoch: 67, iters: 1420, time: 0.097, data: 0.001) G_GAN: 0.751 G_L1: 2.201 D_real: 0.576 D_fake: 0.653 \n",
      "(epoch: 67, iters: 1520, time: 0.098, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.751 D_fake: 0.643 \n",
      "(epoch: 67, iters: 1620, time: 0.105, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.753 D_fake: 0.653 \n",
      "(epoch: 67, iters: 1720, time: 0.099, data: 0.001) G_GAN: 0.750 G_L1: 3.384 D_real: 0.548 D_fake: 0.645 \n",
      "(epoch: 67, iters: 1820, time: 0.101, data: 0.002) G_GAN: 0.778 G_L1: 0.000 D_real: 0.782 D_fake: 0.631 \n",
      "(epoch: 67, iters: 1920, time: 0.100, data: 0.001) G_GAN: 0.703 G_L1: 0.000 D_real: 0.712 D_fake: 0.570 \n",
      "(epoch: 67, iters: 2020, time: 0.100, data: 0.002) G_GAN: 0.781 G_L1: 1.903 D_real: 0.608 D_fake: 0.618 \n",
      "(epoch: 67, iters: 2120, time: 0.096, data: 0.001) G_GAN: 0.846 G_L1: 0.000 D_real: 0.872 D_fake: 0.652 \n",
      "(epoch: 67, iters: 2220, time: 0.100, data: 0.001) G_GAN: 0.664 G_L1: 0.000 D_real: 0.653 D_fake: 0.618 \n",
      "End of epoch 67 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 68, iters: 40, time: 0.119, data: 0.001) G_GAN: 0.746 G_L1: 1.545 D_real: 0.592 D_fake: 0.727 \n",
      "(epoch: 68, iters: 140, time: 0.098, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.740 D_fake: 0.624 \n",
      "(epoch: 68, iters: 240, time: 0.097, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.746 D_fake: 0.657 \n",
      "(epoch: 68, iters: 340, time: 0.096, data: 0.001) G_GAN: 0.758 G_L1: 0.576 D_real: 0.629 D_fake: 0.638 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 68, iters: 440, time: 0.095, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.740 D_fake: 0.653 \n",
      "(epoch: 68, iters: 540, time: 0.096, data: 0.003) G_GAN: 0.723 G_L1: 0.000 D_real: 0.724 D_fake: 0.665 \n",
      "(epoch: 68, iters: 640, time: 0.096, data: 0.002) G_GAN: 0.766 G_L1: 3.338 D_real: 0.560 D_fake: 0.632 \n",
      "(epoch: 68, iters: 740, time: 0.096, data: 0.001) G_GAN: 0.751 G_L1: 0.000 D_real: 0.755 D_fake: 0.638 \n",
      "(epoch: 68, iters: 840, time: 0.095, data: 0.001) G_GAN: 0.704 G_L1: 0.000 D_real: 0.697 D_fake: 0.692 \n",
      "(epoch: 68, iters: 940, time: 0.097, data: 0.001) G_GAN: 0.783 G_L1: 1.224 D_real: 0.629 D_fake: 0.600 \n",
      "(epoch: 68, iters: 1040, time: 0.105, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.770 D_fake: 0.628 \n",
      "(epoch: 68, iters: 1140, time: 0.097, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.753 D_fake: 0.642 \n",
      "(epoch: 68, iters: 1240, time: 0.097, data: 0.001) G_GAN: 0.974 G_L1: 2.557 D_real: 0.714 D_fake: 0.485 \n",
      "(epoch: 68, iters: 1340, time: 0.098, data: 0.001) G_GAN: 0.758 G_L1: 0.000 D_real: 0.762 D_fake: 0.663 \n",
      "(epoch: 68, iters: 1440, time: 0.098, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.762 D_fake: 0.631 \n",
      "(epoch: 68, iters: 1540, time: 0.110, data: 0.002) G_GAN: 0.762 G_L1: 1.958 D_real: 0.584 D_fake: 0.647 \n",
      "(epoch: 68, iters: 1640, time: 0.111, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.750 D_fake: 0.645 \n",
      "(epoch: 68, iters: 1740, time: 0.100, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.737 D_fake: 0.654 \n",
      "(epoch: 68, iters: 1840, time: 0.098, data: 0.002) G_GAN: 0.776 G_L1: 0.311 D_real: 0.657 D_fake: 0.630 \n",
      "(epoch: 68, iters: 1940, time: 0.115, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.746 D_fake: 0.646 \n",
      "(epoch: 68, iters: 2040, time: 0.097, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.733 D_fake: 0.656 \n",
      "(epoch: 68, iters: 2140, time: 0.099, data: 0.002) G_GAN: 0.784 G_L1: 0.787 D_real: 0.652 D_fake: 0.614 \n",
      "(epoch: 68, iters: 2240, time: 0.098, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.717 D_fake: 0.675 \n",
      "saving the latest model (epoch 68, total_steps 155000)\n",
      "End of epoch 68 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 69, iters: 60, time: 0.115, data: 0.001) G_GAN: 0.709 G_L1: 0.000 D_real: 0.710 D_fake: 0.695 \n",
      "(epoch: 69, iters: 160, time: 0.110, data: 0.001) G_GAN: 0.766 G_L1: 3.185 D_real: 0.549 D_fake: 0.636 \n",
      "(epoch: 69, iters: 260, time: 0.095, data: 0.001) G_GAN: 0.775 G_L1: 0.000 D_real: 0.779 D_fake: 0.620 \n",
      "(epoch: 69, iters: 360, time: 0.096, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.738 D_fake: 0.637 \n",
      "(epoch: 69, iters: 460, time: 0.099, data: 0.002) G_GAN: 0.781 G_L1: 2.593 D_real: 0.585 D_fake: 0.616 \n",
      "(epoch: 69, iters: 560, time: 0.099, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.759 D_fake: 0.629 \n",
      "(epoch: 69, iters: 660, time: 0.096, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.741 D_fake: 0.639 \n",
      "(epoch: 69, iters: 760, time: 0.096, data: 0.001) G_GAN: 0.763 G_L1: 2.399 D_real: 0.580 D_fake: 0.638 \n",
      "(epoch: 69, iters: 860, time: 0.096, data: 0.001) G_GAN: 0.751 G_L1: 0.000 D_real: 0.757 D_fake: 0.583 \n",
      "(epoch: 69, iters: 960, time: 0.096, data: 0.001) G_GAN: 0.710 G_L1: 0.000 D_real: 0.711 D_fake: 0.678 \n",
      "(epoch: 69, iters: 1060, time: 0.100, data: 0.001) G_GAN: 0.734 G_L1: 0.087 D_real: 0.669 D_fake: 0.634 \n",
      "(epoch: 69, iters: 1160, time: 0.094, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.742 D_fake: 0.648 \n",
      "(epoch: 69, iters: 1260, time: 0.095, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.743 D_fake: 0.652 \n",
      "(epoch: 69, iters: 1360, time: 0.096, data: 0.001) G_GAN: 0.752 G_L1: 4.502 D_real: 0.523 D_fake: 0.622 \n",
      "(epoch: 69, iters: 1460, time: 0.097, data: 0.002) G_GAN: 0.762 G_L1: 0.000 D_real: 0.768 D_fake: 0.631 \n",
      "(epoch: 69, iters: 1560, time: 0.095, data: 0.001) G_GAN: 0.736 G_L1: 0.000 D_real: 0.737 D_fake: 0.655 \n",
      "(epoch: 69, iters: 1660, time: 0.097, data: 0.001) G_GAN: 0.753 G_L1: 1.973 D_real: 0.583 D_fake: 0.640 \n",
      "(epoch: 69, iters: 1760, time: 0.097, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.752 D_fake: 0.642 \n",
      "(epoch: 69, iters: 1860, time: 0.098, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.732 D_fake: 0.588 \n",
      "(epoch: 69, iters: 1960, time: 0.100, data: 0.002) G_GAN: 0.754 G_L1: 0.417 D_real: 0.656 D_fake: 0.643 \n",
      "(epoch: 69, iters: 2060, time: 0.096, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.740 D_fake: 0.656 \n",
      "(epoch: 69, iters: 2160, time: 0.107, data: 0.001) G_GAN: 0.624 G_L1: 0.000 D_real: 0.673 D_fake: 0.528 \n",
      "(epoch: 69, iters: 2260, time: 0.105, data: 0.001) G_GAN: 0.767 G_L1: 3.017 D_real: 0.565 D_fake: 0.629 \n",
      "End of epoch 69 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 70, iters: 80, time: 0.108, data: 0.001) G_GAN: 0.743 G_L1: 0.000 D_real: 0.745 D_fake: 0.637 \n",
      "(epoch: 70, iters: 180, time: 0.108, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.732 D_fake: 0.644 \n",
      "(epoch: 70, iters: 280, time: 0.111, data: 0.001) G_GAN: 0.739 G_L1: 1.052 D_real: 0.610 D_fake: 0.679 \n",
      "(epoch: 70, iters: 380, time: 0.098, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.759 D_fake: 0.659 \n",
      "(epoch: 70, iters: 480, time: 0.097, data: 0.001) G_GAN: 0.734 G_L1: 0.000 D_real: 0.735 D_fake: 0.654 \n",
      "(epoch: 70, iters: 580, time: 0.105, data: 0.001) G_GAN: 0.755 G_L1: 4.208 D_real: 0.524 D_fake: 0.653 \n",
      "(epoch: 70, iters: 680, time: 0.096, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.749 D_fake: 0.643 \n",
      "(epoch: 70, iters: 780, time: 0.097, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.743 D_fake: 0.647 \n",
      "(epoch: 70, iters: 880, time: 0.095, data: 0.002) G_GAN: 0.747 G_L1: 3.483 D_real: 0.529 D_fake: 0.652 \n",
      "(epoch: 70, iters: 980, time: 0.107, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.727 D_fake: 0.595 \n",
      "(epoch: 70, iters: 1080, time: 0.097, data: 0.001) G_GAN: 0.709 G_L1: 0.000 D_real: 0.710 D_fake: 0.679 \n",
      "(epoch: 70, iters: 1180, time: 0.100, data: 0.001) G_GAN: 0.790 G_L1: 0.978 D_real: 0.646 D_fake: 0.632 \n",
      "(epoch: 70, iters: 1280, time: 0.105, data: 0.001) G_GAN: 0.788 G_L1: 0.000 D_real: 0.798 D_fake: 0.607 \n",
      "(epoch: 70, iters: 1380, time: 0.096, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.730 D_fake: 0.646 \n",
      "(epoch: 70, iters: 1480, time: 0.098, data: 0.001) G_GAN: 0.748 G_L1: 1.681 D_real: 0.587 D_fake: 0.636 \n",
      "(epoch: 70, iters: 1580, time: 0.096, data: 0.001) G_GAN: 0.755 G_L1: 0.000 D_real: 0.756 D_fake: 0.640 \n",
      "(epoch: 70, iters: 1680, time: 0.112, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.743 D_fake: 0.648 \n",
      "(epoch: 70, iters: 1780, time: 0.097, data: 0.001) G_GAN: 0.748 G_L1: 3.487 D_real: 0.536 D_fake: 0.636 \n",
      "(epoch: 70, iters: 1880, time: 0.100, data: 0.001) G_GAN: 0.766 G_L1: 0.000 D_real: 0.768 D_fake: 0.628 \n",
      "(epoch: 70, iters: 1980, time: 0.099, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.741 D_fake: 0.650 \n",
      "(epoch: 70, iters: 2080, time: 0.098, data: 0.002) G_GAN: 0.745 G_L1: 2.663 D_real: 0.543 D_fake: 0.653 \n",
      "(epoch: 70, iters: 2180, time: 0.105, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.758 D_fake: 0.627 \n",
      "(epoch: 70, iters: 2280, time: 0.097, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.753 D_fake: 0.625 \n",
      "saving the model at the end of epoch 70, iters 159600\n",
      "End of epoch 70 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 71, iters: 100, time: 0.107, data: 0.296) G_GAN: 0.780 G_L1: 2.739 D_real: 0.573 D_fake: 0.623 \n",
      "(epoch: 71, iters: 200, time: 0.106, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.746 D_fake: 0.644 \n",
      "(epoch: 71, iters: 300, time: 0.096, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.718 D_fake: 0.649 \n",
      "(epoch: 71, iters: 400, time: 0.111, data: 0.001) G_GAN: 0.738 G_L1: 1.900 D_real: 0.564 D_fake: 0.660 \n",
      "saving the latest model (epoch 71, total_steps 160000)\n",
      "(epoch: 71, iters: 500, time: 0.110, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.734 D_fake: 0.654 \n",
      "(epoch: 71, iters: 600, time: 0.098, data: 0.001) G_GAN: 0.759 G_L1: 0.000 D_real: 0.761 D_fake: 0.632 \n",
      "(epoch: 71, iters: 700, time: 0.100, data: 0.002) G_GAN: 0.835 G_L1: 2.269 D_real: 0.628 D_fake: 0.580 \n",
      "(epoch: 71, iters: 800, time: 0.097, data: 0.001) G_GAN: 0.753 G_L1: 0.000 D_real: 0.757 D_fake: 0.649 \n",
      "(epoch: 71, iters: 900, time: 0.093, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.726 D_fake: 0.501 \n",
      "(epoch: 71, iters: 1000, time: 0.099, data: 0.001) G_GAN: 0.859 G_L1: 2.064 D_real: 0.634 D_fake: 0.614 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 71, iters: 1100, time: 0.097, data: 0.002) G_GAN: 0.797 G_L1: 0.000 D_real: 0.803 D_fake: 0.612 \n",
      "(epoch: 71, iters: 1200, time: 0.111, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.725 D_fake: 0.665 \n",
      "(epoch: 71, iters: 1300, time: 0.098, data: 0.002) G_GAN: 0.798 G_L1: 3.100 D_real: 0.593 D_fake: 0.600 \n",
      "(epoch: 71, iters: 1400, time: 0.108, data: 0.002) G_GAN: 0.779 G_L1: 0.000 D_real: 0.782 D_fake: 0.617 \n",
      "(epoch: 71, iters: 1500, time: 0.097, data: 0.001) G_GAN: 0.744 G_L1: 0.000 D_real: 0.745 D_fake: 0.649 \n",
      "(epoch: 71, iters: 1600, time: 0.096, data: 0.001) G_GAN: 0.750 G_L1: 1.704 D_real: 0.589 D_fake: 0.644 \n",
      "(epoch: 71, iters: 1700, time: 0.098, data: 0.002) G_GAN: 0.809 G_L1: 0.000 D_real: 0.817 D_fake: 0.638 \n",
      "(epoch: 71, iters: 1800, time: 0.097, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.731 D_fake: 0.660 \n",
      "(epoch: 71, iters: 1900, time: 0.099, data: 0.001) G_GAN: 0.740 G_L1: 4.005 D_real: 0.508 D_fake: 0.659 \n",
      "(epoch: 71, iters: 2000, time: 0.100, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.760 D_fake: 0.651 \n",
      "(epoch: 71, iters: 2100, time: 0.104, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.734 D_fake: 0.661 \n",
      "(epoch: 71, iters: 2200, time: 0.111, data: 0.002) G_GAN: 0.727 G_L1: 1.935 D_real: 0.558 D_fake: 0.660 \n",
      "End of epoch 71 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 72, iters: 20, time: 0.119, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.747 D_fake: 0.646 \n",
      "(epoch: 72, iters: 120, time: 0.096, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.738 D_fake: 0.652 \n",
      "(epoch: 72, iters: 220, time: 0.099, data: 0.002) G_GAN: 0.765 G_L1: 3.205 D_real: 0.552 D_fake: 0.654 \n",
      "(epoch: 72, iters: 320, time: 0.095, data: 0.001) G_GAN: 0.744 G_L1: 0.000 D_real: 0.746 D_fake: 0.647 \n",
      "(epoch: 72, iters: 420, time: 0.096, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.725 D_fake: 0.664 \n",
      "(epoch: 72, iters: 520, time: 0.095, data: 0.002) G_GAN: 0.762 G_L1: 1.603 D_real: 0.594 D_fake: 0.635 \n",
      "(epoch: 72, iters: 620, time: 0.098, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.764 D_fake: 0.640 \n",
      "(epoch: 72, iters: 720, time: 0.097, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.739 D_fake: 0.651 \n",
      "(epoch: 72, iters: 820, time: 0.094, data: 0.002) G_GAN: 0.736 G_L1: 2.187 D_real: 0.559 D_fake: 0.668 \n",
      "(epoch: 72, iters: 920, time: 0.094, data: 0.001) G_GAN: 0.736 G_L1: 0.000 D_real: 0.739 D_fake: 0.638 \n",
      "(epoch: 72, iters: 1020, time: 0.099, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.757 D_fake: 0.632 \n",
      "(epoch: 72, iters: 1120, time: 0.099, data: 0.002) G_GAN: 0.784 G_L1: 1.002 D_real: 0.645 D_fake: 0.619 \n",
      "(epoch: 72, iters: 1220, time: 0.106, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.607 \n",
      "(epoch: 72, iters: 1320, time: 0.098, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.728 D_fake: 0.662 \n",
      "(epoch: 72, iters: 1420, time: 0.106, data: 0.001) G_GAN: 0.765 G_L1: 2.201 D_real: 0.593 D_fake: 0.646 \n",
      "(epoch: 72, iters: 1520, time: 0.099, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.760 D_fake: 0.634 \n",
      "(epoch: 72, iters: 1620, time: 0.095, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.739 D_fake: 0.640 \n",
      "(epoch: 72, iters: 1720, time: 0.101, data: 0.001) G_GAN: 0.760 G_L1: 3.384 D_real: 0.548 D_fake: 0.637 \n",
      "(epoch: 72, iters: 1820, time: 0.099, data: 0.002) G_GAN: 0.768 G_L1: 0.000 D_real: 0.771 D_fake: 0.628 \n",
      "(epoch: 72, iters: 1920, time: 0.097, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.732 D_fake: 0.662 \n",
      "(epoch: 72, iters: 2020, time: 0.098, data: 0.002) G_GAN: 0.756 G_L1: 1.903 D_real: 0.581 D_fake: 0.726 \n",
      "(epoch: 72, iters: 2120, time: 0.098, data: 0.002) G_GAN: 0.783 G_L1: 0.000 D_real: 0.788 D_fake: 0.612 \n",
      "(epoch: 72, iters: 2220, time: 0.100, data: 0.001) G_GAN: 0.682 G_L1: 0.000 D_real: 0.681 D_fake: 0.718 \n",
      "End of epoch 72 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 73, iters: 40, time: 0.121, data: 0.001) G_GAN: 0.772 G_L1: 1.545 D_real: 0.608 D_fake: 0.628 \n",
      "(epoch: 73, iters: 140, time: 0.095, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.751 D_fake: 0.646 \n",
      "(epoch: 73, iters: 240, time: 0.108, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.747 D_fake: 0.603 \n",
      "(epoch: 73, iters: 340, time: 0.096, data: 0.005) G_GAN: 0.756 G_L1: 0.576 D_real: 0.633 D_fake: 0.640 \n",
      "(epoch: 73, iters: 440, time: 0.106, data: 0.001) G_GAN: 0.761 G_L1: 0.000 D_real: 0.763 D_fake: 0.633 \n",
      "(epoch: 73, iters: 540, time: 0.095, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.705 D_fake: 0.684 \n",
      "(epoch: 73, iters: 640, time: 0.106, data: 0.002) G_GAN: 0.778 G_L1: 3.338 D_real: 0.566 D_fake: 0.651 \n",
      "(epoch: 73, iters: 740, time: 0.107, data: 0.001) G_GAN: 0.759 G_L1: 0.000 D_real: 0.763 D_fake: 0.633 \n",
      "(epoch: 73, iters: 840, time: 0.095, data: 0.001) G_GAN: 0.708 G_L1: 0.000 D_real: 0.711 D_fake: 0.637 \n",
      "saving the latest model (epoch 73, total_steps 165000)\n",
      "(epoch: 73, iters: 940, time: 0.101, data: 0.001) G_GAN: 0.820 G_L1: 1.224 D_real: 0.653 D_fake: 0.592 \n",
      "(epoch: 73, iters: 1040, time: 0.096, data: 0.001) G_GAN: 0.763 G_L1: 0.000 D_real: 0.771 D_fake: 0.642 \n",
      "(epoch: 73, iters: 1140, time: 0.097, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.643 \n",
      "(epoch: 73, iters: 1240, time: 0.106, data: 0.001) G_GAN: 0.801 G_L1: 2.557 D_real: 0.586 D_fake: 0.608 \n",
      "(epoch: 73, iters: 1340, time: 0.098, data: 0.001) G_GAN: 0.858 G_L1: 0.000 D_real: 0.899 D_fake: 0.524 \n",
      "(epoch: 73, iters: 1440, time: 0.100, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.644 \n",
      "(epoch: 73, iters: 1540, time: 0.109, data: 0.001) G_GAN: 0.788 G_L1: 1.958 D_real: 0.593 D_fake: 0.648 \n",
      "(epoch: 73, iters: 1640, time: 0.096, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.748 D_fake: 0.643 \n",
      "(epoch: 73, iters: 1740, time: 0.099, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.746 D_fake: 0.630 \n",
      "(epoch: 73, iters: 1840, time: 0.097, data: 0.001) G_GAN: 0.750 G_L1: 0.311 D_real: 0.640 D_fake: 0.637 \n",
      "(epoch: 73, iters: 1940, time: 0.098, data: 0.001) G_GAN: 0.769 G_L1: 0.000 D_real: 0.771 D_fake: 0.624 \n",
      "(epoch: 73, iters: 2040, time: 0.098, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.744 D_fake: 0.639 \n",
      "(epoch: 73, iters: 2140, time: 0.099, data: 0.005) G_GAN: 0.776 G_L1: 0.787 D_real: 0.648 D_fake: 0.635 \n",
      "(epoch: 73, iters: 2240, time: 0.098, data: 0.001) G_GAN: 0.815 G_L1: 0.000 D_real: 0.810 D_fake: 0.595 \n",
      "End of epoch 73 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 74, iters: 60, time: 0.106, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.736 D_fake: 0.659 \n",
      "(epoch: 74, iters: 160, time: 0.100, data: 0.002) G_GAN: 0.746 G_L1: 3.185 D_real: 0.532 D_fake: 0.655 \n",
      "(epoch: 74, iters: 260, time: 0.104, data: 0.001) G_GAN: 0.565 G_L1: 0.000 D_real: 0.470 D_fake: 0.990 \n",
      "(epoch: 74, iters: 360, time: 0.097, data: 0.001) G_GAN: 0.672 G_L1: 0.000 D_real: 0.673 D_fake: 0.682 \n",
      "(epoch: 74, iters: 460, time: 0.099, data: 0.002) G_GAN: 0.828 G_L1: 2.593 D_real: 0.618 D_fake: 0.650 \n",
      "(epoch: 74, iters: 560, time: 0.098, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.738 D_fake: 0.652 \n",
      "(epoch: 74, iters: 660, time: 0.097, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.731 D_fake: 0.649 \n",
      "(epoch: 74, iters: 760, time: 0.096, data: 0.001) G_GAN: 0.748 G_L1: 2.399 D_real: 0.572 D_fake: 0.656 \n",
      "(epoch: 74, iters: 860, time: 0.096, data: 0.001) G_GAN: 0.752 G_L1: 0.000 D_real: 0.754 D_fake: 0.643 \n",
      "(epoch: 74, iters: 960, time: 0.095, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.700 D_fake: 0.694 \n",
      "(epoch: 74, iters: 1060, time: 0.095, data: 0.001) G_GAN: 0.712 G_L1: 0.087 D_real: 0.662 D_fake: 0.677 \n",
      "(epoch: 74, iters: 1160, time: 0.097, data: 0.001) G_GAN: 0.767 G_L1: 0.000 D_real: 0.770 D_fake: 0.611 \n",
      "(epoch: 74, iters: 1260, time: 0.099, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.729 D_fake: 0.641 \n",
      "(epoch: 74, iters: 1360, time: 0.096, data: 0.002) G_GAN: 0.743 G_L1: 4.502 D_real: 0.516 D_fake: 0.654 \n",
      "(epoch: 74, iters: 1460, time: 0.098, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.767 D_fake: 0.601 \n",
      "(epoch: 74, iters: 1560, time: 0.096, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.734 D_fake: 0.651 \n",
      "(epoch: 74, iters: 1660, time: 0.098, data: 0.001) G_GAN: 0.760 G_L1: 1.973 D_real: 0.591 D_fake: 0.626 \n",
      "(epoch: 74, iters: 1760, time: 0.097, data: 0.001) G_GAN: 0.773 G_L1: 0.000 D_real: 0.777 D_fake: 0.621 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 74, iters: 1860, time: 0.099, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.717 D_fake: 0.674 \n",
      "(epoch: 74, iters: 1960, time: 0.099, data: 0.002) G_GAN: 0.772 G_L1: 0.417 D_real: 0.655 D_fake: 0.627 \n",
      "(epoch: 74, iters: 2060, time: 0.095, data: 0.001) G_GAN: 0.720 G_L1: 0.000 D_real: 0.721 D_fake: 0.671 \n",
      "(epoch: 74, iters: 2160, time: 0.099, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.719 D_fake: 0.554 \n",
      "(epoch: 74, iters: 2260, time: 0.093, data: 0.002) G_GAN: 0.866 G_L1: 3.017 D_real: 0.639 D_fake: 0.547 \n",
      "End of epoch 74 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 75, iters: 80, time: 0.104, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.717 D_fake: 0.633 \n",
      "(epoch: 75, iters: 180, time: 0.100, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.722 D_fake: 0.667 \n",
      "(epoch: 75, iters: 280, time: 0.105, data: 0.002) G_GAN: 0.733 G_L1: 1.052 D_real: 0.596 D_fake: 0.660 \n",
      "(epoch: 75, iters: 380, time: 0.099, data: 0.002) G_GAN: 0.812 G_L1: 0.000 D_real: 0.821 D_fake: 0.578 \n",
      "(epoch: 75, iters: 480, time: 0.099, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.730 D_fake: 0.641 \n",
      "(epoch: 75, iters: 580, time: 0.100, data: 0.002) G_GAN: 0.761 G_L1: 4.208 D_real: 0.522 D_fake: 0.634 \n",
      "(epoch: 75, iters: 680, time: 0.109, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.724 D_fake: 0.668 \n",
      "(epoch: 75, iters: 780, time: 0.097, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.724 D_fake: 0.632 \n",
      "(epoch: 75, iters: 880, time: 0.095, data: 0.001) G_GAN: 0.749 G_L1: 3.483 D_real: 0.529 D_fake: 0.651 \n",
      "(epoch: 75, iters: 980, time: 0.096, data: 0.001) G_GAN: 0.753 G_L1: 0.000 D_real: 0.756 D_fake: 0.642 \n",
      "(epoch: 75, iters: 1080, time: 0.095, data: 0.001) G_GAN: 0.649 G_L1: 0.000 D_real: 0.651 D_fake: 0.740 \n",
      "(epoch: 75, iters: 1180, time: 0.097, data: 0.002) G_GAN: 0.752 G_L1: 0.978 D_real: 0.609 D_fake: 0.642 \n",
      "(epoch: 75, iters: 1280, time: 0.098, data: 0.001) G_GAN: 0.767 G_L1: 0.000 D_real: 0.780 D_fake: 0.680 \n",
      "saving the latest model (epoch 75, total_steps 170000)\n",
      "(epoch: 75, iters: 1380, time: 0.096, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.727 D_fake: 0.664 \n",
      "(epoch: 75, iters: 1480, time: 0.107, data: 0.001) G_GAN: 0.743 G_L1: 1.681 D_real: 0.579 D_fake: 0.652 \n",
      "(epoch: 75, iters: 1580, time: 0.096, data: 0.001) G_GAN: 0.755 G_L1: 0.000 D_real: 0.757 D_fake: 0.637 \n",
      "(epoch: 75, iters: 1680, time: 0.110, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.749 D_fake: 0.645 \n",
      "(epoch: 75, iters: 1780, time: 0.103, data: 0.001) G_GAN: 0.751 G_L1: 3.487 D_real: 0.533 D_fake: 0.643 \n",
      "(epoch: 75, iters: 1880, time: 0.099, data: 0.001) G_GAN: 0.764 G_L1: 0.000 D_real: 0.766 D_fake: 0.631 \n",
      "(epoch: 75, iters: 1980, time: 0.100, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.740 D_fake: 0.653 \n",
      "(epoch: 75, iters: 2080, time: 0.098, data: 0.002) G_GAN: 0.741 G_L1: 2.663 D_real: 0.550 D_fake: 0.648 \n",
      "(epoch: 75, iters: 2180, time: 0.098, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.733 D_fake: 0.653 \n",
      "(epoch: 75, iters: 2280, time: 0.096, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.732 D_fake: 0.660 \n",
      "saving the model at the end of epoch 75, iters 171000\n",
      "End of epoch 75 / 200 \t Time Taken: 127 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 76, iters: 100, time: 0.107, data: 0.286) G_GAN: 0.775 G_L1: 2.739 D_real: 0.574 D_fake: 0.649 \n",
      "(epoch: 76, iters: 200, time: 0.096, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.731 D_fake: 0.653 \n",
      "(epoch: 76, iters: 300, time: 0.096, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.718 D_fake: 0.672 \n",
      "(epoch: 76, iters: 400, time: 0.099, data: 0.002) G_GAN: 0.730 G_L1: 1.900 D_real: 0.566 D_fake: 0.663 \n",
      "(epoch: 76, iters: 500, time: 0.098, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.733 D_fake: 0.656 \n",
      "(epoch: 76, iters: 600, time: 0.108, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.738 D_fake: 0.646 \n",
      "(epoch: 76, iters: 700, time: 0.100, data: 0.001) G_GAN: 0.874 G_L1: 2.269 D_real: 0.651 D_fake: 0.554 \n",
      "(epoch: 76, iters: 800, time: 0.098, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.769 D_fake: 0.630 \n",
      "(epoch: 76, iters: 900, time: 0.105, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.722 D_fake: 0.668 \n",
      "(epoch: 76, iters: 1000, time: 0.100, data: 0.001) G_GAN: 0.772 G_L1: 2.064 D_real: 0.582 D_fake: 0.630 \n",
      "(epoch: 76, iters: 1100, time: 0.098, data: 0.002) G_GAN: 0.786 G_L1: 0.000 D_real: 0.792 D_fake: 0.606 \n",
      "(epoch: 76, iters: 1200, time: 0.098, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.712 D_fake: 0.677 \n",
      "(epoch: 76, iters: 1300, time: 0.099, data: 0.002) G_GAN: 0.786 G_L1: 3.100 D_real: 0.574 D_fake: 0.657 \n",
      "(epoch: 76, iters: 1400, time: 0.108, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.749 D_fake: 0.654 \n",
      "(epoch: 76, iters: 1500, time: 0.101, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.733 D_fake: 0.659 \n",
      "(epoch: 76, iters: 1600, time: 0.096, data: 0.001) G_GAN: 0.731 G_L1: 1.704 D_real: 0.589 D_fake: 0.654 \n",
      "(epoch: 76, iters: 1700, time: 0.098, data: 0.001) G_GAN: 0.778 G_L1: 0.000 D_real: 0.785 D_fake: 0.640 \n",
      "(epoch: 76, iters: 1800, time: 0.094, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.727 D_fake: 0.613 \n",
      "(epoch: 76, iters: 1900, time: 0.098, data: 0.002) G_GAN: 0.719 G_L1: 4.005 D_real: 0.492 D_fake: 0.687 \n",
      "(epoch: 76, iters: 2000, time: 0.109, data: 0.001) G_GAN: 0.763 G_L1: 0.000 D_real: 0.765 D_fake: 0.629 \n",
      "(epoch: 76, iters: 2100, time: 0.094, data: 0.001) G_GAN: 0.621 G_L1: 0.000 D_real: 0.662 D_fake: 0.451 \n",
      "(epoch: 76, iters: 2200, time: 0.109, data: 0.001) G_GAN: 0.847 G_L1: 1.935 D_real: 0.626 D_fake: 0.544 \n",
      "End of epoch 76 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 77, iters: 20, time: 0.103, data: 0.001) G_GAN: 0.801 G_L1: 0.000 D_real: 0.806 D_fake: 0.744 \n",
      "(epoch: 77, iters: 120, time: 0.098, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.749 D_fake: 0.641 \n",
      "(epoch: 77, iters: 220, time: 0.098, data: 0.001) G_GAN: 0.808 G_L1: 3.205 D_real: 0.579 D_fake: 0.638 \n",
      "(epoch: 77, iters: 320, time: 0.098, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.749 D_fake: 0.645 \n",
      "(epoch: 77, iters: 420, time: 0.097, data: 0.001) G_GAN: 0.713 G_L1: 0.000 D_real: 0.714 D_fake: 0.675 \n",
      "(epoch: 77, iters: 520, time: 0.096, data: 0.001) G_GAN: 0.820 G_L1: 1.603 D_real: 0.655 D_fake: 0.604 \n",
      "(epoch: 77, iters: 620, time: 0.100, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.723 D_fake: 0.668 \n",
      "(epoch: 77, iters: 720, time: 0.098, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.745 D_fake: 0.656 \n",
      "(epoch: 77, iters: 820, time: 0.099, data: 0.001) G_GAN: 0.755 G_L1: 2.187 D_real: 0.576 D_fake: 0.639 \n",
      "(epoch: 77, iters: 920, time: 0.106, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.695 D_fake: 0.695 \n",
      "(epoch: 77, iters: 1020, time: 0.108, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.695 D_fake: 0.672 \n",
      "(epoch: 77, iters: 1120, time: 0.108, data: 0.002) G_GAN: 0.725 G_L1: 1.002 D_real: 0.598 D_fake: 0.627 \n",
      "(epoch: 77, iters: 1220, time: 0.097, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.752 D_fake: 0.537 \n",
      "(epoch: 77, iters: 1320, time: 0.098, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.704 D_fake: 0.692 \n",
      "(epoch: 77, iters: 1420, time: 0.098, data: 0.002) G_GAN: 0.710 G_L1: 2.201 D_real: 0.540 D_fake: 0.703 \n",
      "(epoch: 77, iters: 1520, time: 0.100, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.740 D_fake: 0.651 \n",
      "(epoch: 77, iters: 1620, time: 0.110, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.750 D_fake: 0.642 \n",
      "(epoch: 77, iters: 1720, time: 0.101, data: 0.002) G_GAN: 0.744 G_L1: 3.384 D_real: 0.531 D_fake: 0.653 \n",
      "saving the latest model (epoch 77, total_steps 175000)\n",
      "(epoch: 77, iters: 1820, time: 0.110, data: 0.002) G_GAN: 0.786 G_L1: 0.000 D_real: 0.791 D_fake: 0.629 \n",
      "(epoch: 77, iters: 1920, time: 0.097, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.728 D_fake: 0.652 \n",
      "(epoch: 77, iters: 2020, time: 0.100, data: 0.001) G_GAN: 0.788 G_L1: 1.903 D_real: 0.617 D_fake: 0.622 \n",
      "(epoch: 77, iters: 2120, time: 0.097, data: 0.001) G_GAN: 0.773 G_L1: 0.000 D_real: 0.775 D_fake: 0.655 \n",
      "(epoch: 77, iters: 2220, time: 0.100, data: 0.002) G_GAN: 0.663 G_L1: 0.000 D_real: 0.659 D_fake: 0.735 \n",
      "End of epoch 77 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 78, iters: 40, time: 0.108, data: 0.001) G_GAN: 0.757 G_L1: 1.545 D_real: 0.599 D_fake: 0.639 \n",
      "(epoch: 78, iters: 140, time: 0.097, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.746 D_fake: 0.659 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 78, iters: 240, time: 0.106, data: 0.001) G_GAN: 0.709 G_L1: 0.000 D_real: 0.709 D_fake: 0.682 \n",
      "(epoch: 78, iters: 340, time: 0.097, data: 0.001) G_GAN: 0.741 G_L1: 0.576 D_real: 0.641 D_fake: 0.668 \n",
      "(epoch: 78, iters: 440, time: 0.095, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.738 D_fake: 0.654 \n",
      "(epoch: 78, iters: 540, time: 0.095, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.690 D_fake: 0.698 \n",
      "(epoch: 78, iters: 640, time: 0.107, data: 0.002) G_GAN: 0.750 G_L1: 3.338 D_real: 0.557 D_fake: 0.631 \n",
      "(epoch: 78, iters: 740, time: 0.093, data: 0.002) G_GAN: 0.766 G_L1: 0.000 D_real: 0.773 D_fake: 0.624 \n",
      "(epoch: 78, iters: 840, time: 0.094, data: 0.001) G_GAN: 0.717 G_L1: 0.000 D_real: 0.719 D_fake: 0.672 \n",
      "(epoch: 78, iters: 940, time: 0.097, data: 0.001) G_GAN: 0.811 G_L1: 1.224 D_real: 0.667 D_fake: 0.579 \n",
      "(epoch: 78, iters: 1040, time: 0.105, data: 0.002) G_GAN: 0.678 G_L1: 0.000 D_real: 0.676 D_fake: 0.717 \n",
      "(epoch: 78, iters: 1140, time: 0.098, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.707 D_fake: 0.568 \n",
      "(epoch: 78, iters: 1240, time: 0.095, data: 0.001) G_GAN: 0.920 G_L1: 2.557 D_real: 0.705 D_fake: 0.611 \n",
      "(epoch: 78, iters: 1340, time: 0.099, data: 0.001) G_GAN: 0.845 G_L1: 0.000 D_real: 0.867 D_fake: 0.670 \n",
      "(epoch: 78, iters: 1440, time: 0.098, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.753 D_fake: 0.641 \n",
      "(epoch: 78, iters: 1540, time: 0.099, data: 0.002) G_GAN: 0.804 G_L1: 1.958 D_real: 0.615 D_fake: 0.640 \n",
      "(epoch: 78, iters: 1640, time: 0.110, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.730 D_fake: 0.658 \n",
      "(epoch: 78, iters: 1740, time: 0.101, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.744 D_fake: 0.648 \n",
      "(epoch: 78, iters: 1840, time: 0.100, data: 0.001) G_GAN: 0.757 G_L1: 0.311 D_real: 0.657 D_fake: 0.639 \n",
      "(epoch: 78, iters: 1940, time: 0.113, data: 0.002) G_GAN: 0.791 G_L1: 0.000 D_real: 0.797 D_fake: 0.602 \n",
      "(epoch: 78, iters: 2040, time: 0.098, data: 0.001) G_GAN: 0.762 G_L1: 0.000 D_real: 0.765 D_fake: 0.628 \n",
      "(epoch: 78, iters: 2140, time: 0.098, data: 0.002) G_GAN: 0.801 G_L1: 0.787 D_real: 0.666 D_fake: 0.649 \n",
      "(epoch: 78, iters: 2240, time: 0.097, data: 0.002) G_GAN: 0.678 G_L1: 0.000 D_real: 0.674 D_fake: 0.705 \n",
      "End of epoch 78 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 79, iters: 60, time: 0.121, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.725 D_fake: 0.668 \n",
      "(epoch: 79, iters: 160, time: 0.098, data: 0.002) G_GAN: 0.750 G_L1: 3.185 D_real: 0.542 D_fake: 0.629 \n",
      "(epoch: 79, iters: 260, time: 0.108, data: 0.002) G_GAN: 0.846 G_L1: 0.000 D_real: 0.888 D_fake: 0.543 \n",
      "(epoch: 79, iters: 360, time: 0.095, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.719 D_fake: 0.671 \n",
      "(epoch: 79, iters: 460, time: 0.098, data: 0.002) G_GAN: 0.790 G_L1: 2.593 D_real: 0.583 D_fake: 0.612 \n",
      "(epoch: 79, iters: 560, time: 0.098, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.748 D_fake: 0.646 \n",
      "(epoch: 79, iters: 660, time: 0.098, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.720 D_fake: 0.671 \n",
      "(epoch: 79, iters: 760, time: 0.097, data: 0.002) G_GAN: 0.716 G_L1: 2.399 D_real: 0.538 D_fake: 0.690 \n",
      "(epoch: 79, iters: 860, time: 0.094, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.728 D_fake: 0.588 \n",
      "(epoch: 79, iters: 960, time: 0.106, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.710 D_fake: 0.632 \n",
      "(epoch: 79, iters: 1060, time: 0.093, data: 0.002) G_GAN: 0.742 G_L1: 0.087 D_real: 0.668 D_fake: 0.654 \n",
      "(epoch: 79, iters: 1160, time: 0.106, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.765 D_fake: 0.624 \n",
      "(epoch: 79, iters: 1260, time: 0.096, data: 0.002) G_GAN: 0.644 G_L1: 0.000 D_real: 0.635 D_fake: 0.765 \n",
      "(epoch: 79, iters: 1360, time: 0.096, data: 0.001) G_GAN: 0.738 G_L1: 4.502 D_real: 0.501 D_fake: 0.658 \n",
      "(epoch: 79, iters: 1460, time: 0.095, data: 0.001) G_GAN: 0.762 G_L1: 0.000 D_real: 0.768 D_fake: 0.649 \n",
      "(epoch: 79, iters: 1560, time: 0.094, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.727 D_fake: 0.663 \n",
      "(epoch: 79, iters: 1660, time: 0.096, data: 0.002) G_GAN: 0.787 G_L1: 1.973 D_real: 0.603 D_fake: 0.612 \n",
      "(epoch: 79, iters: 1760, time: 0.098, data: 0.001) G_GAN: 0.762 G_L1: 0.000 D_real: 0.766 D_fake: 0.628 \n",
      "(epoch: 79, iters: 1860, time: 0.098, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.725 D_fake: 0.657 \n",
      "(epoch: 79, iters: 1960, time: 0.098, data: 0.001) G_GAN: 0.771 G_L1: 0.417 D_real: 0.654 D_fake: 0.628 \n",
      "(epoch: 79, iters: 2060, time: 0.094, data: 0.001) G_GAN: 0.724 G_L1: 0.000 D_real: 0.725 D_fake: 0.667 \n",
      "(epoch: 79, iters: 2160, time: 0.097, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.715 D_fake: 0.549 \n",
      "saving the latest model (epoch 79, total_steps 180000)\n",
      "(epoch: 79, iters: 2260, time: 0.094, data: 0.001) G_GAN: 0.739 G_L1: 3.017 D_real: 0.544 D_fake: 0.655 \n",
      "End of epoch 79 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 80, iters: 80, time: 0.118, data: 0.001) G_GAN: 0.720 G_L1: 0.000 D_real: 0.722 D_fake: 0.668 \n",
      "(epoch: 80, iters: 180, time: 0.100, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.723 D_fake: 0.666 \n",
      "(epoch: 80, iters: 280, time: 0.098, data: 0.001) G_GAN: 0.749 G_L1: 1.052 D_real: 0.616 D_fake: 0.666 \n",
      "(epoch: 80, iters: 380, time: 0.099, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.767 D_fake: 0.631 \n",
      "(epoch: 80, iters: 480, time: 0.110, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.723 D_fake: 0.660 \n",
      "(epoch: 80, iters: 580, time: 0.097, data: 0.002) G_GAN: 0.761 G_L1: 4.208 D_real: 0.528 D_fake: 0.648 \n",
      "(epoch: 80, iters: 680, time: 0.095, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.744 D_fake: 0.621 \n",
      "(epoch: 80, iters: 780, time: 0.096, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.734 D_fake: 0.657 \n",
      "(epoch: 80, iters: 880, time: 0.094, data: 0.001) G_GAN: 0.761 G_L1: 3.483 D_real: 0.527 D_fake: 0.645 \n",
      "(epoch: 80, iters: 980, time: 0.096, data: 0.002) G_GAN: 0.702 G_L1: 0.000 D_real: 0.702 D_fake: 0.689 \n",
      "(epoch: 80, iters: 1080, time: 0.097, data: 0.002) G_GAN: 0.674 G_L1: 0.000 D_real: 0.675 D_fake: 0.715 \n",
      "(epoch: 80, iters: 1180, time: 0.096, data: 0.002) G_GAN: 0.778 G_L1: 0.978 D_real: 0.639 D_fake: 0.622 \n",
      "(epoch: 80, iters: 1280, time: 0.096, data: 0.001) G_GAN: 0.801 G_L1: 0.000 D_real: 0.806 D_fake: 0.633 \n",
      "(epoch: 80, iters: 1380, time: 0.097, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.728 D_fake: 0.641 \n",
      "(epoch: 80, iters: 1480, time: 0.098, data: 0.001) G_GAN: 0.741 G_L1: 1.681 D_real: 0.574 D_fake: 0.661 \n",
      "(epoch: 80, iters: 1580, time: 0.097, data: 0.001) G_GAN: 0.783 G_L1: 0.000 D_real: 0.785 D_fake: 0.614 \n",
      "(epoch: 80, iters: 1680, time: 0.110, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.747 D_fake: 0.644 \n",
      "(epoch: 80, iters: 1780, time: 0.098, data: 0.002) G_GAN: 0.749 G_L1: 3.487 D_real: 0.533 D_fake: 0.645 \n",
      "(epoch: 80, iters: 1880, time: 0.099, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.754 D_fake: 0.653 \n",
      "(epoch: 80, iters: 1980, time: 0.098, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.733 D_fake: 0.658 \n",
      "(epoch: 80, iters: 2080, time: 0.108, data: 0.002) G_GAN: 0.737 G_L1: 2.663 D_real: 0.544 D_fake: 0.652 \n",
      "(epoch: 80, iters: 2180, time: 0.100, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.707 D_fake: 0.681 \n",
      "(epoch: 80, iters: 2280, time: 0.097, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.757 D_fake: 0.592 \n",
      "saving the model at the end of epoch 80, iters 182400\n",
      "End of epoch 80 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 81, iters: 100, time: 0.108, data: 0.286) G_GAN: 0.776 G_L1: 2.739 D_real: 0.578 D_fake: 0.652 \n",
      "(epoch: 81, iters: 200, time: 0.098, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.718 D_fake: 0.654 \n",
      "(epoch: 81, iters: 300, time: 0.099, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.729 D_fake: 0.662 \n",
      "(epoch: 81, iters: 400, time: 0.096, data: 0.002) G_GAN: 0.751 G_L1: 1.900 D_real: 0.583 D_fake: 0.644 \n",
      "(epoch: 81, iters: 500, time: 0.099, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.733 D_fake: 0.657 \n",
      "(epoch: 81, iters: 600, time: 0.105, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.742 D_fake: 0.640 \n",
      "(epoch: 81, iters: 700, time: 0.100, data: 0.002) G_GAN: 0.832 G_L1: 2.269 D_real: 0.621 D_fake: 0.583 \n",
      "(epoch: 81, iters: 800, time: 0.100, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.740 D_fake: 0.656 \n",
      "(epoch: 81, iters: 900, time: 0.105, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.708 D_fake: 0.688 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 81, iters: 1000, time: 0.100, data: 0.003) G_GAN: 0.770 G_L1: 2.064 D_real: 0.575 D_fake: 0.632 \n",
      "(epoch: 81, iters: 1100, time: 0.100, data: 0.001) G_GAN: 0.770 G_L1: 0.000 D_real: 0.772 D_fake: 0.639 \n",
      "(epoch: 81, iters: 1200, time: 0.097, data: 0.001) G_GAN: 0.736 G_L1: 0.000 D_real: 0.738 D_fake: 0.652 \n",
      "(epoch: 81, iters: 1300, time: 0.098, data: 0.001) G_GAN: 0.804 G_L1: 3.100 D_real: 0.583 D_fake: 0.600 \n",
      "(epoch: 81, iters: 1400, time: 0.096, data: 0.002) G_GAN: 0.789 G_L1: 0.000 D_real: 0.793 D_fake: 0.607 \n",
      "(epoch: 81, iters: 1500, time: 0.099, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.737 D_fake: 0.657 \n",
      "(epoch: 81, iters: 1600, time: 0.108, data: 0.002) G_GAN: 0.754 G_L1: 1.704 D_real: 0.587 D_fake: 0.639 \n",
      "(epoch: 81, iters: 1700, time: 0.109, data: 0.001) G_GAN: 0.800 G_L1: 0.000 D_real: 0.804 D_fake: 0.598 \n",
      "(epoch: 81, iters: 1800, time: 0.096, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.734 D_fake: 0.657 \n",
      "(epoch: 81, iters: 1900, time: 0.109, data: 0.001) G_GAN: 0.757 G_L1: 4.005 D_real: 0.526 D_fake: 0.641 \n",
      "(epoch: 81, iters: 2000, time: 0.097, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.754 D_fake: 0.641 \n",
      "(epoch: 81, iters: 2100, time: 0.095, data: 0.002) G_GAN: 0.643 G_L1: 0.000 D_real: 0.633 D_fake: 0.762 \n",
      "(epoch: 81, iters: 2200, time: 0.099, data: 0.002) G_GAN: 0.697 G_L1: 1.935 D_real: 0.512 D_fake: 0.729 \n",
      "End of epoch 81 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 82, iters: 20, time: 0.104, data: 0.002) G_GAN: 0.781 G_L1: 0.000 D_real: 0.788 D_fake: 0.613 \n",
      "(epoch: 82, iters: 120, time: 0.096, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.712 D_fake: 0.672 \n",
      "(epoch: 82, iters: 220, time: 0.096, data: 0.002) G_GAN: 0.765 G_L1: 3.205 D_real: 0.545 D_fake: 0.633 \n",
      "(epoch: 82, iters: 320, time: 0.099, data: 0.002) G_GAN: 0.762 G_L1: 0.000 D_real: 0.764 D_fake: 0.633 \n",
      "saving the latest model (epoch 82, total_steps 185000)\n",
      "(epoch: 82, iters: 420, time: 0.107, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.723 D_fake: 0.665 \n",
      "(epoch: 82, iters: 520, time: 0.094, data: 0.001) G_GAN: 0.785 G_L1: 1.603 D_real: 0.608 D_fake: 0.618 \n",
      "(epoch: 82, iters: 620, time: 0.098, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.644 \n",
      "(epoch: 82, iters: 720, time: 0.099, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.726 D_fake: 0.632 \n",
      "(epoch: 82, iters: 820, time: 0.109, data: 0.001) G_GAN: 0.747 G_L1: 2.187 D_real: 0.570 D_fake: 0.652 \n",
      "(epoch: 82, iters: 920, time: 0.108, data: 0.001) G_GAN: 0.749 G_L1: 0.000 D_real: 0.754 D_fake: 0.598 \n",
      "(epoch: 82, iters: 1020, time: 0.096, data: 0.002) G_GAN: 0.659 G_L1: 0.000 D_real: 0.661 D_fake: 0.730 \n",
      "(epoch: 82, iters: 1120, time: 0.099, data: 0.002) G_GAN: 0.777 G_L1: 1.002 D_real: 0.628 D_fake: 0.601 \n",
      "(epoch: 82, iters: 1220, time: 0.097, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.748 D_fake: 0.583 \n",
      "(epoch: 82, iters: 1320, time: 0.097, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.715 D_fake: 0.666 \n",
      "(epoch: 82, iters: 1420, time: 0.106, data: 0.001) G_GAN: 0.884 G_L1: 2.201 D_real: 0.667 D_fake: 0.545 \n",
      "(epoch: 82, iters: 1520, time: 0.097, data: 0.002) G_GAN: 0.773 G_L1: 0.000 D_real: 0.773 D_fake: 0.627 \n",
      "(epoch: 82, iters: 1620, time: 0.094, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.743 D_fake: 0.656 \n",
      "(epoch: 82, iters: 1720, time: 0.098, data: 0.002) G_GAN: 0.761 G_L1: 3.384 D_real: 0.551 D_fake: 0.644 \n",
      "(epoch: 82, iters: 1820, time: 0.098, data: 0.002) G_GAN: 0.784 G_L1: 0.000 D_real: 0.792 D_fake: 0.609 \n",
      "(epoch: 82, iters: 1920, time: 0.106, data: 0.001) G_GAN: 0.734 G_L1: 0.000 D_real: 0.737 D_fake: 0.619 \n",
      "(epoch: 82, iters: 2020, time: 0.098, data: 0.001) G_GAN: 0.760 G_L1: 1.903 D_real: 0.590 D_fake: 0.646 \n",
      "(epoch: 82, iters: 2120, time: 0.106, data: 0.002) G_GAN: 0.860 G_L1: 0.000 D_real: 0.925 D_fake: 0.524 \n",
      "(epoch: 82, iters: 2220, time: 0.098, data: 0.002) G_GAN: 0.643 G_L1: 0.000 D_real: 0.662 D_fake: 0.408 \n",
      "End of epoch 82 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 83, iters: 40, time: 0.105, data: 0.002) G_GAN: 0.740 G_L1: 1.545 D_real: 0.571 D_fake: 0.656 \n",
      "(epoch: 83, iters: 140, time: 0.097, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.727 D_fake: 0.628 \n",
      "(epoch: 83, iters: 240, time: 0.096, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.728 D_fake: 0.578 \n",
      "(epoch: 83, iters: 340, time: 0.098, data: 0.002) G_GAN: 0.734 G_L1: 0.576 D_real: 0.622 D_fake: 0.662 \n",
      "(epoch: 83, iters: 440, time: 0.096, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.737 D_fake: 0.635 \n",
      "(epoch: 83, iters: 540, time: 0.106, data: 0.001) G_GAN: 0.757 G_L1: 0.000 D_real: 0.757 D_fake: 0.635 \n",
      "(epoch: 83, iters: 640, time: 0.099, data: 0.001) G_GAN: 0.800 G_L1: 3.338 D_real: 0.586 D_fake: 0.675 \n",
      "(epoch: 83, iters: 740, time: 0.095, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.761 D_fake: 0.634 \n",
      "(epoch: 83, iters: 840, time: 0.096, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.717 D_fake: 0.672 \n",
      "(epoch: 83, iters: 940, time: 0.098, data: 0.001) G_GAN: 0.791 G_L1: 1.224 D_real: 0.622 D_fake: 0.620 \n",
      "(epoch: 83, iters: 1040, time: 0.094, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.757 D_fake: 0.673 \n",
      "(epoch: 83, iters: 1140, time: 0.098, data: 0.001) G_GAN: 0.720 G_L1: 0.000 D_real: 0.721 D_fake: 0.667 \n",
      "(epoch: 83, iters: 1240, time: 0.095, data: 0.001) G_GAN: 0.914 G_L1: 2.557 D_real: 0.670 D_fake: 0.527 \n",
      "(epoch: 83, iters: 1340, time: 0.099, data: 0.001) G_GAN: 0.831 G_L1: 0.000 D_real: 0.835 D_fake: 0.611 \n",
      "(epoch: 83, iters: 1440, time: 0.100, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.734 D_fake: 0.682 \n",
      "(epoch: 83, iters: 1540, time: 0.097, data: 0.001) G_GAN: 0.793 G_L1: 1.958 D_real: 0.608 D_fake: 0.610 \n",
      "(epoch: 83, iters: 1640, time: 0.108, data: 0.001) G_GAN: 0.749 G_L1: 0.000 D_real: 0.752 D_fake: 0.621 \n",
      "(epoch: 83, iters: 1740, time: 0.108, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.758 D_fake: 0.636 \n",
      "(epoch: 83, iters: 1840, time: 0.093, data: 0.002) G_GAN: 0.751 G_L1: 0.311 D_real: 0.656 D_fake: 0.610 \n",
      "(epoch: 83, iters: 1940, time: 0.098, data: 0.001) G_GAN: 0.786 G_L1: 0.000 D_real: 0.792 D_fake: 0.602 \n",
      "(epoch: 83, iters: 2040, time: 0.098, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.734 D_fake: 0.657 \n",
      "(epoch: 83, iters: 2140, time: 0.110, data: 0.001) G_GAN: 0.802 G_L1: 0.787 D_real: 0.658 D_fake: 0.598 \n",
      "(epoch: 83, iters: 2240, time: 0.098, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.712 D_fake: 0.650 \n",
      "End of epoch 83 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 84, iters: 60, time: 0.117, data: 0.001) G_GAN: 0.720 G_L1: 0.000 D_real: 0.720 D_fake: 0.672 \n",
      "(epoch: 84, iters: 160, time: 0.101, data: 0.001) G_GAN: 0.765 G_L1: 3.185 D_real: 0.551 D_fake: 0.635 \n",
      "(epoch: 84, iters: 260, time: 0.098, data: 0.002) G_GAN: 0.821 G_L1: 0.000 D_real: 0.851 D_fake: 0.649 \n",
      "(epoch: 84, iters: 360, time: 0.095, data: 0.001) G_GAN: 0.714 G_L1: 0.000 D_real: 0.715 D_fake: 0.675 \n",
      "(epoch: 84, iters: 460, time: 0.098, data: 0.002) G_GAN: 0.827 G_L1: 2.593 D_real: 0.633 D_fake: 0.656 \n",
      "(epoch: 84, iters: 560, time: 0.111, data: 0.001) G_GAN: 0.764 G_L1: 0.000 D_real: 0.767 D_fake: 0.630 \n",
      "(epoch: 84, iters: 660, time: 0.110, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.721 D_fake: 0.674 \n",
      "(epoch: 84, iters: 760, time: 0.096, data: 0.002) G_GAN: 0.749 G_L1: 2.399 D_real: 0.573 D_fake: 0.659 \n",
      "saving the latest model (epoch 84, total_steps 190000)\n",
      "(epoch: 84, iters: 860, time: 0.096, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.750 D_fake: 0.554 \n",
      "(epoch: 84, iters: 960, time: 0.097, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.712 D_fake: 0.694 \n",
      "(epoch: 84, iters: 1060, time: 0.097, data: 0.001) G_GAN: 0.715 G_L1: 0.087 D_real: 0.632 D_fake: 0.691 \n",
      "(epoch: 84, iters: 1160, time: 0.107, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.744 D_fake: 0.652 \n",
      "(epoch: 84, iters: 1260, time: 0.107, data: 0.002) G_GAN: 0.671 G_L1: 0.000 D_real: 0.676 D_fake: 0.519 \n",
      "(epoch: 84, iters: 1360, time: 0.095, data: 0.001) G_GAN: 0.792 G_L1: 4.502 D_real: 0.532 D_fake: 0.618 \n",
      "(epoch: 84, iters: 1460, time: 0.109, data: 0.001) G_GAN: 0.785 G_L1: 0.000 D_real: 0.797 D_fake: 0.604 \n",
      "(epoch: 84, iters: 1560, time: 0.095, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.748 D_fake: 0.652 \n",
      "(epoch: 84, iters: 1660, time: 0.108, data: 0.001) G_GAN: 0.755 G_L1: 1.973 D_real: 0.582 D_fake: 0.655 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 84, iters: 1760, time: 0.110, data: 0.001) G_GAN: 0.755 G_L1: 0.000 D_real: 0.766 D_fake: 0.672 \n",
      "(epoch: 84, iters: 1860, time: 0.103, data: 0.001) G_GAN: 0.703 G_L1: 0.000 D_real: 0.705 D_fake: 0.636 \n",
      "(epoch: 84, iters: 1960, time: 0.099, data: 0.002) G_GAN: 0.778 G_L1: 0.417 D_real: 0.659 D_fake: 0.633 \n",
      "(epoch: 84, iters: 2060, time: 0.096, data: 0.002) G_GAN: 0.775 G_L1: 0.000 D_real: 0.776 D_fake: 0.612 \n",
      "(epoch: 84, iters: 2160, time: 0.098, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.735 D_fake: 0.655 \n",
      "(epoch: 84, iters: 2260, time: 0.095, data: 0.002) G_GAN: 0.850 G_L1: 3.017 D_real: 0.617 D_fake: 0.637 \n",
      "End of epoch 84 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 85, iters: 80, time: 0.117, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.731 D_fake: 0.661 \n",
      "(epoch: 85, iters: 180, time: 0.109, data: 0.001) G_GAN: 0.711 G_L1: 0.000 D_real: 0.714 D_fake: 0.675 \n",
      "(epoch: 85, iters: 280, time: 0.098, data: 0.001) G_GAN: 0.741 G_L1: 1.052 D_real: 0.609 D_fake: 0.617 \n",
      "(epoch: 85, iters: 380, time: 0.098, data: 0.002) G_GAN: 0.768 G_L1: 0.000 D_real: 0.771 D_fake: 0.627 \n",
      "(epoch: 85, iters: 480, time: 0.096, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.730 D_fake: 0.664 \n",
      "(epoch: 85, iters: 580, time: 0.102, data: 0.001) G_GAN: 0.777 G_L1: 4.208 D_real: 0.547 D_fake: 0.590 \n",
      "(epoch: 85, iters: 680, time: 0.098, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.709 D_fake: 0.681 \n",
      "(epoch: 85, iters: 780, time: 0.106, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.723 D_fake: 0.641 \n",
      "(epoch: 85, iters: 880, time: 0.097, data: 0.001) G_GAN: 0.745 G_L1: 3.483 D_real: 0.521 D_fake: 0.659 \n",
      "(epoch: 85, iters: 980, time: 0.097, data: 0.001) G_GAN: 0.791 G_L1: 0.000 D_real: 0.796 D_fake: 0.626 \n",
      "(epoch: 85, iters: 1080, time: 0.107, data: 0.001) G_GAN: 0.592 G_L1: 0.000 D_real: 0.611 D_fake: 0.623 \n",
      "(epoch: 85, iters: 1180, time: 0.098, data: 0.001) G_GAN: 0.757 G_L1: 0.978 D_real: 0.605 D_fake: 0.641 \n",
      "(epoch: 85, iters: 1280, time: 0.109, data: 0.001) G_GAN: 0.815 G_L1: 0.000 D_real: 0.836 D_fake: 0.575 \n",
      "(epoch: 85, iters: 1380, time: 0.097, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.711 D_fake: 0.664 \n",
      "(epoch: 85, iters: 1480, time: 0.099, data: 0.002) G_GAN: 0.733 G_L1: 1.681 D_real: 0.575 D_fake: 0.572 \n",
      "(epoch: 85, iters: 1580, time: 0.096, data: 0.001) G_GAN: 0.763 G_L1: 0.000 D_real: 0.774 D_fake: 0.660 \n",
      "(epoch: 85, iters: 1680, time: 0.098, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.734 D_fake: 0.656 \n",
      "(epoch: 85, iters: 1780, time: 0.097, data: 0.001) G_GAN: 0.748 G_L1: 3.487 D_real: 0.535 D_fake: 0.640 \n",
      "(epoch: 85, iters: 1880, time: 0.099, data: 0.001) G_GAN: 0.762 G_L1: 0.000 D_real: 0.764 D_fake: 0.633 \n",
      "(epoch: 85, iters: 1980, time: 0.098, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.741 D_fake: 0.650 \n",
      "(epoch: 85, iters: 2080, time: 0.096, data: 0.001) G_GAN: 0.768 G_L1: 2.663 D_real: 0.571 D_fake: 0.647 \n",
      "(epoch: 85, iters: 2180, time: 0.098, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.738 D_fake: 0.652 \n",
      "(epoch: 85, iters: 2280, time: 0.097, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.718 D_fake: 0.675 \n",
      "saving the model at the end of epoch 85, iters 193800\n",
      "End of epoch 85 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 86, iters: 100, time: 0.117, data: 0.286) G_GAN: 0.783 G_L1: 2.739 D_real: 0.569 D_fake: 0.622 \n",
      "(epoch: 86, iters: 200, time: 0.096, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.725 D_fake: 0.669 \n",
      "(epoch: 86, iters: 300, time: 0.095, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.733 D_fake: 0.678 \n",
      "(epoch: 86, iters: 400, time: 0.097, data: 0.002) G_GAN: 0.759 G_L1: 1.900 D_real: 0.597 D_fake: 0.661 \n",
      "(epoch: 86, iters: 500, time: 0.100, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.720 D_fake: 0.578 \n",
      "(epoch: 86, iters: 600, time: 0.107, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.745 D_fake: 0.646 \n",
      "(epoch: 86, iters: 700, time: 0.098, data: 0.001) G_GAN: 0.908 G_L1: 2.269 D_real: 0.674 D_fake: 0.664 \n",
      "(epoch: 86, iters: 800, time: 0.110, data: 0.001) G_GAN: 0.724 G_L1: 0.000 D_real: 0.727 D_fake: 0.661 \n",
      "(epoch: 86, iters: 900, time: 0.095, data: 0.002) G_GAN: 0.625 G_L1: 0.000 D_real: 0.610 D_fake: 0.732 \n",
      "(epoch: 86, iters: 1000, time: 0.096, data: 0.001) G_GAN: 0.826 G_L1: 2.064 D_real: 0.622 D_fake: 0.594 \n",
      "(epoch: 86, iters: 1100, time: 0.098, data: 0.001) G_GAN: 0.792 G_L1: 0.000 D_real: 0.806 D_fake: 0.628 \n",
      "(epoch: 86, iters: 1200, time: 0.099, data: 0.001) G_GAN: 0.703 G_L1: 0.000 D_real: 0.701 D_fake: 0.687 \n",
      "saving the latest model (epoch 86, total_steps 195000)\n",
      "(epoch: 86, iters: 1300, time: 0.107, data: 0.001) G_GAN: 0.805 G_L1: 3.100 D_real: 0.578 D_fake: 0.594 \n",
      "(epoch: 86, iters: 1400, time: 0.098, data: 0.001) G_GAN: 0.798 G_L1: 0.000 D_real: 0.813 D_fake: 0.594 \n",
      "(epoch: 86, iters: 1500, time: 0.097, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.726 D_fake: 0.666 \n",
      "(epoch: 86, iters: 1600, time: 0.109, data: 0.001) G_GAN: 0.769 G_L1: 1.704 D_real: 0.599 D_fake: 0.625 \n",
      "(epoch: 86, iters: 1700, time: 0.109, data: 0.002) G_GAN: 0.779 G_L1: 0.000 D_real: 0.783 D_fake: 0.616 \n",
      "(epoch: 86, iters: 1800, time: 0.095, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.723 D_fake: 0.666 \n",
      "(epoch: 86, iters: 1900, time: 0.100, data: 0.002) G_GAN: 0.784 G_L1: 4.005 D_real: 0.538 D_fake: 0.621 \n",
      "(epoch: 86, iters: 2000, time: 0.095, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.645 \n",
      "(epoch: 86, iters: 2100, time: 0.094, data: 0.001) G_GAN: 0.600 G_L1: 0.000 D_real: 0.569 D_fake: 0.848 \n",
      "(epoch: 86, iters: 2200, time: 0.098, data: 0.002) G_GAN: 0.716 G_L1: 1.935 D_real: 0.545 D_fake: 0.679 \n",
      "End of epoch 86 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 87, iters: 20, time: 0.115, data: 0.001) G_GAN: 0.773 G_L1: 0.000 D_real: 0.778 D_fake: 0.625 \n",
      "(epoch: 87, iters: 120, time: 0.097, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.728 D_fake: 0.581 \n",
      "(epoch: 87, iters: 220, time: 0.097, data: 0.002) G_GAN: 0.775 G_L1: 3.205 D_real: 0.548 D_fake: 0.582 \n",
      "(epoch: 87, iters: 320, time: 0.095, data: 0.001) G_GAN: 0.749 G_L1: 0.000 D_real: 0.756 D_fake: 0.628 \n",
      "(epoch: 87, iters: 420, time: 0.109, data: 0.001) G_GAN: 0.707 G_L1: 0.000 D_real: 0.708 D_fake: 0.681 \n",
      "(epoch: 87, iters: 520, time: 0.095, data: 0.001) G_GAN: 0.782 G_L1: 1.603 D_real: 0.625 D_fake: 0.552 \n",
      "(epoch: 87, iters: 620, time: 0.100, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.747 D_fake: 0.646 \n",
      "(epoch: 87, iters: 720, time: 0.098, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.700 D_fake: 0.688 \n",
      "(epoch: 87, iters: 820, time: 0.096, data: 0.001) G_GAN: 0.810 G_L1: 2.187 D_real: 0.610 D_fake: 0.599 \n",
      "(epoch: 87, iters: 920, time: 0.096, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.734 D_fake: 0.502 \n",
      "(epoch: 87, iters: 1020, time: 0.095, data: 0.001) G_GAN: 0.704 G_L1: 0.000 D_real: 0.706 D_fake: 0.685 \n",
      "(epoch: 87, iters: 1120, time: 0.097, data: 0.001) G_GAN: 0.790 G_L1: 1.002 D_real: 0.637 D_fake: 0.610 \n",
      "(epoch: 87, iters: 1220, time: 0.096, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.730 D_fake: 0.597 \n",
      "(epoch: 87, iters: 1320, time: 0.108, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.725 D_fake: 0.653 \n",
      "(epoch: 87, iters: 1420, time: 0.098, data: 0.002) G_GAN: 0.748 G_L1: 2.201 D_real: 0.561 D_fake: 0.651 \n",
      "(epoch: 87, iters: 1520, time: 0.099, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.737 D_fake: 0.664 \n",
      "(epoch: 87, iters: 1620, time: 0.097, data: 0.001) G_GAN: 0.724 G_L1: 0.000 D_real: 0.726 D_fake: 0.665 \n",
      "(epoch: 87, iters: 1720, time: 0.099, data: 0.002) G_GAN: 0.760 G_L1: 3.384 D_real: 0.548 D_fake: 0.584 \n",
      "(epoch: 87, iters: 1820, time: 0.112, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.758 D_fake: 0.596 \n",
      "(epoch: 87, iters: 1920, time: 0.097, data: 0.001) G_GAN: 0.719 G_L1: 0.000 D_real: 0.721 D_fake: 0.673 \n",
      "(epoch: 87, iters: 2020, time: 0.099, data: 0.001) G_GAN: 0.771 G_L1: 1.903 D_real: 0.598 D_fake: 0.628 \n",
      "(epoch: 87, iters: 2120, time: 0.099, data: 0.001) G_GAN: 0.804 G_L1: 0.000 D_real: 0.807 D_fake: 0.597 \n",
      "(epoch: 87, iters: 2220, time: 0.100, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.728 D_fake: 0.665 \n",
      "End of epoch 87 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 88, iters: 40, time: 0.109, data: 0.001) G_GAN: 0.764 G_L1: 1.545 D_real: 0.593 D_fake: 0.636 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 88, iters: 140, time: 0.096, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.749 D_fake: 0.645 \n",
      "(epoch: 88, iters: 240, time: 0.098, data: 0.001) G_GAN: 0.744 G_L1: 0.000 D_real: 0.746 D_fake: 0.647 \n",
      "(epoch: 88, iters: 340, time: 0.097, data: 0.002) G_GAN: 0.722 G_L1: 0.576 D_real: 0.595 D_fake: 0.672 \n",
      "(epoch: 88, iters: 440, time: 0.107, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.749 D_fake: 0.647 \n",
      "(epoch: 88, iters: 540, time: 0.094, data: 0.001) G_GAN: 0.749 G_L1: 0.000 D_real: 0.766 D_fake: 0.533 \n",
      "(epoch: 88, iters: 640, time: 0.097, data: 0.001) G_GAN: 0.852 G_L1: 3.338 D_real: 0.614 D_fake: 0.566 \n",
      "(epoch: 88, iters: 740, time: 0.096, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.767 D_fake: 0.628 \n",
      "(epoch: 88, iters: 840, time: 0.097, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.723 D_fake: 0.666 \n",
      "(epoch: 88, iters: 940, time: 0.106, data: 0.001) G_GAN: 0.747 G_L1: 1.224 D_real: 0.594 D_fake: 0.656 \n",
      "(epoch: 88, iters: 1040, time: 0.096, data: 0.001) G_GAN: 0.779 G_L1: 0.000 D_real: 0.788 D_fake: 0.617 \n",
      "(epoch: 88, iters: 1140, time: 0.096, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.736 D_fake: 0.653 \n",
      "(epoch: 88, iters: 1240, time: 0.097, data: 0.001) G_GAN: 0.857 G_L1: 2.557 D_real: 0.647 D_fake: 0.664 \n",
      "(epoch: 88, iters: 1340, time: 0.099, data: 0.001) G_GAN: 0.760 G_L1: 0.000 D_real: 0.763 D_fake: 0.647 \n",
      "(epoch: 88, iters: 1440, time: 0.100, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.740 D_fake: 0.652 \n",
      "(epoch: 88, iters: 1540, time: 0.098, data: 0.001) G_GAN: 0.785 G_L1: 1.958 D_real: 0.593 D_fake: 0.645 \n",
      "(epoch: 88, iters: 1640, time: 0.097, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.744 D_fake: 0.648 \n",
      "saving the latest model (epoch 88, total_steps 200000)\n",
      "(epoch: 88, iters: 1740, time: 0.097, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.746 D_fake: 0.647 \n",
      "(epoch: 88, iters: 1840, time: 0.098, data: 0.002) G_GAN: 0.755 G_L1: 0.311 D_real: 0.641 D_fake: 0.641 \n",
      "(epoch: 88, iters: 1940, time: 0.110, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.764 D_fake: 0.669 \n",
      "(epoch: 88, iters: 2040, time: 0.098, data: 0.001) G_GAN: 0.719 G_L1: 0.000 D_real: 0.721 D_fake: 0.663 \n",
      "(epoch: 88, iters: 2140, time: 0.108, data: 0.001) G_GAN: 0.864 G_L1: 0.787 D_real: 0.714 D_fake: 0.547 \n",
      "(epoch: 88, iters: 2240, time: 0.099, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.703 D_fake: 0.689 \n",
      "End of epoch 88 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 89, iters: 60, time: 0.116, data: 0.001) G_GAN: 0.743 G_L1: 0.000 D_real: 0.746 D_fake: 0.668 \n",
      "(epoch: 89, iters: 160, time: 0.108, data: 0.001) G_GAN: 0.756 G_L1: 3.185 D_real: 0.529 D_fake: 0.647 \n",
      "(epoch: 89, iters: 260, time: 0.097, data: 0.002) G_GAN: 0.846 G_L1: 0.000 D_real: 0.860 D_fake: 0.561 \n",
      "(epoch: 89, iters: 360, time: 0.108, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.701 D_fake: 0.602 \n",
      "(epoch: 89, iters: 460, time: 0.100, data: 0.001) G_GAN: 0.783 G_L1: 2.593 D_real: 0.602 D_fake: 0.647 \n",
      "(epoch: 89, iters: 560, time: 0.097, data: 0.002) G_GAN: 0.779 G_L1: 0.000 D_real: 0.790 D_fake: 0.610 \n",
      "(epoch: 89, iters: 660, time: 0.097, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.706 D_fake: 0.684 \n",
      "(epoch: 89, iters: 760, time: 0.097, data: 0.002) G_GAN: 0.780 G_L1: 2.399 D_real: 0.584 D_fake: 0.621 \n",
      "(epoch: 89, iters: 860, time: 0.094, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.738 D_fake: 0.658 \n",
      "(epoch: 89, iters: 960, time: 0.094, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.738 D_fake: 0.661 \n",
      "(epoch: 89, iters: 1060, time: 0.095, data: 0.003) G_GAN: 0.722 G_L1: 0.087 D_real: 0.659 D_fake: 0.611 \n",
      "(epoch: 89, iters: 1160, time: 0.095, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.752 D_fake: 0.645 \n",
      "(epoch: 89, iters: 1260, time: 0.109, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.720 D_fake: 0.488 \n",
      "(epoch: 89, iters: 1360, time: 0.096, data: 0.001) G_GAN: 0.737 G_L1: 4.502 D_real: 0.502 D_fake: 0.658 \n",
      "(epoch: 89, iters: 1460, time: 0.096, data: 0.001) G_GAN: 0.801 G_L1: 0.000 D_real: 0.824 D_fake: 0.648 \n",
      "(epoch: 89, iters: 1560, time: 0.095, data: 0.001) G_GAN: 0.715 G_L1: 0.000 D_real: 0.717 D_fake: 0.637 \n",
      "(epoch: 89, iters: 1660, time: 0.098, data: 0.002) G_GAN: 0.766 G_L1: 1.973 D_real: 0.584 D_fake: 0.636 \n",
      "(epoch: 89, iters: 1760, time: 0.098, data: 0.001) G_GAN: 0.789 G_L1: 0.000 D_real: 0.794 D_fake: 0.633 \n",
      "(epoch: 89, iters: 1860, time: 0.100, data: 0.001) G_GAN: 0.721 G_L1: 0.000 D_real: 0.723 D_fake: 0.642 \n",
      "(epoch: 89, iters: 1960, time: 0.099, data: 0.001) G_GAN: 0.770 G_L1: 0.417 D_real: 0.654 D_fake: 0.631 \n",
      "(epoch: 89, iters: 2060, time: 0.095, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.745 D_fake: 0.649 \n",
      "(epoch: 89, iters: 2160, time: 0.108, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.731 D_fake: 0.659 \n",
      "(epoch: 89, iters: 2260, time: 0.094, data: 0.001) G_GAN: 0.768 G_L1: 3.017 D_real: 0.557 D_fake: 0.603 \n",
      "End of epoch 89 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 90, iters: 80, time: 0.102, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.739 D_fake: 0.653 \n",
      "(epoch: 90, iters: 180, time: 0.098, data: 0.001) G_GAN: 0.719 G_L1: 0.000 D_real: 0.722 D_fake: 0.667 \n",
      "(epoch: 90, iters: 280, time: 0.098, data: 0.002) G_GAN: 0.741 G_L1: 1.052 D_real: 0.606 D_fake: 0.669 \n",
      "(epoch: 90, iters: 380, time: 0.111, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.740 D_fake: 0.655 \n",
      "(epoch: 90, iters: 480, time: 0.098, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.701 D_fake: 0.686 \n",
      "(epoch: 90, iters: 580, time: 0.101, data: 0.002) G_GAN: 0.760 G_L1: 4.208 D_real: 0.521 D_fake: 0.636 \n",
      "(epoch: 90, iters: 680, time: 0.097, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.752 D_fake: 0.643 \n",
      "(epoch: 90, iters: 780, time: 0.096, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.717 D_fake: 0.671 \n",
      "(epoch: 90, iters: 880, time: 0.106, data: 0.002) G_GAN: 0.727 G_L1: 3.483 D_real: 0.528 D_fake: 0.616 \n",
      "(epoch: 90, iters: 980, time: 0.100, data: 0.001) G_GAN: 0.736 G_L1: 0.000 D_real: 0.738 D_fake: 0.669 \n",
      "(epoch: 90, iters: 1080, time: 0.095, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.714 D_fake: 0.676 \n",
      "(epoch: 90, iters: 1180, time: 0.099, data: 0.002) G_GAN: 0.761 G_L1: 0.978 D_real: 0.618 D_fake: 0.642 \n",
      "(epoch: 90, iters: 1280, time: 0.100, data: 0.001) G_GAN: 0.806 G_L1: 0.000 D_real: 0.817 D_fake: 0.630 \n",
      "(epoch: 90, iters: 1380, time: 0.096, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.738 D_fake: 0.653 \n",
      "(epoch: 90, iters: 1480, time: 0.109, data: 0.001) G_GAN: 0.743 G_L1: 1.681 D_real: 0.576 D_fake: 0.655 \n",
      "(epoch: 90, iters: 1580, time: 0.098, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.748 D_fake: 0.644 \n",
      "(epoch: 90, iters: 1680, time: 0.099, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.758 D_fake: 0.635 \n",
      "(epoch: 90, iters: 1780, time: 0.096, data: 0.001) G_GAN: 0.748 G_L1: 3.487 D_real: 0.538 D_fake: 0.646 \n",
      "(epoch: 90, iters: 1880, time: 0.098, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.761 D_fake: 0.644 \n",
      "(epoch: 90, iters: 1980, time: 0.097, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.750 D_fake: 0.642 \n",
      "(epoch: 90, iters: 2080, time: 0.097, data: 0.002) G_GAN: 0.730 G_L1: 2.663 D_real: 0.529 D_fake: 0.656 \n",
      "saving the latest model (epoch 90, total_steps 205000)\n",
      "(epoch: 90, iters: 2180, time: 0.097, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.746 D_fake: 0.644 \n",
      "(epoch: 90, iters: 2280, time: 0.106, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.730 D_fake: 0.657 \n",
      "saving the model at the end of epoch 90, iters 205200\n",
      "End of epoch 90 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 91, iters: 100, time: 0.105, data: 0.283) G_GAN: 0.804 G_L1: 2.739 D_real: 0.579 D_fake: 0.603 \n",
      "(epoch: 91, iters: 200, time: 0.097, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.729 D_fake: 0.664 \n",
      "(epoch: 91, iters: 300, time: 0.096, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.727 D_fake: 0.664 \n",
      "(epoch: 91, iters: 400, time: 0.098, data: 0.001) G_GAN: 0.754 G_L1: 1.900 D_real: 0.581 D_fake: 0.644 \n",
      "(epoch: 91, iters: 500, time: 0.099, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.739 D_fake: 0.651 \n",
      "(epoch: 91, iters: 600, time: 0.099, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.758 D_fake: 0.634 \n",
      "(epoch: 91, iters: 700, time: 0.097, data: 0.002) G_GAN: 0.939 G_L1: 2.269 D_real: 0.682 D_fake: 0.520 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 91, iters: 800, time: 0.109, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.756 D_fake: 0.644 \n",
      "(epoch: 91, iters: 900, time: 0.094, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.701 D_fake: 0.697 \n",
      "(epoch: 91, iters: 1000, time: 0.098, data: 0.002) G_GAN: 0.842 G_L1: 2.064 D_real: 0.629 D_fake: 0.578 \n",
      "(epoch: 91, iters: 1100, time: 0.099, data: 0.001) G_GAN: 0.797 G_L1: 0.000 D_real: 0.801 D_fake: 0.598 \n",
      "(epoch: 91, iters: 1200, time: 0.099, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.709 D_fake: 0.662 \n",
      "(epoch: 91, iters: 1300, time: 0.097, data: 0.001) G_GAN: 0.781 G_L1: 3.100 D_real: 0.549 D_fake: 0.642 \n",
      "(epoch: 91, iters: 1400, time: 0.097, data: 0.002) G_GAN: 0.766 G_L1: 0.000 D_real: 0.767 D_fake: 0.630 \n",
      "(epoch: 91, iters: 1500, time: 0.097, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.737 D_fake: 0.651 \n",
      "(epoch: 91, iters: 1600, time: 0.098, data: 0.002) G_GAN: 0.744 G_L1: 1.704 D_real: 0.576 D_fake: 0.648 \n",
      "(epoch: 91, iters: 1700, time: 0.102, data: 0.001) G_GAN: 0.782 G_L1: 0.000 D_real: 0.789 D_fake: 0.657 \n",
      "(epoch: 91, iters: 1800, time: 0.109, data: 0.001) G_GAN: 0.721 G_L1: 0.000 D_real: 0.722 D_fake: 0.665 \n",
      "(epoch: 91, iters: 1900, time: 0.096, data: 0.001) G_GAN: 0.772 G_L1: 4.005 D_real: 0.525 D_fake: 0.633 \n",
      "(epoch: 91, iters: 2000, time: 0.098, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.743 D_fake: 0.652 \n",
      "(epoch: 91, iters: 2100, time: 0.105, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.704 D_fake: 0.637 \n",
      "(epoch: 91, iters: 2200, time: 0.103, data: 0.001) G_GAN: 0.768 G_L1: 1.935 D_real: 0.574 D_fake: 0.590 \n",
      "End of epoch 91 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 92, iters: 20, time: 0.105, data: 0.001) G_GAN: 0.769 G_L1: 0.000 D_real: 0.773 D_fake: 0.646 \n",
      "(epoch: 92, iters: 120, time: 0.109, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.733 D_fake: 0.657 \n",
      "(epoch: 92, iters: 220, time: 0.097, data: 0.001) G_GAN: 0.768 G_L1: 3.205 D_real: 0.535 D_fake: 0.637 \n",
      "(epoch: 92, iters: 320, time: 0.098, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.745 D_fake: 0.665 \n",
      "(epoch: 92, iters: 420, time: 0.108, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.688 D_fake: 0.649 \n",
      "(epoch: 92, iters: 520, time: 0.096, data: 0.002) G_GAN: 0.851 G_L1: 1.603 D_real: 0.654 D_fake: 0.563 \n",
      "(epoch: 92, iters: 620, time: 0.108, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.745 D_fake: 0.647 \n",
      "(epoch: 92, iters: 720, time: 0.107, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.725 D_fake: 0.659 \n",
      "(epoch: 92, iters: 820, time: 0.095, data: 0.001) G_GAN: 0.787 G_L1: 2.187 D_real: 0.597 D_fake: 0.647 \n",
      "(epoch: 92, iters: 920, time: 0.094, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.699 D_fake: 0.696 \n",
      "(epoch: 92, iters: 1020, time: 0.097, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.699 D_fake: 0.617 \n",
      "(epoch: 92, iters: 1120, time: 0.099, data: 0.001) G_GAN: 0.750 G_L1: 1.002 D_real: 0.614 D_fake: 0.647 \n",
      "(epoch: 92, iters: 1220, time: 0.097, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.726 D_fake: 0.663 \n",
      "(epoch: 92, iters: 1320, time: 0.108, data: 0.001) G_GAN: 0.736 G_L1: 0.000 D_real: 0.736 D_fake: 0.655 \n",
      "(epoch: 92, iters: 1420, time: 0.096, data: 0.002) G_GAN: 0.801 G_L1: 2.201 D_real: 0.611 D_fake: 0.643 \n",
      "(epoch: 92, iters: 1520, time: 0.098, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.725 D_fake: 0.651 \n",
      "(epoch: 92, iters: 1620, time: 0.095, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.711 D_fake: 0.655 \n",
      "(epoch: 92, iters: 1720, time: 0.095, data: 0.001) G_GAN: 0.741 G_L1: 3.384 D_real: 0.522 D_fake: 0.658 \n",
      "(epoch: 92, iters: 1820, time: 0.109, data: 0.002) G_GAN: 0.772 G_L1: 0.000 D_real: 0.783 D_fake: 0.618 \n",
      "(epoch: 92, iters: 1920, time: 0.097, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.719 D_fake: 0.631 \n",
      "(epoch: 92, iters: 2020, time: 0.099, data: 0.001) G_GAN: 0.770 G_L1: 1.903 D_real: 0.600 D_fake: 0.622 \n",
      "(epoch: 92, iters: 2120, time: 0.108, data: 0.002) G_GAN: 0.786 G_L1: 0.000 D_real: 0.789 D_fake: 0.725 \n",
      "(epoch: 92, iters: 2220, time: 0.112, data: 0.002) G_GAN: 0.659 G_L1: 0.000 D_real: 0.643 D_fake: 0.754 \n",
      "End of epoch 92 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 93, iters: 40, time: 0.106, data: 0.001) G_GAN: 0.755 G_L1: 1.545 D_real: 0.593 D_fake: 0.649 \n",
      "(epoch: 93, iters: 140, time: 0.098, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.770 D_fake: 0.648 \n",
      "(epoch: 93, iters: 240, time: 0.098, data: 0.001) G_GAN: 0.724 G_L1: 0.000 D_real: 0.726 D_fake: 0.666 \n",
      "saving the latest model (epoch 93, total_steps 210000)\n",
      "(epoch: 93, iters: 340, time: 0.097, data: 0.001) G_GAN: 0.751 G_L1: 0.576 D_real: 0.643 D_fake: 0.652 \n",
      "(epoch: 93, iters: 440, time: 0.096, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.764 D_fake: 0.656 \n",
      "(epoch: 93, iters: 540, time: 0.095, data: 0.002) G_GAN: 0.663 G_L1: 0.000 D_real: 0.654 D_fake: 0.738 \n",
      "(epoch: 93, iters: 640, time: 0.097, data: 0.002) G_GAN: 0.803 G_L1: 3.338 D_real: 0.576 D_fake: 0.656 \n",
      "(epoch: 93, iters: 740, time: 0.094, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.741 D_fake: 0.605 \n",
      "(epoch: 93, iters: 840, time: 0.096, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.719 D_fake: 0.629 \n",
      "(epoch: 93, iters: 940, time: 0.099, data: 0.001) G_GAN: 0.805 G_L1: 1.224 D_real: 0.634 D_fake: 0.582 \n",
      "(epoch: 93, iters: 1040, time: 0.094, data: 0.001) G_GAN: 0.765 G_L1: 0.000 D_real: 0.771 D_fake: 0.632 \n",
      "(epoch: 93, iters: 1140, time: 0.098, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.739 D_fake: 0.650 \n",
      "(epoch: 93, iters: 1240, time: 0.096, data: 0.001) G_GAN: 0.865 G_L1: 2.557 D_real: 0.630 D_fake: 0.668 \n",
      "(epoch: 93, iters: 1340, time: 0.098, data: 0.001) G_GAN: 0.867 G_L1: 0.000 D_real: 0.904 D_fake: 0.537 \n",
      "(epoch: 93, iters: 1440, time: 0.101, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.761 D_fake: 0.634 \n",
      "(epoch: 93, iters: 1540, time: 0.096, data: 0.001) G_GAN: 0.788 G_L1: 1.958 D_real: 0.597 D_fake: 0.658 \n",
      "(epoch: 93, iters: 1640, time: 0.110, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.734 D_fake: 0.648 \n",
      "(epoch: 93, iters: 1740, time: 0.100, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.726 D_fake: 0.588 \n",
      "(epoch: 93, iters: 1840, time: 0.097, data: 0.002) G_GAN: 0.736 G_L1: 0.311 D_real: 0.644 D_fake: 0.635 \n",
      "(epoch: 93, iters: 1940, time: 0.108, data: 0.001) G_GAN: 0.770 G_L1: 0.000 D_real: 0.779 D_fake: 0.617 \n",
      "(epoch: 93, iters: 2040, time: 0.097, data: 0.002) G_GAN: 0.776 G_L1: 0.000 D_real: 0.779 D_fake: 0.617 \n",
      "(epoch: 93, iters: 2140, time: 0.096, data: 0.002) G_GAN: 0.886 G_L1: 0.787 D_real: 0.746 D_fake: 0.613 \n",
      "(epoch: 93, iters: 2240, time: 0.098, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.706 D_fake: 0.688 \n",
      "End of epoch 93 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 94, iters: 60, time: 0.106, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.727 D_fake: 0.667 \n",
      "(epoch: 94, iters: 160, time: 0.099, data: 0.001) G_GAN: 0.748 G_L1: 3.185 D_real: 0.523 D_fake: 0.654 \n",
      "(epoch: 94, iters: 260, time: 0.099, data: 0.001) G_GAN: 0.802 G_L1: 0.000 D_real: 0.818 D_fake: 0.592 \n",
      "(epoch: 94, iters: 360, time: 0.096, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.718 D_fake: 0.671 \n",
      "(epoch: 94, iters: 460, time: 0.098, data: 0.002) G_GAN: 0.800 G_L1: 2.593 D_real: 0.599 D_fake: 0.657 \n",
      "(epoch: 94, iters: 560, time: 0.098, data: 0.002) G_GAN: 0.773 G_L1: 0.000 D_real: 0.777 D_fake: 0.598 \n",
      "(epoch: 94, iters: 660, time: 0.097, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.725 D_fake: 0.657 \n",
      "(epoch: 94, iters: 760, time: 0.096, data: 0.001) G_GAN: 0.750 G_L1: 2.399 D_real: 0.559 D_fake: 0.648 \n",
      "(epoch: 94, iters: 860, time: 0.097, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.752 D_fake: 0.646 \n",
      "(epoch: 94, iters: 960, time: 0.096, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.824 D_fake: 0.348 \n",
      "(epoch: 94, iters: 1060, time: 0.096, data: 0.002) G_GAN: 0.705 G_L1: 0.087 D_real: 0.624 D_fake: 0.696 \n",
      "(epoch: 94, iters: 1160, time: 0.096, data: 0.002) G_GAN: 0.774 G_L1: 0.000 D_real: 0.781 D_fake: 0.621 \n",
      "(epoch: 94, iters: 1260, time: 0.098, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.709 D_fake: 0.691 \n",
      "(epoch: 94, iters: 1360, time: 0.097, data: 0.002) G_GAN: 0.748 G_L1: 4.502 D_real: 0.506 D_fake: 0.650 \n",
      "(epoch: 94, iters: 1460, time: 0.095, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.771 D_fake: 0.653 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 94, iters: 1560, time: 0.101, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.718 D_fake: 0.667 \n",
      "(epoch: 94, iters: 1660, time: 0.096, data: 0.002) G_GAN: 0.778 G_L1: 1.973 D_real: 0.585 D_fake: 0.626 \n",
      "(epoch: 94, iters: 1760, time: 0.096, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.762 D_fake: 0.633 \n",
      "(epoch: 94, iters: 1860, time: 0.097, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.707 D_fake: 0.669 \n",
      "(epoch: 94, iters: 1960, time: 0.105, data: 0.001) G_GAN: 0.755 G_L1: 0.417 D_real: 0.640 D_fake: 0.647 \n",
      "(epoch: 94, iters: 2060, time: 0.095, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.732 D_fake: 0.662 \n",
      "(epoch: 94, iters: 2160, time: 0.107, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.728 D_fake: 0.662 \n",
      "(epoch: 94, iters: 2260, time: 0.107, data: 0.001) G_GAN: 0.845 G_L1: 3.017 D_real: 0.586 D_fake: 0.650 \n",
      "End of epoch 94 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 95, iters: 80, time: 0.104, data: 0.001) G_GAN: 0.721 G_L1: 0.000 D_real: 0.724 D_fake: 0.668 \n",
      "(epoch: 95, iters: 180, time: 0.108, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.719 D_fake: 0.670 \n",
      "(epoch: 95, iters: 280, time: 0.096, data: 0.001) G_GAN: 0.744 G_L1: 1.052 D_real: 0.600 D_fake: 0.655 \n",
      "(epoch: 95, iters: 380, time: 0.101, data: 0.003) G_GAN: 0.791 G_L1: 0.000 D_real: 0.798 D_fake: 0.606 \n",
      "(epoch: 95, iters: 480, time: 0.098, data: 0.002) G_GAN: 0.644 G_L1: 0.000 D_real: 0.647 D_fake: 0.745 \n",
      "(epoch: 95, iters: 580, time: 0.100, data: 0.002) G_GAN: 0.819 G_L1: 4.208 D_real: 0.563 D_fake: 0.592 \n",
      "(epoch: 95, iters: 680, time: 0.099, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.750 D_fake: 0.644 \n",
      "saving the latest model (epoch 95, total_steps 215000)\n",
      "(epoch: 95, iters: 780, time: 0.108, data: 0.001) G_GAN: 0.719 G_L1: 0.000 D_real: 0.719 D_fake: 0.669 \n",
      "(epoch: 95, iters: 880, time: 0.095, data: 0.002) G_GAN: 0.741 G_L1: 3.483 D_real: 0.516 D_fake: 0.636 \n",
      "(epoch: 95, iters: 980, time: 0.109, data: 0.002) G_GAN: 0.804 G_L1: 0.000 D_real: 0.812 D_fake: 0.592 \n",
      "(epoch: 95, iters: 1080, time: 0.095, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.701 D_fake: 0.688 \n",
      "(epoch: 95, iters: 1180, time: 0.099, data: 0.001) G_GAN: 0.783 G_L1: 0.978 D_real: 0.640 D_fake: 0.635 \n",
      "(epoch: 95, iters: 1280, time: 0.102, data: 0.002) G_GAN: 0.840 G_L1: 0.000 D_real: 0.854 D_fake: 0.524 \n",
      "(epoch: 95, iters: 1380, time: 0.107, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.722 D_fake: 0.669 \n",
      "(epoch: 95, iters: 1480, time: 0.096, data: 0.002) G_GAN: 0.722 G_L1: 1.681 D_real: 0.561 D_fake: 0.672 \n",
      "(epoch: 95, iters: 1580, time: 0.109, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.644 \n",
      "(epoch: 95, iters: 1680, time: 0.097, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.746 D_fake: 0.650 \n",
      "(epoch: 95, iters: 1780, time: 0.096, data: 0.002) G_GAN: 0.751 G_L1: 3.487 D_real: 0.547 D_fake: 0.599 \n",
      "(epoch: 95, iters: 1880, time: 0.096, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.759 D_fake: 0.665 \n",
      "(epoch: 95, iters: 1980, time: 0.110, data: 0.003) G_GAN: 0.742 G_L1: 0.000 D_real: 0.745 D_fake: 0.647 \n",
      "(epoch: 95, iters: 2080, time: 0.097, data: 0.001) G_GAN: 0.756 G_L1: 2.663 D_real: 0.558 D_fake: 0.645 \n",
      "(epoch: 95, iters: 2180, time: 0.099, data: 0.001) G_GAN: 0.793 G_L1: 0.000 D_real: 0.796 D_fake: 0.614 \n",
      "(epoch: 95, iters: 2280, time: 0.108, data: 0.001) G_GAN: 0.717 G_L1: 0.000 D_real: 0.720 D_fake: 0.635 \n",
      "saving the model at the end of epoch 95, iters 216600\n",
      "End of epoch 95 / 200 \t Time Taken: 127 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 96, iters: 100, time: 0.117, data: 0.306) G_GAN: 0.783 G_L1: 2.739 D_real: 0.568 D_fake: 0.624 \n",
      "(epoch: 96, iters: 200, time: 0.108, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.763 D_fake: 0.635 \n",
      "(epoch: 96, iters: 300, time: 0.096, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.732 D_fake: 0.691 \n",
      "(epoch: 96, iters: 400, time: 0.098, data: 0.001) G_GAN: 0.746 G_L1: 1.900 D_real: 0.563 D_fake: 0.655 \n",
      "(epoch: 96, iters: 500, time: 0.100, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.717 D_fake: 0.655 \n",
      "(epoch: 96, iters: 600, time: 0.098, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.761 D_fake: 0.633 \n",
      "(epoch: 96, iters: 700, time: 0.100, data: 0.002) G_GAN: 1.140 G_L1: 2.269 D_real: 0.947 D_fake: 0.651 \n",
      "(epoch: 96, iters: 800, time: 0.099, data: 0.002) G_GAN: 0.770 G_L1: 0.000 D_real: 0.775 D_fake: 0.625 \n",
      "(epoch: 96, iters: 900, time: 0.103, data: 0.001) G_GAN: 0.680 G_L1: 0.000 D_real: 0.695 D_fake: 0.356 \n",
      "(epoch: 96, iters: 1000, time: 0.098, data: 0.001) G_GAN: 0.821 G_L1: 2.064 D_real: 0.586 D_fake: 0.602 \n",
      "(epoch: 96, iters: 1100, time: 0.099, data: 0.001) G_GAN: 0.785 G_L1: 0.000 D_real: 0.793 D_fake: 0.608 \n",
      "(epoch: 96, iters: 1200, time: 0.109, data: 0.001) G_GAN: 0.705 G_L1: 0.000 D_real: 0.706 D_fake: 0.683 \n",
      "(epoch: 96, iters: 1300, time: 0.099, data: 0.002) G_GAN: 0.819 G_L1: 3.100 D_real: 0.593 D_fake: 0.595 \n",
      "(epoch: 96, iters: 1400, time: 0.099, data: 0.002) G_GAN: 0.812 G_L1: 0.000 D_real: 0.825 D_fake: 0.586 \n",
      "(epoch: 96, iters: 1500, time: 0.109, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.750 D_fake: 0.639 \n",
      "(epoch: 96, iters: 1600, time: 0.097, data: 0.002) G_GAN: 0.761 G_L1: 1.704 D_real: 0.594 D_fake: 0.635 \n",
      "(epoch: 96, iters: 1700, time: 0.098, data: 0.002) G_GAN: 0.797 G_L1: 0.000 D_real: 0.801 D_fake: 0.602 \n",
      "(epoch: 96, iters: 1800, time: 0.107, data: 0.003) G_GAN: 0.721 G_L1: 0.000 D_real: 0.722 D_fake: 0.662 \n",
      "(epoch: 96, iters: 1900, time: 0.098, data: 0.000) G_GAN: 0.747 G_L1: 4.005 D_real: 0.505 D_fake: 0.657 \n",
      "(epoch: 96, iters: 2000, time: 0.097, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.760 D_fake: 0.668 \n",
      "(epoch: 96, iters: 2100, time: 0.095, data: 0.003) G_GAN: 0.496 G_L1: 0.000 D_real: 0.532 D_fake: 0.664 \n",
      "(epoch: 96, iters: 2200, time: 0.100, data: 0.002) G_GAN: 0.767 G_L1: 1.935 D_real: 0.582 D_fake: 0.635 \n",
      "End of epoch 96 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 97, iters: 20, time: 0.106, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.742 D_fake: 0.657 \n",
      "(epoch: 97, iters: 120, time: 0.099, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.700 D_fake: 0.656 \n",
      "(epoch: 97, iters: 220, time: 0.109, data: 0.002) G_GAN: 0.775 G_L1: 3.205 D_real: 0.551 D_fake: 0.624 \n",
      "(epoch: 97, iters: 320, time: 0.111, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.755 D_fake: 0.642 \n",
      "(epoch: 97, iters: 420, time: 0.099, data: 0.001) G_GAN: 0.714 G_L1: 0.000 D_real: 0.717 D_fake: 0.644 \n",
      "(epoch: 97, iters: 520, time: 0.095, data: 0.002) G_GAN: 0.784 G_L1: 1.603 D_real: 0.611 D_fake: 0.615 \n",
      "(epoch: 97, iters: 620, time: 0.097, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.757 D_fake: 0.636 \n",
      "(epoch: 97, iters: 720, time: 0.110, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.707 D_fake: 0.680 \n",
      "(epoch: 97, iters: 820, time: 0.105, data: 0.002) G_GAN: 0.763 G_L1: 2.187 D_real: 0.569 D_fake: 0.640 \n",
      "(epoch: 97, iters: 920, time: 0.095, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.698 D_fake: 0.648 \n",
      "(epoch: 97, iters: 1020, time: 0.109, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.713 D_fake: 0.653 \n",
      "(epoch: 97, iters: 1120, time: 0.109, data: 0.001) G_GAN: 0.788 G_L1: 1.002 D_real: 0.645 D_fake: 0.611 \n",
      "saving the latest model (epoch 97, total_steps 220000)\n",
      "(epoch: 97, iters: 1220, time: 0.108, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.741 D_fake: 0.649 \n",
      "(epoch: 97, iters: 1320, time: 0.098, data: 0.001) G_GAN: 0.734 G_L1: 0.000 D_real: 0.736 D_fake: 0.654 \n",
      "(epoch: 97, iters: 1420, time: 0.099, data: 0.001) G_GAN: 0.758 G_L1: 2.201 D_real: 0.579 D_fake: 0.641 \n",
      "(epoch: 97, iters: 1520, time: 0.099, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.763 D_fake: 0.633 \n",
      "(epoch: 97, iters: 1620, time: 0.097, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.753 D_fake: 0.643 \n",
      "(epoch: 97, iters: 1720, time: 0.102, data: 0.001) G_GAN: 0.767 G_L1: 3.384 D_real: 0.553 D_fake: 0.632 \n",
      "(epoch: 97, iters: 1820, time: 0.098, data: 0.001) G_GAN: 0.772 G_L1: 0.000 D_real: 0.775 D_fake: 0.616 \n",
      "(epoch: 97, iters: 1920, time: 0.096, data: 0.001) G_GAN: 0.744 G_L1: 0.000 D_real: 0.745 D_fake: 0.651 \n",
      "(epoch: 97, iters: 2020, time: 0.100, data: 0.002) G_GAN: 0.781 G_L1: 1.903 D_real: 0.602 D_fake: 0.686 \n",
      "(epoch: 97, iters: 2120, time: 0.106, data: 0.002) G_GAN: 0.778 G_L1: 0.000 D_real: 0.780 D_fake: 0.670 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 97, iters: 2220, time: 0.099, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.723 D_fake: 0.675 \n",
      "End of epoch 97 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 98, iters: 40, time: 0.112, data: 0.002) G_GAN: 0.728 G_L1: 1.545 D_real: 0.565 D_fake: 0.674 \n",
      "(epoch: 98, iters: 140, time: 0.097, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.744 D_fake: 0.645 \n",
      "(epoch: 98, iters: 240, time: 0.099, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.755 D_fake: 0.641 \n",
      "(epoch: 98, iters: 340, time: 0.095, data: 0.002) G_GAN: 0.767 G_L1: 0.576 D_real: 0.649 D_fake: 0.675 \n",
      "(epoch: 98, iters: 440, time: 0.105, data: 0.003) G_GAN: 0.749 G_L1: 0.000 D_real: 0.751 D_fake: 0.645 \n",
      "(epoch: 98, iters: 540, time: 0.094, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.705 D_fake: 0.633 \n",
      "(epoch: 98, iters: 640, time: 0.109, data: 0.001) G_GAN: 0.722 G_L1: 3.338 D_real: 0.519 D_fake: 0.679 \n",
      "(epoch: 98, iters: 740, time: 0.095, data: 0.001) G_GAN: 0.764 G_L1: 0.000 D_real: 0.764 D_fake: 0.623 \n",
      "(epoch: 98, iters: 840, time: 0.098, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.714 D_fake: 0.684 \n",
      "(epoch: 98, iters: 940, time: 0.100, data: 0.001) G_GAN: 0.787 G_L1: 1.224 D_real: 0.615 D_fake: 0.622 \n",
      "(epoch: 98, iters: 1040, time: 0.096, data: 0.002) G_GAN: 0.611 G_L1: 0.000 D_real: 0.514 D_fake: 0.921 \n",
      "(epoch: 98, iters: 1140, time: 0.097, data: 0.002) G_GAN: 0.674 G_L1: 0.000 D_real: 0.667 D_fake: 0.722 \n",
      "(epoch: 98, iters: 1240, time: 0.095, data: 0.002) G_GAN: 0.936 G_L1: 2.557 D_real: 0.654 D_fake: 0.519 \n",
      "(epoch: 98, iters: 1340, time: 0.098, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.747 D_fake: 0.719 \n",
      "(epoch: 98, iters: 1440, time: 0.101, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.746 D_fake: 0.510 \n",
      "(epoch: 98, iters: 1540, time: 0.112, data: 0.001) G_GAN: 0.808 G_L1: 1.958 D_real: 0.610 D_fake: 0.598 \n",
      "(epoch: 98, iters: 1640, time: 0.100, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.743 D_fake: 0.644 \n",
      "(epoch: 98, iters: 1740, time: 0.098, data: 0.000) G_GAN: 0.745 G_L1: 0.000 D_real: 0.746 D_fake: 0.648 \n",
      "(epoch: 98, iters: 1840, time: 0.097, data: 0.002) G_GAN: 0.747 G_L1: 0.311 D_real: 0.652 D_fake: 0.649 \n",
      "(epoch: 98, iters: 1940, time: 0.101, data: 0.002) G_GAN: 0.786 G_L1: 0.000 D_real: 0.790 D_fake: 0.612 \n",
      "(epoch: 98, iters: 2040, time: 0.100, data: 0.001) G_GAN: 0.756 G_L1: 0.000 D_real: 0.755 D_fake: 0.637 \n",
      "(epoch: 98, iters: 2140, time: 0.101, data: 0.002) G_GAN: 0.844 G_L1: 0.787 D_real: 0.704 D_fake: 0.650 \n",
      "(epoch: 98, iters: 2240, time: 0.109, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.722 D_fake: 0.658 \n",
      "End of epoch 98 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 99, iters: 60, time: 0.113, data: 0.001) G_GAN: 0.713 G_L1: 0.000 D_real: 0.712 D_fake: 0.702 \n",
      "(epoch: 99, iters: 160, time: 0.110, data: 0.002) G_GAN: 0.761 G_L1: 3.185 D_real: 0.531 D_fake: 0.664 \n",
      "(epoch: 99, iters: 260, time: 0.102, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.752 D_fake: 0.649 \n",
      "(epoch: 99, iters: 360, time: 0.097, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.703 D_fake: 0.668 \n",
      "(epoch: 99, iters: 460, time: 0.098, data: 0.002) G_GAN: 0.770 G_L1: 2.593 D_real: 0.590 D_fake: 0.637 \n",
      "(epoch: 99, iters: 560, time: 0.097, data: 0.001) G_GAN: 0.756 G_L1: 0.000 D_real: 0.759 D_fake: 0.632 \n",
      "(epoch: 99, iters: 660, time: 0.097, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.723 D_fake: 0.669 \n",
      "(epoch: 99, iters: 760, time: 0.096, data: 0.001) G_GAN: 0.744 G_L1: 2.399 D_real: 0.556 D_fake: 0.663 \n",
      "(epoch: 99, iters: 860, time: 0.105, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.766 D_fake: 0.717 \n",
      "(epoch: 99, iters: 960, time: 0.095, data: 0.001) G_GAN: 0.713 G_L1: 0.000 D_real: 0.714 D_fake: 0.675 \n",
      "(epoch: 99, iters: 1060, time: 0.106, data: 0.003) G_GAN: 0.702 G_L1: 0.087 D_real: 0.644 D_fake: 0.684 \n",
      "(epoch: 99, iters: 1160, time: 0.096, data: 0.001) G_GAN: 0.759 G_L1: 0.000 D_real: 0.763 D_fake: 0.635 \n",
      "(epoch: 99, iters: 1260, time: 0.097, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.736 D_fake: 0.665 \n",
      "(epoch: 99, iters: 1360, time: 0.107, data: 0.001) G_GAN: 0.757 G_L1: 4.502 D_real: 0.504 D_fake: 0.603 \n",
      "(epoch: 99, iters: 1460, time: 0.097, data: 0.002) G_GAN: 0.848 G_L1: 0.000 D_real: 0.860 D_fake: 0.537 \n",
      "(epoch: 99, iters: 1560, time: 0.097, data: 0.001) G_GAN: 0.714 G_L1: 0.000 D_real: 0.716 D_fake: 0.661 \n",
      "saving the latest model (epoch 99, total_steps 225000)\n",
      "(epoch: 99, iters: 1660, time: 0.097, data: 0.002) G_GAN: 0.760 G_L1: 1.973 D_real: 0.568 D_fake: 0.639 \n",
      "(epoch: 99, iters: 1760, time: 0.099, data: 0.001) G_GAN: 0.769 G_L1: 0.000 D_real: 0.772 D_fake: 0.625 \n",
      "(epoch: 99, iters: 1860, time: 0.098, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.731 D_fake: 0.621 \n",
      "(epoch: 99, iters: 1960, time: 0.098, data: 0.001) G_GAN: 0.753 G_L1: 0.417 D_real: 0.640 D_fake: 0.653 \n",
      "(epoch: 99, iters: 2060, time: 0.094, data: 0.001) G_GAN: 0.734 G_L1: 0.000 D_real: 0.738 D_fake: 0.622 \n",
      "(epoch: 99, iters: 2160, time: 0.097, data: 0.001) G_GAN: 0.686 G_L1: 0.000 D_real: 0.687 D_fake: 0.702 \n",
      "(epoch: 99, iters: 2260, time: 0.094, data: 0.001) G_GAN: 0.809 G_L1: 3.017 D_real: 0.548 D_fake: 0.623 \n",
      "End of epoch 99 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 100, iters: 80, time: 0.106, data: 0.001) G_GAN: 0.718 G_L1: 0.000 D_real: 0.721 D_fake: 0.651 \n",
      "(epoch: 100, iters: 180, time: 0.097, data: 0.001) G_GAN: 0.702 G_L1: 0.000 D_real: 0.704 D_fake: 0.684 \n",
      "(epoch: 100, iters: 280, time: 0.109, data: 0.001) G_GAN: 0.724 G_L1: 1.052 D_real: 0.588 D_fake: 0.631 \n",
      "(epoch: 100, iters: 380, time: 0.100, data: 0.001) G_GAN: 0.775 G_L1: 0.000 D_real: 0.779 D_fake: 0.620 \n",
      "(epoch: 100, iters: 480, time: 0.097, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.718 D_fake: 0.610 \n",
      "(epoch: 100, iters: 580, time: 0.099, data: 0.001) G_GAN: 0.758 G_L1: 4.208 D_real: 0.523 D_fake: 0.634 \n",
      "(epoch: 100, iters: 680, time: 0.097, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.741 D_fake: 0.652 \n",
      "(epoch: 100, iters: 780, time: 0.095, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.723 D_fake: 0.668 \n",
      "(epoch: 100, iters: 880, time: 0.096, data: 0.001) G_GAN: 0.758 G_L1: 3.483 D_real: 0.539 D_fake: 0.644 \n",
      "(epoch: 100, iters: 980, time: 0.097, data: 0.001) G_GAN: 0.771 G_L1: 0.000 D_real: 0.780 D_fake: 0.619 \n",
      "(epoch: 100, iters: 1080, time: 0.107, data: 0.001) G_GAN: 0.664 G_L1: 0.000 D_real: 0.657 D_fake: 0.727 \n",
      "(epoch: 100, iters: 1180, time: 0.098, data: 0.001) G_GAN: 0.841 G_L1: 0.978 D_real: 0.671 D_fake: 0.575 \n",
      "(epoch: 100, iters: 1280, time: 0.099, data: 0.001) G_GAN: 0.825 G_L1: 0.000 D_real: 0.836 D_fake: 0.580 \n",
      "(epoch: 100, iters: 1380, time: 0.097, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.725 D_fake: 0.653 \n",
      "(epoch: 100, iters: 1480, time: 0.100, data: 0.002) G_GAN: 0.752 G_L1: 1.681 D_real: 0.579 D_fake: 0.646 \n",
      "(epoch: 100, iters: 1580, time: 0.098, data: 0.001) G_GAN: 0.758 G_L1: 0.000 D_real: 0.763 D_fake: 0.645 \n",
      "(epoch: 100, iters: 1680, time: 0.110, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.748 D_fake: 0.666 \n",
      "(epoch: 100, iters: 1780, time: 0.099, data: 0.002) G_GAN: 0.746 G_L1: 3.487 D_real: 0.540 D_fake: 0.625 \n",
      "(epoch: 100, iters: 1880, time: 0.109, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.762 D_fake: 0.636 \n",
      "(epoch: 100, iters: 1980, time: 0.100, data: 0.001) G_GAN: 0.759 G_L1: 0.000 D_real: 0.762 D_fake: 0.632 \n",
      "(epoch: 100, iters: 2080, time: 0.097, data: 0.001) G_GAN: 0.733 G_L1: 2.663 D_real: 0.530 D_fake: 0.672 \n",
      "(epoch: 100, iters: 2180, time: 0.096, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.704 D_fake: 0.685 \n",
      "(epoch: 100, iters: 2280, time: 0.097, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.726 D_fake: 0.637 \n",
      "saving the model at the end of epoch 100, iters 228000\n",
      "End of epoch 100 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001980\n",
      "(epoch: 101, iters: 100, time: 0.118, data: 0.256) G_GAN: 0.777 G_L1: 2.739 D_real: 0.564 D_fake: 0.628 \n",
      "(epoch: 101, iters: 200, time: 0.097, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.718 D_fake: 0.678 \n",
      "(epoch: 101, iters: 300, time: 0.096, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.707 D_fake: 0.685 \n",
      "(epoch: 101, iters: 400, time: 0.096, data: 0.001) G_GAN: 0.759 G_L1: 1.900 D_real: 0.575 D_fake: 0.665 \n",
      "(epoch: 101, iters: 500, time: 0.101, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.727 D_fake: 0.627 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 101, iters: 600, time: 0.100, data: 0.001) G_GAN: 0.711 G_L1: 0.000 D_real: 0.714 D_fake: 0.654 \n",
      "(epoch: 101, iters: 700, time: 0.099, data: 0.002) G_GAN: 0.828 G_L1: 2.269 D_real: 0.605 D_fake: 0.670 \n",
      "(epoch: 101, iters: 800, time: 0.099, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.733 D_fake: 0.664 \n",
      "(epoch: 101, iters: 900, time: 0.094, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.693 D_fake: 0.697 \n",
      "(epoch: 101, iters: 1000, time: 0.098, data: 0.002) G_GAN: 0.753 G_L1: 2.064 D_real: 0.554 D_fake: 0.660 \n",
      "(epoch: 101, iters: 1100, time: 0.099, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.756 D_fake: 0.651 \n",
      "(epoch: 101, iters: 1200, time: 0.097, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.725 D_fake: 0.594 \n",
      "(epoch: 101, iters: 1300, time: 0.108, data: 0.001) G_GAN: 0.783 G_L1: 3.100 D_real: 0.563 D_fake: 0.619 \n",
      "(epoch: 101, iters: 1400, time: 0.100, data: 0.001) G_GAN: 0.784 G_L1: 0.000 D_real: 0.808 D_fake: 0.642 \n",
      "(epoch: 101, iters: 1500, time: 0.110, data: 0.001) G_GAN: 0.724 G_L1: 0.000 D_real: 0.725 D_fake: 0.662 \n",
      "(epoch: 101, iters: 1600, time: 0.097, data: 0.002) G_GAN: 0.778 G_L1: 1.704 D_real: 0.598 D_fake: 0.626 \n",
      "(epoch: 101, iters: 1700, time: 0.098, data: 0.001) G_GAN: 0.807 G_L1: 0.000 D_real: 0.813 D_fake: 0.616 \n",
      "(epoch: 101, iters: 1800, time: 0.097, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.731 D_fake: 0.655 \n",
      "(epoch: 101, iters: 1900, time: 0.099, data: 0.002) G_GAN: 0.719 G_L1: 4.005 D_real: 0.492 D_fake: 0.688 \n",
      "(epoch: 101, iters: 2000, time: 0.107, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.756 D_fake: 0.639 \n",
      "saving the latest model (epoch 101, total_steps 230000)\n",
      "(epoch: 101, iters: 2100, time: 0.094, data: 0.001) G_GAN: 0.659 G_L1: 0.000 D_real: 0.656 D_fake: 0.731 \n",
      "(epoch: 101, iters: 2200, time: 0.098, data: 0.001) G_GAN: 0.829 G_L1: 1.935 D_real: 0.626 D_fake: 0.585 \n",
      "End of epoch 101 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001960\n",
      "(epoch: 102, iters: 20, time: 0.107, data: 0.001) G_GAN: 0.779 G_L1: 0.000 D_real: 0.785 D_fake: 0.616 \n",
      "(epoch: 102, iters: 120, time: 0.096, data: 0.001) G_GAN: 0.674 G_L1: 0.000 D_real: 0.675 D_fake: 0.716 \n",
      "(epoch: 102, iters: 220, time: 0.098, data: 0.001) G_GAN: 0.787 G_L1: 3.205 D_real: 0.549 D_fake: 0.620 \n",
      "(epoch: 102, iters: 320, time: 0.097, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.741 D_fake: 0.657 \n",
      "(epoch: 102, iters: 420, time: 0.096, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.761 D_fake: 0.625 \n",
      "(epoch: 102, iters: 520, time: 0.095, data: 0.001) G_GAN: 0.771 G_L1: 1.603 D_real: 0.605 D_fake: 0.653 \n",
      "(epoch: 102, iters: 620, time: 0.100, data: 0.002) G_GAN: 0.768 G_L1: 0.000 D_real: 0.770 D_fake: 0.626 \n",
      "(epoch: 102, iters: 720, time: 0.100, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.698 D_fake: 0.657 \n",
      "(epoch: 102, iters: 820, time: 0.095, data: 0.002) G_GAN: 0.740 G_L1: 2.187 D_real: 0.544 D_fake: 0.662 \n",
      "(epoch: 102, iters: 920, time: 0.098, data: 0.001) G_GAN: 0.625 G_L1: 0.000 D_real: 0.663 D_fake: 0.603 \n",
      "(epoch: 102, iters: 1020, time: 0.099, data: 0.002) G_GAN: 0.658 G_L1: 0.000 D_real: 0.661 D_fake: 0.730 \n",
      "(epoch: 102, iters: 1120, time: 0.097, data: 0.003) G_GAN: 0.759 G_L1: 1.002 D_real: 0.622 D_fake: 0.638 \n",
      "(epoch: 102, iters: 1220, time: 0.101, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.696 \n",
      "(epoch: 102, iters: 1320, time: 0.109, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.689 D_fake: 0.701 \n",
      "(epoch: 102, iters: 1420, time: 0.099, data: 0.002) G_GAN: 0.754 G_L1: 2.201 D_real: 0.563 D_fake: 0.611 \n",
      "(epoch: 102, iters: 1520, time: 0.104, data: 0.001) G_GAN: 0.756 G_L1: 0.000 D_real: 0.759 D_fake: 0.651 \n",
      "(epoch: 102, iters: 1620, time: 0.094, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.744 D_fake: 0.660 \n",
      "(epoch: 102, iters: 1720, time: 0.101, data: 0.002) G_GAN: 0.753 G_L1: 3.384 D_real: 0.536 D_fake: 0.646 \n",
      "(epoch: 102, iters: 1820, time: 0.100, data: 0.001) G_GAN: 0.789 G_L1: 0.000 D_real: 0.794 D_fake: 0.606 \n",
      "(epoch: 102, iters: 1920, time: 0.106, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.726 D_fake: 0.642 \n",
      "(epoch: 102, iters: 2020, time: 0.099, data: 0.002) G_GAN: 0.786 G_L1: 1.903 D_real: 0.608 D_fake: 0.610 \n",
      "(epoch: 102, iters: 2120, time: 0.097, data: 0.002) G_GAN: 0.801 G_L1: 0.000 D_real: 0.808 D_fake: 0.624 \n",
      "(epoch: 102, iters: 2220, time: 0.099, data: 0.001) G_GAN: 0.699 G_L1: 0.000 D_real: 0.702 D_fake: 0.556 \n",
      "End of epoch 102 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001941\n",
      "(epoch: 103, iters: 40, time: 0.115, data: 0.002) G_GAN: 0.738 G_L1: 1.545 D_real: 0.564 D_fake: 0.674 \n",
      "(epoch: 103, iters: 140, time: 0.097, data: 0.003) G_GAN: 0.736 G_L1: 0.000 D_real: 0.740 D_fake: 0.561 \n",
      "(epoch: 103, iters: 240, time: 0.096, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.749 D_fake: 0.652 \n",
      "(epoch: 103, iters: 340, time: 0.110, data: 0.001) G_GAN: 0.760 G_L1: 0.576 D_real: 0.623 D_fake: 0.638 \n",
      "(epoch: 103, iters: 440, time: 0.096, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.723 D_fake: 0.591 \n",
      "(epoch: 103, iters: 540, time: 0.105, data: 0.002) G_GAN: 0.665 G_L1: 0.000 D_real: 0.664 D_fake: 0.726 \n",
      "(epoch: 103, iters: 640, time: 0.096, data: 0.001) G_GAN: 0.841 G_L1: 3.338 D_real: 0.605 D_fake: 0.580 \n",
      "(epoch: 103, iters: 740, time: 0.104, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.736 D_fake: 0.656 \n",
      "(epoch: 103, iters: 840, time: 0.093, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.695 D_fake: 0.694 \n",
      "(epoch: 103, iters: 940, time: 0.097, data: 0.001) G_GAN: 0.774 G_L1: 1.224 D_real: 0.604 D_fake: 0.652 \n",
      "(epoch: 103, iters: 1040, time: 0.094, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.765 D_fake: 0.633 \n",
      "(epoch: 103, iters: 1140, time: 0.097, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.710 D_fake: 0.679 \n",
      "(epoch: 103, iters: 1240, time: 0.094, data: 0.002) G_GAN: 0.844 G_L1: 2.557 D_real: 0.674 D_fake: 0.647 \n",
      "(epoch: 103, iters: 1340, time: 0.107, data: 0.002) G_GAN: 0.936 G_L1: 0.000 D_real: 0.971 D_fake: 0.381 \n",
      "(epoch: 103, iters: 1440, time: 0.099, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.720 D_fake: 0.674 \n",
      "(epoch: 103, iters: 1540, time: 0.100, data: 0.001) G_GAN: 0.785 G_L1: 1.958 D_real: 0.599 D_fake: 0.616 \n",
      "(epoch: 103, iters: 1640, time: 0.098, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.754 D_fake: 0.617 \n",
      "(epoch: 103, iters: 1740, time: 0.097, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.744 D_fake: 0.602 \n",
      "(epoch: 103, iters: 1840, time: 0.097, data: 0.002) G_GAN: 0.739 G_L1: 0.311 D_real: 0.628 D_fake: 0.656 \n",
      "(epoch: 103, iters: 1940, time: 0.097, data: 0.002) G_GAN: 0.770 G_L1: 0.000 D_real: 0.775 D_fake: 0.621 \n",
      "(epoch: 103, iters: 2040, time: 0.097, data: 0.001) G_GAN: 0.773 G_L1: 0.000 D_real: 0.775 D_fake: 0.681 \n",
      "(epoch: 103, iters: 2140, time: 0.100, data: 0.002) G_GAN: 0.821 G_L1: 0.787 D_real: 0.673 D_fake: 0.584 \n",
      "(epoch: 103, iters: 2240, time: 0.099, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.707 D_fake: 0.686 \n",
      "End of epoch 103 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001921\n",
      "(epoch: 104, iters: 60, time: 0.113, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.721 D_fake: 0.672 \n",
      "(epoch: 104, iters: 160, time: 0.099, data: 0.001) G_GAN: 0.767 G_L1: 3.185 D_real: 0.546 D_fake: 0.581 \n",
      "saving the latest model (epoch 104, total_steps 235000)\n",
      "(epoch: 104, iters: 260, time: 0.100, data: 0.002) G_GAN: 0.783 G_L1: 0.000 D_real: 0.801 D_fake: 0.659 \n",
      "(epoch: 104, iters: 360, time: 0.096, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.718 D_fake: 0.671 \n",
      "(epoch: 104, iters: 460, time: 0.100, data: 0.001) G_GAN: 0.805 G_L1: 2.593 D_real: 0.588 D_fake: 0.649 \n",
      "(epoch: 104, iters: 560, time: 0.097, data: 0.001) G_GAN: 0.763 G_L1: 0.000 D_real: 0.768 D_fake: 0.652 \n",
      "(epoch: 104, iters: 660, time: 0.098, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.746 D_fake: 0.648 \n",
      "(epoch: 104, iters: 760, time: 0.097, data: 0.002) G_GAN: 0.751 G_L1: 2.399 D_real: 0.561 D_fake: 0.628 \n",
      "(epoch: 104, iters: 860, time: 0.098, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.760 D_fake: 0.640 \n",
      "(epoch: 104, iters: 960, time: 0.096, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.761 D_fake: 0.586 \n",
      "(epoch: 104, iters: 1060, time: 0.096, data: 0.001) G_GAN: 0.705 G_L1: 0.087 D_real: 0.639 D_fake: 0.656 \n",
      "(epoch: 104, iters: 1160, time: 0.095, data: 0.002) G_GAN: 0.779 G_L1: 0.000 D_real: 0.781 D_fake: 0.620 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 104, iters: 1260, time: 0.097, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.746 D_fake: 0.559 \n",
      "(epoch: 104, iters: 1360, time: 0.096, data: 0.001) G_GAN: 0.756 G_L1: 4.502 D_real: 0.516 D_fake: 0.647 \n",
      "(epoch: 104, iters: 1460, time: 0.094, data: 0.001) G_GAN: 0.813 G_L1: 0.000 D_real: 0.826 D_fake: 0.582 \n",
      "(epoch: 104, iters: 1560, time: 0.095, data: 0.001) G_GAN: 0.717 G_L1: 0.000 D_real: 0.726 D_fake: 0.601 \n",
      "(epoch: 104, iters: 1660, time: 0.096, data: 0.001) G_GAN: 0.773 G_L1: 1.973 D_real: 0.586 D_fake: 0.620 \n",
      "(epoch: 104, iters: 1760, time: 0.097, data: 0.001) G_GAN: 0.759 G_L1: 0.000 D_real: 0.767 D_fake: 0.657 \n",
      "(epoch: 104, iters: 1860, time: 0.099, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.728 D_fake: 0.657 \n",
      "(epoch: 104, iters: 1960, time: 0.098, data: 0.002) G_GAN: 0.757 G_L1: 0.417 D_real: 0.649 D_fake: 0.641 \n",
      "(epoch: 104, iters: 2060, time: 0.107, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.747 D_fake: 0.647 \n",
      "(epoch: 104, iters: 2160, time: 0.107, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.728 D_fake: 0.620 \n",
      "(epoch: 104, iters: 2260, time: 0.096, data: 0.002) G_GAN: 0.841 G_L1: 3.017 D_real: 0.590 D_fake: 0.578 \n",
      "End of epoch 104 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001901\n",
      "(epoch: 105, iters: 80, time: 0.104, data: 0.001) G_GAN: 0.749 G_L1: 0.000 D_real: 0.753 D_fake: 0.644 \n",
      "(epoch: 105, iters: 180, time: 0.099, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.695 D_fake: 0.663 \n",
      "(epoch: 105, iters: 280, time: 0.110, data: 0.001) G_GAN: 0.729 G_L1: 1.052 D_real: 0.587 D_fake: 0.666 \n",
      "(epoch: 105, iters: 380, time: 0.100, data: 0.001) G_GAN: 0.749 G_L1: 0.000 D_real: 0.751 D_fake: 0.644 \n",
      "(epoch: 105, iters: 480, time: 0.098, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.717 D_fake: 0.672 \n",
      "(epoch: 105, iters: 580, time: 0.100, data: 0.002) G_GAN: 0.750 G_L1: 4.208 D_real: 0.511 D_fake: 0.647 \n",
      "(epoch: 105, iters: 680, time: 0.096, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.754 D_fake: 0.562 \n",
      "(epoch: 105, iters: 780, time: 0.108, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.591 \n",
      "(epoch: 105, iters: 880, time: 0.094, data: 0.001) G_GAN: 0.759 G_L1: 3.483 D_real: 0.526 D_fake: 0.650 \n",
      "(epoch: 105, iters: 980, time: 0.109, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.739 D_fake: 0.655 \n",
      "(epoch: 105, iters: 1080, time: 0.095, data: 0.001) G_GAN: 0.651 G_L1: 0.000 D_real: 0.664 D_fake: 0.668 \n",
      "(epoch: 105, iters: 1180, time: 0.100, data: 0.002) G_GAN: 0.868 G_L1: 0.978 D_real: 0.696 D_fake: 0.550 \n",
      "(epoch: 105, iters: 1280, time: 0.098, data: 0.001) G_GAN: 0.777 G_L1: 0.000 D_real: 0.792 D_fake: 0.666 \n",
      "(epoch: 105, iters: 1380, time: 0.097, data: 0.002) G_GAN: 0.702 G_L1: 0.000 D_real: 0.703 D_fake: 0.688 \n",
      "(epoch: 105, iters: 1480, time: 0.098, data: 0.001) G_GAN: 0.734 G_L1: 1.681 D_real: 0.566 D_fake: 0.662 \n",
      "(epoch: 105, iters: 1580, time: 0.096, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.751 D_fake: 0.641 \n",
      "(epoch: 105, iters: 1680, time: 0.099, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.741 D_fake: 0.659 \n",
      "(epoch: 105, iters: 1780, time: 0.097, data: 0.001) G_GAN: 0.750 G_L1: 3.487 D_real: 0.534 D_fake: 0.631 \n",
      "(epoch: 105, iters: 1880, time: 0.101, data: 0.002) G_GAN: 0.768 G_L1: 0.000 D_real: 0.771 D_fake: 0.629 \n",
      "(epoch: 105, iters: 1980, time: 0.097, data: 0.001) G_GAN: 0.744 G_L1: 0.000 D_real: 0.746 D_fake: 0.645 \n",
      "(epoch: 105, iters: 2080, time: 0.096, data: 0.002) G_GAN: 0.688 G_L1: 2.663 D_real: 0.511 D_fake: 0.653 \n",
      "(epoch: 105, iters: 2180, time: 0.108, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.754 D_fake: 0.638 \n",
      "(epoch: 105, iters: 2280, time: 0.096, data: 0.001) G_GAN: 0.708 G_L1: 0.000 D_real: 0.704 D_fake: 0.689 \n",
      "saving the model at the end of epoch 105, iters 239400\n",
      "End of epoch 105 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001881\n",
      "(epoch: 106, iters: 100, time: 0.108, data: 0.287) G_GAN: 0.840 G_L1: 2.739 D_real: 0.604 D_fake: 0.580 \n",
      "(epoch: 106, iters: 200, time: 0.097, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.743 D_fake: 0.653 \n",
      "(epoch: 106, iters: 300, time: 0.099, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.723 D_fake: 0.669 \n",
      "(epoch: 106, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.773 G_L1: 1.900 D_real: 0.582 D_fake: 0.636 \n",
      "(epoch: 106, iters: 500, time: 0.096, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.705 D_fake: 0.684 \n",
      "(epoch: 106, iters: 600, time: 0.103, data: 0.001) G_GAN: 0.636 G_L1: 0.000 D_real: 0.631 D_fake: 0.760 \n",
      "saving the latest model (epoch 106, total_steps 240000)\n",
      "(epoch: 106, iters: 700, time: 0.098, data: 0.001) G_GAN: 0.988 G_L1: 2.269 D_real: 0.720 D_fake: 0.477 \n",
      "(epoch: 106, iters: 800, time: 0.096, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.764 D_fake: 0.653 \n",
      "(epoch: 106, iters: 900, time: 0.093, data: 0.002) G_GAN: 0.661 G_L1: 0.000 D_real: 0.662 D_fake: 0.674 \n",
      "(epoch: 106, iters: 1000, time: 0.097, data: 0.002) G_GAN: 0.791 G_L1: 2.064 D_real: 0.594 D_fake: 0.616 \n",
      "(epoch: 106, iters: 1100, time: 0.108, data: 0.001) G_GAN: 0.765 G_L1: 0.000 D_real: 0.768 D_fake: 0.637 \n",
      "(epoch: 106, iters: 1200, time: 0.097, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.744 D_fake: 0.639 \n",
      "(epoch: 106, iters: 1300, time: 0.111, data: 0.001) G_GAN: 0.808 G_L1: 3.100 D_real: 0.569 D_fake: 0.596 \n",
      "(epoch: 106, iters: 1400, time: 0.097, data: 0.002) G_GAN: 0.807 G_L1: 0.000 D_real: 0.813 D_fake: 0.595 \n",
      "(epoch: 106, iters: 1500, time: 0.097, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.727 D_fake: 0.671 \n",
      "(epoch: 106, iters: 1600, time: 0.098, data: 0.002) G_GAN: 0.743 G_L1: 1.704 D_real: 0.569 D_fake: 0.655 \n",
      "(epoch: 106, iters: 1700, time: 0.112, data: 0.001) G_GAN: 0.773 G_L1: 0.000 D_real: 0.777 D_fake: 0.622 \n",
      "(epoch: 106, iters: 1800, time: 0.095, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.717 D_fake: 0.673 \n",
      "(epoch: 106, iters: 1900, time: 0.103, data: 0.001) G_GAN: 0.766 G_L1: 4.005 D_real: 0.527 D_fake: 0.639 \n",
      "(epoch: 106, iters: 2000, time: 0.097, data: 0.001) G_GAN: 0.763 G_L1: 0.000 D_real: 0.766 D_fake: 0.634 \n",
      "(epoch: 106, iters: 2100, time: 0.096, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.686 D_fake: 0.705 \n",
      "(epoch: 106, iters: 2200, time: 0.113, data: 0.002) G_GAN: 0.744 G_L1: 1.935 D_real: 0.556 D_fake: 0.514 \n",
      "End of epoch 106 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001861\n",
      "(epoch: 107, iters: 20, time: 0.114, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.740 D_fake: 0.652 \n",
      "(epoch: 107, iters: 120, time: 0.096, data: 0.003) G_GAN: 0.699 G_L1: 0.000 D_real: 0.701 D_fake: 0.668 \n",
      "(epoch: 107, iters: 220, time: 0.108, data: 0.002) G_GAN: 0.748 G_L1: 3.205 D_real: 0.541 D_fake: 0.650 \n",
      "(epoch: 107, iters: 320, time: 0.099, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.754 D_fake: 0.651 \n",
      "(epoch: 107, iters: 420, time: 0.096, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.714 D_fake: 0.653 \n",
      "(epoch: 107, iters: 520, time: 0.107, data: 0.001) G_GAN: 0.813 G_L1: 1.603 D_real: 0.631 D_fake: 0.673 \n",
      "(epoch: 107, iters: 620, time: 0.103, data: 0.001) G_GAN: 0.753 G_L1: 0.000 D_real: 0.755 D_fake: 0.640 \n",
      "(epoch: 107, iters: 720, time: 0.098, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.711 D_fake: 0.668 \n",
      "(epoch: 107, iters: 820, time: 0.094, data: 0.001) G_GAN: 0.744 G_L1: 2.187 D_real: 0.552 D_fake: 0.645 \n",
      "(epoch: 107, iters: 920, time: 0.106, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.719 D_fake: 0.613 \n",
      "(epoch: 107, iters: 1020, time: 0.098, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.695 D_fake: 0.496 \n",
      "(epoch: 107, iters: 1120, time: 0.100, data: 0.001) G_GAN: 0.767 G_L1: 1.002 D_real: 0.609 D_fake: 0.634 \n",
      "(epoch: 107, iters: 1220, time: 0.101, data: 0.002) G_GAN: 0.762 G_L1: 0.000 D_real: 0.801 D_fake: 0.607 \n",
      "(epoch: 107, iters: 1320, time: 0.100, data: 0.002) G_GAN: 0.677 G_L1: 0.000 D_real: 0.677 D_fake: 0.713 \n",
      "(epoch: 107, iters: 1420, time: 0.107, data: 0.002) G_GAN: 0.787 G_L1: 2.201 D_real: 0.611 D_fake: 0.585 \n",
      "(epoch: 107, iters: 1520, time: 0.099, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.747 D_fake: 0.628 \n",
      "(epoch: 107, iters: 1620, time: 0.098, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.738 D_fake: 0.655 \n",
      "(epoch: 107, iters: 1720, time: 0.098, data: 0.002) G_GAN: 0.754 G_L1: 3.384 D_real: 0.541 D_fake: 0.637 \n",
      "(epoch: 107, iters: 1820, time: 0.097, data: 0.001) G_GAN: 0.756 G_L1: 0.000 D_real: 0.758 D_fake: 0.637 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 107, iters: 1920, time: 0.103, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.733 D_fake: 0.630 \n",
      "(epoch: 107, iters: 2020, time: 0.098, data: 0.001) G_GAN: 0.775 G_L1: 1.903 D_real: 0.598 D_fake: 0.619 \n",
      "(epoch: 107, iters: 2120, time: 0.097, data: 0.001) G_GAN: 0.751 G_L1: 0.000 D_real: 0.749 D_fake: 0.834 \n",
      "(epoch: 107, iters: 2220, time: 0.098, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.728 D_fake: 0.667 \n",
      "End of epoch 107 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001842\n",
      "(epoch: 108, iters: 40, time: 0.106, data: 0.001) G_GAN: 0.757 G_L1: 1.545 D_real: 0.595 D_fake: 0.642 \n",
      "(epoch: 108, iters: 140, time: 0.098, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.767 D_fake: 0.665 \n",
      "(epoch: 108, iters: 240, time: 0.096, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.729 D_fake: 0.663 \n",
      "(epoch: 108, iters: 340, time: 0.096, data: 0.001) G_GAN: 0.734 G_L1: 0.576 D_real: 0.617 D_fake: 0.661 \n",
      "(epoch: 108, iters: 440, time: 0.106, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.742 D_fake: 0.653 \n",
      "(epoch: 108, iters: 540, time: 0.094, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.721 D_fake: 0.668 \n",
      "(epoch: 108, iters: 640, time: 0.098, data: 0.001) G_GAN: 0.800 G_L1: 3.338 D_real: 0.569 D_fake: 0.608 \n",
      "(epoch: 108, iters: 740, time: 0.094, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.761 D_fake: 0.635 \n",
      "(epoch: 108, iters: 840, time: 0.107, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.722 D_fake: 0.685 \n",
      "(epoch: 108, iters: 940, time: 0.109, data: 0.001) G_GAN: 0.804 G_L1: 1.224 D_real: 0.634 D_fake: 0.609 \n",
      "(epoch: 108, iters: 1040, time: 0.095, data: 0.002) G_GAN: 0.613 G_L1: 0.000 D_real: 0.674 D_fake: 0.597 \n",
      "saving the latest model (epoch 108, total_steps 245000)\n",
      "(epoch: 108, iters: 1140, time: 0.099, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.705 D_fake: 0.508 \n",
      "(epoch: 108, iters: 1240, time: 0.094, data: 0.001) G_GAN: 0.996 G_L1: 2.557 D_real: 0.702 D_fake: 0.480 \n",
      "(epoch: 108, iters: 1340, time: 0.097, data: 0.001) G_GAN: 0.840 G_L1: 0.000 D_real: 0.888 D_fake: 0.673 \n",
      "(epoch: 108, iters: 1440, time: 0.100, data: 0.001) G_GAN: 0.711 G_L1: 0.000 D_real: 0.717 D_fake: 0.676 \n",
      "(epoch: 108, iters: 1540, time: 0.097, data: 0.001) G_GAN: 0.773 G_L1: 1.958 D_real: 0.580 D_fake: 0.631 \n",
      "(epoch: 108, iters: 1640, time: 0.097, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.746 D_fake: 0.654 \n",
      "(epoch: 108, iters: 1740, time: 0.099, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.741 D_fake: 0.605 \n",
      "(epoch: 108, iters: 1840, time: 0.098, data: 0.002) G_GAN: 0.744 G_L1: 0.311 D_real: 0.627 D_fake: 0.641 \n",
      "(epoch: 108, iters: 1940, time: 0.098, data: 0.001) G_GAN: 0.756 G_L1: 0.000 D_real: 0.762 D_fake: 0.633 \n",
      "(epoch: 108, iters: 2040, time: 0.098, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.724 D_fake: 0.651 \n",
      "(epoch: 108, iters: 2140, time: 0.099, data: 0.002) G_GAN: 0.791 G_L1: 0.787 D_real: 0.654 D_fake: 0.604 \n",
      "(epoch: 108, iters: 2240, time: 0.098, data: 0.002) G_GAN: 0.622 G_L1: 0.000 D_real: 0.635 D_fake: 0.596 \n",
      "End of epoch 108 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001822\n",
      "(epoch: 109, iters: 60, time: 0.105, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.734 D_fake: 0.551 \n",
      "(epoch: 109, iters: 160, time: 0.099, data: 0.002) G_GAN: 0.782 G_L1: 3.185 D_real: 0.546 D_fake: 0.685 \n",
      "(epoch: 109, iters: 260, time: 0.096, data: 0.002) G_GAN: 0.857 G_L1: 0.000 D_real: 0.873 D_fake: 0.553 \n",
      "(epoch: 109, iters: 360, time: 0.097, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.717 D_fake: 0.673 \n",
      "(epoch: 109, iters: 460, time: 0.099, data: 0.002) G_GAN: 0.842 G_L1: 2.593 D_real: 0.610 D_fake: 0.670 \n",
      "(epoch: 109, iters: 560, time: 0.107, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.748 D_fake: 0.648 \n",
      "(epoch: 109, iters: 660, time: 0.111, data: 0.003) G_GAN: 0.746 G_L1: 0.000 D_real: 0.748 D_fake: 0.640 \n",
      "(epoch: 109, iters: 760, time: 0.095, data: 0.002) G_GAN: 0.754 G_L1: 2.399 D_real: 0.568 D_fake: 0.646 \n",
      "(epoch: 109, iters: 860, time: 0.104, data: 0.002) G_GAN: 0.778 G_L1: 0.000 D_real: 0.786 D_fake: 0.619 \n",
      "(epoch: 109, iters: 960, time: 0.097, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.741 D_fake: 0.651 \n",
      "(epoch: 109, iters: 1060, time: 0.094, data: 0.002) G_GAN: 0.734 G_L1: 0.087 D_real: 0.652 D_fake: 0.650 \n",
      "(epoch: 109, iters: 1160, time: 0.094, data: 0.001) G_GAN: 0.771 G_L1: 0.000 D_real: 0.777 D_fake: 0.624 \n",
      "(epoch: 109, iters: 1260, time: 0.097, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.729 D_fake: 0.469 \n",
      "(epoch: 109, iters: 1360, time: 0.097, data: 0.001) G_GAN: 0.749 G_L1: 4.502 D_real: 0.511 D_fake: 0.659 \n",
      "(epoch: 109, iters: 1460, time: 0.095, data: 0.001) G_GAN: 0.766 G_L1: 0.000 D_real: 0.771 D_fake: 0.647 \n",
      "(epoch: 109, iters: 1560, time: 0.096, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.701 D_fake: 0.650 \n",
      "(epoch: 109, iters: 1660, time: 0.095, data: 0.002) G_GAN: 0.776 G_L1: 1.973 D_real: 0.579 D_fake: 0.628 \n",
      "(epoch: 109, iters: 1760, time: 0.099, data: 0.002) G_GAN: 0.781 G_L1: 0.000 D_real: 0.786 D_fake: 0.636 \n",
      "(epoch: 109, iters: 1860, time: 0.104, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.709 D_fake: 0.682 \n",
      "(epoch: 109, iters: 1960, time: 0.109, data: 0.001) G_GAN: 0.762 G_L1: 0.417 D_real: 0.642 D_fake: 0.638 \n",
      "(epoch: 109, iters: 2060, time: 0.094, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.742 D_fake: 0.635 \n",
      "(epoch: 109, iters: 2160, time: 0.101, data: 0.001) G_GAN: 0.685 G_L1: 0.000 D_real: 0.690 D_fake: 0.698 \n",
      "(epoch: 109, iters: 2260, time: 0.096, data: 0.002) G_GAN: 0.907 G_L1: 3.017 D_real: 0.639 D_fake: 0.675 \n",
      "End of epoch 109 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001802\n",
      "(epoch: 110, iters: 80, time: 0.102, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.713 D_fake: 0.679 \n",
      "(epoch: 110, iters: 180, time: 0.098, data: 0.002) G_GAN: 0.670 G_L1: 0.000 D_real: 0.673 D_fake: 0.699 \n",
      "(epoch: 110, iters: 280, time: 0.096, data: 0.002) G_GAN: 0.748 G_L1: 1.052 D_real: 0.604 D_fake: 0.643 \n",
      "(epoch: 110, iters: 380, time: 0.099, data: 0.002) G_GAN: 0.806 G_L1: 0.000 D_real: 0.810 D_fake: 0.598 \n",
      "(epoch: 110, iters: 480, time: 0.097, data: 0.001) G_GAN: 0.712 G_L1: 0.000 D_real: 0.715 D_fake: 0.657 \n",
      "(epoch: 110, iters: 580, time: 0.108, data: 0.001) G_GAN: 0.777 G_L1: 4.208 D_real: 0.519 D_fake: 0.660 \n",
      "(epoch: 110, iters: 680, time: 0.100, data: 0.001) G_GAN: 0.763 G_L1: 0.000 D_real: 0.766 D_fake: 0.663 \n",
      "(epoch: 110, iters: 780, time: 0.098, data: 0.001) G_GAN: 0.709 G_L1: 0.000 D_real: 0.710 D_fake: 0.632 \n",
      "(epoch: 110, iters: 880, time: 0.094, data: 0.002) G_GAN: 0.754 G_L1: 3.483 D_real: 0.521 D_fake: 0.648 \n",
      "(epoch: 110, iters: 980, time: 0.097, data: 0.001) G_GAN: 0.787 G_L1: 0.000 D_real: 0.792 D_fake: 0.613 \n",
      "(epoch: 110, iters: 1080, time: 0.105, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 110, iters: 1180, time: 0.110, data: 0.001) G_GAN: 0.780 G_L1: 0.978 D_real: 0.627 D_fake: 0.627 \n",
      "(epoch: 110, iters: 1280, time: 0.107, data: 0.002) G_GAN: 0.824 G_L1: 0.000 D_real: 0.840 D_fake: 0.578 \n",
      "(epoch: 110, iters: 1380, time: 0.095, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.728 D_fake: 0.658 \n",
      "(epoch: 110, iters: 1480, time: 0.096, data: 0.002) G_GAN: 0.757 G_L1: 1.681 D_real: 0.582 D_fake: 0.645 \n",
      "saving the latest model (epoch 110, total_steps 250000)\n",
      "(epoch: 110, iters: 1580, time: 0.098, data: 0.001) G_GAN: 0.755 G_L1: 0.000 D_real: 0.757 D_fake: 0.636 \n",
      "(epoch: 110, iters: 1680, time: 0.098, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.754 D_fake: 0.640 \n",
      "(epoch: 110, iters: 1780, time: 0.098, data: 0.002) G_GAN: 0.750 G_L1: 3.487 D_real: 0.531 D_fake: 0.649 \n",
      "(epoch: 110, iters: 1880, time: 0.098, data: 0.002) G_GAN: 0.781 G_L1: 0.000 D_real: 0.785 D_fake: 0.618 \n",
      "(epoch: 110, iters: 1980, time: 0.099, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.734 D_fake: 0.658 \n",
      "(epoch: 110, iters: 2080, time: 0.096, data: 0.001) G_GAN: 0.760 G_L1: 2.663 D_real: 0.551 D_fake: 0.653 \n",
      "(epoch: 110, iters: 2180, time: 0.098, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.751 D_fake: 0.596 \n",
      "(epoch: 110, iters: 2280, time: 0.096, data: 0.001) G_GAN: 0.736 G_L1: 0.000 D_real: 0.739 D_fake: 0.630 \n",
      "saving the model at the end of epoch 110, iters 250800\n",
      "End of epoch 110 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001782\n",
      "(epoch: 111, iters: 100, time: 0.121, data: 0.281) G_GAN: 0.812 G_L1: 2.739 D_real: 0.578 D_fake: 0.605 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 111, iters: 200, time: 0.097, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.711 D_fake: 0.666 \n",
      "(epoch: 111, iters: 300, time: 0.097, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.739 D_fake: 0.654 \n",
      "(epoch: 111, iters: 400, time: 0.099, data: 0.001) G_GAN: 0.768 G_L1: 1.900 D_real: 0.578 D_fake: 0.640 \n",
      "(epoch: 111, iters: 500, time: 0.097, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.739 D_fake: 0.638 \n",
      "(epoch: 111, iters: 600, time: 0.098, data: 0.001) G_GAN: 0.756 G_L1: 0.000 D_real: 0.760 D_fake: 0.597 \n",
      "(epoch: 111, iters: 700, time: 0.113, data: 0.002) G_GAN: 0.893 G_L1: 2.269 D_real: 0.624 D_fake: 0.553 \n",
      "(epoch: 111, iters: 800, time: 0.098, data: 0.001) G_GAN: 0.757 G_L1: 0.000 D_real: 0.760 D_fake: 0.650 \n",
      "(epoch: 111, iters: 900, time: 0.103, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.715 D_fake: 0.678 \n",
      "(epoch: 111, iters: 1000, time: 0.099, data: 0.002) G_GAN: 0.839 G_L1: 2.064 D_real: 0.599 D_fake: 0.593 \n",
      "(epoch: 111, iters: 1100, time: 0.097, data: 0.002) G_GAN: 0.842 G_L1: 0.000 D_real: 0.848 D_fake: 0.565 \n",
      "(epoch: 111, iters: 1200, time: 0.098, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.729 D_fake: 0.637 \n",
      "(epoch: 111, iters: 1300, time: 0.097, data: 0.002) G_GAN: 0.775 G_L1: 3.100 D_real: 0.537 D_fake: 0.635 \n",
      "(epoch: 111, iters: 1400, time: 0.099, data: 0.001) G_GAN: 0.773 G_L1: 0.000 D_real: 0.780 D_fake: 0.629 \n",
      "(epoch: 111, iters: 1500, time: 0.097, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.729 D_fake: 0.666 \n",
      "(epoch: 111, iters: 1600, time: 0.097, data: 0.002) G_GAN: 0.773 G_L1: 1.704 D_real: 0.620 D_fake: 0.669 \n",
      "(epoch: 111, iters: 1700, time: 0.099, data: 0.001) G_GAN: 0.768 G_L1: 0.000 D_real: 0.773 D_fake: 0.644 \n",
      "(epoch: 111, iters: 1800, time: 0.094, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.729 D_fake: 0.661 \n",
      "(epoch: 111, iters: 1900, time: 0.100, data: 0.002) G_GAN: 0.777 G_L1: 4.005 D_real: 0.519 D_fake: 0.633 \n",
      "(epoch: 111, iters: 2000, time: 0.097, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.756 D_fake: 0.654 \n",
      "(epoch: 111, iters: 2100, time: 0.095, data: 0.001) G_GAN: 0.679 G_L1: 0.000 D_real: 0.686 D_fake: 0.693 \n",
      "(epoch: 111, iters: 2200, time: 0.098, data: 0.002) G_GAN: 0.781 G_L1: 1.935 D_real: 0.567 D_fake: 0.647 \n",
      "End of epoch 111 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001762\n",
      "(epoch: 112, iters: 20, time: 0.119, data: 0.002) G_GAN: 0.794 G_L1: 0.000 D_real: 0.800 D_fake: 0.595 \n",
      "(epoch: 112, iters: 120, time: 0.096, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.695 D_fake: 0.651 \n",
      "(epoch: 112, iters: 220, time: 0.100, data: 0.001) G_GAN: 0.779 G_L1: 3.205 D_real: 0.556 D_fake: 0.706 \n",
      "(epoch: 112, iters: 320, time: 0.100, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.743 D_fake: 0.639 \n",
      "(epoch: 112, iters: 420, time: 0.100, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.723 D_fake: 0.666 \n",
      "(epoch: 112, iters: 520, time: 0.096, data: 0.001) G_GAN: 0.819 G_L1: 1.603 D_real: 0.614 D_fake: 0.601 \n",
      "(epoch: 112, iters: 620, time: 0.097, data: 0.001) G_GAN: 0.759 G_L1: 0.000 D_real: 0.761 D_fake: 0.633 \n",
      "(epoch: 112, iters: 720, time: 0.113, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.687 D_fake: 0.700 \n",
      "(epoch: 112, iters: 820, time: 0.094, data: 0.001) G_GAN: 0.784 G_L1: 2.187 D_real: 0.597 D_fake: 0.657 \n",
      "(epoch: 112, iters: 920, time: 0.095, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.731 D_fake: 0.663 \n",
      "(epoch: 112, iters: 1020, time: 0.099, data: 0.001) G_GAN: 0.703 G_L1: 0.000 D_real: 0.704 D_fake: 0.687 \n",
      "(epoch: 112, iters: 1120, time: 0.108, data: 0.002) G_GAN: 0.787 G_L1: 1.002 D_real: 0.637 D_fake: 0.617 \n",
      "(epoch: 112, iters: 1220, time: 0.096, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.737 D_fake: 0.653 \n",
      "(epoch: 112, iters: 1320, time: 0.108, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.715 D_fake: 0.647 \n",
      "(epoch: 112, iters: 1420, time: 0.097, data: 0.001) G_GAN: 0.755 G_L1: 2.201 D_real: 0.554 D_fake: 0.678 \n",
      "(epoch: 112, iters: 1520, time: 0.097, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.740 D_fake: 0.653 \n",
      "(epoch: 112, iters: 1620, time: 0.093, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.758 D_fake: 0.636 \n",
      "(epoch: 112, iters: 1720, time: 0.098, data: 0.002) G_GAN: 0.763 G_L1: 3.384 D_real: 0.543 D_fake: 0.566 \n",
      "(epoch: 112, iters: 1820, time: 0.097, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.751 D_fake: 0.649 \n",
      "(epoch: 112, iters: 1920, time: 0.096, data: 0.002) G_GAN: 0.618 G_L1: 0.000 D_real: 0.623 D_fake: 0.761 \n",
      "saving the latest model (epoch 112, total_steps 255000)\n",
      "(epoch: 112, iters: 2020, time: 0.098, data: 0.001) G_GAN: 0.792 G_L1: 1.903 D_real: 0.607 D_fake: 0.664 \n",
      "(epoch: 112, iters: 2120, time: 0.109, data: 0.002) G_GAN: 0.821 G_L1: 0.000 D_real: 0.833 D_fake: 0.667 \n",
      "(epoch: 112, iters: 2220, time: 0.100, data: 0.002) G_GAN: 0.617 G_L1: 0.000 D_real: 0.625 D_fake: 0.769 \n",
      "End of epoch 112 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001743\n",
      "(epoch: 113, iters: 40, time: 0.104, data: 0.002) G_GAN: 0.767 G_L1: 1.545 D_real: 0.592 D_fake: 0.636 \n",
      "(epoch: 113, iters: 140, time: 0.096, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.747 D_fake: 0.628 \n",
      "(epoch: 113, iters: 240, time: 0.100, data: 0.001) G_GAN: 0.717 G_L1: 0.000 D_real: 0.720 D_fake: 0.679 \n",
      "(epoch: 113, iters: 340, time: 0.097, data: 0.002) G_GAN: 0.771 G_L1: 0.576 D_real: 0.635 D_fake: 0.633 \n",
      "(epoch: 113, iters: 440, time: 0.096, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.735 D_fake: 0.647 \n",
      "(epoch: 113, iters: 540, time: 0.110, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.729 D_fake: 0.654 \n",
      "(epoch: 113, iters: 640, time: 0.096, data: 0.001) G_GAN: 0.830 G_L1: 3.338 D_real: 0.586 D_fake: 0.586 \n",
      "(epoch: 113, iters: 740, time: 0.094, data: 0.001) G_GAN: 0.758 G_L1: 0.000 D_real: 0.774 D_fake: 0.604 \n",
      "(epoch: 113, iters: 840, time: 0.094, data: 0.002) G_GAN: 0.702 G_L1: 0.000 D_real: 0.705 D_fake: 0.627 \n",
      "(epoch: 113, iters: 940, time: 0.121, data: 0.001) G_GAN: 0.943 G_L1: 1.224 D_real: 0.758 D_fake: 0.485 \n",
      "(epoch: 113, iters: 1040, time: 0.104, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.734 D_fake: 0.668 \n",
      "(epoch: 113, iters: 1140, time: 0.097, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.720 D_fake: 0.684 \n",
      "(epoch: 113, iters: 1240, time: 0.094, data: 0.002) G_GAN: 0.842 G_L1: 2.557 D_real: 0.607 D_fake: 0.655 \n",
      "(epoch: 113, iters: 1340, time: 0.098, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.758 D_fake: 0.659 \n",
      "(epoch: 113, iters: 1440, time: 0.109, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.732 D_fake: 0.693 \n",
      "(epoch: 113, iters: 1540, time: 0.098, data: 0.002) G_GAN: 0.773 G_L1: 1.958 D_real: 0.567 D_fake: 0.632 \n",
      "(epoch: 113, iters: 1640, time: 0.100, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.731 D_fake: 0.634 \n",
      "(epoch: 113, iters: 1740, time: 0.098, data: 0.001) G_GAN: 0.744 G_L1: 0.000 D_real: 0.745 D_fake: 0.673 \n",
      "(epoch: 113, iters: 1840, time: 0.099, data: 0.001) G_GAN: 0.753 G_L1: 0.311 D_real: 0.651 D_fake: 0.647 \n",
      "(epoch: 113, iters: 1940, time: 0.098, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.765 D_fake: 0.637 \n",
      "(epoch: 113, iters: 2040, time: 0.109, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.726 D_fake: 0.665 \n",
      "(epoch: 113, iters: 2140, time: 0.098, data: 0.002) G_GAN: 0.842 G_L1: 0.787 D_real: 0.678 D_fake: 0.682 \n",
      "(epoch: 113, iters: 2240, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.696 D_fake: 0.668 \n",
      "End of epoch 113 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001723\n",
      "(epoch: 114, iters: 60, time: 0.116, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.715 D_fake: 0.514 \n",
      "(epoch: 114, iters: 160, time: 0.109, data: 0.002) G_GAN: 0.745 G_L1: 3.185 D_real: 0.509 D_fake: 0.679 \n",
      "(epoch: 114, iters: 260, time: 0.097, data: 0.002) G_GAN: 0.843 G_L1: 0.000 D_real: 0.871 D_fake: 0.556 \n",
      "(epoch: 114, iters: 360, time: 0.095, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.727 D_fake: 0.666 \n",
      "(epoch: 114, iters: 460, time: 0.101, data: 0.002) G_GAN: 0.842 G_L1: 2.593 D_real: 0.618 D_fake: 0.656 \n",
      "(epoch: 114, iters: 560, time: 0.098, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.761 D_fake: 0.637 \n",
      "(epoch: 114, iters: 660, time: 0.100, data: 0.001) G_GAN: 0.734 G_L1: 0.000 D_real: 0.736 D_fake: 0.659 \n",
      "(epoch: 114, iters: 760, time: 0.096, data: 0.001) G_GAN: 0.761 G_L1: 2.399 D_real: 0.570 D_fake: 0.642 \n",
      "(epoch: 114, iters: 860, time: 0.094, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.764 D_fake: 0.544 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 114, iters: 960, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.688 D_fake: 0.713 \n",
      "(epoch: 114, iters: 1060, time: 0.107, data: 0.002) G_GAN: 0.677 G_L1: 0.087 D_real: 0.598 D_fake: 0.729 \n",
      "(epoch: 114, iters: 1160, time: 0.107, data: 0.004) G_GAN: 0.724 G_L1: 0.000 D_real: 0.734 D_fake: 0.664 \n",
      "(epoch: 114, iters: 1260, time: 0.099, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.728 D_fake: 0.679 \n",
      "(epoch: 114, iters: 1360, time: 0.097, data: 0.002) G_GAN: 0.741 G_L1: 4.502 D_real: 0.508 D_fake: 0.465 \n",
      "(epoch: 114, iters: 1460, time: 0.098, data: 0.001) G_GAN: 0.789 G_L1: 0.000 D_real: 0.798 D_fake: 0.610 \n",
      "(epoch: 114, iters: 1560, time: 0.096, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.712 D_fake: 0.677 \n",
      "(epoch: 114, iters: 1660, time: 0.107, data: 0.002) G_GAN: 0.778 G_L1: 1.973 D_real: 0.581 D_fake: 0.633 \n",
      "(epoch: 114, iters: 1760, time: 0.097, data: 0.001) G_GAN: 0.800 G_L1: 0.000 D_real: 0.804 D_fake: 0.600 \n",
      "(epoch: 114, iters: 1860, time: 0.097, data: 0.001) G_GAN: 0.717 G_L1: 0.000 D_real: 0.718 D_fake: 0.673 \n",
      "(epoch: 114, iters: 1960, time: 0.098, data: 0.001) G_GAN: 0.771 G_L1: 0.417 D_real: 0.662 D_fake: 0.588 \n",
      "(epoch: 114, iters: 2060, time: 0.093, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.725 D_fake: 0.672 \n",
      "(epoch: 114, iters: 2160, time: 0.098, data: 0.001) G_GAN: 0.646 G_L1: 0.000 D_real: 0.643 D_fake: 0.749 \n",
      "(epoch: 114, iters: 2260, time: 0.094, data: 0.002) G_GAN: 1.003 G_L1: 3.017 D_real: 0.685 D_fake: 0.480 \n",
      "End of epoch 114 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001703\n",
      "(epoch: 115, iters: 80, time: 0.103, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.723 D_fake: 0.670 \n",
      "saving the latest model (epoch 115, total_steps 260000)\n",
      "(epoch: 115, iters: 180, time: 0.098, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.704 D_fake: 0.658 \n",
      "(epoch: 115, iters: 280, time: 0.097, data: 0.001) G_GAN: 0.737 G_L1: 1.052 D_real: 0.585 D_fake: 0.617 \n",
      "(epoch: 115, iters: 380, time: 0.098, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.755 D_fake: 0.642 \n",
      "(epoch: 115, iters: 480, time: 0.098, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.693 D_fake: 0.652 \n",
      "(epoch: 115, iters: 580, time: 0.100, data: 0.001) G_GAN: 0.792 G_L1: 4.208 D_real: 0.533 D_fake: 0.617 \n",
      "(epoch: 115, iters: 680, time: 0.099, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.724 D_fake: 0.669 \n",
      "(epoch: 115, iters: 780, time: 0.098, data: 0.001) G_GAN: 0.705 G_L1: 0.000 D_real: 0.705 D_fake: 0.684 \n",
      "(epoch: 115, iters: 880, time: 0.096, data: 0.001) G_GAN: 0.753 G_L1: 3.483 D_real: 0.526 D_fake: 0.651 \n",
      "(epoch: 115, iters: 980, time: 0.098, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.740 D_fake: 0.654 \n",
      "(epoch: 115, iters: 1080, time: 0.095, data: 0.002) G_GAN: 0.652 G_L1: 0.000 D_real: 0.644 D_fake: 0.749 \n",
      "(epoch: 115, iters: 1180, time: 0.096, data: 0.001) G_GAN: 0.789 G_L1: 0.978 D_real: 0.628 D_fake: 0.614 \n",
      "(epoch: 115, iters: 1280, time: 0.100, data: 0.002) G_GAN: 0.868 G_L1: 0.000 D_real: 0.892 D_fake: 0.624 \n",
      "(epoch: 115, iters: 1380, time: 0.107, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.746 D_fake: 0.666 \n",
      "(epoch: 115, iters: 1480, time: 0.109, data: 0.002) G_GAN: 0.760 G_L1: 1.681 D_real: 0.583 D_fake: 0.653 \n",
      "(epoch: 115, iters: 1580, time: 0.096, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.753 D_fake: 0.640 \n",
      "(epoch: 115, iters: 1680, time: 0.097, data: 0.001) G_GAN: 0.764 G_L1: 0.000 D_real: 0.768 D_fake: 0.721 \n",
      "(epoch: 115, iters: 1780, time: 0.100, data: 0.002) G_GAN: 0.752 G_L1: 3.487 D_real: 0.532 D_fake: 0.646 \n",
      "(epoch: 115, iters: 1880, time: 0.100, data: 0.002) G_GAN: 0.770 G_L1: 0.000 D_real: 0.774 D_fake: 0.629 \n",
      "(epoch: 115, iters: 1980, time: 0.110, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.740 D_fake: 0.664 \n",
      "(epoch: 115, iters: 2080, time: 0.109, data: 0.001) G_GAN: 0.786 G_L1: 2.663 D_real: 0.554 D_fake: 0.635 \n",
      "(epoch: 115, iters: 2180, time: 0.097, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.747 D_fake: 0.640 \n",
      "(epoch: 115, iters: 2280, time: 0.108, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.693 D_fake: 0.620 \n",
      "saving the model at the end of epoch 115, iters 262200\n",
      "End of epoch 115 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001683\n",
      "(epoch: 116, iters: 100, time: 0.107, data: 0.279) G_GAN: 0.806 G_L1: 2.739 D_real: 0.564 D_fake: 0.609 \n",
      "(epoch: 116, iters: 200, time: 0.098, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.748 D_fake: 0.651 \n",
      "(epoch: 116, iters: 300, time: 0.098, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.727 D_fake: 0.669 \n",
      "(epoch: 116, iters: 400, time: 0.098, data: 0.001) G_GAN: 0.757 G_L1: 1.900 D_real: 0.558 D_fake: 0.657 \n",
      "(epoch: 116, iters: 500, time: 0.099, data: 0.001) G_GAN: 0.720 G_L1: 0.000 D_real: 0.724 D_fake: 0.666 \n",
      "(epoch: 116, iters: 600, time: 0.098, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.748 D_fake: 0.644 \n",
      "(epoch: 116, iters: 700, time: 0.099, data: 0.002) G_GAN: 0.923 G_L1: 2.269 D_real: 0.683 D_fake: 0.671 \n",
      "(epoch: 116, iters: 800, time: 0.099, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.750 D_fake: 0.651 \n",
      "(epoch: 116, iters: 900, time: 0.093, data: 0.002) G_GAN: 0.607 G_L1: 0.000 D_real: 0.612 D_fake: 0.831 \n",
      "(epoch: 116, iters: 1000, time: 0.100, data: 0.001) G_GAN: 0.787 G_L1: 2.064 D_real: 0.583 D_fake: 0.607 \n",
      "(epoch: 116, iters: 1100, time: 0.113, data: 0.001) G_GAN: 0.808 G_L1: 0.000 D_real: 0.811 D_fake: 0.592 \n",
      "(epoch: 116, iters: 1200, time: 0.097, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.725 D_fake: 0.562 \n",
      "(epoch: 116, iters: 1300, time: 0.109, data: 0.002) G_GAN: 0.788 G_L1: 3.100 D_real: 0.576 D_fake: 0.586 \n",
      "(epoch: 116, iters: 1400, time: 0.099, data: 0.002) G_GAN: 0.773 G_L1: 0.000 D_real: 0.800 D_fake: 0.684 \n",
      "(epoch: 116, iters: 1500, time: 0.096, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.720 D_fake: 0.690 \n",
      "(epoch: 116, iters: 1600, time: 0.095, data: 0.001) G_GAN: 0.759 G_L1: 1.704 D_real: 0.578 D_fake: 0.662 \n",
      "(epoch: 116, iters: 1700, time: 0.114, data: 0.001) G_GAN: 0.763 G_L1: 0.000 D_real: 0.768 D_fake: 0.618 \n",
      "(epoch: 116, iters: 1800, time: 0.095, data: 0.001) G_GAN: 0.711 G_L1: 0.000 D_real: 0.712 D_fake: 0.677 \n",
      "(epoch: 116, iters: 1900, time: 0.110, data: 0.002) G_GAN: 0.788 G_L1: 4.005 D_real: 0.531 D_fake: 0.643 \n",
      "(epoch: 116, iters: 2000, time: 0.097, data: 0.001) G_GAN: 0.751 G_L1: 0.000 D_real: 0.753 D_fake: 0.618 \n",
      "(epoch: 116, iters: 2100, time: 0.094, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.718 D_fake: 0.676 \n",
      "(epoch: 116, iters: 2200, time: 0.104, data: 0.002) G_GAN: 0.740 G_L1: 1.935 D_real: 0.532 D_fake: 0.665 \n",
      "End of epoch 116 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001663\n",
      "(epoch: 117, iters: 20, time: 0.105, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.752 D_fake: 0.668 \n",
      "(epoch: 117, iters: 120, time: 0.096, data: 0.001) G_GAN: 0.719 G_L1: 0.000 D_real: 0.726 D_fake: 0.642 \n",
      "(epoch: 117, iters: 220, time: 0.098, data: 0.001) G_GAN: 0.765 G_L1: 3.205 D_real: 0.532 D_fake: 0.642 \n",
      "(epoch: 117, iters: 320, time: 0.111, data: 0.001) G_GAN: 0.752 G_L1: 0.000 D_real: 0.757 D_fake: 0.645 \n",
      "(epoch: 117, iters: 420, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.694 D_fake: 0.694 \n",
      "(epoch: 117, iters: 520, time: 0.106, data: 0.001) G_GAN: 0.794 G_L1: 1.603 D_real: 0.613 D_fake: 0.615 \n",
      "saving the latest model (epoch 117, total_steps 265000)\n",
      "(epoch: 117, iters: 620, time: 0.098, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.754 D_fake: 0.642 \n",
      "(epoch: 117, iters: 720, time: 0.099, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.697 D_fake: 0.690 \n",
      "(epoch: 117, iters: 820, time: 0.095, data: 0.002) G_GAN: 0.779 G_L1: 2.187 D_real: 0.589 D_fake: 0.667 \n",
      "(epoch: 117, iters: 920, time: 0.096, data: 0.001) G_GAN: 0.718 G_L1: 0.000 D_real: 0.721 D_fake: 0.675 \n",
      "(epoch: 117, iters: 1020, time: 0.097, data: 0.002) G_GAN: 0.686 G_L1: 0.000 D_real: 0.682 D_fake: 0.712 \n",
      "(epoch: 117, iters: 1120, time: 0.101, data: 0.001) G_GAN: 0.811 G_L1: 1.002 D_real: 0.658 D_fake: 0.591 \n",
      "(epoch: 117, iters: 1220, time: 0.094, data: 0.001) G_GAN: 0.672 G_L1: 0.000 D_real: 0.708 D_fake: 0.678 \n",
      "(epoch: 117, iters: 1320, time: 0.099, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.701 D_fake: 0.607 \n",
      "(epoch: 117, iters: 1420, time: 0.110, data: 0.001) G_GAN: 0.798 G_L1: 2.201 D_real: 0.605 D_fake: 0.694 \n",
      "(epoch: 117, iters: 1520, time: 0.110, data: 0.001) G_GAN: 0.758 G_L1: 0.000 D_real: 0.760 D_fake: 0.638 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 117, iters: 1620, time: 0.094, data: 0.001) G_GAN: 0.705 G_L1: 0.000 D_real: 0.708 D_fake: 0.684 \n",
      "(epoch: 117, iters: 1720, time: 0.099, data: 0.001) G_GAN: 0.787 G_L1: 3.384 D_real: 0.550 D_fake: 0.621 \n",
      "(epoch: 117, iters: 1820, time: 0.108, data: 0.002) G_GAN: 0.796 G_L1: 0.000 D_real: 0.805 D_fake: 0.590 \n",
      "(epoch: 117, iters: 1920, time: 0.113, data: 0.001) G_GAN: 0.708 G_L1: 0.000 D_real: 0.698 D_fake: 0.592 \n",
      "(epoch: 117, iters: 2020, time: 0.099, data: 0.002) G_GAN: 0.856 G_L1: 1.903 D_real: 0.649 D_fake: 0.565 \n",
      "(epoch: 117, iters: 2120, time: 0.096, data: 0.001) G_GAN: 0.881 G_L1: 0.000 D_real: 0.910 D_fake: 0.527 \n",
      "(epoch: 117, iters: 2220, time: 0.100, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.694 D_fake: 0.440 \n",
      "End of epoch 117 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001644\n",
      "(epoch: 118, iters: 40, time: 0.109, data: 0.002) G_GAN: 0.738 G_L1: 1.545 D_real: 0.555 D_fake: 0.664 \n",
      "(epoch: 118, iters: 140, time: 0.108, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.725 D_fake: 0.664 \n",
      "(epoch: 118, iters: 240, time: 0.104, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.730 D_fake: 0.663 \n",
      "(epoch: 118, iters: 340, time: 0.097, data: 0.002) G_GAN: 0.735 G_L1: 0.576 D_real: 0.614 D_fake: 0.661 \n",
      "(epoch: 118, iters: 440, time: 0.093, data: 0.001) G_GAN: 0.755 G_L1: 0.000 D_real: 0.766 D_fake: 0.647 \n",
      "(epoch: 118, iters: 540, time: 0.106, data: 0.001) G_GAN: 0.715 G_L1: 0.000 D_real: 0.716 D_fake: 0.674 \n",
      "(epoch: 118, iters: 640, time: 0.095, data: 0.002) G_GAN: 0.829 G_L1: 3.338 D_real: 0.583 D_fake: 0.656 \n",
      "(epoch: 118, iters: 740, time: 0.093, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.756 D_fake: 0.622 \n",
      "(epoch: 118, iters: 840, time: 0.094, data: 0.001) G_GAN: 0.711 G_L1: 0.000 D_real: 0.712 D_fake: 0.677 \n",
      "(epoch: 118, iters: 940, time: 0.097, data: 0.001) G_GAN: 0.790 G_L1: 1.224 D_real: 0.616 D_fake: 0.591 \n",
      "(epoch: 118, iters: 1040, time: 0.093, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.741 D_fake: 0.662 \n",
      "(epoch: 118, iters: 1140, time: 0.108, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.730 D_fake: 0.660 \n",
      "(epoch: 118, iters: 1240, time: 0.094, data: 0.001) G_GAN: 0.906 G_L1: 2.557 D_real: 0.634 D_fake: 0.543 \n",
      "(epoch: 118, iters: 1340, time: 0.099, data: 0.002) G_GAN: 0.799 G_L1: 0.000 D_real: 0.803 D_fake: 0.605 \n",
      "(epoch: 118, iters: 1440, time: 0.108, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.730 D_fake: 0.664 \n",
      "(epoch: 118, iters: 1540, time: 0.096, data: 0.001) G_GAN: 0.807 G_L1: 1.958 D_real: 0.590 D_fake: 0.607 \n",
      "(epoch: 118, iters: 1640, time: 0.097, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.745 D_fake: 0.633 \n",
      "(epoch: 118, iters: 1740, time: 0.100, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.744 D_fake: 0.650 \n",
      "(epoch: 118, iters: 1840, time: 0.099, data: 0.002) G_GAN: 0.758 G_L1: 0.311 D_real: 0.642 D_fake: 0.645 \n",
      "(epoch: 118, iters: 1940, time: 0.098, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.747 D_fake: 0.658 \n",
      "(epoch: 118, iters: 2040, time: 0.105, data: 0.001) G_GAN: 0.711 G_L1: 0.000 D_real: 0.714 D_fake: 0.665 \n",
      "(epoch: 118, iters: 2140, time: 0.099, data: 0.002) G_GAN: 0.835 G_L1: 0.787 D_real: 0.664 D_fake: 0.582 \n",
      "(epoch: 118, iters: 2240, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.695 D_fake: 0.699 \n",
      "End of epoch 118 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001624\n",
      "(epoch: 119, iters: 60, time: 0.103, data: 0.001) G_GAN: 0.676 G_L1: 0.000 D_real: 0.674 D_fake: 0.764 \n",
      "(epoch: 119, iters: 160, time: 0.099, data: 0.005) G_GAN: 0.768 G_L1: 3.185 D_real: 0.524 D_fake: 0.636 \n",
      "(epoch: 119, iters: 260, time: 0.096, data: 0.002) G_GAN: 0.803 G_L1: 0.000 D_real: 0.813 D_fake: 0.599 \n",
      "(epoch: 119, iters: 360, time: 0.106, data: 0.002) G_GAN: 0.665 G_L1: 0.000 D_real: 0.662 D_fake: 0.730 \n",
      "(epoch: 119, iters: 460, time: 0.099, data: 0.002) G_GAN: 0.841 G_L1: 2.593 D_real: 0.600 D_fake: 0.671 \n",
      "(epoch: 119, iters: 560, time: 0.096, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.755 D_fake: 0.645 \n",
      "(epoch: 119, iters: 660, time: 0.096, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.696 \n",
      "(epoch: 119, iters: 760, time: 0.097, data: 0.001) G_GAN: 0.738 G_L1: 2.399 D_real: 0.550 D_fake: 0.670 \n",
      "(epoch: 119, iters: 860, time: 0.092, data: 0.001) G_GAN: 0.787 G_L1: 0.000 D_real: 0.791 D_fake: 0.608 \n",
      "(epoch: 119, iters: 960, time: 0.094, data: 0.001) G_GAN: 0.682 G_L1: 0.000 D_real: 0.681 D_fake: 0.710 \n",
      "saving the latest model (epoch 119, total_steps 270000)\n",
      "(epoch: 119, iters: 1060, time: 0.109, data: 0.001) G_GAN: 0.718 G_L1: 0.087 D_real: 0.628 D_fake: 0.689 \n",
      "(epoch: 119, iters: 1160, time: 0.095, data: 0.002) G_GAN: 0.783 G_L1: 0.000 D_real: 0.793 D_fake: 0.531 \n",
      "(epoch: 119, iters: 1260, time: 0.096, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.712 D_fake: 0.692 \n",
      "(epoch: 119, iters: 1360, time: 0.095, data: 0.002) G_GAN: 0.737 G_L1: 4.502 D_real: 0.491 D_fake: 0.666 \n",
      "(epoch: 119, iters: 1460, time: 0.096, data: 0.002) G_GAN: 0.864 G_L1: 0.000 D_real: 0.889 D_fake: 0.547 \n",
      "(epoch: 119, iters: 1560, time: 0.106, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.700 D_fake: 0.688 \n",
      "(epoch: 119, iters: 1660, time: 0.096, data: 0.002) G_GAN: 0.778 G_L1: 1.973 D_real: 0.585 D_fake: 0.629 \n",
      "(epoch: 119, iters: 1760, time: 0.108, data: 0.002) G_GAN: 0.801 G_L1: 0.000 D_real: 0.804 D_fake: 0.599 \n",
      "(epoch: 119, iters: 1860, time: 0.099, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.716 D_fake: 0.682 \n",
      "(epoch: 119, iters: 1960, time: 0.097, data: 0.001) G_GAN: 0.750 G_L1: 0.417 D_real: 0.633 D_fake: 0.653 \n",
      "(epoch: 119, iters: 2060, time: 0.095, data: 0.001) G_GAN: 0.713 G_L1: 0.000 D_real: 0.716 D_fake: 0.669 \n",
      "(epoch: 119, iters: 2160, time: 0.096, data: 0.001) G_GAN: 0.680 G_L1: 0.000 D_real: 0.685 D_fake: 0.605 \n",
      "(epoch: 119, iters: 2260, time: 0.091, data: 0.001) G_GAN: 0.921 G_L1: 3.017 D_real: 0.612 D_fake: 0.539 \n",
      "End of epoch 119 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001604\n",
      "(epoch: 120, iters: 80, time: 0.112, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.719 D_fake: 0.828 \n",
      "(epoch: 120, iters: 180, time: 0.098, data: 0.001) G_GAN: 0.708 G_L1: 0.000 D_real: 0.709 D_fake: 0.679 \n",
      "(epoch: 120, iters: 280, time: 0.097, data: 0.001) G_GAN: 0.744 G_L1: 1.052 D_real: 0.588 D_fake: 0.655 \n",
      "(epoch: 120, iters: 380, time: 0.101, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.750 D_fake: 0.647 \n",
      "(epoch: 120, iters: 480, time: 0.097, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.692 D_fake: 0.624 \n",
      "(epoch: 120, iters: 580, time: 0.110, data: 0.002) G_GAN: 0.823 G_L1: 4.208 D_real: 0.545 D_fake: 0.641 \n",
      "(epoch: 120, iters: 680, time: 0.097, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.739 D_fake: 0.654 \n",
      "(epoch: 120, iters: 780, time: 0.097, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.700 D_fake: 0.680 \n",
      "(epoch: 120, iters: 880, time: 0.096, data: 0.002) G_GAN: 0.771 G_L1: 3.483 D_real: 0.516 D_fake: 0.677 \n",
      "(epoch: 120, iters: 980, time: 0.099, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.748 D_fake: 0.650 \n",
      "(epoch: 120, iters: 1080, time: 0.095, data: 0.001) G_GAN: 0.670 G_L1: 0.000 D_real: 0.667 D_fake: 0.724 \n",
      "(epoch: 120, iters: 1180, time: 0.105, data: 0.001) G_GAN: 0.803 G_L1: 0.978 D_real: 0.628 D_fake: 0.642 \n",
      "(epoch: 120, iters: 1280, time: 0.098, data: 0.001) G_GAN: 0.861 G_L1: 0.000 D_real: 0.875 D_fake: 0.550 \n",
      "(epoch: 120, iters: 1380, time: 0.097, data: 0.001) G_GAN: 0.703 G_L1: 0.000 D_real: 0.704 D_fake: 0.687 \n",
      "(epoch: 120, iters: 1480, time: 0.097, data: 0.001) G_GAN: 0.772 G_L1: 1.681 D_real: 0.586 D_fake: 0.633 \n",
      "(epoch: 120, iters: 1580, time: 0.101, data: 0.001) G_GAN: 0.767 G_L1: 0.000 D_real: 0.771 D_fake: 0.625 \n",
      "(epoch: 120, iters: 1680, time: 0.108, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.748 D_fake: 0.649 \n",
      "(epoch: 120, iters: 1780, time: 0.097, data: 0.001) G_GAN: 0.754 G_L1: 3.487 D_real: 0.531 D_fake: 0.643 \n",
      "(epoch: 120, iters: 1880, time: 0.101, data: 0.002) G_GAN: 0.775 G_L1: 0.000 D_real: 0.784 D_fake: 0.539 \n",
      "(epoch: 120, iters: 1980, time: 0.107, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.731 D_fake: 0.656 \n",
      "(epoch: 120, iters: 2080, time: 0.100, data: 0.002) G_GAN: 0.774 G_L1: 2.663 D_real: 0.550 D_fake: 0.571 \n",
      "(epoch: 120, iters: 2180, time: 0.101, data: 0.001) G_GAN: 0.724 G_L1: 0.000 D_real: 0.727 D_fake: 0.664 \n",
      "(epoch: 120, iters: 2280, time: 0.097, data: 0.004) G_GAN: 0.718 G_L1: 0.000 D_real: 0.722 D_fake: 0.745 \n",
      "saving the model at the end of epoch 120, iters 273600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 120 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001584\n",
      "(epoch: 121, iters: 100, time: 0.107, data: 0.274) G_GAN: 0.814 G_L1: 2.739 D_real: 0.568 D_fake: 0.663 \n",
      "(epoch: 121, iters: 200, time: 0.097, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.749 D_fake: 0.639 \n",
      "(epoch: 121, iters: 300, time: 0.103, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.740 D_fake: 0.658 \n",
      "(epoch: 121, iters: 400, time: 0.098, data: 0.001) G_GAN: 0.763 G_L1: 1.900 D_real: 0.565 D_fake: 0.645 \n",
      "(epoch: 121, iters: 500, time: 0.097, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.714 D_fake: 0.647 \n",
      "(epoch: 121, iters: 600, time: 0.098, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.729 D_fake: 0.661 \n",
      "(epoch: 121, iters: 700, time: 0.099, data: 0.001) G_GAN: 0.969 G_L1: 2.269 D_real: 0.684 D_fake: 0.505 \n",
      "(epoch: 121, iters: 800, time: 0.100, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.704 D_fake: 0.684 \n",
      "(epoch: 121, iters: 900, time: 0.092, data: 0.002) G_GAN: 0.644 G_L1: 0.000 D_real: 0.642 D_fake: 0.755 \n",
      "(epoch: 121, iters: 1000, time: 0.111, data: 0.002) G_GAN: 0.897 G_L1: 2.064 D_real: 0.649 D_fake: 0.654 \n",
      "(epoch: 121, iters: 1100, time: 0.097, data: 0.002) G_GAN: 0.815 G_L1: 0.000 D_real: 0.824 D_fake: 0.584 \n",
      "(epoch: 121, iters: 1200, time: 0.099, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.710 D_fake: 0.678 \n",
      "(epoch: 121, iters: 1300, time: 0.097, data: 0.002) G_GAN: 0.776 G_L1: 3.100 D_real: 0.547 D_fake: 0.624 \n",
      "(epoch: 121, iters: 1400, time: 0.099, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.769 D_fake: 0.633 \n",
      "saving the latest model (epoch 121, total_steps 275000)\n",
      "(epoch: 121, iters: 1500, time: 0.098, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.728 D_fake: 0.668 \n",
      "(epoch: 121, iters: 1600, time: 0.095, data: 0.001) G_GAN: 0.730 G_L1: 1.704 D_real: 0.558 D_fake: 0.634 \n",
      "(epoch: 121, iters: 1700, time: 0.112, data: 0.001) G_GAN: 0.783 G_L1: 0.000 D_real: 0.786 D_fake: 0.614 \n",
      "(epoch: 121, iters: 1800, time: 0.106, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.727 D_fake: 0.634 \n",
      "(epoch: 121, iters: 1900, time: 0.100, data: 0.002) G_GAN: 0.817 G_L1: 4.005 D_real: 0.524 D_fake: 0.609 \n",
      "(epoch: 121, iters: 2000, time: 0.097, data: 0.002) G_GAN: 0.772 G_L1: 0.000 D_real: 0.774 D_fake: 0.626 \n",
      "(epoch: 121, iters: 2100, time: 0.107, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.717 D_fake: 0.677 \n",
      "(epoch: 121, iters: 2200, time: 0.100, data: 0.002) G_GAN: 0.759 G_L1: 1.935 D_real: 0.549 D_fake: 0.671 \n",
      "End of epoch 121 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001564\n",
      "(epoch: 122, iters: 20, time: 0.104, data: 0.001) G_GAN: 0.783 G_L1: 0.000 D_real: 0.790 D_fake: 0.620 \n",
      "(epoch: 122, iters: 120, time: 0.096, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.688 D_fake: 0.696 \n",
      "(epoch: 122, iters: 220, time: 0.112, data: 0.002) G_GAN: 0.781 G_L1: 3.205 D_real: 0.536 D_fake: 0.599 \n",
      "(epoch: 122, iters: 320, time: 0.099, data: 0.001) G_GAN: 0.761 G_L1: 0.000 D_real: 0.765 D_fake: 0.645 \n",
      "(epoch: 122, iters: 420, time: 0.108, data: 0.002) G_GAN: 0.671 G_L1: 0.000 D_real: 0.675 D_fake: 0.664 \n",
      "(epoch: 122, iters: 520, time: 0.097, data: 0.001) G_GAN: 0.771 G_L1: 1.603 D_real: 0.578 D_fake: 0.639 \n",
      "(epoch: 122, iters: 620, time: 0.097, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.745 D_fake: 0.651 \n",
      "(epoch: 122, iters: 720, time: 0.096, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 122, iters: 820, time: 0.105, data: 0.002) G_GAN: 0.738 G_L1: 2.187 D_real: 0.549 D_fake: 0.686 \n",
      "(epoch: 122, iters: 920, time: 0.096, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.724 D_fake: 0.668 \n",
      "(epoch: 122, iters: 1020, time: 0.098, data: 0.002) G_GAN: 0.668 G_L1: 0.000 D_real: 0.674 D_fake: 0.636 \n",
      "(epoch: 122, iters: 1120, time: 0.110, data: 0.001) G_GAN: 0.820 G_L1: 1.002 D_real: 0.640 D_fake: 0.619 \n",
      "(epoch: 122, iters: 1220, time: 0.098, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.731 D_fake: 0.550 \n",
      "(epoch: 122, iters: 1320, time: 0.097, data: 0.001) G_GAN: 0.707 G_L1: 0.000 D_real: 0.707 D_fake: 0.683 \n",
      "(epoch: 122, iters: 1420, time: 0.097, data: 0.001) G_GAN: 0.777 G_L1: 2.201 D_real: 0.581 D_fake: 0.666 \n",
      "(epoch: 122, iters: 1520, time: 0.109, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.766 D_fake: 0.649 \n",
      "(epoch: 122, iters: 1620, time: 0.094, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.742 D_fake: 0.652 \n",
      "(epoch: 122, iters: 1720, time: 0.098, data: 0.002) G_GAN: 0.764 G_L1: 3.384 D_real: 0.538 D_fake: 0.648 \n",
      "(epoch: 122, iters: 1820, time: 0.099, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.762 D_fake: 0.644 \n",
      "(epoch: 122, iters: 1920, time: 0.101, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.751 D_fake: 0.641 \n",
      "(epoch: 122, iters: 2020, time: 0.099, data: 0.003) G_GAN: 0.765 G_L1: 1.903 D_real: 0.567 D_fake: 0.640 \n",
      "(epoch: 122, iters: 2120, time: 0.100, data: 0.003) G_GAN: 0.872 G_L1: 0.000 D_real: 0.883 D_fake: 0.543 \n",
      "(epoch: 122, iters: 2220, time: 0.110, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.735 D_fake: 0.583 \n",
      "End of epoch 122 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001545\n",
      "(epoch: 123, iters: 40, time: 0.106, data: 0.002) G_GAN: 0.763 G_L1: 1.545 D_real: 0.574 D_fake: 0.587 \n",
      "(epoch: 123, iters: 140, time: 0.098, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.741 D_fake: 0.649 \n",
      "(epoch: 123, iters: 240, time: 0.099, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.741 D_fake: 0.697 \n",
      "(epoch: 123, iters: 340, time: 0.098, data: 0.002) G_GAN: 0.775 G_L1: 0.576 D_real: 0.645 D_fake: 0.685 \n",
      "(epoch: 123, iters: 440, time: 0.106, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.753 D_fake: 0.644 \n",
      "(epoch: 123, iters: 540, time: 0.095, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.732 D_fake: 0.659 \n",
      "(epoch: 123, iters: 640, time: 0.096, data: 0.002) G_GAN: 0.841 G_L1: 3.338 D_real: 0.576 D_fake: 0.654 \n",
      "(epoch: 123, iters: 740, time: 0.102, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.735 D_fake: 0.632 \n",
      "(epoch: 123, iters: 840, time: 0.094, data: 0.002) G_GAN: 0.675 G_L1: 0.000 D_real: 0.677 D_fake: 0.650 \n",
      "(epoch: 123, iters: 940, time: 0.098, data: 0.002) G_GAN: 0.781 G_L1: 1.224 D_real: 0.627 D_fake: 0.653 \n",
      "(epoch: 123, iters: 1040, time: 0.096, data: 0.002) G_GAN: 0.702 G_L1: 0.000 D_real: 0.726 D_fake: 0.638 \n",
      "(epoch: 123, iters: 1140, time: 0.098, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.725 D_fake: 0.562 \n",
      "(epoch: 123, iters: 1240, time: 0.096, data: 0.001) G_GAN: 0.952 G_L1: 2.557 D_real: 0.663 D_fake: 0.575 \n",
      "(epoch: 123, iters: 1340, time: 0.110, data: 0.002) G_GAN: 0.793 G_L1: 0.000 D_real: 0.791 D_fake: 0.614 \n",
      "(epoch: 123, iters: 1440, time: 0.100, data: 0.001) G_GAN: 0.719 G_L1: 0.000 D_real: 0.723 D_fake: 0.710 \n",
      "(epoch: 123, iters: 1540, time: 0.098, data: 0.002) G_GAN: 0.779 G_L1: 1.958 D_real: 0.563 D_fake: 0.649 \n",
      "(epoch: 123, iters: 1640, time: 0.097, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.726 D_fake: 0.619 \n",
      "(epoch: 123, iters: 1740, time: 0.101, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.757 D_fake: 0.632 \n",
      "(epoch: 123, iters: 1840, time: 0.099, data: 0.002) G_GAN: 0.759 G_L1: 0.311 D_real: 0.644 D_fake: 0.623 \n",
      "saving the latest model (epoch 123, total_steps 280000)\n",
      "(epoch: 123, iters: 1940, time: 0.104, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.742 D_fake: 0.549 \n",
      "(epoch: 123, iters: 2040, time: 0.099, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.733 D_fake: 0.659 \n",
      "(epoch: 123, iters: 2140, time: 0.114, data: 0.001) G_GAN: 0.704 G_L1: 0.787 D_real: 0.596 D_fake: 0.623 \n",
      "(epoch: 123, iters: 2240, time: 0.098, data: 0.001) G_GAN: 0.721 G_L1: 0.000 D_real: 0.721 D_fake: 0.675 \n",
      "End of epoch 123 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001525\n",
      "(epoch: 124, iters: 60, time: 0.106, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.717 D_fake: 0.700 \n",
      "(epoch: 124, iters: 160, time: 0.110, data: 0.001) G_GAN: 0.773 G_L1: 3.185 D_real: 0.529 D_fake: 0.641 \n",
      "(epoch: 124, iters: 260, time: 0.112, data: 0.001) G_GAN: 0.824 G_L1: 0.000 D_real: 0.836 D_fake: 0.583 \n",
      "(epoch: 124, iters: 360, time: 0.096, data: 0.001) G_GAN: 0.707 G_L1: 0.000 D_real: 0.707 D_fake: 0.684 \n",
      "(epoch: 124, iters: 460, time: 0.109, data: 0.002) G_GAN: 0.853 G_L1: 2.593 D_real: 0.602 D_fake: 0.576 \n",
      "(epoch: 124, iters: 560, time: 0.097, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.765 D_fake: 0.634 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 124, iters: 660, time: 0.097, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.729 D_fake: 0.667 \n",
      "(epoch: 124, iters: 760, time: 0.103, data: 0.001) G_GAN: 0.775 G_L1: 2.399 D_real: 0.576 D_fake: 0.631 \n",
      "(epoch: 124, iters: 860, time: 0.094, data: 0.002) G_GAN: 0.766 G_L1: 0.000 D_real: 0.787 D_fake: 0.616 \n",
      "(epoch: 124, iters: 960, time: 0.096, data: 0.002) G_GAN: 0.842 G_L1: 0.000 D_real: 0.916 D_fake: 0.570 \n",
      "(epoch: 124, iters: 1060, time: 0.098, data: 0.002) G_GAN: 0.759 G_L1: 0.087 D_real: 0.687 D_fake: 0.641 \n",
      "(epoch: 124, iters: 1160, time: 0.097, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.749 D_fake: 0.656 \n",
      "(epoch: 124, iters: 1260, time: 0.099, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.745 D_fake: 0.632 \n",
      "(epoch: 124, iters: 1360, time: 0.097, data: 0.002) G_GAN: 0.743 G_L1: 4.502 D_real: 0.497 D_fake: 0.675 \n",
      "(epoch: 124, iters: 1460, time: 0.107, data: 0.002) G_GAN: 0.822 G_L1: 0.000 D_real: 0.845 D_fake: 0.574 \n",
      "(epoch: 124, iters: 1560, time: 0.094, data: 0.001) G_GAN: 0.704 G_L1: 0.000 D_real: 0.705 D_fake: 0.677 \n",
      "(epoch: 124, iters: 1660, time: 0.097, data: 0.002) G_GAN: 0.812 G_L1: 1.973 D_real: 0.613 D_fake: 0.639 \n",
      "(epoch: 124, iters: 1760, time: 0.109, data: 0.002) G_GAN: 0.783 G_L1: 0.000 D_real: 0.798 D_fake: 0.656 \n",
      "(epoch: 124, iters: 1860, time: 0.097, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.734 D_fake: 0.659 \n",
      "(epoch: 124, iters: 1960, time: 0.109, data: 0.001) G_GAN: 0.744 G_L1: 0.417 D_real: 0.635 D_fake: 0.650 \n",
      "(epoch: 124, iters: 2060, time: 0.095, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.738 D_fake: 0.618 \n",
      "(epoch: 124, iters: 2160, time: 0.098, data: 0.002) G_GAN: 0.683 G_L1: 0.000 D_real: 0.684 D_fake: 0.705 \n",
      "(epoch: 124, iters: 2260, time: 0.106, data: 0.001) G_GAN: 0.944 G_L1: 3.017 D_real: 0.646 D_fake: 0.521 \n",
      "End of epoch 124 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001505\n",
      "(epoch: 125, iters: 80, time: 0.113, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.736 D_fake: 0.628 \n",
      "(epoch: 125, iters: 180, time: 0.107, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 125, iters: 280, time: 0.097, data: 0.002) G_GAN: 0.776 G_L1: 1.052 D_real: 0.599 D_fake: 0.631 \n",
      "(epoch: 125, iters: 380, time: 0.099, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.749 D_fake: 0.604 \n",
      "(epoch: 125, iters: 480, time: 0.098, data: 0.001) G_GAN: 0.684 G_L1: 0.000 D_real: 0.689 D_fake: 0.634 \n",
      "(epoch: 125, iters: 580, time: 0.099, data: 0.002) G_GAN: 0.817 G_L1: 4.208 D_real: 0.539 D_fake: 0.574 \n",
      "(epoch: 125, iters: 680, time: 0.097, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.740 D_fake: 0.627 \n",
      "(epoch: 125, iters: 780, time: 0.097, data: 0.001) G_GAN: 0.706 G_L1: 0.000 D_real: 0.705 D_fake: 0.687 \n",
      "(epoch: 125, iters: 880, time: 0.095, data: 0.001) G_GAN: 0.737 G_L1: 3.483 D_real: 0.508 D_fake: 0.471 \n",
      "(epoch: 125, iters: 980, time: 0.108, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.708 D_fake: 0.694 \n",
      "(epoch: 125, iters: 1080, time: 0.096, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.703 D_fake: 0.673 \n",
      "(epoch: 125, iters: 1180, time: 0.098, data: 0.001) G_GAN: 0.837 G_L1: 0.978 D_real: 0.655 D_fake: 0.667 \n",
      "(epoch: 125, iters: 1280, time: 0.099, data: 0.001) G_GAN: 0.904 G_L1: 0.000 D_real: 0.943 D_fake: 0.714 \n",
      "(epoch: 125, iters: 1380, time: 0.097, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.721 D_fake: 0.675 \n",
      "(epoch: 125, iters: 1480, time: 0.099, data: 0.001) G_GAN: 0.733 G_L1: 1.681 D_real: 0.560 D_fake: 0.573 \n",
      "(epoch: 125, iters: 1580, time: 0.098, data: 0.001) G_GAN: 0.721 G_L1: 0.000 D_real: 0.724 D_fake: 0.659 \n",
      "(epoch: 125, iters: 1680, time: 0.099, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.731 D_fake: 0.638 \n",
      "(epoch: 125, iters: 1780, time: 0.099, data: 0.002) G_GAN: 0.741 G_L1: 3.487 D_real: 0.508 D_fake: 0.664 \n",
      "(epoch: 125, iters: 1880, time: 0.099, data: 0.001) G_GAN: 0.758 G_L1: 0.000 D_real: 0.761 D_fake: 0.639 \n",
      "(epoch: 125, iters: 1980, time: 0.100, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.722 D_fake: 0.669 \n",
      "(epoch: 125, iters: 2080, time: 0.097, data: 0.001) G_GAN: 0.776 G_L1: 2.663 D_real: 0.545 D_fake: 0.638 \n",
      "(epoch: 125, iters: 2180, time: 0.099, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.713 D_fake: 0.659 \n",
      "(epoch: 125, iters: 2280, time: 0.096, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.710 D_fake: 0.684 \n",
      "saving the latest model (epoch 125, total_steps 285000)\n",
      "saving the model at the end of epoch 125, iters 285000\n",
      "End of epoch 125 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001485\n",
      "(epoch: 126, iters: 100, time: 0.104, data: 0.303) G_GAN: 0.854 G_L1: 2.739 D_real: 0.583 D_fake: 0.581 \n",
      "(epoch: 126, iters: 200, time: 0.095, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.740 D_fake: 0.644 \n",
      "(epoch: 126, iters: 300, time: 0.095, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.731 D_fake: 0.674 \n",
      "(epoch: 126, iters: 400, time: 0.108, data: 0.002) G_GAN: 0.799 G_L1: 1.900 D_real: 0.587 D_fake: 0.618 \n",
      "(epoch: 126, iters: 500, time: 0.110, data: 0.005) G_GAN: 0.719 G_L1: 0.000 D_real: 0.722 D_fake: 0.667 \n",
      "(epoch: 126, iters: 600, time: 0.100, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.706 D_fake: 0.683 \n",
      "(epoch: 126, iters: 700, time: 0.097, data: 0.002) G_GAN: 0.931 G_L1: 2.269 D_real: 0.639 D_fake: 0.640 \n",
      "(epoch: 126, iters: 800, time: 0.099, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.738 D_fake: 0.648 \n",
      "(epoch: 126, iters: 900, time: 0.093, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.752 D_fake: 0.707 \n",
      "(epoch: 126, iters: 1000, time: 0.108, data: 0.002) G_GAN: 0.846 G_L1: 2.064 D_real: 0.583 D_fake: 0.680 \n",
      "(epoch: 126, iters: 1100, time: 0.098, data: 0.001) G_GAN: 0.773 G_L1: 0.000 D_real: 0.776 D_fake: 0.623 \n",
      "(epoch: 126, iters: 1200, time: 0.095, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.736 D_fake: 0.654 \n",
      "(epoch: 126, iters: 1300, time: 0.095, data: 0.001) G_GAN: 0.810 G_L1: 3.100 D_real: 0.559 D_fake: 0.661 \n",
      "(epoch: 126, iters: 1400, time: 0.097, data: 0.001) G_GAN: 0.790 G_L1: 0.000 D_real: 0.791 D_fake: 0.614 \n",
      "(epoch: 126, iters: 1500, time: 0.108, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.730 D_fake: 0.664 \n",
      "(epoch: 126, iters: 1600, time: 0.096, data: 0.001) G_GAN: 0.764 G_L1: 1.704 D_real: 0.573 D_fake: 0.643 \n",
      "(epoch: 126, iters: 1700, time: 0.112, data: 0.001) G_GAN: 0.771 G_L1: 0.000 D_real: 0.776 D_fake: 0.624 \n",
      "(epoch: 126, iters: 1800, time: 0.094, data: 0.001) G_GAN: 0.706 G_L1: 0.000 D_real: 0.708 D_fake: 0.662 \n",
      "(epoch: 126, iters: 1900, time: 0.097, data: 0.002) G_GAN: 0.818 G_L1: 4.005 D_real: 0.534 D_fake: 0.603 \n",
      "(epoch: 126, iters: 2000, time: 0.097, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.767 D_fake: 0.610 \n",
      "(epoch: 126, iters: 2100, time: 0.093, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.731 D_fake: 0.668 \n",
      "(epoch: 126, iters: 2200, time: 0.097, data: 0.001) G_GAN: 0.774 G_L1: 1.935 D_real: 0.557 D_fake: 0.561 \n",
      "End of epoch 126 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001465\n",
      "(epoch: 127, iters: 20, time: 0.105, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.758 D_fake: 0.641 \n",
      "(epoch: 127, iters: 120, time: 0.098, data: 0.002) G_GAN: 0.674 G_L1: 0.000 D_real: 0.681 D_fake: 0.641 \n",
      "(epoch: 127, iters: 220, time: 0.100, data: 0.001) G_GAN: 0.798 G_L1: 3.205 D_real: 0.549 D_fake: 0.620 \n",
      "(epoch: 127, iters: 320, time: 0.098, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.761 D_fake: 0.640 \n",
      "(epoch: 127, iters: 420, time: 0.098, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.742 D_fake: 0.652 \n",
      "(epoch: 127, iters: 520, time: 0.096, data: 0.002) G_GAN: 0.820 G_L1: 1.603 D_real: 0.604 D_fake: 0.645 \n",
      "(epoch: 127, iters: 620, time: 0.099, data: 0.002) G_GAN: 0.794 G_L1: 0.000 D_real: 0.800 D_fake: 0.606 \n",
      "(epoch: 127, iters: 720, time: 0.097, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.699 D_fake: 0.700 \n",
      "(epoch: 127, iters: 820, time: 0.100, data: 0.002) G_GAN: 0.826 G_L1: 2.187 D_real: 0.584 D_fake: 0.596 \n",
      "(epoch: 127, iters: 920, time: 0.097, data: 0.001) G_GAN: 0.666 G_L1: 0.000 D_real: 0.666 D_fake: 0.725 \n",
      "(epoch: 127, iters: 1020, time: 0.100, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.729 D_fake: 0.665 \n",
      "(epoch: 127, iters: 1120, time: 0.099, data: 0.002) G_GAN: 0.794 G_L1: 1.002 D_real: 0.639 D_fake: 0.610 \n",
      "(epoch: 127, iters: 1220, time: 0.099, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.688 D_fake: 0.700 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 127, iters: 1320, time: 0.110, data: 0.001) G_GAN: 0.699 G_L1: 0.000 D_real: 0.699 D_fake: 0.693 \n",
      "(epoch: 127, iters: 1420, time: 0.100, data: 0.002) G_GAN: 0.771 G_L1: 2.201 D_real: 0.551 D_fake: 0.644 \n",
      "(epoch: 127, iters: 1520, time: 0.104, data: 0.001) G_GAN: 0.743 G_L1: 0.000 D_real: 0.745 D_fake: 0.656 \n",
      "(epoch: 127, iters: 1620, time: 0.095, data: 0.001) G_GAN: 0.777 G_L1: 0.000 D_real: 0.787 D_fake: 0.611 \n",
      "(epoch: 127, iters: 1720, time: 0.099, data: 0.002) G_GAN: 0.767 G_L1: 3.384 D_real: 0.528 D_fake: 0.637 \n",
      "(epoch: 127, iters: 1820, time: 0.108, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.773 D_fake: 0.627 \n",
      "(epoch: 127, iters: 1920, time: 0.098, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.751 D_fake: 0.653 \n",
      "(epoch: 127, iters: 2020, time: 0.098, data: 0.003) G_GAN: 0.771 G_L1: 1.903 D_real: 0.579 D_fake: 0.633 \n",
      "(epoch: 127, iters: 2120, time: 0.098, data: 0.001) G_GAN: 0.778 G_L1: 0.000 D_real: 0.781 D_fake: 0.621 \n",
      "(epoch: 127, iters: 2220, time: 0.098, data: 0.001) G_GAN: 0.685 G_L1: 0.000 D_real: 0.686 D_fake: 0.710 \n",
      "End of epoch 127 / 200 \t Time Taken: 122 sec\n",
      "learning rate = 0.0001446\n",
      "(epoch: 128, iters: 40, time: 0.107, data: 0.001) G_GAN: 0.775 G_L1: 1.545 D_real: 0.573 D_fake: 0.635 \n",
      "(epoch: 128, iters: 140, time: 0.097, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.740 D_fake: 0.650 \n",
      "(epoch: 128, iters: 240, time: 0.096, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.740 D_fake: 0.654 \n",
      "(epoch: 128, iters: 340, time: 0.097, data: 0.001) G_GAN: 0.752 G_L1: 0.576 D_real: 0.615 D_fake: 0.648 \n",
      "(epoch: 128, iters: 440, time: 0.097, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.755 D_fake: 0.643 \n",
      "saving the latest model (epoch 128, total_steps 290000)\n",
      "(epoch: 128, iters: 540, time: 0.095, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.728 D_fake: 0.663 \n",
      "(epoch: 128, iters: 640, time: 0.099, data: 0.002) G_GAN: 0.783 G_L1: 3.338 D_real: 0.544 D_fake: 0.648 \n",
      "(epoch: 128, iters: 740, time: 0.094, data: 0.002) G_GAN: 0.781 G_L1: 0.000 D_real: 0.794 D_fake: 0.611 \n",
      "(epoch: 128, iters: 840, time: 0.095, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.706 D_fake: 0.683 \n",
      "(epoch: 128, iters: 940, time: 0.098, data: 0.001) G_GAN: 0.783 G_L1: 1.224 D_real: 0.614 D_fake: 0.632 \n",
      "(epoch: 128, iters: 1040, time: 0.105, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.759 D_fake: 0.623 \n",
      "(epoch: 128, iters: 1140, time: 0.100, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.729 D_fake: 0.655 \n",
      "(epoch: 128, iters: 1240, time: 0.109, data: 0.002) G_GAN: 0.969 G_L1: 2.557 D_real: 0.661 D_fake: 0.511 \n",
      "(epoch: 128, iters: 1340, time: 0.099, data: 0.002) G_GAN: 0.904 G_L1: 0.000 D_real: 0.928 D_fake: 0.514 \n",
      "(epoch: 128, iters: 1440, time: 0.098, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.691 D_fake: 0.718 \n",
      "(epoch: 128, iters: 1540, time: 0.096, data: 0.002) G_GAN: 0.781 G_L1: 1.958 D_real: 0.567 D_fake: 0.655 \n",
      "(epoch: 128, iters: 1640, time: 0.098, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.734 D_fake: 0.657 \n",
      "(epoch: 128, iters: 1740, time: 0.098, data: 0.003) G_GAN: 0.756 G_L1: 0.000 D_real: 0.757 D_fake: 0.640 \n",
      "(epoch: 128, iters: 1840, time: 0.097, data: 0.001) G_GAN: 0.765 G_L1: 0.311 D_real: 0.638 D_fake: 0.644 \n",
      "(epoch: 128, iters: 1940, time: 0.108, data: 0.001) G_GAN: 0.764 G_L1: 0.000 D_real: 0.770 D_fake: 0.625 \n",
      "(epoch: 128, iters: 2040, time: 0.099, data: 0.001) G_GAN: 0.704 G_L1: 0.000 D_real: 0.705 D_fake: 0.684 \n",
      "(epoch: 128, iters: 2140, time: 0.106, data: 0.001) G_GAN: 0.859 G_L1: 0.787 D_real: 0.673 D_fake: 0.565 \n",
      "(epoch: 128, iters: 2240, time: 0.096, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.701 D_fake: 0.667 \n",
      "End of epoch 128 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001426\n",
      "(epoch: 129, iters: 60, time: 0.118, data: 0.001) G_GAN: 0.706 G_L1: 0.000 D_real: 0.706 D_fake: 0.687 \n",
      "(epoch: 129, iters: 160, time: 0.098, data: 0.002) G_GAN: 0.757 G_L1: 3.185 D_real: 0.507 D_fake: 0.669 \n",
      "(epoch: 129, iters: 260, time: 0.098, data: 0.002) G_GAN: 0.859 G_L1: 0.000 D_real: 0.888 D_fake: 0.552 \n",
      "(epoch: 129, iters: 360, time: 0.097, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.726 D_fake: 0.665 \n",
      "(epoch: 129, iters: 460, time: 0.100, data: 0.002) G_GAN: 0.866 G_L1: 2.593 D_real: 0.601 D_fake: 0.662 \n",
      "(epoch: 129, iters: 560, time: 0.098, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.753 D_fake: 0.644 \n",
      "(epoch: 129, iters: 660, time: 0.099, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.734 D_fake: 0.645 \n",
      "(epoch: 129, iters: 760, time: 0.098, data: 0.002) G_GAN: 0.793 G_L1: 2.399 D_real: 0.572 D_fake: 0.620 \n",
      "(epoch: 129, iters: 860, time: 0.103, data: 0.001) G_GAN: 0.786 G_L1: 0.000 D_real: 0.788 D_fake: 0.622 \n",
      "(epoch: 129, iters: 960, time: 0.094, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.604 D_fake: 0.859 \n",
      "(epoch: 129, iters: 1060, time: 0.095, data: 0.001) G_GAN: 0.723 G_L1: 0.087 D_real: 0.624 D_fake: 0.682 \n",
      "(epoch: 129, iters: 1160, time: 0.094, data: 0.002) G_GAN: 0.770 G_L1: 0.000 D_real: 0.775 D_fake: 0.630 \n",
      "(epoch: 129, iters: 1260, time: 0.103, data: 0.002) G_GAN: 0.769 G_L1: 0.000 D_real: 0.773 D_fake: 0.647 \n",
      "(epoch: 129, iters: 1360, time: 0.097, data: 0.001) G_GAN: 0.771 G_L1: 4.502 D_real: 0.516 D_fake: 0.635 \n",
      "(epoch: 129, iters: 1460, time: 0.097, data: 0.002) G_GAN: 0.817 G_L1: 0.000 D_real: 0.838 D_fake: 0.604 \n",
      "(epoch: 129, iters: 1560, time: 0.098, data: 0.001) G_GAN: 0.682 G_L1: 0.000 D_real: 0.683 D_fake: 0.693 \n",
      "(epoch: 129, iters: 1660, time: 0.096, data: 0.001) G_GAN: 0.779 G_L1: 1.973 D_real: 0.573 D_fake: 0.627 \n",
      "(epoch: 129, iters: 1760, time: 0.096, data: 0.001) G_GAN: 0.802 G_L1: 0.000 D_real: 0.824 D_fake: 0.644 \n",
      "(epoch: 129, iters: 1860, time: 0.097, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.726 D_fake: 0.630 \n",
      "(epoch: 129, iters: 1960, time: 0.097, data: 0.001) G_GAN: 0.744 G_L1: 0.417 D_real: 0.629 D_fake: 0.677 \n",
      "(epoch: 129, iters: 2060, time: 0.094, data: 0.001) G_GAN: 0.758 G_L1: 0.000 D_real: 0.760 D_fake: 0.639 \n",
      "(epoch: 129, iters: 2160, time: 0.096, data: 0.001) G_GAN: 0.684 G_L1: 0.000 D_real: 0.685 D_fake: 0.706 \n",
      "(epoch: 129, iters: 2260, time: 0.094, data: 0.001) G_GAN: 0.905 G_L1: 3.017 D_real: 0.621 D_fake: 0.539 \n",
      "End of epoch 129 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001406\n",
      "(epoch: 130, iters: 80, time: 0.106, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.713 D_fake: 0.633 \n",
      "(epoch: 130, iters: 180, time: 0.099, data: 0.002) G_GAN: 0.672 G_L1: 0.000 D_real: 0.675 D_fake: 0.714 \n",
      "(epoch: 130, iters: 280, time: 0.111, data: 0.002) G_GAN: 0.741 G_L1: 1.052 D_real: 0.569 D_fake: 0.665 \n",
      "(epoch: 130, iters: 380, time: 0.097, data: 0.001) G_GAN: 0.760 G_L1: 0.000 D_real: 0.766 D_fake: 0.695 \n",
      "(epoch: 130, iters: 480, time: 0.099, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.688 D_fake: 0.700 \n",
      "(epoch: 130, iters: 580, time: 0.099, data: 0.002) G_GAN: 0.824 G_L1: 4.208 D_real: 0.540 D_fake: 0.642 \n",
      "(epoch: 130, iters: 680, time: 0.097, data: 0.001) G_GAN: 0.733 G_L1: 0.000 D_real: 0.735 D_fake: 0.660 \n",
      "(epoch: 130, iters: 780, time: 0.096, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.719 D_fake: 0.674 \n",
      "(epoch: 130, iters: 880, time: 0.095, data: 0.001) G_GAN: 0.760 G_L1: 3.483 D_real: 0.527 D_fake: 0.649 \n",
      "saving the latest model (epoch 130, total_steps 295000)\n",
      "(epoch: 130, iters: 980, time: 0.098, data: 0.001) G_GAN: 0.704 G_L1: 0.000 D_real: 0.702 D_fake: 0.709 \n",
      "(epoch: 130, iters: 1080, time: 0.106, data: 0.002) G_GAN: 0.674 G_L1: 0.000 D_real: 0.678 D_fake: 0.691 \n",
      "(epoch: 130, iters: 1180, time: 0.098, data: 0.001) G_GAN: 0.774 G_L1: 0.978 D_real: 0.609 D_fake: 0.648 \n",
      "(epoch: 130, iters: 1280, time: 0.098, data: 0.002) G_GAN: 0.843 G_L1: 0.000 D_real: 0.873 D_fake: 0.658 \n",
      "(epoch: 130, iters: 1380, time: 0.093, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.731 D_fake: 0.648 \n",
      "(epoch: 130, iters: 1480, time: 0.098, data: 0.003) G_GAN: 0.756 G_L1: 1.681 D_real: 0.559 D_fake: 0.692 \n",
      "(epoch: 130, iters: 1580, time: 0.097, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.750 D_fake: 0.643 \n",
      "(epoch: 130, iters: 1680, time: 0.099, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.763 D_fake: 0.633 \n",
      "(epoch: 130, iters: 1780, time: 0.096, data: 0.001) G_GAN: 0.760 G_L1: 3.487 D_real: 0.532 D_fake: 0.643 \n",
      "(epoch: 130, iters: 1880, time: 0.099, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.757 D_fake: 0.644 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 130, iters: 1980, time: 0.100, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.735 D_fake: 0.657 \n",
      "(epoch: 130, iters: 2080, time: 0.097, data: 0.002) G_GAN: 0.737 G_L1: 2.663 D_real: 0.515 D_fake: 0.674 \n",
      "(epoch: 130, iters: 2180, time: 0.096, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.709 D_fake: 0.679 \n",
      "(epoch: 130, iters: 2280, time: 0.108, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.720 D_fake: 0.677 \n",
      "saving the model at the end of epoch 130, iters 296400\n",
      "End of epoch 130 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001386\n",
      "(epoch: 131, iters: 100, time: 0.108, data: 0.278) G_GAN: 0.836 G_L1: 2.739 D_real: 0.560 D_fake: 0.600 \n",
      "(epoch: 131, iters: 200, time: 0.107, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.651 \n",
      "(epoch: 131, iters: 300, time: 0.098, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.718 D_fake: 0.618 \n",
      "(epoch: 131, iters: 400, time: 0.108, data: 0.002) G_GAN: 0.744 G_L1: 1.900 D_real: 0.523 D_fake: 0.676 \n",
      "(epoch: 131, iters: 500, time: 0.099, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.696 D_fake: 0.686 \n",
      "(epoch: 131, iters: 600, time: 0.105, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.761 D_fake: 0.633 \n",
      "(epoch: 131, iters: 700, time: 0.098, data: 0.002) G_GAN: 1.093 G_L1: 2.269 D_real: 0.789 D_fake: 0.689 \n",
      "(epoch: 131, iters: 800, time: 0.097, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.760 D_fake: 0.644 \n",
      "(epoch: 131, iters: 900, time: 0.094, data: 0.001) G_GAN: 0.712 G_L1: 0.000 D_real: 0.714 D_fake: 0.672 \n",
      "(epoch: 131, iters: 1000, time: 0.099, data: 0.002) G_GAN: 0.883 G_L1: 2.064 D_real: 0.627 D_fake: 0.566 \n",
      "(epoch: 131, iters: 1100, time: 0.098, data: 0.002) G_GAN: 0.783 G_L1: 0.000 D_real: 0.786 D_fake: 0.615 \n",
      "(epoch: 131, iters: 1200, time: 0.109, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.692 D_fake: 0.665 \n",
      "(epoch: 131, iters: 1300, time: 0.107, data: 0.001) G_GAN: 0.820 G_L1: 3.100 D_real: 0.559 D_fake: 0.656 \n",
      "(epoch: 131, iters: 1400, time: 0.106, data: 0.002) G_GAN: 0.780 G_L1: 0.000 D_real: 0.783 D_fake: 0.621 \n",
      "(epoch: 131, iters: 1500, time: 0.096, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.735 D_fake: 0.663 \n",
      "(epoch: 131, iters: 1600, time: 0.095, data: 0.001) G_GAN: 0.777 G_L1: 1.704 D_real: 0.592 D_fake: 0.637 \n",
      "(epoch: 131, iters: 1700, time: 0.099, data: 0.002) G_GAN: 0.793 G_L1: 0.000 D_real: 0.802 D_fake: 0.639 \n",
      "(epoch: 131, iters: 1800, time: 0.096, data: 0.001) G_GAN: 0.724 G_L1: 0.000 D_real: 0.725 D_fake: 0.664 \n",
      "(epoch: 131, iters: 1900, time: 0.099, data: 0.001) G_GAN: 0.817 G_L1: 4.005 D_real: 0.531 D_fake: 0.613 \n",
      "(epoch: 131, iters: 2000, time: 0.108, data: 0.001) G_GAN: 0.783 G_L1: 0.000 D_real: 0.788 D_fake: 0.615 \n",
      "(epoch: 131, iters: 2100, time: 0.095, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.687 D_fake: 0.706 \n",
      "(epoch: 131, iters: 2200, time: 0.110, data: 0.002) G_GAN: 0.775 G_L1: 1.935 D_real: 0.530 D_fake: 0.746 \n",
      "End of epoch 131 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001366\n",
      "(epoch: 132, iters: 20, time: 0.119, data: 0.001) G_GAN: 0.794 G_L1: 0.000 D_real: 0.805 D_fake: 0.604 \n",
      "(epoch: 132, iters: 120, time: 0.097, data: 0.002) G_GAN: 0.665 G_L1: 0.000 D_real: 0.665 D_fake: 0.724 \n",
      "(epoch: 132, iters: 220, time: 0.099, data: 0.002) G_GAN: 0.797 G_L1: 3.205 D_real: 0.548 D_fake: 0.550 \n",
      "(epoch: 132, iters: 320, time: 0.112, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.738 D_fake: 0.662 \n",
      "(epoch: 132, iters: 420, time: 0.108, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.708 D_fake: 0.680 \n",
      "(epoch: 132, iters: 520, time: 0.096, data: 0.002) G_GAN: 0.843 G_L1: 1.603 D_real: 0.636 D_fake: 0.649 \n",
      "(epoch: 132, iters: 620, time: 0.098, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.763 D_fake: 0.621 \n",
      "(epoch: 132, iters: 720, time: 0.099, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.694 D_fake: 0.693 \n",
      "(epoch: 132, iters: 820, time: 0.096, data: 0.002) G_GAN: 0.851 G_L1: 2.187 D_real: 0.610 D_fake: 0.581 \n",
      "(epoch: 132, iters: 920, time: 0.096, data: 0.001) G_GAN: 0.719 G_L1: 0.000 D_real: 0.720 D_fake: 0.672 \n",
      "(epoch: 132, iters: 1020, time: 0.099, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.698 D_fake: 0.695 \n",
      "(epoch: 132, iters: 1120, time: 0.099, data: 0.001) G_GAN: 0.795 G_L1: 1.002 D_real: 0.631 D_fake: 0.618 \n",
      "(epoch: 132, iters: 1220, time: 0.097, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.729 D_fake: 0.661 \n",
      "(epoch: 132, iters: 1320, time: 0.097, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.749 D_fake: 0.646 \n",
      "saving the latest model (epoch 132, total_steps 300000)\n",
      "(epoch: 132, iters: 1420, time: 0.098, data: 0.002) G_GAN: 0.776 G_L1: 2.201 D_real: 0.552 D_fake: 0.640 \n",
      "(epoch: 132, iters: 1520, time: 0.098, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.751 D_fake: 0.636 \n",
      "(epoch: 132, iters: 1620, time: 0.104, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.718 D_fake: 0.673 \n",
      "(epoch: 132, iters: 1720, time: 0.101, data: 0.002) G_GAN: 0.769 G_L1: 3.384 D_real: 0.520 D_fake: 0.673 \n",
      "(epoch: 132, iters: 1820, time: 0.110, data: 0.002) G_GAN: 0.772 G_L1: 0.000 D_real: 0.782 D_fake: 0.620 \n",
      "(epoch: 132, iters: 1920, time: 0.096, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.749 D_fake: 0.624 \n",
      "(epoch: 132, iters: 2020, time: 0.098, data: 0.001) G_GAN: 0.774 G_L1: 1.903 D_real: 0.571 D_fake: 0.635 \n",
      "(epoch: 132, iters: 2120, time: 0.109, data: 0.001) G_GAN: 0.771 G_L1: 0.000 D_real: 0.776 D_fake: 0.548 \n",
      "(epoch: 132, iters: 2220, time: 0.099, data: 0.001) G_GAN: 0.655 G_L1: 0.000 D_real: 0.651 D_fake: 0.749 \n",
      "End of epoch 132 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001347\n",
      "(epoch: 133, iters: 40, time: 0.116, data: 0.001) G_GAN: 0.777 G_L1: 1.545 D_real: 0.568 D_fake: 0.669 \n",
      "(epoch: 133, iters: 140, time: 0.096, data: 0.001) G_GAN: 0.711 G_L1: 0.000 D_real: 0.726 D_fake: 0.723 \n",
      "(epoch: 133, iters: 240, time: 0.096, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.720 D_fake: 0.673 \n",
      "(epoch: 133, iters: 340, time: 0.099, data: 0.002) G_GAN: 0.770 G_L1: 0.576 D_real: 0.629 D_fake: 0.622 \n",
      "(epoch: 133, iters: 440, time: 0.096, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.734 D_fake: 0.633 \n",
      "(epoch: 133, iters: 540, time: 0.096, data: 0.002) G_GAN: 0.678 G_L1: 0.000 D_real: 0.691 D_fake: 0.720 \n",
      "(epoch: 133, iters: 640, time: 0.098, data: 0.002) G_GAN: 0.946 G_L1: 3.338 D_real: 0.623 D_fake: 0.536 \n",
      "(epoch: 133, iters: 740, time: 0.095, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.737 D_fake: 0.657 \n",
      "(epoch: 133, iters: 840, time: 0.096, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.699 D_fake: 0.627 \n",
      "(epoch: 133, iters: 940, time: 0.097, data: 0.001) G_GAN: 0.825 G_L1: 1.224 D_real: 0.647 D_fake: 0.637 \n",
      "(epoch: 133, iters: 1040, time: 0.093, data: 0.001) G_GAN: 0.602 G_L1: 0.000 D_real: 0.669 D_fake: 0.678 \n",
      "(epoch: 133, iters: 1140, time: 0.107, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.723 D_fake: 0.669 \n",
      "(epoch: 133, iters: 1240, time: 0.095, data: 0.000) G_GAN: 0.823 G_L1: 2.557 D_real: 0.590 D_fake: 0.665 \n",
      "(epoch: 133, iters: 1340, time: 0.109, data: 0.002) G_GAN: 0.785 G_L1: 0.000 D_real: 0.790 D_fake: 0.683 \n",
      "(epoch: 133, iters: 1440, time: 0.101, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.714 D_fake: 0.682 \n",
      "(epoch: 133, iters: 1540, time: 0.099, data: 0.002) G_GAN: 0.789 G_L1: 1.958 D_real: 0.558 D_fake: 0.626 \n",
      "(epoch: 133, iters: 1640, time: 0.096, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.717 D_fake: 0.645 \n",
      "(epoch: 133, iters: 1740, time: 0.099, data: 0.001) G_GAN: 0.752 G_L1: 0.000 D_real: 0.754 D_fake: 0.644 \n",
      "(epoch: 133, iters: 1840, time: 0.102, data: 0.002) G_GAN: 0.759 G_L1: 0.311 D_real: 0.621 D_fake: 0.653 \n",
      "(epoch: 133, iters: 1940, time: 0.108, data: 0.002) G_GAN: 0.788 G_L1: 0.000 D_real: 0.795 D_fake: 0.607 \n",
      "(epoch: 133, iters: 2040, time: 0.098, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.700 D_fake: 0.676 \n",
      "(epoch: 133, iters: 2140, time: 0.098, data: 0.002) G_GAN: 0.873 G_L1: 0.787 D_real: 0.678 D_fake: 0.560 \n",
      "(epoch: 133, iters: 2240, time: 0.099, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.750 D_fake: 0.652 \n",
      "End of epoch 133 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001327\n",
      "(epoch: 134, iters: 60, time: 0.103, data: 0.002) G_GAN: 0.684 G_L1: 0.000 D_real: 0.683 D_fake: 0.710 \n",
      "(epoch: 134, iters: 160, time: 0.098, data: 0.002) G_GAN: 0.776 G_L1: 3.185 D_real: 0.518 D_fake: 0.649 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 134, iters: 260, time: 0.096, data: 0.002) G_GAN: 0.807 G_L1: 0.000 D_real: 0.817 D_fake: 0.598 \n",
      "(epoch: 134, iters: 360, time: 0.097, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.699 D_fake: 0.689 \n",
      "(epoch: 134, iters: 460, time: 0.098, data: 0.002) G_GAN: 0.823 G_L1: 2.593 D_real: 0.567 D_fake: 0.604 \n",
      "(epoch: 134, iters: 560, time: 0.096, data: 0.002) G_GAN: 0.768 G_L1: 0.000 D_real: 0.770 D_fake: 0.632 \n",
      "(epoch: 134, iters: 660, time: 0.098, data: 0.001) G_GAN: 0.712 G_L1: 0.000 D_real: 0.714 D_fake: 0.681 \n",
      "(epoch: 134, iters: 760, time: 0.098, data: 0.002) G_GAN: 0.725 G_L1: 2.399 D_real: 0.531 D_fake: 0.605 \n",
      "(epoch: 134, iters: 860, time: 0.095, data: 0.002) G_GAN: 0.797 G_L1: 0.000 D_real: 0.803 D_fake: 0.613 \n",
      "(epoch: 134, iters: 960, time: 0.095, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.709 D_fake: 0.649 \n",
      "(epoch: 134, iters: 1060, time: 0.104, data: 0.001) G_GAN: 0.726 G_L1: 0.087 D_real: 0.619 D_fake: 0.685 \n",
      "(epoch: 134, iters: 1160, time: 0.095, data: 0.000) G_GAN: 0.770 G_L1: 0.000 D_real: 0.784 D_fake: 0.605 \n",
      "(epoch: 134, iters: 1260, time: 0.098, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.747 D_fake: 0.668 \n",
      "(epoch: 134, iters: 1360, time: 0.094, data: 0.001) G_GAN: 0.763 G_L1: 4.502 D_real: 0.495 D_fake: 0.459 \n",
      "(epoch: 134, iters: 1460, time: 0.095, data: 0.002) G_GAN: 0.884 G_L1: 0.000 D_real: 0.912 D_fake: 0.643 \n",
      "(epoch: 134, iters: 1560, time: 0.095, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.700 D_fake: 0.667 \n",
      "(epoch: 134, iters: 1660, time: 0.096, data: 0.002) G_GAN: 0.816 G_L1: 1.973 D_real: 0.584 D_fake: 0.615 \n",
      "(epoch: 134, iters: 1760, time: 0.098, data: 0.001) G_GAN: 0.802 G_L1: 0.000 D_real: 0.814 D_fake: 0.592 \n",
      "saving the latest model (epoch 134, total_steps 305000)\n",
      "(epoch: 134, iters: 1860, time: 0.102, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.722 D_fake: 0.647 \n",
      "(epoch: 134, iters: 1960, time: 0.100, data: 0.002) G_GAN: 0.781 G_L1: 0.417 D_real: 0.665 D_fake: 0.626 \n",
      "(epoch: 134, iters: 2060, time: 0.096, data: 0.001) G_GAN: 0.772 G_L1: 0.000 D_real: 0.776 D_fake: 0.625 \n",
      "(epoch: 134, iters: 2160, time: 0.102, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.714 D_fake: 0.635 \n",
      "(epoch: 134, iters: 2260, time: 0.104, data: 0.001) G_GAN: 0.919 G_L1: 3.017 D_real: 0.612 D_fake: 0.540 \n",
      "End of epoch 134 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001307\n",
      "(epoch: 135, iters: 80, time: 0.104, data: 0.001) G_GAN: 0.764 G_L1: 0.000 D_real: 0.775 D_fake: 0.610 \n",
      "(epoch: 135, iters: 180, time: 0.098, data: 0.001) G_GAN: 0.681 G_L1: 0.000 D_real: 0.683 D_fake: 0.705 \n",
      "(epoch: 135, iters: 280, time: 0.101, data: 0.002) G_GAN: 0.801 G_L1: 1.052 D_real: 0.621 D_fake: 0.615 \n",
      "(epoch: 135, iters: 380, time: 0.099, data: 0.001) G_GAN: 0.776 G_L1: 0.000 D_real: 0.784 D_fake: 0.658 \n",
      "(epoch: 135, iters: 480, time: 0.110, data: 0.002) G_GAN: 0.672 G_L1: 0.000 D_real: 0.676 D_fake: 0.681 \n",
      "(epoch: 135, iters: 580, time: 0.098, data: 0.002) G_GAN: 0.837 G_L1: 4.208 D_real: 0.545 D_fake: 0.661 \n",
      "(epoch: 135, iters: 680, time: 0.096, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.753 D_fake: 0.645 \n",
      "(epoch: 135, iters: 780, time: 0.095, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.700 D_fake: 0.557 \n",
      "(epoch: 135, iters: 880, time: 0.093, data: 0.002) G_GAN: 0.785 G_L1: 3.483 D_real: 0.513 D_fake: 0.595 \n",
      "(epoch: 135, iters: 980, time: 0.095, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.728 D_fake: 0.678 \n",
      "(epoch: 135, iters: 1080, time: 0.106, data: 0.000) G_GAN: 0.685 G_L1: 0.000 D_real: 0.689 D_fake: 0.696 \n",
      "(epoch: 135, iters: 1180, time: 0.109, data: 0.001) G_GAN: 0.768 G_L1: 0.978 D_real: 0.601 D_fake: 0.640 \n",
      "(epoch: 135, iters: 1280, time: 0.099, data: 0.002) G_GAN: 0.812 G_L1: 0.000 D_real: 0.862 D_fake: 0.682 \n",
      "(epoch: 135, iters: 1380, time: 0.098, data: 0.002) G_GAN: 0.678 G_L1: 0.000 D_real: 0.677 D_fake: 0.716 \n",
      "(epoch: 135, iters: 1480, time: 0.099, data: 0.002) G_GAN: 0.730 G_L1: 1.681 D_real: 0.554 D_fake: 0.588 \n",
      "(epoch: 135, iters: 1580, time: 0.096, data: 0.001) G_GAN: 0.711 G_L1: 0.000 D_real: 0.714 D_fake: 0.654 \n",
      "(epoch: 135, iters: 1680, time: 0.099, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.732 D_fake: 0.660 \n",
      "(epoch: 135, iters: 1780, time: 0.108, data: 0.001) G_GAN: 0.756 G_L1: 3.487 D_real: 0.522 D_fake: 0.654 \n",
      "(epoch: 135, iters: 1880, time: 0.097, data: 0.001) G_GAN: 0.756 G_L1: 0.000 D_real: 0.762 D_fake: 0.642 \n",
      "(epoch: 135, iters: 1980, time: 0.106, data: 0.001) G_GAN: 0.715 G_L1: 0.000 D_real: 0.717 D_fake: 0.659 \n",
      "(epoch: 135, iters: 2080, time: 0.096, data: 0.001) G_GAN: 0.791 G_L1: 2.663 D_real: 0.537 D_fake: 0.638 \n",
      "(epoch: 135, iters: 2180, time: 0.098, data: 0.001) G_GAN: 0.660 G_L1: 0.000 D_real: 0.668 D_fake: 0.595 \n",
      "(epoch: 135, iters: 2280, time: 0.097, data: 0.001) G_GAN: 0.704 G_L1: 0.000 D_real: 0.704 D_fake: 0.626 \n",
      "saving the model at the end of epoch 135, iters 307800\n",
      "End of epoch 135 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0001287\n",
      "(epoch: 136, iters: 100, time: 0.107, data: 0.285) G_GAN: 0.834 G_L1: 2.739 D_real: 0.558 D_fake: 0.622 \n",
      "(epoch: 136, iters: 200, time: 0.094, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.746 D_fake: 0.638 \n",
      "(epoch: 136, iters: 300, time: 0.109, data: 0.001) G_GAN: 0.711 G_L1: 0.000 D_real: 0.715 D_fake: 0.648 \n",
      "(epoch: 136, iters: 400, time: 0.098, data: 0.001) G_GAN: 0.753 G_L1: 1.900 D_real: 0.536 D_fake: 0.666 \n",
      "(epoch: 136, iters: 500, time: 0.100, data: 0.002) G_GAN: 0.673 G_L1: 0.000 D_real: 0.673 D_fake: 0.715 \n",
      "(epoch: 136, iters: 600, time: 0.100, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.721 D_fake: 0.609 \n",
      "(epoch: 136, iters: 700, time: 0.097, data: 0.002) G_GAN: 0.983 G_L1: 2.269 D_real: 0.642 D_fake: 0.503 \n",
      "(epoch: 136, iters: 800, time: 0.100, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.750 D_fake: 0.657 \n",
      "(epoch: 136, iters: 900, time: 0.092, data: 0.002) G_GAN: 0.686 G_L1: 0.000 D_real: 0.690 D_fake: 0.501 \n",
      "(epoch: 136, iters: 1000, time: 0.111, data: 0.002) G_GAN: 0.855 G_L1: 2.064 D_real: 0.583 D_fake: 0.595 \n",
      "(epoch: 136, iters: 1100, time: 0.098, data: 0.002) G_GAN: 0.771 G_L1: 0.000 D_real: 0.775 D_fake: 0.604 \n",
      "(epoch: 136, iters: 1200, time: 0.093, data: 0.002) G_GAN: 0.665 G_L1: 0.000 D_real: 0.667 D_fake: 0.722 \n",
      "(epoch: 136, iters: 1300, time: 0.111, data: 0.002) G_GAN: 0.790 G_L1: 3.100 D_real: 0.524 D_fake: 0.637 \n",
      "(epoch: 136, iters: 1400, time: 0.100, data: 0.002) G_GAN: 0.805 G_L1: 0.000 D_real: 0.812 D_fake: 0.606 \n",
      "(epoch: 136, iters: 1500, time: 0.098, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.699 D_fake: 0.696 \n",
      "(epoch: 136, iters: 1600, time: 0.098, data: 0.002) G_GAN: 0.803 G_L1: 1.704 D_real: 0.607 D_fake: 0.642 \n",
      "(epoch: 136, iters: 1700, time: 0.100, data: 0.002) G_GAN: 0.762 G_L1: 0.000 D_real: 0.766 D_fake: 0.633 \n",
      "(epoch: 136, iters: 1800, time: 0.095, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.701 D_fake: 0.690 \n",
      "(epoch: 136, iters: 1900, time: 0.098, data: 0.001) G_GAN: 0.779 G_L1: 4.005 D_real: 0.505 D_fake: 0.643 \n",
      "(epoch: 136, iters: 2000, time: 0.111, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.752 D_fake: 0.579 \n",
      "(epoch: 136, iters: 2100, time: 0.105, data: 0.001) G_GAN: 0.639 G_L1: 0.000 D_real: 0.648 D_fake: 0.514 \n",
      "(epoch: 136, iters: 2200, time: 0.110, data: 0.001) G_GAN: 0.745 G_L1: 1.935 D_real: 0.532 D_fake: 0.456 \n",
      "saving the latest model (epoch 136, total_steps 310000)\n",
      "End of epoch 136 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001267\n",
      "(epoch: 137, iters: 20, time: 0.107, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.764 D_fake: 0.655 \n",
      "(epoch: 137, iters: 120, time: 0.097, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.687 D_fake: 0.702 \n",
      "(epoch: 137, iters: 220, time: 0.106, data: 0.002) G_GAN: 0.785 G_L1: 3.205 D_real: 0.530 D_fake: 0.566 \n",
      "(epoch: 137, iters: 320, time: 0.099, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.732 D_fake: 0.667 \n",
      "(epoch: 137, iters: 420, time: 0.096, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.688 D_fake: 0.658 \n",
      "(epoch: 137, iters: 520, time: 0.108, data: 0.001) G_GAN: 0.912 G_L1: 1.603 D_real: 0.663 D_fake: 0.543 \n",
      "(epoch: 137, iters: 620, time: 0.097, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.751 D_fake: 0.567 \n",
      "(epoch: 137, iters: 720, time: 0.097, data: 0.001) G_GAN: 0.663 G_L1: 0.000 D_real: 0.666 D_fake: 0.697 \n",
      "(epoch: 137, iters: 820, time: 0.109, data: 0.002) G_GAN: 0.845 G_L1: 2.187 D_real: 0.609 D_fake: 0.703 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 137, iters: 920, time: 0.107, data: 0.002) G_GAN: 0.678 G_L1: 0.000 D_real: 0.684 D_fake: 0.375 \n",
      "(epoch: 137, iters: 1020, time: 0.109, data: 0.001) G_GAN: 0.647 G_L1: 0.000 D_real: 0.648 D_fake: 0.686 \n",
      "(epoch: 137, iters: 1120, time: 0.098, data: 0.002) G_GAN: 0.812 G_L1: 1.002 D_real: 0.644 D_fake: 0.603 \n",
      "(epoch: 137, iters: 1220, time: 0.110, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.682 D_fake: 0.706 \n",
      "(epoch: 137, iters: 1320, time: 0.099, data: 0.001) G_GAN: 0.704 G_L1: 0.000 D_real: 0.705 D_fake: 0.659 \n",
      "(epoch: 137, iters: 1420, time: 0.110, data: 0.001) G_GAN: 0.851 G_L1: 2.201 D_real: 0.581 D_fake: 0.594 \n",
      "(epoch: 137, iters: 1520, time: 0.099, data: 0.001) G_GAN: 0.709 G_L1: 0.000 D_real: 0.712 D_fake: 0.661 \n",
      "(epoch: 137, iters: 1620, time: 0.104, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.739 D_fake: 0.662 \n",
      "(epoch: 137, iters: 1720, time: 0.097, data: 0.001) G_GAN: 0.776 G_L1: 3.384 D_real: 0.524 D_fake: 0.642 \n",
      "(epoch: 137, iters: 1820, time: 0.097, data: 0.002) G_GAN: 0.773 G_L1: 0.000 D_real: 0.781 D_fake: 0.620 \n",
      "(epoch: 137, iters: 1920, time: 0.098, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.742 D_fake: 0.647 \n",
      "(epoch: 137, iters: 2020, time: 0.112, data: 0.001) G_GAN: 0.773 G_L1: 1.903 D_real: 0.567 D_fake: 0.648 \n",
      "(epoch: 137, iters: 2120, time: 0.111, data: 0.001) G_GAN: 0.764 G_L1: 0.000 D_real: 0.767 D_fake: 0.634 \n",
      "(epoch: 137, iters: 2220, time: 0.111, data: 0.003) G_GAN: 0.709 G_L1: 0.000 D_real: 0.715 D_fake: 0.590 \n",
      "End of epoch 137 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001248\n",
      "(epoch: 138, iters: 40, time: 0.120, data: 0.001) G_GAN: 0.781 G_L1: 1.545 D_real: 0.574 D_fake: 0.704 \n",
      "(epoch: 138, iters: 140, time: 0.096, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.711 D_fake: 0.644 \n",
      "(epoch: 138, iters: 240, time: 0.097, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.698 D_fake: 0.674 \n",
      "(epoch: 138, iters: 340, time: 0.108, data: 0.001) G_GAN: 0.736 G_L1: 0.576 D_real: 0.603 D_fake: 0.684 \n",
      "(epoch: 138, iters: 440, time: 0.106, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.750 D_fake: 0.649 \n",
      "(epoch: 138, iters: 540, time: 0.096, data: 0.002) G_GAN: 0.603 G_L1: 0.000 D_real: 0.590 D_fake: 0.816 \n",
      "(epoch: 138, iters: 640, time: 0.097, data: 0.002) G_GAN: 0.830 G_L1: 3.338 D_real: 0.547 D_fake: 0.614 \n",
      "(epoch: 138, iters: 740, time: 0.096, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.735 D_fake: 0.566 \n",
      "(epoch: 138, iters: 840, time: 0.102, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.692 D_fake: 0.650 \n",
      "(epoch: 138, iters: 940, time: 0.100, data: 0.002) G_GAN: 0.790 G_L1: 1.224 D_real: 0.616 D_fake: 0.623 \n",
      "(epoch: 138, iters: 1040, time: 0.095, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.734 D_fake: 0.671 \n",
      "(epoch: 138, iters: 1140, time: 0.097, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.723 D_fake: 0.666 \n",
      "(epoch: 138, iters: 1240, time: 0.096, data: 0.002) G_GAN: 0.907 G_L1: 2.557 D_real: 0.613 D_fake: 0.547 \n",
      "(epoch: 138, iters: 1340, time: 0.099, data: 0.002) G_GAN: 0.812 G_L1: 0.000 D_real: 0.820 D_fake: 0.517 \n",
      "(epoch: 138, iters: 1440, time: 0.098, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.719 D_fake: 0.680 \n",
      "(epoch: 138, iters: 1540, time: 0.099, data: 0.001) G_GAN: 0.858 G_L1: 1.958 D_real: 0.603 D_fake: 0.577 \n",
      "(epoch: 138, iters: 1640, time: 0.097, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.749 D_fake: 0.645 \n",
      "(epoch: 138, iters: 1740, time: 0.099, data: 0.001) G_GAN: 0.755 G_L1: 0.000 D_real: 0.757 D_fake: 0.510 \n",
      "(epoch: 138, iters: 1840, time: 0.108, data: 0.003) G_GAN: 0.764 G_L1: 0.311 D_real: 0.631 D_fake: 0.636 \n",
      "(epoch: 138, iters: 1940, time: 0.098, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.740 D_fake: 0.674 \n",
      "(epoch: 138, iters: 2040, time: 0.098, data: 0.001) G_GAN: 0.702 G_L1: 0.000 D_real: 0.712 D_fake: 0.655 \n",
      "(epoch: 138, iters: 2140, time: 0.114, data: 0.001) G_GAN: 0.889 G_L1: 0.787 D_real: 0.704 D_fake: 0.704 \n",
      "(epoch: 138, iters: 2240, time: 0.097, data: 0.001) G_GAN: 0.684 G_L1: 0.000 D_real: 0.683 D_fake: 0.690 \n",
      "End of epoch 138 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001228\n",
      "(epoch: 139, iters: 60, time: 0.105, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.690 D_fake: 0.711 \n",
      "(epoch: 139, iters: 160, time: 0.097, data: 0.002) G_GAN: 0.813 G_L1: 3.185 D_real: 0.544 D_fake: 0.614 \n",
      "(epoch: 139, iters: 260, time: 0.097, data: 0.002) G_GAN: 0.820 G_L1: 0.000 D_real: 0.843 D_fake: 0.579 \n",
      "(epoch: 139, iters: 360, time: 0.106, data: 0.001) G_GAN: 0.720 G_L1: 0.000 D_real: 0.724 D_fake: 0.678 \n",
      "saving the latest model (epoch 139, total_steps 315000)\n",
      "(epoch: 139, iters: 460, time: 0.113, data: 0.002) G_GAN: 0.829 G_L1: 2.593 D_real: 0.567 D_fake: 0.601 \n",
      "(epoch: 139, iters: 560, time: 0.108, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.763 D_fake: 0.498 \n",
      "(epoch: 139, iters: 660, time: 0.098, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.709 \n",
      "(epoch: 139, iters: 760, time: 0.105, data: 0.001) G_GAN: 0.801 G_L1: 2.399 D_real: 0.579 D_fake: 0.612 \n",
      "(epoch: 139, iters: 860, time: 0.092, data: 0.001) G_GAN: 0.763 G_L1: 0.000 D_real: 0.766 D_fake: 0.650 \n",
      "(epoch: 139, iters: 960, time: 0.095, data: 0.002) G_GAN: 0.656 G_L1: 0.000 D_real: 0.654 D_fake: 0.491 \n",
      "(epoch: 139, iters: 1060, time: 0.096, data: 0.002) G_GAN: 0.718 G_L1: 0.087 D_real: 0.623 D_fake: 0.691 \n",
      "(epoch: 139, iters: 1160, time: 0.096, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.763 D_fake: 0.645 \n",
      "(epoch: 139, iters: 1260, time: 0.099, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.746 D_fake: 0.670 \n",
      "(epoch: 139, iters: 1360, time: 0.107, data: 0.001) G_GAN: 0.779 G_L1: 4.502 D_real: 0.513 D_fake: 0.626 \n",
      "(epoch: 139, iters: 1460, time: 0.096, data: 0.001) G_GAN: 0.811 G_L1: 0.000 D_real: 0.834 D_fake: 0.645 \n",
      "(epoch: 139, iters: 1560, time: 0.097, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.702 D_fake: 0.665 \n",
      "(epoch: 139, iters: 1660, time: 0.099, data: 0.001) G_GAN: 0.832 G_L1: 1.973 D_real: 0.593 D_fake: 0.682 \n",
      "(epoch: 139, iters: 1760, time: 0.099, data: 0.002) G_GAN: 0.817 G_L1: 0.000 D_real: 0.837 D_fake: 0.623 \n",
      "(epoch: 139, iters: 1860, time: 0.098, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.712 D_fake: 0.680 \n",
      "(epoch: 139, iters: 1960, time: 0.100, data: 0.001) G_GAN: 0.797 G_L1: 0.417 D_real: 0.671 D_fake: 0.616 \n",
      "(epoch: 139, iters: 2060, time: 0.105, data: 0.002) G_GAN: 0.769 G_L1: 0.000 D_real: 0.772 D_fake: 0.630 \n",
      "(epoch: 139, iters: 2160, time: 0.096, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.696 D_fake: 0.645 \n",
      "(epoch: 139, iters: 2260, time: 0.096, data: 0.002) G_GAN: 0.943 G_L1: 3.017 D_real: 0.615 D_fake: 0.594 \n",
      "End of epoch 139 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001208\n",
      "(epoch: 140, iters: 80, time: 0.103, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.757 D_fake: 0.598 \n",
      "(epoch: 140, iters: 180, time: 0.100, data: 0.003) G_GAN: 0.685 G_L1: 0.000 D_real: 0.689 D_fake: 0.687 \n",
      "(epoch: 140, iters: 280, time: 0.097, data: 0.002) G_GAN: 0.757 G_L1: 1.052 D_real: 0.591 D_fake: 0.685 \n",
      "(epoch: 140, iters: 380, time: 0.097, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.745 D_fake: 0.651 \n",
      "(epoch: 140, iters: 480, time: 0.110, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.694 \n",
      "(epoch: 140, iters: 580, time: 0.113, data: 0.001) G_GAN: 0.825 G_L1: 4.208 D_real: 0.536 D_fake: 0.680 \n",
      "(epoch: 140, iters: 680, time: 0.110, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.744 D_fake: 0.655 \n",
      "(epoch: 140, iters: 780, time: 0.097, data: 0.001) G_GAN: 0.680 G_L1: 0.000 D_real: 0.681 D_fake: 0.714 \n",
      "(epoch: 140, iters: 880, time: 0.095, data: 0.002) G_GAN: 0.784 G_L1: 3.483 D_real: 0.516 D_fake: 0.643 \n",
      "(epoch: 140, iters: 980, time: 0.096, data: 0.002) G_GAN: 0.776 G_L1: 0.000 D_real: 0.780 D_fake: 0.634 \n",
      "(epoch: 140, iters: 1080, time: 0.105, data: 0.002) G_GAN: 0.628 G_L1: 0.000 D_real: 0.632 D_fake: 0.764 \n",
      "(epoch: 140, iters: 1180, time: 0.108, data: 0.002) G_GAN: 0.770 G_L1: 0.978 D_real: 0.602 D_fake: 0.620 \n",
      "(epoch: 140, iters: 1280, time: 0.114, data: 0.001) G_GAN: 0.907 G_L1: 0.000 D_real: 0.947 D_fake: 0.680 \n",
      "(epoch: 140, iters: 1380, time: 0.097, data: 0.001) G_GAN: 0.709 G_L1: 0.000 D_real: 0.707 D_fake: 0.689 \n",
      "(epoch: 140, iters: 1480, time: 0.097, data: 0.001) G_GAN: 0.808 G_L1: 1.681 D_real: 0.596 D_fake: 0.690 \n",
      "(epoch: 140, iters: 1580, time: 0.097, data: 0.001) G_GAN: 0.788 G_L1: 0.000 D_real: 0.795 D_fake: 0.605 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 140, iters: 1680, time: 0.112, data: 0.001) G_GAN: 0.744 G_L1: 0.000 D_real: 0.746 D_fake: 0.639 \n",
      "(epoch: 140, iters: 1780, time: 0.097, data: 0.002) G_GAN: 0.765 G_L1: 3.487 D_real: 0.529 D_fake: 0.645 \n",
      "(epoch: 140, iters: 1880, time: 0.098, data: 0.002) G_GAN: 0.776 G_L1: 0.000 D_real: 0.790 D_fake: 0.638 \n",
      "(epoch: 140, iters: 1980, time: 0.098, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.706 D_fake: 0.686 \n",
      "(epoch: 140, iters: 2080, time: 0.096, data: 0.001) G_GAN: 0.782 G_L1: 2.663 D_real: 0.521 D_fake: 0.664 \n",
      "(epoch: 140, iters: 2180, time: 0.110, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.708 D_fake: 0.682 \n",
      "(epoch: 140, iters: 2280, time: 0.096, data: 0.002) G_GAN: 0.669 G_L1: 0.000 D_real: 0.671 D_fake: 0.671 \n",
      "saving the model at the end of epoch 140, iters 319200\n",
      "End of epoch 140 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0001188\n",
      "(epoch: 141, iters: 100, time: 0.106, data: 0.277) G_GAN: 0.923 G_L1: 2.739 D_real: 0.632 D_fake: 0.541 \n",
      "(epoch: 141, iters: 200, time: 0.095, data: 0.001) G_GAN: 0.759 G_L1: 0.000 D_real: 0.762 D_fake: 0.641 \n",
      "(epoch: 141, iters: 300, time: 0.095, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.702 D_fake: 0.614 \n",
      "(epoch: 141, iters: 400, time: 0.109, data: 0.002) G_GAN: 0.793 G_L1: 1.900 D_real: 0.569 D_fake: 0.621 \n",
      "(epoch: 141, iters: 500, time: 0.101, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.693 D_fake: 0.601 \n",
      "(epoch: 141, iters: 600, time: 0.111, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.730 D_fake: 0.661 \n",
      "(epoch: 141, iters: 700, time: 0.097, data: 0.001) G_GAN: 0.911 G_L1: 2.269 D_real: 0.605 D_fake: 0.632 \n",
      "(epoch: 141, iters: 800, time: 0.099, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.754 D_fake: 0.653 \n",
      "saving the latest model (epoch 141, total_steps 320000)\n",
      "(epoch: 141, iters: 900, time: 0.091, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.696 D_fake: 0.709 \n",
      "(epoch: 141, iters: 1000, time: 0.098, data: 0.002) G_GAN: 0.856 G_L1: 2.064 D_real: 0.596 D_fake: 0.649 \n",
      "(epoch: 141, iters: 1100, time: 0.099, data: 0.001) G_GAN: 0.807 G_L1: 0.000 D_real: 0.813 D_fake: 0.595 \n",
      "(epoch: 141, iters: 1200, time: 0.098, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.711 D_fake: 0.658 \n",
      "(epoch: 141, iters: 1300, time: 0.098, data: 0.002) G_GAN: 0.836 G_L1: 3.100 D_real: 0.567 D_fake: 0.645 \n",
      "(epoch: 141, iters: 1400, time: 0.109, data: 0.001) G_GAN: 0.791 G_L1: 0.000 D_real: 0.795 D_fake: 0.632 \n",
      "(epoch: 141, iters: 1500, time: 0.096, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.735 D_fake: 0.662 \n",
      "(epoch: 141, iters: 1600, time: 0.097, data: 0.001) G_GAN: 0.813 G_L1: 1.704 D_real: 0.599 D_fake: 0.610 \n",
      "(epoch: 141, iters: 1700, time: 0.099, data: 0.001) G_GAN: 0.763 G_L1: 0.000 D_real: 0.769 D_fake: 0.632 \n",
      "(epoch: 141, iters: 1800, time: 0.096, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.703 D_fake: 0.687 \n",
      "(epoch: 141, iters: 1900, time: 0.111, data: 0.001) G_GAN: 0.827 G_L1: 4.005 D_real: 0.527 D_fake: 0.567 \n",
      "(epoch: 141, iters: 2000, time: 0.109, data: 0.001) G_GAN: 0.768 G_L1: 0.000 D_real: 0.779 D_fake: 0.660 \n",
      "(epoch: 141, iters: 2100, time: 0.096, data: 0.002) G_GAN: 0.619 G_L1: 0.000 D_real: 0.633 D_fake: 0.689 \n",
      "(epoch: 141, iters: 2200, time: 0.100, data: 0.002) G_GAN: 0.759 G_L1: 1.935 D_real: 0.531 D_fake: 0.691 \n",
      "End of epoch 141 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001168\n",
      "(epoch: 142, iters: 20, time: 0.116, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.743 D_fake: 0.671 \n",
      "(epoch: 142, iters: 120, time: 0.108, data: 0.001) G_GAN: 0.640 G_L1: 0.000 D_real: 0.647 D_fake: 0.706 \n",
      "(epoch: 142, iters: 220, time: 0.107, data: 0.002) G_GAN: 0.819 G_L1: 3.205 D_real: 0.534 D_fake: 0.631 \n",
      "(epoch: 142, iters: 320, time: 0.098, data: 0.002) G_GAN: 0.750 G_L1: 0.000 D_real: 0.756 D_fake: 0.650 \n",
      "(epoch: 142, iters: 420, time: 0.097, data: 0.001) G_GAN: 0.674 G_L1: 0.000 D_real: 0.681 D_fake: 0.699 \n",
      "(epoch: 142, iters: 520, time: 0.096, data: 0.002) G_GAN: 0.912 G_L1: 1.603 D_real: 0.668 D_fake: 0.731 \n",
      "(epoch: 142, iters: 620, time: 0.094, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.748 D_fake: 0.610 \n",
      "(epoch: 142, iters: 720, time: 0.109, data: 0.001) G_GAN: 0.677 G_L1: 0.000 D_real: 0.677 D_fake: 0.711 \n",
      "(epoch: 142, iters: 820, time: 0.095, data: 0.001) G_GAN: 0.808 G_L1: 2.187 D_real: 0.572 D_fake: 0.607 \n",
      "(epoch: 142, iters: 920, time: 0.095, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.769 D_fake: 0.621 \n",
      "(epoch: 142, iters: 1020, time: 0.107, data: 0.002) G_GAN: 0.669 G_L1: 0.000 D_real: 0.673 D_fake: 0.604 \n",
      "(epoch: 142, iters: 1120, time: 0.110, data: 0.002) G_GAN: 0.731 G_L1: 1.002 D_real: 0.571 D_fake: 0.690 \n",
      "(epoch: 142, iters: 1220, time: 0.096, data: 0.002) G_GAN: 0.678 G_L1: 0.000 D_real: 0.684 D_fake: 0.667 \n",
      "(epoch: 142, iters: 1320, time: 0.098, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.703 D_fake: 0.550 \n",
      "(epoch: 142, iters: 1420, time: 0.099, data: 0.002) G_GAN: 0.784 G_L1: 2.201 D_real: 0.537 D_fake: 0.645 \n",
      "(epoch: 142, iters: 1520, time: 0.108, data: 0.001) G_GAN: 0.743 G_L1: 0.000 D_real: 0.747 D_fake: 0.650 \n",
      "(epoch: 142, iters: 1620, time: 0.096, data: 0.001) G_GAN: 0.763 G_L1: 0.000 D_real: 0.767 D_fake: 0.628 \n",
      "(epoch: 142, iters: 1720, time: 0.099, data: 0.001) G_GAN: 0.796 G_L1: 3.384 D_real: 0.522 D_fake: 0.630 \n",
      "(epoch: 142, iters: 1820, time: 0.109, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.767 D_fake: 0.612 \n",
      "(epoch: 142, iters: 1920, time: 0.096, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.749 D_fake: 0.524 \n",
      "(epoch: 142, iters: 2020, time: 0.109, data: 0.002) G_GAN: 0.813 G_L1: 1.903 D_real: 0.607 D_fake: 0.604 \n",
      "(epoch: 142, iters: 2120, time: 0.097, data: 0.001) G_GAN: 0.829 G_L1: 0.000 D_real: 0.842 D_fake: 0.579 \n",
      "(epoch: 142, iters: 2220, time: 0.099, data: 0.002) G_GAN: 0.677 G_L1: 0.000 D_real: 0.677 D_fake: 0.682 \n",
      "End of epoch 142 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001149\n",
      "(epoch: 143, iters: 40, time: 0.106, data: 0.002) G_GAN: 0.776 G_L1: 1.545 D_real: 0.558 D_fake: 0.648 \n",
      "(epoch: 143, iters: 140, time: 0.098, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.772 D_fake: 0.481 \n",
      "(epoch: 143, iters: 240, time: 0.096, data: 0.001) G_GAN: 0.706 G_L1: 0.000 D_real: 0.713 D_fake: 0.528 \n",
      "(epoch: 143, iters: 340, time: 0.106, data: 0.001) G_GAN: 0.754 G_L1: 0.576 D_real: 0.611 D_fake: 0.663 \n",
      "(epoch: 143, iters: 440, time: 0.095, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.737 D_fake: 0.641 \n",
      "(epoch: 143, iters: 540, time: 0.095, data: 0.002) G_GAN: 0.675 G_L1: 0.000 D_real: 0.685 D_fake: 0.656 \n",
      "(epoch: 143, iters: 640, time: 0.098, data: 0.002) G_GAN: 0.787 G_L1: 3.338 D_real: 0.529 D_fake: 0.641 \n",
      "(epoch: 143, iters: 740, time: 0.094, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.728 D_fake: 0.588 \n",
      "(epoch: 143, iters: 840, time: 0.094, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.723 D_fake: 0.670 \n",
      "(epoch: 143, iters: 940, time: 0.101, data: 0.001) G_GAN: 0.832 G_L1: 1.224 D_real: 0.642 D_fake: 0.628 \n",
      "(epoch: 143, iters: 1040, time: 0.095, data: 0.002) G_GAN: 0.769 G_L1: 0.000 D_real: 0.785 D_fake: 0.677 \n",
      "(epoch: 143, iters: 1140, time: 0.097, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.740 D_fake: 0.651 \n",
      "(epoch: 143, iters: 1240, time: 0.106, data: 0.001) G_GAN: 0.925 G_L1: 2.557 D_real: 0.635 D_fake: 0.639 \n",
      "saving the latest model (epoch 143, total_steps 325000)\n",
      "(epoch: 143, iters: 1340, time: 0.110, data: 0.001) G_GAN: 0.810 G_L1: 0.000 D_real: 0.825 D_fake: 0.588 \n",
      "(epoch: 143, iters: 1440, time: 0.101, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.716 D_fake: 0.681 \n",
      "(epoch: 143, iters: 1540, time: 0.109, data: 0.002) G_GAN: 0.839 G_L1: 1.958 D_real: 0.588 D_fake: 0.594 \n",
      "(epoch: 143, iters: 1640, time: 0.097, data: 0.001) G_GAN: 0.704 G_L1: 0.000 D_real: 0.706 D_fake: 0.684 \n",
      "(epoch: 143, iters: 1740, time: 0.111, data: 0.001) G_GAN: 0.713 G_L1: 0.000 D_real: 0.712 D_fake: 0.679 \n",
      "(epoch: 143, iters: 1840, time: 0.098, data: 0.001) G_GAN: 0.777 G_L1: 0.311 D_real: 0.638 D_fake: 0.644 \n",
      "(epoch: 143, iters: 1940, time: 0.098, data: 0.002) G_GAN: 0.769 G_L1: 0.000 D_real: 0.775 D_fake: 0.625 \n",
      "(epoch: 143, iters: 2040, time: 0.099, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.744 D_fake: 0.661 \n",
      "(epoch: 143, iters: 2140, time: 0.109, data: 0.002) G_GAN: 0.917 G_L1: 0.787 D_real: 0.699 D_fake: 0.527 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 143, iters: 2240, time: 0.110, data: 0.001) G_GAN: 0.656 G_L1: 0.000 D_real: 0.661 D_fake: 0.670 \n",
      "End of epoch 143 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001129\n",
      "(epoch: 144, iters: 60, time: 0.105, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.689 D_fake: 0.706 \n",
      "(epoch: 144, iters: 160, time: 0.109, data: 0.002) G_GAN: 0.787 G_L1: 3.185 D_real: 0.534 D_fake: 0.640 \n",
      "(epoch: 144, iters: 260, time: 0.099, data: 0.001) G_GAN: 0.804 G_L1: 0.000 D_real: 0.818 D_fake: 0.596 \n",
      "(epoch: 144, iters: 360, time: 0.108, data: 0.002) G_GAN: 0.656 G_L1: 0.000 D_real: 0.658 D_fake: 0.738 \n",
      "(epoch: 144, iters: 460, time: 0.111, data: 0.002) G_GAN: 0.841 G_L1: 2.593 D_real: 0.587 D_fake: 0.588 \n",
      "(epoch: 144, iters: 560, time: 0.098, data: 0.001) G_GAN: 0.771 G_L1: 0.000 D_real: 0.779 D_fake: 0.622 \n",
      "(epoch: 144, iters: 660, time: 0.097, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.730 D_fake: 0.669 \n",
      "(epoch: 144, iters: 760, time: 0.095, data: 0.002) G_GAN: 0.798 G_L1: 2.399 D_real: 0.558 D_fake: 0.623 \n",
      "(epoch: 144, iters: 860, time: 0.093, data: 0.002) G_GAN: 0.781 G_L1: 0.000 D_real: 0.786 D_fake: 0.626 \n",
      "(epoch: 144, iters: 960, time: 0.107, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.689 D_fake: 0.706 \n",
      "(epoch: 144, iters: 1060, time: 0.108, data: 0.001) G_GAN: 0.749 G_L1: 0.087 D_real: 0.651 D_fake: 0.667 \n",
      "(epoch: 144, iters: 1160, time: 0.097, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.745 D_fake: 0.621 \n",
      "(epoch: 144, iters: 1260, time: 0.102, data: 0.001) G_GAN: 0.751 G_L1: 0.000 D_real: 0.754 D_fake: 0.661 \n",
      "(epoch: 144, iters: 1360, time: 0.099, data: 0.001) G_GAN: 0.720 G_L1: 4.502 D_real: 0.482 D_fake: 0.692 \n",
      "(epoch: 144, iters: 1460, time: 0.107, data: 0.001) G_GAN: 0.867 G_L1: 0.000 D_real: 0.886 D_fake: 0.549 \n",
      "(epoch: 144, iters: 1560, time: 0.094, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.701 D_fake: 0.660 \n",
      "(epoch: 144, iters: 1660, time: 0.098, data: 0.001) G_GAN: 0.797 G_L1: 1.973 D_real: 0.569 D_fake: 0.619 \n",
      "(epoch: 144, iters: 1760, time: 0.110, data: 0.002) G_GAN: 0.800 G_L1: 0.000 D_real: 0.808 D_fake: 0.600 \n",
      "(epoch: 144, iters: 1860, time: 0.100, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.745 D_fake: 0.653 \n",
      "(epoch: 144, iters: 1960, time: 0.110, data: 0.002) G_GAN: 0.801 G_L1: 0.417 D_real: 0.668 D_fake: 0.614 \n",
      "(epoch: 144, iters: 2060, time: 0.095, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.715 D_fake: 0.655 \n",
      "(epoch: 144, iters: 2160, time: 0.096, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.703 D_fake: 0.611 \n",
      "(epoch: 144, iters: 2260, time: 0.094, data: 0.001) G_GAN: 1.052 G_L1: 3.017 D_real: 0.689 D_fake: 0.678 \n",
      "End of epoch 144 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001109\n",
      "(epoch: 145, iters: 80, time: 0.115, data: 0.001) G_GAN: 0.718 G_L1: 0.000 D_real: 0.726 D_fake: 0.657 \n",
      "(epoch: 145, iters: 180, time: 0.109, data: 0.001) G_GAN: 0.703 G_L1: 0.000 D_real: 0.704 D_fake: 0.684 \n",
      "(epoch: 145, iters: 280, time: 0.097, data: 0.002) G_GAN: 0.758 G_L1: 1.052 D_real: 0.575 D_fake: 0.657 \n",
      "(epoch: 145, iters: 380, time: 0.110, data: 0.002) G_GAN: 0.781 G_L1: 0.000 D_real: 0.787 D_fake: 0.636 \n",
      "(epoch: 145, iters: 480, time: 0.097, data: 0.002) G_GAN: 0.680 G_L1: 0.000 D_real: 0.684 D_fake: 0.634 \n",
      "(epoch: 145, iters: 580, time: 0.100, data: 0.001) G_GAN: 0.914 G_L1: 4.208 D_real: 0.563 D_fake: 0.585 \n",
      "(epoch: 145, iters: 680, time: 0.108, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.746 D_fake: 0.640 \n",
      "(epoch: 145, iters: 780, time: 0.105, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.696 D_fake: 0.725 \n",
      "(epoch: 145, iters: 880, time: 0.102, data: 0.002) G_GAN: 0.755 G_L1: 3.483 D_real: 0.483 D_fake: 0.670 \n",
      "(epoch: 145, iters: 980, time: 0.096, data: 0.001) G_GAN: 0.799 G_L1: 0.000 D_real: 0.815 D_fake: 0.672 \n",
      "(epoch: 145, iters: 1080, time: 0.094, data: 0.001) G_GAN: 0.603 G_L1: 0.000 D_real: 0.626 D_fake: 0.686 \n",
      "(epoch: 145, iters: 1180, time: 0.106, data: 0.001) G_GAN: 0.815 G_L1: 0.978 D_real: 0.642 D_fake: 0.692 \n",
      "(epoch: 145, iters: 1280, time: 0.111, data: 0.001) G_GAN: 0.874 G_L1: 0.000 D_real: 0.899 D_fake: 0.540 \n",
      "(epoch: 145, iters: 1380, time: 0.096, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.737 D_fake: 0.640 \n",
      "(epoch: 145, iters: 1480, time: 0.097, data: 0.002) G_GAN: 0.757 G_L1: 1.681 D_real: 0.551 D_fake: 0.657 \n",
      "(epoch: 145, iters: 1580, time: 0.096, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.738 D_fake: 0.653 \n",
      "(epoch: 145, iters: 1680, time: 0.108, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.726 D_fake: 0.666 \n",
      "saving the latest model (epoch 145, total_steps 330000)\n",
      "(epoch: 145, iters: 1780, time: 0.096, data: 0.001) G_GAN: 0.740 G_L1: 3.487 D_real: 0.503 D_fake: 0.620 \n",
      "(epoch: 145, iters: 1880, time: 0.099, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.742 D_fake: 0.644 \n",
      "(epoch: 145, iters: 1980, time: 0.098, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.700 D_fake: 0.691 \n",
      "(epoch: 145, iters: 2080, time: 0.100, data: 0.002) G_GAN: 0.759 G_L1: 2.663 D_real: 0.510 D_fake: 0.674 \n",
      "(epoch: 145, iters: 2180, time: 0.112, data: 0.002) G_GAN: 0.664 G_L1: 0.000 D_real: 0.666 D_fake: 0.725 \n",
      "(epoch: 145, iters: 2280, time: 0.095, data: 0.001) G_GAN: 0.703 G_L1: 0.000 D_real: 0.696 D_fake: 0.699 \n",
      "saving the model at the end of epoch 145, iters 330600\n",
      "End of epoch 145 / 200 \t Time Taken: 127 sec\n",
      "learning rate = 0.0001089\n",
      "(epoch: 146, iters: 100, time: 0.107, data: 3.707) G_GAN: 0.928 G_L1: 2.739 D_real: 0.627 D_fake: 0.664 \n",
      "(epoch: 146, iters: 200, time: 0.096, data: 0.002) G_GAN: 0.779 G_L1: 0.000 D_real: 0.784 D_fake: 0.620 \n",
      "(epoch: 146, iters: 300, time: 0.098, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.696 D_fake: 0.702 \n",
      "(epoch: 146, iters: 400, time: 0.096, data: 0.002) G_GAN: 0.788 G_L1: 1.900 D_real: 0.556 D_fake: 0.659 \n",
      "(epoch: 146, iters: 500, time: 0.098, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.714 D_fake: 0.563 \n",
      "(epoch: 146, iters: 600, time: 0.109, data: 0.002) G_GAN: 0.673 G_L1: 0.000 D_real: 0.673 D_fake: 0.717 \n",
      "(epoch: 146, iters: 700, time: 0.109, data: 0.001) G_GAN: 0.989 G_L1: 2.269 D_real: 0.665 D_fake: 0.585 \n",
      "(epoch: 146, iters: 800, time: 0.108, data: 0.001) G_GAN: 0.726 G_L1: 0.000 D_real: 0.733 D_fake: 0.671 \n",
      "(epoch: 146, iters: 900, time: 0.095, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.711 D_fake: 0.699 \n",
      "(epoch: 146, iters: 1000, time: 0.108, data: 0.002) G_GAN: 0.882 G_L1: 2.064 D_real: 0.605 D_fake: 0.639 \n",
      "(epoch: 146, iters: 1100, time: 0.099, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.774 D_fake: 0.595 \n",
      "(epoch: 146, iters: 1200, time: 0.095, data: 0.001) G_GAN: 0.712 G_L1: 0.000 D_real: 0.712 D_fake: 0.676 \n",
      "(epoch: 146, iters: 1300, time: 0.099, data: 0.002) G_GAN: 0.813 G_L1: 3.100 D_real: 0.547 D_fake: 0.704 \n",
      "(epoch: 146, iters: 1400, time: 0.098, data: 0.002) G_GAN: 0.851 G_L1: 0.000 D_real: 0.859 D_fake: 0.566 \n",
      "(epoch: 146, iters: 1500, time: 0.098, data: 0.001) G_GAN: 0.720 G_L1: 0.000 D_real: 0.724 D_fake: 0.662 \n",
      "(epoch: 146, iters: 1600, time: 0.096, data: 0.001) G_GAN: 0.787 G_L1: 1.704 D_real: 0.565 D_fake: 0.614 \n",
      "(epoch: 146, iters: 1700, time: 0.099, data: 0.002) G_GAN: 0.760 G_L1: 0.000 D_real: 0.766 D_fake: 0.623 \n",
      "(epoch: 146, iters: 1800, time: 0.107, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.693 D_fake: 0.624 \n",
      "(epoch: 146, iters: 1900, time: 0.098, data: 0.002) G_GAN: 0.758 G_L1: 4.005 D_real: 0.499 D_fake: 0.659 \n",
      "(epoch: 146, iters: 2000, time: 0.103, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.749 D_fake: 0.679 \n",
      "(epoch: 146, iters: 2100, time: 0.093, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.708 D_fake: 0.686 \n",
      "(epoch: 146, iters: 2200, time: 0.098, data: 0.002) G_GAN: 0.737 G_L1: 1.935 D_real: 0.507 D_fake: 0.690 \n",
      "End of epoch 146 / 200 \t Time Taken: 127 sec\n",
      "learning rate = 0.0001069\n",
      "(epoch: 147, iters: 20, time: 0.121, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.762 D_fake: 0.642 \n",
      "(epoch: 147, iters: 120, time: 0.096, data: 0.001) G_GAN: 0.719 G_L1: 0.000 D_real: 0.720 D_fake: 0.670 \n",
      "(epoch: 147, iters: 220, time: 0.104, data: 0.002) G_GAN: 0.823 G_L1: 3.205 D_real: 0.546 D_fake: 0.606 \n",
      "(epoch: 147, iters: 320, time: 0.107, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.748 D_fake: 0.674 \n",
      "(epoch: 147, iters: 420, time: 0.099, data: 0.002) G_GAN: 0.660 G_L1: 0.000 D_real: 0.668 D_fake: 0.649 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 147, iters: 520, time: 0.097, data: 0.002) G_GAN: 0.902 G_L1: 1.603 D_real: 0.653 D_fake: 0.558 \n",
      "(epoch: 147, iters: 620, time: 0.099, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.771 D_fake: 0.631 \n",
      "(epoch: 147, iters: 720, time: 0.099, data: 0.002) G_GAN: 0.668 G_L1: 0.000 D_real: 0.667 D_fake: 0.722 \n",
      "(epoch: 147, iters: 820, time: 0.096, data: 0.002) G_GAN: 0.865 G_L1: 2.187 D_real: 0.607 D_fake: 0.572 \n",
      "(epoch: 147, iters: 920, time: 0.094, data: 0.002) G_GAN: 0.667 G_L1: 0.000 D_real: 0.671 D_fake: 0.770 \n",
      "(epoch: 147, iters: 1020, time: 0.096, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.695 D_fake: 0.698 \n",
      "(epoch: 147, iters: 1120, time: 0.099, data: 0.002) G_GAN: 0.755 G_L1: 1.002 D_real: 0.592 D_fake: 0.626 \n",
      "(epoch: 147, iters: 1220, time: 0.096, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.722 D_fake: 0.669 \n",
      "(epoch: 147, iters: 1320, time: 0.097, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.726 D_fake: 0.671 \n",
      "(epoch: 147, iters: 1420, time: 0.099, data: 0.001) G_GAN: 0.703 G_L1: 2.201 D_real: 0.477 D_fake: 0.737 \n",
      "(epoch: 147, iters: 1520, time: 0.098, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.746 D_fake: 0.561 \n",
      "(epoch: 147, iters: 1620, time: 0.095, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.710 D_fake: 0.648 \n",
      "(epoch: 147, iters: 1720, time: 0.100, data: 0.001) G_GAN: 0.760 G_L1: 3.384 D_real: 0.510 D_fake: 0.573 \n",
      "(epoch: 147, iters: 1820, time: 0.099, data: 0.002) G_GAN: 0.780 G_L1: 0.000 D_real: 0.795 D_fake: 0.649 \n",
      "(epoch: 147, iters: 1920, time: 0.100, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.743 D_fake: 0.666 \n",
      "(epoch: 147, iters: 2020, time: 0.100, data: 0.002) G_GAN: 0.790 G_L1: 1.903 D_real: 0.583 D_fake: 0.624 \n",
      "(epoch: 147, iters: 2120, time: 0.099, data: 0.002) G_GAN: 0.823 G_L1: 0.000 D_real: 0.842 D_fake: 0.673 \n",
      "saving the latest model (epoch 147, total_steps 335000)\n",
      "(epoch: 147, iters: 2220, time: 0.101, data: 0.002) G_GAN: 0.662 G_L1: 0.000 D_real: 0.660 D_fake: 0.737 \n",
      "End of epoch 147 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001050\n",
      "(epoch: 148, iters: 40, time: 0.113, data: 0.002) G_GAN: 0.805 G_L1: 1.545 D_real: 0.577 D_fake: 0.649 \n",
      "(epoch: 148, iters: 140, time: 0.096, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.741 D_fake: 0.649 \n",
      "(epoch: 148, iters: 240, time: 0.096, data: 0.002) G_GAN: 0.647 G_L1: 0.000 D_real: 0.644 D_fake: 0.750 \n",
      "(epoch: 148, iters: 340, time: 0.097, data: 0.001) G_GAN: 0.780 G_L1: 0.576 D_real: 0.644 D_fake: 0.653 \n",
      "(epoch: 148, iters: 440, time: 0.101, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.695 D_fake: 0.699 \n",
      "(epoch: 148, iters: 540, time: 0.093, data: 0.002) G_GAN: 0.682 G_L1: 0.000 D_real: 0.684 D_fake: 0.711 \n",
      "(epoch: 148, iters: 640, time: 0.096, data: 0.002) G_GAN: 0.917 G_L1: 3.338 D_real: 0.584 D_fake: 0.550 \n",
      "(epoch: 148, iters: 740, time: 0.095, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.715 D_fake: 0.677 \n",
      "(epoch: 148, iters: 840, time: 0.095, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.702 D_fake: 0.688 \n",
      "(epoch: 148, iters: 940, time: 0.099, data: 0.002) G_GAN: 0.834 G_L1: 1.224 D_real: 0.652 D_fake: 0.600 \n",
      "(epoch: 148, iters: 1040, time: 0.105, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.746 D_fake: 0.665 \n",
      "(epoch: 148, iters: 1140, time: 0.109, data: 0.001) G_GAN: 0.703 G_L1: 0.000 D_real: 0.706 D_fake: 0.683 \n",
      "(epoch: 148, iters: 1240, time: 0.110, data: 0.002) G_GAN: 1.035 G_L1: 2.557 D_real: 0.690 D_fake: 0.478 \n",
      "(epoch: 148, iters: 1340, time: 0.099, data: 0.001) G_GAN: 0.772 G_L1: 0.000 D_real: 0.772 D_fake: 0.632 \n",
      "(epoch: 148, iters: 1440, time: 0.106, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.713 D_fake: 0.660 \n",
      "(epoch: 148, iters: 1540, time: 0.100, data: 0.001) G_GAN: 0.849 G_L1: 1.958 D_real: 0.589 D_fake: 0.602 \n",
      "(epoch: 148, iters: 1640, time: 0.109, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.729 D_fake: 0.663 \n",
      "(epoch: 148, iters: 1740, time: 0.099, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.735 D_fake: 0.683 \n",
      "(epoch: 148, iters: 1840, time: 0.098, data: 0.002) G_GAN: 0.791 G_L1: 0.311 D_real: 0.654 D_fake: 0.637 \n",
      "(epoch: 148, iters: 1940, time: 0.100, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.771 D_fake: 0.630 \n",
      "(epoch: 148, iters: 2040, time: 0.099, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.699 D_fake: 0.692 \n",
      "(epoch: 148, iters: 2140, time: 0.101, data: 0.001) G_GAN: 0.912 G_L1: 0.787 D_real: 0.688 D_fake: 0.542 \n",
      "(epoch: 148, iters: 2240, time: 0.098, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.690 D_fake: 0.709 \n",
      "End of epoch 148 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0001030\n",
      "(epoch: 149, iters: 60, time: 0.118, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.690 D_fake: 0.705 \n",
      "(epoch: 149, iters: 160, time: 0.112, data: 0.002) G_GAN: 0.787 G_L1: 3.185 D_real: 0.506 D_fake: 0.662 \n",
      "(epoch: 149, iters: 260, time: 0.105, data: 0.001) G_GAN: 0.815 G_L1: 0.000 D_real: 0.839 D_fake: 0.578 \n",
      "(epoch: 149, iters: 360, time: 0.098, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.721 D_fake: 0.672 \n",
      "(epoch: 149, iters: 460, time: 0.099, data: 0.002) G_GAN: 0.848 G_L1: 2.593 D_real: 0.577 D_fake: 0.587 \n",
      "(epoch: 149, iters: 560, time: 0.098, data: 0.002) G_GAN: 0.776 G_L1: 0.000 D_real: 0.781 D_fake: 0.623 \n",
      "(epoch: 149, iters: 660, time: 0.097, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.711 D_fake: 0.689 \n",
      "(epoch: 149, iters: 760, time: 0.097, data: 0.002) G_GAN: 0.809 G_L1: 2.399 D_real: 0.562 D_fake: 0.621 \n",
      "(epoch: 149, iters: 860, time: 0.095, data: 0.001) G_GAN: 0.796 G_L1: 0.000 D_real: 0.803 D_fake: 0.726 \n",
      "(epoch: 149, iters: 960, time: 0.106, data: 0.002) G_GAN: 0.680 G_L1: 0.000 D_real: 0.694 D_fake: 0.633 \n",
      "(epoch: 149, iters: 1060, time: 0.097, data: 0.002) G_GAN: 0.747 G_L1: 0.087 D_real: 0.618 D_fake: 0.678 \n",
      "(epoch: 149, iters: 1160, time: 0.096, data: 0.002) G_GAN: 0.781 G_L1: 0.000 D_real: 0.788 D_fake: 0.620 \n",
      "(epoch: 149, iters: 1260, time: 0.097, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.724 D_fake: 0.692 \n",
      "(epoch: 149, iters: 1360, time: 0.097, data: 0.001) G_GAN: 0.763 G_L1: 4.502 D_real: 0.502 D_fake: 0.648 \n",
      "(epoch: 149, iters: 1460, time: 0.098, data: 0.001) G_GAN: 0.776 G_L1: 0.000 D_real: 0.785 D_fake: 0.624 \n",
      "(epoch: 149, iters: 1560, time: 0.107, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.709 D_fake: 0.680 \n",
      "(epoch: 149, iters: 1660, time: 0.108, data: 0.001) G_GAN: 0.863 G_L1: 1.973 D_real: 0.605 D_fake: 0.576 \n",
      "(epoch: 149, iters: 1760, time: 0.108, data: 0.002) G_GAN: 0.776 G_L1: 0.000 D_real: 0.800 D_fake: 0.655 \n",
      "(epoch: 149, iters: 1860, time: 0.099, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.729 D_fake: 0.665 \n",
      "(epoch: 149, iters: 1960, time: 0.099, data: 0.001) G_GAN: 0.774 G_L1: 0.417 D_real: 0.648 D_fake: 0.639 \n",
      "(epoch: 149, iters: 2060, time: 0.094, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.748 D_fake: 0.590 \n",
      "(epoch: 149, iters: 2160, time: 0.098, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.703 D_fake: 0.660 \n",
      "(epoch: 149, iters: 2260, time: 0.095, data: 0.002) G_GAN: 0.897 G_L1: 3.017 D_real: 0.602 D_fake: 0.661 \n",
      "End of epoch 149 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0001010\n",
      "(epoch: 150, iters: 80, time: 0.118, data: 0.001) G_GAN: 0.718 G_L1: 0.000 D_real: 0.721 D_fake: 0.633 \n",
      "(epoch: 150, iters: 180, time: 0.099, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.683 D_fake: 0.638 \n",
      "(epoch: 150, iters: 280, time: 0.098, data: 0.002) G_GAN: 0.762 G_L1: 1.052 D_real: 0.594 D_fake: 0.649 \n",
      "saving the latest model (epoch 150, total_steps 340000)\n",
      "(epoch: 150, iters: 380, time: 0.101, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.760 D_fake: 0.631 \n",
      "(epoch: 150, iters: 480, time: 0.097, data: 0.001) G_GAN: 0.674 G_L1: 0.000 D_real: 0.676 D_fake: 0.689 \n",
      "(epoch: 150, iters: 580, time: 0.099, data: 0.002) G_GAN: 0.833 G_L1: 4.208 D_real: 0.528 D_fake: 0.619 \n",
      "(epoch: 150, iters: 680, time: 0.097, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.724 D_fake: 0.530 \n",
      "(epoch: 150, iters: 780, time: 0.096, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.724 D_fake: 0.674 \n",
      "(epoch: 150, iters: 880, time: 0.093, data: 0.001) G_GAN: 0.790 G_L1: 3.483 D_real: 0.497 D_fake: 0.615 \n",
      "(epoch: 150, iters: 980, time: 0.097, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.761 D_fake: 0.653 \n",
      "(epoch: 150, iters: 1080, time: 0.098, data: 0.001) G_GAN: 0.609 G_L1: 0.000 D_real: 0.601 D_fake: 0.800 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 150, iters: 1180, time: 0.098, data: 0.002) G_GAN: 0.801 G_L1: 0.978 D_real: 0.617 D_fake: 0.652 \n",
      "(epoch: 150, iters: 1280, time: 0.097, data: 0.002) G_GAN: 0.872 G_L1: 0.000 D_real: 0.916 D_fake: 0.669 \n",
      "(epoch: 150, iters: 1380, time: 0.096, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.698 D_fake: 0.698 \n",
      "(epoch: 150, iters: 1480, time: 0.112, data: 0.001) G_GAN: 0.768 G_L1: 1.681 D_real: 0.550 D_fake: 0.675 \n",
      "(epoch: 150, iters: 1580, time: 0.095, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.735 D_fake: 0.657 \n",
      "(epoch: 150, iters: 1680, time: 0.098, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.736 D_fake: 0.658 \n",
      "(epoch: 150, iters: 1780, time: 0.100, data: 0.001) G_GAN: 0.779 G_L1: 3.487 D_real: 0.532 D_fake: 0.618 \n",
      "(epoch: 150, iters: 1880, time: 0.099, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.766 D_fake: 0.638 \n",
      "(epoch: 150, iters: 1980, time: 0.098, data: 0.001) G_GAN: 0.697 G_L1: 0.000 D_real: 0.698 D_fake: 0.693 \n",
      "(epoch: 150, iters: 2080, time: 0.098, data: 0.001) G_GAN: 0.829 G_L1: 2.663 D_real: 0.552 D_fake: 0.650 \n",
      "(epoch: 150, iters: 2180, time: 0.099, data: 0.002) G_GAN: 0.676 G_L1: 0.000 D_real: 0.680 D_fake: 0.645 \n",
      "(epoch: 150, iters: 2280, time: 0.098, data: 0.001) G_GAN: 0.668 G_L1: 0.000 D_real: 0.670 D_fake: 0.729 \n",
      "saving the model at the end of epoch 150, iters 342000\n",
      "End of epoch 150 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000990\n",
      "(epoch: 151, iters: 100, time: 0.110, data: 0.280) G_GAN: 0.883 G_L1: 2.739 D_real: 0.594 D_fake: 0.651 \n",
      "(epoch: 151, iters: 200, time: 0.111, data: 0.001) G_GAN: 0.758 G_L1: 0.000 D_real: 0.760 D_fake: 0.647 \n",
      "(epoch: 151, iters: 300, time: 0.098, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.734 D_fake: 0.649 \n",
      "(epoch: 151, iters: 400, time: 0.097, data: 0.002) G_GAN: 0.803 G_L1: 1.900 D_real: 0.564 D_fake: 0.588 \n",
      "(epoch: 151, iters: 500, time: 0.099, data: 0.001) G_GAN: 0.681 G_L1: 0.000 D_real: 0.689 D_fake: 0.623 \n",
      "(epoch: 151, iters: 600, time: 0.099, data: 0.001) G_GAN: 0.720 G_L1: 0.000 D_real: 0.723 D_fake: 0.609 \n",
      "(epoch: 151, iters: 700, time: 0.108, data: 0.001) G_GAN: 1.141 G_L1: 2.269 D_real: 0.744 D_fake: 0.432 \n",
      "(epoch: 151, iters: 800, time: 0.097, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.774 D_fake: 0.638 \n",
      "(epoch: 151, iters: 900, time: 0.093, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.725 D_fake: 0.681 \n",
      "(epoch: 151, iters: 1000, time: 0.109, data: 0.002) G_GAN: 0.832 G_L1: 2.064 D_real: 0.565 D_fake: 0.709 \n",
      "(epoch: 151, iters: 1100, time: 0.097, data: 0.001) G_GAN: 0.775 G_L1: 0.000 D_real: 0.787 D_fake: 0.611 \n",
      "(epoch: 151, iters: 1200, time: 0.099, data: 0.002) G_GAN: 0.677 G_L1: 0.000 D_real: 0.679 D_fake: 0.577 \n",
      "(epoch: 151, iters: 1300, time: 0.098, data: 0.002) G_GAN: 0.845 G_L1: 3.100 D_real: 0.562 D_fake: 0.690 \n",
      "(epoch: 151, iters: 1400, time: 0.098, data: 0.002) G_GAN: 0.788 G_L1: 0.000 D_real: 0.796 D_fake: 0.588 \n",
      "(epoch: 151, iters: 1500, time: 0.106, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.725 D_fake: 0.552 \n",
      "(epoch: 151, iters: 1600, time: 0.110, data: 0.001) G_GAN: 0.811 G_L1: 1.704 D_real: 0.574 D_fake: 0.619 \n",
      "(epoch: 151, iters: 1700, time: 0.114, data: 0.001) G_GAN: 0.744 G_L1: 0.000 D_real: 0.756 D_fake: 0.621 \n",
      "(epoch: 151, iters: 1800, time: 0.093, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.717 D_fake: 0.689 \n",
      "(epoch: 151, iters: 1900, time: 0.099, data: 0.001) G_GAN: 0.857 G_L1: 4.005 D_real: 0.542 D_fake: 0.586 \n",
      "(epoch: 151, iters: 2000, time: 0.098, data: 0.002) G_GAN: 0.769 G_L1: 0.000 D_real: 0.778 D_fake: 0.632 \n",
      "(epoch: 151, iters: 2100, time: 0.094, data: 0.002) G_GAN: 0.639 G_L1: 0.000 D_real: 0.659 D_fake: 0.405 \n",
      "(epoch: 151, iters: 2200, time: 0.110, data: 0.002) G_GAN: 0.788 G_L1: 1.935 D_real: 0.547 D_fake: 0.640 \n",
      "End of epoch 151 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000970\n",
      "(epoch: 152, iters: 20, time: 0.105, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.747 D_fake: 0.655 \n",
      "(epoch: 152, iters: 120, time: 0.098, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.686 D_fake: 0.701 \n",
      "(epoch: 152, iters: 220, time: 0.098, data: 0.002) G_GAN: 0.818 G_L1: 3.205 D_real: 0.531 D_fake: 0.619 \n",
      "(epoch: 152, iters: 320, time: 0.097, data: 0.002) G_GAN: 0.776 G_L1: 0.000 D_real: 0.782 D_fake: 0.577 \n",
      "(epoch: 152, iters: 420, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.694 D_fake: 0.695 \n",
      "(epoch: 152, iters: 520, time: 0.096, data: 0.002) G_GAN: 0.849 G_L1: 1.603 D_real: 0.620 D_fake: 0.596 \n",
      "(epoch: 152, iters: 620, time: 0.097, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.772 D_fake: 0.656 \n",
      "(epoch: 152, iters: 720, time: 0.098, data: 0.002) G_GAN: 0.675 G_L1: 0.000 D_real: 0.674 D_fake: 0.714 \n",
      "saving the latest model (epoch 152, total_steps 345000)\n",
      "(epoch: 152, iters: 820, time: 0.108, data: 0.002) G_GAN: 0.802 G_L1: 2.187 D_real: 0.560 D_fake: 0.622 \n",
      "(epoch: 152, iters: 920, time: 0.094, data: 0.002) G_GAN: 0.671 G_L1: 0.000 D_real: 0.673 D_fake: 0.719 \n",
      "(epoch: 152, iters: 1020, time: 0.099, data: 0.002) G_GAN: 0.669 G_L1: 0.000 D_real: 0.668 D_fake: 0.726 \n",
      "(epoch: 152, iters: 1120, time: 0.099, data: 0.001) G_GAN: 0.842 G_L1: 1.002 D_real: 0.652 D_fake: 0.543 \n",
      "(epoch: 152, iters: 1220, time: 0.099, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.718 D_fake: 0.672 \n",
      "(epoch: 152, iters: 1320, time: 0.099, data: 0.001) G_GAN: 0.706 G_L1: 0.000 D_real: 0.713 D_fake: 0.642 \n",
      "(epoch: 152, iters: 1420, time: 0.099, data: 0.002) G_GAN: 0.907 G_L1: 2.201 D_real: 0.589 D_fake: 0.567 \n",
      "(epoch: 152, iters: 1520, time: 0.104, data: 0.001) G_GAN: 0.718 G_L1: 0.000 D_real: 0.730 D_fake: 0.669 \n",
      "(epoch: 152, iters: 1620, time: 0.095, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.735 D_fake: 0.652 \n",
      "(epoch: 152, iters: 1720, time: 0.101, data: 0.001) G_GAN: 0.800 G_L1: 3.384 D_real: 0.521 D_fake: 0.626 \n",
      "(epoch: 152, iters: 1820, time: 0.098, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.739 D_fake: 0.656 \n",
      "(epoch: 152, iters: 1920, time: 0.099, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.741 D_fake: 0.677 \n",
      "(epoch: 152, iters: 2020, time: 0.097, data: 0.002) G_GAN: 0.760 G_L1: 1.903 D_real: 0.553 D_fake: 0.654 \n",
      "(epoch: 152, iters: 2120, time: 0.098, data: 0.002) G_GAN: 0.833 G_L1: 0.000 D_real: 0.843 D_fake: 0.716 \n",
      "(epoch: 152, iters: 2220, time: 0.100, data: 0.002) G_GAN: 0.704 G_L1: 0.000 D_real: 0.706 D_fake: 0.692 \n",
      "End of epoch 152 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000950\n",
      "(epoch: 153, iters: 40, time: 0.103, data: 0.002) G_GAN: 0.804 G_L1: 1.545 D_real: 0.570 D_fake: 0.631 \n",
      "(epoch: 153, iters: 140, time: 0.096, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.705 D_fake: 0.683 \n",
      "(epoch: 153, iters: 240, time: 0.097, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.737 D_fake: 0.637 \n",
      "(epoch: 153, iters: 340, time: 0.097, data: 0.002) G_GAN: 0.760 G_L1: 0.576 D_real: 0.626 D_fake: 0.648 \n",
      "(epoch: 153, iters: 440, time: 0.094, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.744 D_fake: 0.655 \n",
      "(epoch: 153, iters: 540, time: 0.094, data: 0.001) G_GAN: 0.657 G_L1: 0.000 D_real: 0.662 D_fake: 0.732 \n",
      "(epoch: 153, iters: 640, time: 0.097, data: 0.002) G_GAN: 0.786 G_L1: 3.338 D_real: 0.501 D_fake: 0.647 \n",
      "(epoch: 153, iters: 740, time: 0.094, data: 0.001) G_GAN: 0.714 G_L1: 0.000 D_real: 0.721 D_fake: 0.617 \n",
      "(epoch: 153, iters: 840, time: 0.097, data: 0.002) G_GAN: 0.682 G_L1: 0.000 D_real: 0.682 D_fake: 0.708 \n",
      "(epoch: 153, iters: 940, time: 0.097, data: 0.001) G_GAN: 0.822 G_L1: 1.224 D_real: 0.642 D_fake: 0.631 \n",
      "(epoch: 153, iters: 1040, time: 0.095, data: 0.002) G_GAN: 0.771 G_L1: 0.000 D_real: 0.780 D_fake: 0.636 \n",
      "(epoch: 153, iters: 1140, time: 0.097, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.726 D_fake: 0.664 \n",
      "(epoch: 153, iters: 1240, time: 0.107, data: 0.002) G_GAN: 0.949 G_L1: 2.557 D_real: 0.615 D_fake: 0.529 \n",
      "(epoch: 153, iters: 1340, time: 0.099, data: 0.002) G_GAN: 0.786 G_L1: 0.000 D_real: 0.789 D_fake: 0.620 \n",
      "(epoch: 153, iters: 1440, time: 0.099, data: 0.001) G_GAN: 0.703 G_L1: 0.000 D_real: 0.703 D_fake: 0.694 \n",
      "(epoch: 153, iters: 1540, time: 0.099, data: 0.001) G_GAN: 0.864 G_L1: 1.958 D_real: 0.592 D_fake: 0.672 \n",
      "(epoch: 153, iters: 1640, time: 0.098, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.718 D_fake: 0.674 \n",
      "(epoch: 153, iters: 1740, time: 0.099, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.715 D_fake: 0.680 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 153, iters: 1840, time: 0.099, data: 0.002) G_GAN: 0.803 G_L1: 0.311 D_real: 0.647 D_fake: 0.626 \n",
      "(epoch: 153, iters: 1940, time: 0.097, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.761 D_fake: 0.592 \n",
      "(epoch: 153, iters: 2040, time: 0.097, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.710 D_fake: 0.680 \n",
      "(epoch: 153, iters: 2140, time: 0.100, data: 0.002) G_GAN: 0.889 G_L1: 0.787 D_real: 0.667 D_fake: 0.721 \n",
      "(epoch: 153, iters: 2240, time: 0.113, data: 0.001) G_GAN: 0.728 G_L1: 0.000 D_real: 0.727 D_fake: 0.670 \n",
      "End of epoch 153 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000931\n",
      "(epoch: 154, iters: 60, time: 0.120, data: 0.002) G_GAN: 0.666 G_L1: 0.000 D_real: 0.665 D_fake: 0.731 \n",
      "(epoch: 154, iters: 160, time: 0.097, data: 0.003) G_GAN: 0.793 G_L1: 3.185 D_real: 0.518 D_fake: 0.639 \n",
      "(epoch: 154, iters: 260, time: 0.098, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.773 D_fake: 0.639 \n",
      "(epoch: 154, iters: 360, time: 0.097, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.708 D_fake: 0.684 \n",
      "(epoch: 154, iters: 460, time: 0.098, data: 0.002) G_GAN: 0.882 G_L1: 2.593 D_real: 0.598 D_fake: 0.564 \n",
      "(epoch: 154, iters: 560, time: 0.097, data: 0.001) G_GAN: 0.744 G_L1: 0.000 D_real: 0.748 D_fake: 0.651 \n",
      "(epoch: 154, iters: 660, time: 0.097, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.729 D_fake: 0.668 \n",
      "(epoch: 154, iters: 760, time: 0.097, data: 0.001) G_GAN: 0.861 G_L1: 2.399 D_real: 0.596 D_fake: 0.584 \n",
      "(epoch: 154, iters: 860, time: 0.094, data: 0.001) G_GAN: 0.760 G_L1: 0.000 D_real: 0.765 D_fake: 0.638 \n",
      "(epoch: 154, iters: 960, time: 0.096, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.720 D_fake: 0.708 \n",
      "(epoch: 154, iters: 1060, time: 0.096, data: 0.001) G_GAN: 0.715 G_L1: 0.087 D_real: 0.582 D_fake: 0.719 \n",
      "(epoch: 154, iters: 1160, time: 0.095, data: 0.001) G_GAN: 0.770 G_L1: 0.000 D_real: 0.781 D_fake: 0.631 \n",
      "saving the latest model (epoch 154, total_steps 350000)\n",
      "(epoch: 154, iters: 1260, time: 0.108, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.768 D_fake: 0.529 \n",
      "(epoch: 154, iters: 1360, time: 0.100, data: 0.001) G_GAN: 0.793 G_L1: 4.502 D_real: 0.514 D_fake: 0.629 \n",
      "(epoch: 154, iters: 1460, time: 0.097, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.782 D_fake: 0.622 \n",
      "(epoch: 154, iters: 1560, time: 0.110, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.695 \n",
      "(epoch: 154, iters: 1660, time: 0.098, data: 0.000) G_GAN: 0.882 G_L1: 1.973 D_real: 0.622 D_fake: 0.563 \n",
      "(epoch: 154, iters: 1760, time: 0.098, data: 0.001) G_GAN: 0.795 G_L1: 0.000 D_real: 0.797 D_fake: 0.609 \n",
      "(epoch: 154, iters: 1860, time: 0.099, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.715 D_fake: 0.678 \n",
      "(epoch: 154, iters: 1960, time: 0.098, data: 0.002) G_GAN: 0.819 G_L1: 0.417 D_real: 0.676 D_fake: 0.629 \n",
      "(epoch: 154, iters: 2060, time: 0.092, data: 0.001) G_GAN: 0.773 G_L1: 0.000 D_real: 0.777 D_fake: 0.594 \n",
      "(epoch: 154, iters: 2160, time: 0.111, data: 0.001) G_GAN: 0.698 G_L1: 0.000 D_real: 0.701 D_fake: 0.666 \n",
      "(epoch: 154, iters: 2260, time: 0.095, data: 0.001) G_GAN: 0.983 G_L1: 3.017 D_real: 0.603 D_fake: 0.632 \n",
      "End of epoch 154 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000911\n",
      "(epoch: 155, iters: 80, time: 0.109, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.731 D_fake: 0.668 \n",
      "(epoch: 155, iters: 180, time: 0.099, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.691 D_fake: 0.707 \n",
      "(epoch: 155, iters: 280, time: 0.100, data: 0.002) G_GAN: 0.772 G_L1: 1.052 D_real: 0.606 D_fake: 0.636 \n",
      "(epoch: 155, iters: 380, time: 0.097, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.743 D_fake: 0.653 \n",
      "(epoch: 155, iters: 480, time: 0.097, data: 0.001) G_GAN: 0.666 G_L1: 0.000 D_real: 0.665 D_fake: 0.723 \n",
      "(epoch: 155, iters: 580, time: 0.098, data: 0.001) G_GAN: 0.833 G_L1: 4.208 D_real: 0.512 D_fake: 0.591 \n",
      "(epoch: 155, iters: 680, time: 0.096, data: 0.001) G_GAN: 0.709 G_L1: 0.000 D_real: 0.715 D_fake: 0.595 \n",
      "(epoch: 155, iters: 780, time: 0.096, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.726 D_fake: 0.675 \n",
      "(epoch: 155, iters: 880, time: 0.106, data: 0.001) G_GAN: 0.800 G_L1: 3.483 D_real: 0.509 D_fake: 0.596 \n",
      "(epoch: 155, iters: 980, time: 0.108, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.753 D_fake: 0.709 \n",
      "(epoch: 155, iters: 1080, time: 0.096, data: 0.001) G_GAN: 0.669 G_L1: 0.000 D_real: 0.680 D_fake: 0.702 \n",
      "(epoch: 155, iters: 1180, time: 0.098, data: 0.001) G_GAN: 0.791 G_L1: 0.978 D_real: 0.608 D_fake: 0.610 \n",
      "(epoch: 155, iters: 1280, time: 0.097, data: 0.002) G_GAN: 0.860 G_L1: 0.000 D_real: 0.888 D_fake: 0.732 \n",
      "(epoch: 155, iters: 1380, time: 0.095, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.694 D_fake: 0.609 \n",
      "(epoch: 155, iters: 1480, time: 0.096, data: 0.002) G_GAN: 0.798 G_L1: 1.681 D_real: 0.569 D_fake: 0.669 \n",
      "(epoch: 155, iters: 1580, time: 0.097, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.730 D_fake: 0.625 \n",
      "(epoch: 155, iters: 1680, time: 0.097, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.746 D_fake: 0.633 \n",
      "(epoch: 155, iters: 1780, time: 0.097, data: 0.002) G_GAN: 0.768 G_L1: 3.487 D_real: 0.522 D_fake: 0.650 \n",
      "(epoch: 155, iters: 1880, time: 0.098, data: 0.001) G_GAN: 0.777 G_L1: 0.000 D_real: 0.783 D_fake: 0.647 \n",
      "(epoch: 155, iters: 1980, time: 0.098, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.713 D_fake: 0.643 \n",
      "(epoch: 155, iters: 2080, time: 0.097, data: 0.001) G_GAN: 0.846 G_L1: 2.663 D_real: 0.535 D_fake: 0.610 \n",
      "(epoch: 155, iters: 2180, time: 0.108, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.699 D_fake: 0.601 \n",
      "(epoch: 155, iters: 2280, time: 0.097, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.697 D_fake: 0.701 \n",
      "saving the model at the end of epoch 155, iters 353400\n",
      "End of epoch 155 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000891\n",
      "(epoch: 156, iters: 100, time: 0.106, data: 0.275) G_GAN: 0.892 G_L1: 2.739 D_real: 0.577 D_fake: 0.679 \n",
      "(epoch: 156, iters: 200, time: 0.105, data: 0.002) G_GAN: 0.771 G_L1: 0.000 D_real: 0.775 D_fake: 0.634 \n",
      "(epoch: 156, iters: 300, time: 0.097, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.748 D_fake: 0.654 \n",
      "(epoch: 156, iters: 400, time: 0.098, data: 0.001) G_GAN: 0.889 G_L1: 1.900 D_real: 0.588 D_fake: 0.634 \n",
      "(epoch: 156, iters: 500, time: 0.102, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.690 D_fake: 0.698 \n",
      "(epoch: 156, iters: 600, time: 0.099, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.731 D_fake: 0.662 \n",
      "(epoch: 156, iters: 700, time: 0.100, data: 0.002) G_GAN: 1.107 G_L1: 2.269 D_real: 0.765 D_fake: 1.104 \n",
      "(epoch: 156, iters: 800, time: 0.098, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.739 D_fake: 0.660 \n",
      "(epoch: 156, iters: 900, time: 0.093, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.717 D_fake: 0.697 \n",
      "(epoch: 156, iters: 1000, time: 0.098, data: 0.002) G_GAN: 0.987 G_L1: 2.064 D_real: 0.652 D_fake: 0.520 \n",
      "(epoch: 156, iters: 1100, time: 0.098, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.752 D_fake: 0.631 \n",
      "(epoch: 156, iters: 1200, time: 0.108, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.700 D_fake: 0.649 \n",
      "(epoch: 156, iters: 1300, time: 0.108, data: 0.002) G_GAN: 0.857 G_L1: 3.100 D_real: 0.560 D_fake: 0.638 \n",
      "(epoch: 156, iters: 1400, time: 0.107, data: 0.002) G_GAN: 0.804 G_L1: 0.000 D_real: 0.812 D_fake: 0.584 \n",
      "(epoch: 156, iters: 1500, time: 0.096, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.734 D_fake: 0.677 \n",
      "(epoch: 156, iters: 1600, time: 0.099, data: 0.001) G_GAN: 0.828 G_L1: 1.704 D_real: 0.567 D_fake: 0.606 \n",
      "saving the latest model (epoch 156, total_steps 355000)\n",
      "(epoch: 156, iters: 1700, time: 0.102, data: 0.001) G_GAN: 0.768 G_L1: 0.000 D_real: 0.780 D_fake: 0.598 \n",
      "(epoch: 156, iters: 1800, time: 0.094, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.717 D_fake: 0.673 \n",
      "(epoch: 156, iters: 1900, time: 0.110, data: 0.001) G_GAN: 0.858 G_L1: 4.005 D_real: 0.533 D_fake: 0.591 \n",
      "(epoch: 156, iters: 2000, time: 0.099, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.769 D_fake: 0.659 \n",
      "(epoch: 156, iters: 2100, time: 0.095, data: 0.002) G_GAN: 0.600 G_L1: 0.000 D_real: 0.596 D_fake: 0.808 \n",
      "(epoch: 156, iters: 2200, time: 0.098, data: 0.003) G_GAN: 0.808 G_L1: 1.935 D_real: 0.559 D_fake: 0.624 \n",
      "End of epoch 156 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000871\n",
      "(epoch: 157, iters: 20, time: 0.117, data: 0.002) G_GAN: 0.788 G_L1: 0.000 D_real: 0.800 D_fake: 0.613 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 157, iters: 120, time: 0.098, data: 0.002) G_GAN: 0.667 G_L1: 0.000 D_real: 0.654 D_fake: 0.737 \n",
      "(epoch: 157, iters: 220, time: 0.109, data: 0.002) G_GAN: 0.860 G_L1: 3.205 D_real: 0.551 D_fake: 0.587 \n",
      "(epoch: 157, iters: 320, time: 0.096, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.753 D_fake: 0.648 \n",
      "(epoch: 157, iters: 420, time: 0.097, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.693 D_fake: 0.696 \n",
      "(epoch: 157, iters: 520, time: 0.106, data: 0.002) G_GAN: 0.850 G_L1: 1.603 D_real: 0.621 D_fake: 0.612 \n",
      "(epoch: 157, iters: 620, time: 0.100, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.723 D_fake: 0.653 \n",
      "(epoch: 157, iters: 720, time: 0.099, data: 0.002) G_GAN: 0.702 G_L1: 0.000 D_real: 0.705 D_fake: 0.683 \n",
      "(epoch: 157, iters: 820, time: 0.098, data: 0.001) G_GAN: 0.871 G_L1: 2.187 D_real: 0.581 D_fake: 0.579 \n",
      "(epoch: 157, iters: 920, time: 0.095, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.688 D_fake: 0.703 \n",
      "(epoch: 157, iters: 1020, time: 0.110, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.722 D_fake: 0.675 \n",
      "(epoch: 157, iters: 1120, time: 0.099, data: 0.001) G_GAN: 0.813 G_L1: 1.002 D_real: 0.630 D_fake: 0.607 \n",
      "(epoch: 157, iters: 1220, time: 0.097, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.704 D_fake: 0.643 \n",
      "(epoch: 157, iters: 1320, time: 0.101, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.719 D_fake: 0.677 \n",
      "(epoch: 157, iters: 1420, time: 0.098, data: 0.002) G_GAN: 0.844 G_L1: 2.201 D_real: 0.550 D_fake: 0.672 \n",
      "(epoch: 157, iters: 1520, time: 0.101, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.732 D_fake: 0.665 \n",
      "(epoch: 157, iters: 1620, time: 0.096, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.734 D_fake: 0.659 \n",
      "(epoch: 157, iters: 1720, time: 0.100, data: 0.001) G_GAN: 0.816 G_L1: 3.384 D_real: 0.526 D_fake: 0.660 \n",
      "(epoch: 157, iters: 1820, time: 0.099, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.746 D_fake: 0.628 \n",
      "(epoch: 157, iters: 1920, time: 0.096, data: 0.001) G_GAN: 0.772 G_L1: 0.000 D_real: 0.777 D_fake: 0.642 \n",
      "(epoch: 157, iters: 2020, time: 0.099, data: 0.002) G_GAN: 0.802 G_L1: 1.903 D_real: 0.567 D_fake: 0.621 \n",
      "(epoch: 157, iters: 2120, time: 0.110, data: 0.002) G_GAN: 0.800 G_L1: 0.000 D_real: 0.809 D_fake: 0.602 \n",
      "(epoch: 157, iters: 2220, time: 0.100, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.690 D_fake: 0.664 \n",
      "End of epoch 157 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000851\n",
      "(epoch: 158, iters: 40, time: 0.108, data: 0.002) G_GAN: 0.820 G_L1: 1.545 D_real: 0.571 D_fake: 0.643 \n",
      "(epoch: 158, iters: 140, time: 0.098, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.738 D_fake: 0.653 \n",
      "(epoch: 158, iters: 240, time: 0.100, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.721 D_fake: 0.673 \n",
      "(epoch: 158, iters: 340, time: 0.097, data: 0.001) G_GAN: 0.782 G_L1: 0.576 D_real: 0.631 D_fake: 0.624 \n",
      "(epoch: 158, iters: 440, time: 0.097, data: 0.001) G_GAN: 0.762 G_L1: 0.000 D_real: 0.770 D_fake: 0.618 \n",
      "(epoch: 158, iters: 540, time: 0.095, data: 0.002) G_GAN: 0.676 G_L1: 0.000 D_real: 0.683 D_fake: 0.709 \n",
      "(epoch: 158, iters: 640, time: 0.106, data: 0.002) G_GAN: 0.886 G_L1: 3.338 D_real: 0.578 D_fake: 0.634 \n",
      "(epoch: 158, iters: 740, time: 0.096, data: 0.001) G_GAN: 0.720 G_L1: 0.000 D_real: 0.730 D_fake: 0.663 \n",
      "(epoch: 158, iters: 840, time: 0.094, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.686 D_fake: 0.682 \n",
      "(epoch: 158, iters: 940, time: 0.097, data: 0.003) G_GAN: 0.817 G_L1: 1.224 D_real: 0.634 D_fake: 0.609 \n",
      "(epoch: 158, iters: 1040, time: 0.096, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.768 D_fake: 0.649 \n",
      "(epoch: 158, iters: 1140, time: 0.098, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.756 D_fake: 0.637 \n",
      "(epoch: 158, iters: 1240, time: 0.096, data: 0.001) G_GAN: 0.918 G_L1: 2.557 D_real: 0.610 D_fake: 0.581 \n",
      "(epoch: 158, iters: 1340, time: 0.110, data: 0.003) G_GAN: 0.796 G_L1: 0.000 D_real: 0.811 D_fake: 0.662 \n",
      "(epoch: 158, iters: 1440, time: 0.110, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.706 D_fake: 0.698 \n",
      "(epoch: 158, iters: 1540, time: 0.097, data: 0.002) G_GAN: 0.859 G_L1: 1.958 D_real: 0.568 D_fake: 0.596 \n",
      "(epoch: 158, iters: 1640, time: 0.111, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.700 D_fake: 0.663 \n",
      "(epoch: 158, iters: 1740, time: 0.102, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.740 D_fake: 0.658 \n",
      "(epoch: 158, iters: 1840, time: 0.101, data: 0.002) G_GAN: 0.787 G_L1: 0.311 D_real: 0.633 D_fake: 0.695 \n",
      "(epoch: 158, iters: 1940, time: 0.099, data: 0.001) G_GAN: 0.752 G_L1: 0.000 D_real: 0.760 D_fake: 0.677 \n",
      "(epoch: 158, iters: 2040, time: 0.098, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.728 D_fake: 0.663 \n",
      "saving the latest model (epoch 158, total_steps 360000)\n",
      "(epoch: 158, iters: 2140, time: 0.111, data: 0.001) G_GAN: 0.915 G_L1: 0.787 D_real: 0.674 D_fake: 0.544 \n",
      "(epoch: 158, iters: 2240, time: 0.098, data: 0.002) G_GAN: 0.660 G_L1: 0.000 D_real: 0.653 D_fake: 0.729 \n",
      "End of epoch 158 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000832\n",
      "(epoch: 159, iters: 60, time: 0.108, data: 0.002) G_GAN: 0.680 G_L1: 0.000 D_real: 0.681 D_fake: 0.714 \n",
      "(epoch: 159, iters: 160, time: 0.098, data: 0.001) G_GAN: 0.828 G_L1: 3.185 D_real: 0.528 D_fake: 0.617 \n",
      "(epoch: 159, iters: 260, time: 0.096, data: 0.001) G_GAN: 0.805 G_L1: 0.000 D_real: 0.849 D_fake: 0.677 \n",
      "(epoch: 159, iters: 360, time: 0.097, data: 0.002) G_GAN: 0.675 G_L1: 0.000 D_real: 0.677 D_fake: 0.674 \n",
      "(epoch: 159, iters: 460, time: 0.099, data: 0.001) G_GAN: 0.832 G_L1: 2.593 D_real: 0.555 D_fake: 0.607 \n",
      "(epoch: 159, iters: 560, time: 0.097, data: 0.001) G_GAN: 0.763 G_L1: 0.000 D_real: 0.766 D_fake: 0.634 \n",
      "(epoch: 159, iters: 660, time: 0.099, data: 0.003) G_GAN: 0.729 G_L1: 0.000 D_real: 0.735 D_fake: 0.680 \n",
      "(epoch: 159, iters: 760, time: 0.108, data: 0.001) G_GAN: 0.804 G_L1: 2.399 D_real: 0.538 D_fake: 0.638 \n",
      "(epoch: 159, iters: 860, time: 0.107, data: 0.001) G_GAN: 0.777 G_L1: 0.000 D_real: 0.805 D_fake: 0.587 \n",
      "(epoch: 159, iters: 960, time: 0.106, data: 0.001) G_GAN: 0.718 G_L1: 0.000 D_real: 0.719 D_fake: 0.672 \n",
      "(epoch: 159, iters: 1060, time: 0.104, data: 0.002) G_GAN: 0.801 G_L1: 0.087 D_real: 0.675 D_fake: 0.641 \n",
      "(epoch: 159, iters: 1160, time: 0.099, data: 0.001) G_GAN: 0.810 G_L1: 0.000 D_real: 0.818 D_fake: 0.603 \n",
      "(epoch: 159, iters: 1260, time: 0.111, data: 0.000) G_GAN: 0.797 G_L1: 0.000 D_real: 0.804 D_fake: 0.657 \n",
      "(epoch: 159, iters: 1360, time: 0.098, data: 0.002) G_GAN: 0.802 G_L1: 4.502 D_real: 0.514 D_fake: 0.544 \n",
      "(epoch: 159, iters: 1460, time: 0.096, data: 0.001) G_GAN: 0.803 G_L1: 0.000 D_real: 0.811 D_fake: 0.601 \n",
      "(epoch: 159, iters: 1560, time: 0.096, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.696 D_fake: 0.695 \n",
      "(epoch: 159, iters: 1660, time: 0.098, data: 0.002) G_GAN: 0.853 G_L1: 1.973 D_real: 0.589 D_fake: 0.596 \n",
      "(epoch: 159, iters: 1760, time: 0.112, data: 0.002) G_GAN: 0.792 G_L1: 0.000 D_real: 0.793 D_fake: 0.620 \n",
      "(epoch: 159, iters: 1860, time: 0.104, data: 0.001) G_GAN: 0.712 G_L1: 0.000 D_real: 0.713 D_fake: 0.683 \n",
      "(epoch: 159, iters: 1960, time: 0.101, data: 0.001) G_GAN: 0.793 G_L1: 0.417 D_real: 0.666 D_fake: 0.629 \n",
      "(epoch: 159, iters: 2060, time: 0.094, data: 0.001) G_GAN: 0.743 G_L1: 0.000 D_real: 0.749 D_fake: 0.657 \n",
      "(epoch: 159, iters: 2160, time: 0.096, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.725 D_fake: 0.600 \n",
      "(epoch: 159, iters: 2260, time: 0.094, data: 0.002) G_GAN: 1.037 G_L1: 3.017 D_real: 0.628 D_fake: 0.491 \n",
      "End of epoch 159 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000812\n",
      "(epoch: 160, iters: 80, time: 0.103, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.755 D_fake: 0.643 \n",
      "(epoch: 160, iters: 180, time: 0.097, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.688 D_fake: 0.701 \n",
      "(epoch: 160, iters: 280, time: 0.096, data: 0.002) G_GAN: 0.722 G_L1: 1.052 D_real: 0.571 D_fake: 0.507 \n",
      "(epoch: 160, iters: 380, time: 0.105, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.748 D_fake: 0.650 \n",
      "(epoch: 160, iters: 480, time: 0.098, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.693 D_fake: 0.695 \n",
      "(epoch: 160, iters: 580, time: 0.100, data: 0.001) G_GAN: 0.833 G_L1: 4.208 D_real: 0.514 D_fake: 0.612 \n",
      "(epoch: 160, iters: 680, time: 0.102, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.746 D_fake: 0.653 \n",
      "(epoch: 160, iters: 780, time: 0.094, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.727 D_fake: 0.675 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 160, iters: 880, time: 0.092, data: 0.002) G_GAN: 0.797 G_L1: 3.483 D_real: 0.502 D_fake: 0.640 \n",
      "(epoch: 160, iters: 980, time: 0.096, data: 0.001) G_GAN: 0.777 G_L1: 0.000 D_real: 0.782 D_fake: 0.640 \n",
      "(epoch: 160, iters: 1080, time: 0.095, data: 0.001) G_GAN: 0.617 G_L1: 0.000 D_real: 0.601 D_fake: 0.800 \n",
      "(epoch: 160, iters: 1180, time: 0.110, data: 0.001) G_GAN: 0.779 G_L1: 0.978 D_real: 0.589 D_fake: 0.634 \n",
      "(epoch: 160, iters: 1280, time: 0.098, data: 0.001) G_GAN: 0.841 G_L1: 0.000 D_real: 0.875 D_fake: 0.650 \n",
      "(epoch: 160, iters: 1380, time: 0.095, data: 0.002) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.708 \n",
      "(epoch: 160, iters: 1480, time: 0.097, data: 0.001) G_GAN: 0.801 G_L1: 1.681 D_real: 0.566 D_fake: 0.600 \n",
      "(epoch: 160, iters: 1580, time: 0.096, data: 0.001) G_GAN: 0.743 G_L1: 0.000 D_real: 0.747 D_fake: 0.645 \n",
      "(epoch: 160, iters: 1680, time: 0.098, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.737 D_fake: 0.655 \n",
      "(epoch: 160, iters: 1780, time: 0.097, data: 0.002) G_GAN: 0.791 G_L1: 3.487 D_real: 0.534 D_fake: 0.633 \n",
      "(epoch: 160, iters: 1880, time: 0.100, data: 0.002) G_GAN: 0.773 G_L1: 0.000 D_real: 0.778 D_fake: 0.629 \n",
      "(epoch: 160, iters: 1980, time: 0.097, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.696 D_fake: 0.677 \n",
      "(epoch: 160, iters: 2080, time: 0.097, data: 0.001) G_GAN: 0.810 G_L1: 2.663 D_real: 0.523 D_fake: 0.639 \n",
      "(epoch: 160, iters: 2180, time: 0.109, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.691 D_fake: 0.667 \n",
      "(epoch: 160, iters: 2280, time: 0.096, data: 0.001) G_GAN: 0.684 G_L1: 0.000 D_real: 0.694 D_fake: 0.610 \n",
      "saving the model at the end of epoch 160, iters 364800\n",
      "End of epoch 160 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000792\n",
      "(epoch: 161, iters: 100, time: 0.106, data: 0.281) G_GAN: 0.882 G_L1: 2.739 D_real: 0.570 D_fake: 0.581 \n",
      "(epoch: 161, iters: 200, time: 0.108, data: 0.001) G_GAN: 0.760 G_L1: 0.000 D_real: 0.764 D_fake: 0.643 \n",
      "saving the latest model (epoch 161, total_steps 365000)\n",
      "(epoch: 161, iters: 300, time: 0.096, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.760 D_fake: 0.644 \n",
      "(epoch: 161, iters: 400, time: 0.095, data: 0.002) G_GAN: 0.810 G_L1: 1.900 D_real: 0.543 D_fake: 0.645 \n",
      "(epoch: 161, iters: 500, time: 0.098, data: 0.001) G_GAN: 0.645 G_L1: 0.000 D_real: 0.643 D_fake: 0.749 \n",
      "(epoch: 161, iters: 600, time: 0.100, data: 0.001) G_GAN: 0.706 G_L1: 0.000 D_real: 0.708 D_fake: 0.684 \n",
      "(epoch: 161, iters: 700, time: 0.098, data: 0.002) G_GAN: 1.000 G_L1: 2.269 D_real: 0.636 D_fake: 0.526 \n",
      "(epoch: 161, iters: 800, time: 0.109, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.762 D_fake: 0.676 \n",
      "(epoch: 161, iters: 900, time: 0.094, data: 0.001) G_GAN: 0.651 G_L1: 0.000 D_real: 0.669 D_fake: 0.481 \n",
      "(epoch: 161, iters: 1000, time: 0.098, data: 0.002) G_GAN: 0.868 G_L1: 2.064 D_real: 0.580 D_fake: 0.591 \n",
      "(epoch: 161, iters: 1100, time: 0.099, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.746 D_fake: 0.652 \n",
      "(epoch: 161, iters: 1200, time: 0.098, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.718 D_fake: 0.672 \n",
      "(epoch: 161, iters: 1300, time: 0.098, data: 0.002) G_GAN: 0.952 G_L1: 3.100 D_real: 0.605 D_fake: 0.534 \n",
      "(epoch: 161, iters: 1400, time: 0.096, data: 0.002) G_GAN: 0.885 G_L1: 0.000 D_real: 0.916 D_fake: 0.532 \n",
      "(epoch: 161, iters: 1500, time: 0.108, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.726 D_fake: 0.643 \n",
      "(epoch: 161, iters: 1600, time: 0.100, data: 0.002) G_GAN: 0.778 G_L1: 1.704 D_real: 0.525 D_fake: 0.664 \n",
      "(epoch: 161, iters: 1700, time: 0.100, data: 0.001) G_GAN: 0.761 G_L1: 0.000 D_real: 0.768 D_fake: 0.634 \n",
      "(epoch: 161, iters: 1800, time: 0.097, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.720 D_fake: 0.670 \n",
      "(epoch: 161, iters: 1900, time: 0.098, data: 0.002) G_GAN: 0.803 G_L1: 4.005 D_real: 0.503 D_fake: 0.669 \n",
      "(epoch: 161, iters: 2000, time: 0.098, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.734 D_fake: 0.666 \n",
      "(epoch: 161, iters: 2100, time: 0.096, data: 0.002) G_GAN: 0.641 G_L1: 0.000 D_real: 0.649 D_fake: 0.671 \n",
      "(epoch: 161, iters: 2200, time: 0.101, data: 0.002) G_GAN: 0.776 G_L1: 1.935 D_real: 0.528 D_fake: 0.659 \n",
      "End of epoch 161 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000772\n",
      "(epoch: 162, iters: 20, time: 0.122, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.775 D_fake: 0.631 \n",
      "(epoch: 162, iters: 120, time: 0.099, data: 0.002) G_GAN: 0.652 G_L1: 0.000 D_real: 0.654 D_fake: 0.720 \n",
      "(epoch: 162, iters: 220, time: 0.096, data: 0.001) G_GAN: 0.862 G_L1: 3.205 D_real: 0.529 D_fake: 0.600 \n",
      "(epoch: 162, iters: 320, time: 0.099, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.732 D_fake: 0.646 \n",
      "(epoch: 162, iters: 420, time: 0.099, data: 0.002) G_GAN: 0.680 G_L1: 0.000 D_real: 0.679 D_fake: 0.710 \n",
      "(epoch: 162, iters: 520, time: 0.097, data: 0.002) G_GAN: 0.843 G_L1: 1.603 D_real: 0.604 D_fake: 0.626 \n",
      "(epoch: 162, iters: 620, time: 0.098, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.731 D_fake: 0.551 \n",
      "(epoch: 162, iters: 720, time: 0.098, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.709 D_fake: 0.679 \n",
      "(epoch: 162, iters: 820, time: 0.105, data: 0.003) G_GAN: 0.878 G_L1: 2.187 D_real: 0.587 D_fake: 0.576 \n",
      "(epoch: 162, iters: 920, time: 0.095, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.701 D_fake: 0.691 \n",
      "(epoch: 162, iters: 1020, time: 0.096, data: 0.000) G_GAN: 0.708 G_L1: 0.000 D_real: 0.716 D_fake: 0.640 \n",
      "(epoch: 162, iters: 1120, time: 0.098, data: 0.002) G_GAN: 0.778 G_L1: 1.002 D_real: 0.596 D_fake: 0.637 \n",
      "(epoch: 162, iters: 1220, time: 0.096, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.715 D_fake: 0.674 \n",
      "(epoch: 162, iters: 1320, time: 0.110, data: 0.001) G_GAN: 0.680 G_L1: 0.000 D_real: 0.678 D_fake: 0.720 \n",
      "(epoch: 162, iters: 1420, time: 0.110, data: 0.002) G_GAN: 0.817 G_L1: 2.201 D_real: 0.516 D_fake: 0.669 \n",
      "(epoch: 162, iters: 1520, time: 0.097, data: 0.002) G_GAN: 0.683 G_L1: 0.000 D_real: 0.697 D_fake: 0.676 \n",
      "(epoch: 162, iters: 1620, time: 0.094, data: 0.002) G_GAN: 0.773 G_L1: 0.000 D_real: 0.785 D_fake: 0.616 \n",
      "(epoch: 162, iters: 1720, time: 0.099, data: 0.002) G_GAN: 0.823 G_L1: 3.384 D_real: 0.541 D_fake: 0.624 \n",
      "(epoch: 162, iters: 1820, time: 0.100, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.737 D_fake: 0.659 \n",
      "(epoch: 162, iters: 1920, time: 0.097, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.745 D_fake: 0.719 \n",
      "(epoch: 162, iters: 2020, time: 0.107, data: 0.002) G_GAN: 0.823 G_L1: 1.903 D_real: 0.579 D_fake: 0.610 \n",
      "(epoch: 162, iters: 2120, time: 0.097, data: 0.001) G_GAN: 0.895 G_L1: 0.000 D_real: 0.918 D_fake: 0.528 \n",
      "(epoch: 162, iters: 2220, time: 0.112, data: 0.001) G_GAN: 0.682 G_L1: 0.000 D_real: 0.680 D_fake: 0.722 \n",
      "End of epoch 162 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000752\n",
      "(epoch: 163, iters: 40, time: 0.115, data: 0.002) G_GAN: 0.816 G_L1: 1.545 D_real: 0.566 D_fake: 0.655 \n",
      "(epoch: 163, iters: 140, time: 0.107, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.717 D_fake: 0.672 \n",
      "(epoch: 163, iters: 240, time: 0.096, data: 0.001) G_GAN: 0.675 G_L1: 0.000 D_real: 0.679 D_fake: 0.715 \n",
      "(epoch: 163, iters: 340, time: 0.098, data: 0.001) G_GAN: 0.680 G_L1: 0.576 D_real: 0.565 D_fake: 0.627 \n",
      "(epoch: 163, iters: 440, time: 0.096, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.732 D_fake: 0.600 \n",
      "(epoch: 163, iters: 540, time: 0.096, data: 0.001) G_GAN: 0.651 G_L1: 0.000 D_real: 0.648 D_fake: 0.731 \n",
      "(epoch: 163, iters: 640, time: 0.107, data: 0.002) G_GAN: 0.911 G_L1: 3.338 D_real: 0.570 D_fake: 0.579 \n",
      "saving the latest model (epoch 163, total_steps 370000)\n",
      "(epoch: 163, iters: 740, time: 0.097, data: 0.001) G_GAN: 0.683 G_L1: 0.000 D_real: 0.710 D_fake: 0.639 \n",
      "(epoch: 163, iters: 840, time: 0.099, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.694 D_fake: 0.696 \n",
      "(epoch: 163, iters: 940, time: 0.100, data: 0.001) G_GAN: 0.824 G_L1: 1.224 D_real: 0.620 D_fake: 0.607 \n",
      "(epoch: 163, iters: 1040, time: 0.103, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.767 D_fake: 0.649 \n",
      "(epoch: 163, iters: 1140, time: 0.110, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.727 D_fake: 0.664 \n",
      "(epoch: 163, iters: 1240, time: 0.096, data: 0.002) G_GAN: 1.007 G_L1: 2.557 D_real: 0.645 D_fake: 0.509 \n",
      "(epoch: 163, iters: 1340, time: 0.114, data: 0.002) G_GAN: 0.775 G_L1: 0.000 D_real: 0.773 D_fake: 0.582 \n",
      "(epoch: 163, iters: 1440, time: 0.098, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.709 D_fake: 0.688 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 163, iters: 1540, time: 0.098, data: 0.002) G_GAN: 0.861 G_L1: 1.958 D_real: 0.556 D_fake: 0.600 \n",
      "(epoch: 163, iters: 1640, time: 0.099, data: 0.001) G_GAN: 0.717 G_L1: 0.000 D_real: 0.721 D_fake: 0.671 \n",
      "(epoch: 163, iters: 1740, time: 0.098, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.749 D_fake: 0.651 \n",
      "(epoch: 163, iters: 1840, time: 0.102, data: 0.002) G_GAN: 0.805 G_L1: 0.311 D_real: 0.632 D_fake: 0.638 \n",
      "(epoch: 163, iters: 1940, time: 0.100, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.751 D_fake: 0.646 \n",
      "(epoch: 163, iters: 2040, time: 0.098, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.681 D_fake: 0.708 \n",
      "(epoch: 163, iters: 2140, time: 0.101, data: 0.001) G_GAN: 0.875 G_L1: 0.787 D_real: 0.631 D_fake: 0.576 \n",
      "(epoch: 163, iters: 2240, time: 0.117, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.725 D_fake: 0.677 \n",
      "End of epoch 163 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000733\n",
      "(epoch: 164, iters: 60, time: 0.105, data: 0.001) G_GAN: 0.682 G_L1: 0.000 D_real: 0.684 D_fake: 0.712 \n",
      "(epoch: 164, iters: 160, time: 0.110, data: 0.002) G_GAN: 0.802 G_L1: 3.185 D_real: 0.505 D_fake: 0.640 \n",
      "(epoch: 164, iters: 260, time: 0.100, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.767 D_fake: 0.649 \n",
      "(epoch: 164, iters: 360, time: 0.108, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.727 D_fake: 0.667 \n",
      "(epoch: 164, iters: 460, time: 0.099, data: 0.002) G_GAN: 0.877 G_L1: 2.593 D_real: 0.576 D_fake: 0.572 \n",
      "(epoch: 164, iters: 560, time: 0.095, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.740 D_fake: 0.669 \n",
      "(epoch: 164, iters: 660, time: 0.097, data: 0.001) G_GAN: 0.691 G_L1: 0.000 D_real: 0.698 D_fake: 0.649 \n",
      "(epoch: 164, iters: 760, time: 0.098, data: 0.002) G_GAN: 0.768 G_L1: 2.399 D_real: 0.529 D_fake: 0.655 \n",
      "(epoch: 164, iters: 860, time: 0.099, data: 0.002) G_GAN: 0.789 G_L1: 0.000 D_real: 0.800 D_fake: 0.732 \n",
      "(epoch: 164, iters: 960, time: 0.096, data: 0.001) G_GAN: 0.681 G_L1: 0.000 D_real: 0.682 D_fake: 0.624 \n",
      "(epoch: 164, iters: 1060, time: 0.097, data: 0.002) G_GAN: 0.834 G_L1: 0.087 D_real: 0.775 D_fake: 0.614 \n",
      "(epoch: 164, iters: 1160, time: 0.099, data: 0.001) G_GAN: 0.794 G_L1: 0.000 D_real: 0.801 D_fake: 0.637 \n",
      "(epoch: 164, iters: 1260, time: 0.099, data: 0.001) G_GAN: 0.772 G_L1: 0.000 D_real: 0.778 D_fake: 0.632 \n",
      "(epoch: 164, iters: 1360, time: 0.096, data: 0.001) G_GAN: 0.803 G_L1: 4.502 D_real: 0.492 D_fake: 0.625 \n",
      "(epoch: 164, iters: 1460, time: 0.098, data: 0.002) G_GAN: 0.819 G_L1: 0.000 D_real: 0.836 D_fake: 0.579 \n",
      "(epoch: 164, iters: 1560, time: 0.096, data: 0.002) G_GAN: 0.667 G_L1: 0.000 D_real: 0.674 D_fake: 0.598 \n",
      "(epoch: 164, iters: 1660, time: 0.098, data: 0.001) G_GAN: 0.877 G_L1: 1.973 D_real: 0.590 D_fake: 0.601 \n",
      "(epoch: 164, iters: 1760, time: 0.110, data: 0.002) G_GAN: 0.823 G_L1: 0.000 D_real: 0.834 D_fake: 0.595 \n",
      "(epoch: 164, iters: 1860, time: 0.100, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.711 D_fake: 0.683 \n",
      "(epoch: 164, iters: 1960, time: 0.110, data: 0.001) G_GAN: 0.777 G_L1: 0.417 D_real: 0.651 D_fake: 0.642 \n",
      "(epoch: 164, iters: 2060, time: 0.095, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.762 D_fake: 0.643 \n",
      "(epoch: 164, iters: 2160, time: 0.098, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.712 D_fake: 0.680 \n",
      "(epoch: 164, iters: 2260, time: 0.094, data: 0.001) G_GAN: 0.944 G_L1: 3.017 D_real: 0.598 D_fake: 0.546 \n",
      "End of epoch 164 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000713\n",
      "(epoch: 165, iters: 80, time: 0.107, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.744 D_fake: 0.614 \n",
      "(epoch: 165, iters: 180, time: 0.100, data: 0.001) G_GAN: 0.669 G_L1: 0.000 D_real: 0.671 D_fake: 0.718 \n",
      "(epoch: 165, iters: 280, time: 0.097, data: 0.002) G_GAN: 0.789 G_L1: 1.052 D_real: 0.606 D_fake: 0.717 \n",
      "(epoch: 165, iters: 380, time: 0.096, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.773 D_fake: 0.622 \n",
      "(epoch: 165, iters: 480, time: 0.097, data: 0.001) G_GAN: 0.685 G_L1: 0.000 D_real: 0.686 D_fake: 0.702 \n",
      "(epoch: 165, iters: 580, time: 0.098, data: 0.001) G_GAN: 0.865 G_L1: 4.208 D_real: 0.531 D_fake: 0.583 \n",
      "(epoch: 165, iters: 680, time: 0.109, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.712 D_fake: 0.685 \n",
      "(epoch: 165, iters: 780, time: 0.097, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.745 D_fake: 0.582 \n",
      "(epoch: 165, iters: 880, time: 0.096, data: 0.002) G_GAN: 0.810 G_L1: 3.483 D_real: 0.493 D_fake: 0.642 \n",
      "(epoch: 165, iters: 980, time: 0.098, data: 0.001) G_GAN: 0.839 G_L1: 0.000 D_real: 0.845 D_fake: 0.594 \n",
      "(epoch: 165, iters: 1080, time: 0.097, data: 0.002) G_GAN: 0.653 G_L1: 0.000 D_real: 0.667 D_fake: 0.673 \n",
      "saving the latest model (epoch 165, total_steps 375000)\n",
      "(epoch: 165, iters: 1180, time: 0.099, data: 0.001) G_GAN: 0.768 G_L1: 0.978 D_real: 0.574 D_fake: 0.648 \n",
      "(epoch: 165, iters: 1280, time: 0.101, data: 0.002) G_GAN: 0.903 G_L1: 0.000 D_real: 0.927 D_fake: 0.702 \n",
      "(epoch: 165, iters: 1380, time: 0.095, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.721 D_fake: 0.540 \n",
      "(epoch: 165, iters: 1480, time: 0.098, data: 0.002) G_GAN: 0.786 G_L1: 1.681 D_real: 0.560 D_fake: 0.642 \n",
      "(epoch: 165, iters: 1580, time: 0.095, data: 0.001) G_GAN: 0.751 G_L1: 0.000 D_real: 0.754 D_fake: 0.639 \n",
      "(epoch: 165, iters: 1680, time: 0.109, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.726 D_fake: 0.661 \n",
      "(epoch: 165, iters: 1780, time: 0.098, data: 0.001) G_GAN: 0.773 G_L1: 3.487 D_real: 0.505 D_fake: 0.652 \n",
      "(epoch: 165, iters: 1880, time: 0.100, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.766 D_fake: 0.639 \n",
      "(epoch: 165, iters: 1980, time: 0.108, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.697 D_fake: 0.652 \n",
      "(epoch: 165, iters: 2080, time: 0.097, data: 0.002) G_GAN: 0.754 G_L1: 2.663 D_real: 0.483 D_fake: 0.692 \n",
      "(epoch: 165, iters: 2180, time: 0.098, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.685 D_fake: 0.622 \n",
      "(epoch: 165, iters: 2280, time: 0.106, data: 0.001) G_GAN: 0.706 G_L1: 0.000 D_real: 0.710 D_fake: 0.690 \n",
      "saving the model at the end of epoch 165, iters 376200\n",
      "End of epoch 165 / 200 \t Time Taken: 127 sec\n",
      "learning rate = 0.0000693\n",
      "(epoch: 166, iters: 100, time: 0.111, data: 0.294) G_GAN: 0.894 G_L1: 2.739 D_real: 0.560 D_fake: 0.576 \n",
      "(epoch: 166, iters: 200, time: 0.106, data: 0.002) G_GAN: 0.766 G_L1: 0.000 D_real: 0.770 D_fake: 0.640 \n",
      "(epoch: 166, iters: 300, time: 0.099, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.749 D_fake: 0.656 \n",
      "(epoch: 166, iters: 400, time: 0.107, data: 0.002) G_GAN: 0.680 G_L1: 1.900 D_real: 0.438 D_fake: 0.784 \n",
      "(epoch: 166, iters: 500, time: 0.097, data: 0.001) G_GAN: 0.673 G_L1: 0.000 D_real: 0.673 D_fake: 0.716 \n",
      "(epoch: 166, iters: 600, time: 0.098, data: 0.001) G_GAN: 0.711 G_L1: 0.000 D_real: 0.713 D_fake: 0.679 \n",
      "(epoch: 166, iters: 700, time: 0.098, data: 0.001) G_GAN: 1.055 G_L1: 2.269 D_real: 0.642 D_fake: 0.682 \n",
      "(epoch: 166, iters: 800, time: 0.098, data: 0.002) G_GAN: 0.769 G_L1: 0.000 D_real: 0.786 D_fake: 0.630 \n",
      "(epoch: 166, iters: 900, time: 0.103, data: 0.002) G_GAN: 0.674 G_L1: 0.000 D_real: 0.692 D_fake: 0.505 \n",
      "(epoch: 166, iters: 1000, time: 0.109, data: 0.001) G_GAN: 0.854 G_L1: 2.064 D_real: 0.567 D_fake: 0.599 \n",
      "(epoch: 166, iters: 1100, time: 0.110, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.719 D_fake: 0.625 \n",
      "(epoch: 166, iters: 1200, time: 0.097, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.709 D_fake: 0.680 \n",
      "(epoch: 166, iters: 1300, time: 0.098, data: 0.002) G_GAN: 0.948 G_L1: 3.100 D_real: 0.593 D_fake: 0.581 \n",
      "(epoch: 166, iters: 1400, time: 0.098, data: 0.001) G_GAN: 0.841 G_L1: 0.000 D_real: 0.854 D_fake: 0.579 \n",
      "(epoch: 166, iters: 1500, time: 0.097, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.744 D_fake: 0.657 \n",
      "(epoch: 166, iters: 1600, time: 0.097, data: 0.001) G_GAN: 0.896 G_L1: 1.704 D_real: 0.607 D_fake: 0.570 \n",
      "(epoch: 166, iters: 1700, time: 0.098, data: 0.001) G_GAN: 0.744 G_L1: 0.000 D_real: 0.752 D_fake: 0.647 \n",
      "(epoch: 166, iters: 1800, time: 0.095, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.733 D_fake: 0.658 \n",
      "(epoch: 166, iters: 1900, time: 0.099, data: 0.001) G_GAN: 0.883 G_L1: 4.005 D_real: 0.548 D_fake: 0.557 \n",
      "(epoch: 166, iters: 2000, time: 0.092, data: 0.001) G_GAN: 0.775 G_L1: 0.000 D_real: 0.780 D_fake: 0.624 \n",
      "(epoch: 166, iters: 2100, time: 0.094, data: 0.001) G_GAN: 0.653 G_L1: 0.000 D_real: 0.673 D_fake: 0.484 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 166, iters: 2200, time: 0.102, data: 0.001) G_GAN: 0.808 G_L1: 1.935 D_real: 0.553 D_fake: 0.633 \n",
      "End of epoch 166 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000673\n",
      "(epoch: 167, iters: 20, time: 0.103, data: 0.001) G_GAN: 0.731 G_L1: 0.000 D_real: 0.747 D_fake: 0.682 \n",
      "(epoch: 167, iters: 120, time: 0.097, data: 0.001) G_GAN: 0.676 G_L1: 0.000 D_real: 0.677 D_fake: 0.712 \n",
      "(epoch: 167, iters: 220, time: 0.098, data: 0.001) G_GAN: 0.865 G_L1: 3.205 D_real: 0.549 D_fake: 0.593 \n",
      "(epoch: 167, iters: 320, time: 0.097, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.756 D_fake: 0.641 \n",
      "(epoch: 167, iters: 420, time: 0.099, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.713 D_fake: 0.618 \n",
      "(epoch: 167, iters: 520, time: 0.095, data: 0.002) G_GAN: 0.889 G_L1: 1.603 D_real: 0.635 D_fake: 0.571 \n",
      "(epoch: 167, iters: 620, time: 0.099, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.709 D_fake: 0.546 \n",
      "(epoch: 167, iters: 720, time: 0.099, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.702 D_fake: 0.654 \n",
      "(epoch: 167, iters: 820, time: 0.096, data: 0.002) G_GAN: 0.966 G_L1: 2.187 D_real: 0.660 D_fake: 0.524 \n",
      "(epoch: 167, iters: 920, time: 0.095, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.722 D_fake: 0.650 \n",
      "(epoch: 167, iters: 1020, time: 0.098, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.707 D_fake: 0.687 \n",
      "(epoch: 167, iters: 1120, time: 0.099, data: 0.002) G_GAN: 0.792 G_L1: 1.002 D_real: 0.601 D_fake: 0.630 \n",
      "(epoch: 167, iters: 1220, time: 0.097, data: 0.001) G_GAN: 0.712 G_L1: 0.000 D_real: 0.714 D_fake: 0.676 \n",
      "(epoch: 167, iters: 1320, time: 0.106, data: 0.001) G_GAN: 0.711 G_L1: 0.000 D_real: 0.715 D_fake: 0.682 \n",
      "(epoch: 167, iters: 1420, time: 0.096, data: 0.002) G_GAN: 0.866 G_L1: 2.201 D_real: 0.542 D_fake: 0.616 \n",
      "(epoch: 167, iters: 1520, time: 0.099, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.742 D_fake: 0.631 \n",
      "saving the latest model (epoch 167, total_steps 380000)\n",
      "(epoch: 167, iters: 1620, time: 0.093, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.689 D_fake: 0.703 \n",
      "(epoch: 167, iters: 1720, time: 0.098, data: 0.002) G_GAN: 0.825 G_L1: 3.384 D_real: 0.524 D_fake: 0.645 \n",
      "(epoch: 167, iters: 1820, time: 0.098, data: 0.003) G_GAN: 0.738 G_L1: 0.000 D_real: 0.750 D_fake: 0.650 \n",
      "(epoch: 167, iters: 1920, time: 0.099, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.741 D_fake: 0.549 \n",
      "(epoch: 167, iters: 2020, time: 0.101, data: 0.002) G_GAN: 0.796 G_L1: 1.903 D_real: 0.564 D_fake: 0.633 \n",
      "(epoch: 167, iters: 2120, time: 0.096, data: 0.001) G_GAN: 0.790 G_L1: 0.000 D_real: 0.798 D_fake: 0.613 \n",
      "(epoch: 167, iters: 2220, time: 0.099, data: 0.002) G_GAN: 0.661 G_L1: 0.000 D_real: 0.659 D_fake: 0.741 \n",
      "End of epoch 167 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000653\n",
      "(epoch: 168, iters: 40, time: 0.105, data: 0.001) G_GAN: 0.803 G_L1: 1.545 D_real: 0.554 D_fake: 0.643 \n",
      "(epoch: 168, iters: 140, time: 0.108, data: 0.001) G_GAN: 0.718 G_L1: 0.000 D_real: 0.727 D_fake: 0.601 \n",
      "(epoch: 168, iters: 240, time: 0.097, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.734 D_fake: 0.661 \n",
      "(epoch: 168, iters: 340, time: 0.095, data: 0.001) G_GAN: 0.745 G_L1: 0.576 D_real: 0.600 D_fake: 0.658 \n",
      "(epoch: 168, iters: 440, time: 0.095, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.758 D_fake: 0.585 \n",
      "(epoch: 168, iters: 540, time: 0.105, data: 0.001) G_GAN: 0.680 G_L1: 0.000 D_real: 0.683 D_fake: 0.708 \n",
      "(epoch: 168, iters: 640, time: 0.096, data: 0.001) G_GAN: 0.905 G_L1: 3.338 D_real: 0.571 D_fake: 0.561 \n",
      "(epoch: 168, iters: 740, time: 0.093, data: 0.001) G_GAN: 0.766 G_L1: 0.000 D_real: 0.796 D_fake: 0.621 \n",
      "(epoch: 168, iters: 840, time: 0.096, data: 0.001) G_GAN: 0.708 G_L1: 0.000 D_real: 0.710 D_fake: 0.683 \n",
      "(epoch: 168, iters: 940, time: 0.099, data: 0.001) G_GAN: 0.844 G_L1: 1.224 D_real: 0.633 D_fake: 0.592 \n",
      "(epoch: 168, iters: 1040, time: 0.093, data: 0.001) G_GAN: 0.734 G_L1: 0.000 D_real: 0.744 D_fake: 0.669 \n",
      "(epoch: 168, iters: 1140, time: 0.098, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.717 D_fake: 0.676 \n",
      "(epoch: 168, iters: 1240, time: 0.095, data: 0.001) G_GAN: 1.007 G_L1: 2.557 D_real: 0.627 D_fake: 0.591 \n",
      "(epoch: 168, iters: 1340, time: 0.098, data: 0.001) G_GAN: 0.776 G_L1: 0.000 D_real: 0.789 D_fake: 0.549 \n",
      "(epoch: 168, iters: 1440, time: 0.098, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.721 D_fake: 0.610 \n",
      "(epoch: 168, iters: 1540, time: 0.099, data: 0.002) G_GAN: 0.898 G_L1: 1.958 D_real: 0.598 D_fake: 0.571 \n",
      "(epoch: 168, iters: 1640, time: 0.096, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.703 D_fake: 0.616 \n",
      "(epoch: 168, iters: 1740, time: 0.097, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.712 D_fake: 0.640 \n",
      "(epoch: 168, iters: 1840, time: 0.098, data: 0.002) G_GAN: 0.823 G_L1: 0.311 D_real: 0.649 D_fake: 0.632 \n",
      "(epoch: 168, iters: 1940, time: 0.097, data: 0.001) G_GAN: 0.765 G_L1: 0.000 D_real: 0.773 D_fake: 0.702 \n",
      "(epoch: 168, iters: 2040, time: 0.098, data: 0.001) G_GAN: 0.717 G_L1: 0.000 D_real: 0.719 D_fake: 0.675 \n",
      "(epoch: 168, iters: 2140, time: 0.099, data: 0.001) G_GAN: 0.922 G_L1: 0.787 D_real: 0.671 D_fake: 0.608 \n",
      "(epoch: 168, iters: 2240, time: 0.100, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.691 D_fake: 0.710 \n",
      "End of epoch 168 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000634\n",
      "(epoch: 169, iters: 60, time: 0.111, data: 0.001) G_GAN: 0.674 G_L1: 0.000 D_real: 0.674 D_fake: 0.722 \n",
      "(epoch: 169, iters: 160, time: 0.099, data: 0.001) G_GAN: 0.813 G_L1: 3.185 D_real: 0.510 D_fake: 0.614 \n",
      "(epoch: 169, iters: 260, time: 0.098, data: 0.002) G_GAN: 0.776 G_L1: 0.000 D_real: 0.787 D_fake: 0.621 \n",
      "(epoch: 169, iters: 360, time: 0.095, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.695 D_fake: 0.700 \n",
      "(epoch: 169, iters: 460, time: 0.100, data: 0.002) G_GAN: 0.887 G_L1: 2.593 D_real: 0.590 D_fake: 0.569 \n",
      "(epoch: 169, iters: 560, time: 0.109, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.740 D_fake: 0.672 \n",
      "(epoch: 169, iters: 660, time: 0.099, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.752 D_fake: 0.681 \n",
      "(epoch: 169, iters: 760, time: 0.099, data: 0.001) G_GAN: 0.808 G_L1: 2.399 D_real: 0.550 D_fake: 0.734 \n",
      "(epoch: 169, iters: 860, time: 0.096, data: 0.002) G_GAN: 0.867 G_L1: 0.000 D_real: 0.881 D_fake: 0.566 \n",
      "(epoch: 169, iters: 960, time: 0.108, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.705 D_fake: 0.573 \n",
      "(epoch: 169, iters: 1060, time: 0.095, data: 0.002) G_GAN: 0.771 G_L1: 0.087 D_real: 0.634 D_fake: 0.672 \n",
      "(epoch: 169, iters: 1160, time: 0.095, data: 0.002) G_GAN: 0.785 G_L1: 0.000 D_real: 0.792 D_fake: 0.581 \n",
      "(epoch: 169, iters: 1260, time: 0.097, data: 0.002) G_GAN: 0.766 G_L1: 0.000 D_real: 0.777 D_fake: 0.660 \n",
      "(epoch: 169, iters: 1360, time: 0.098, data: 0.002) G_GAN: 0.818 G_L1: 4.502 D_real: 0.511 D_fake: 0.618 \n",
      "(epoch: 169, iters: 1460, time: 0.095, data: 0.002) G_GAN: 0.853 G_L1: 0.000 D_real: 0.874 D_fake: 0.631 \n",
      "(epoch: 169, iters: 1560, time: 0.106, data: 0.002) G_GAN: 0.688 G_L1: 0.000 D_real: 0.689 D_fake: 0.702 \n",
      "(epoch: 169, iters: 1660, time: 0.097, data: 0.002) G_GAN: 0.844 G_L1: 1.973 D_real: 0.575 D_fake: 0.604 \n",
      "(epoch: 169, iters: 1760, time: 0.096, data: 0.002) G_GAN: 0.807 G_L1: 0.000 D_real: 0.813 D_fake: 0.598 \n",
      "(epoch: 169, iters: 1860, time: 0.111, data: 0.002) G_GAN: 0.671 G_L1: 0.000 D_real: 0.673 D_fake: 0.682 \n",
      "(epoch: 169, iters: 1960, time: 0.113, data: 0.002) G_GAN: 0.794 G_L1: 0.417 D_real: 0.661 D_fake: 0.597 \n",
      "saving the latest model (epoch 169, total_steps 385000)\n",
      "(epoch: 169, iters: 2060, time: 0.095, data: 0.001) G_GAN: 0.767 G_L1: 0.000 D_real: 0.771 D_fake: 0.637 \n",
      "(epoch: 169, iters: 2160, time: 0.099, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.700 D_fake: 0.696 \n",
      "(epoch: 169, iters: 2260, time: 0.106, data: 0.002) G_GAN: 0.961 G_L1: 3.017 D_real: 0.599 D_fake: 0.535 \n",
      "End of epoch 169 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000614\n",
      "(epoch: 170, iters: 80, time: 0.102, data: 0.002) G_GAN: 0.780 G_L1: 0.000 D_real: 0.788 D_fake: 0.618 \n",
      "(epoch: 170, iters: 180, time: 0.101, data: 0.002) G_GAN: 0.654 G_L1: 0.000 D_real: 0.659 D_fake: 0.678 \n",
      "(epoch: 170, iters: 280, time: 0.099, data: 0.001) G_GAN: 0.792 G_L1: 1.052 D_real: 0.609 D_fake: 0.620 \n",
      "(epoch: 170, iters: 380, time: 0.097, data: 0.002) G_GAN: 0.778 G_L1: 0.000 D_real: 0.792 D_fake: 0.614 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 170, iters: 480, time: 0.095, data: 0.002) G_GAN: 0.674 G_L1: 0.000 D_real: 0.675 D_fake: 0.713 \n",
      "(epoch: 170, iters: 580, time: 0.099, data: 0.002) G_GAN: 0.839 G_L1: 4.208 D_real: 0.501 D_fake: 0.603 \n",
      "(epoch: 170, iters: 680, time: 0.111, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.724 D_fake: 0.673 \n",
      "(epoch: 170, iters: 780, time: 0.097, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.717 D_fake: 0.684 \n",
      "(epoch: 170, iters: 880, time: 0.094, data: 0.002) G_GAN: 0.828 G_L1: 3.483 D_real: 0.500 D_fake: 0.630 \n",
      "(epoch: 170, iters: 980, time: 0.108, data: 0.002) G_GAN: 0.818 G_L1: 0.000 D_real: 0.822 D_fake: 0.623 \n",
      "(epoch: 170, iters: 1080, time: 0.106, data: 0.002) G_GAN: 0.664 G_L1: 0.000 D_real: 0.678 D_fake: 0.632 \n",
      "(epoch: 170, iters: 1180, time: 0.108, data: 0.001) G_GAN: 0.793 G_L1: 0.978 D_real: 0.598 D_fake: 0.627 \n",
      "(epoch: 170, iters: 1280, time: 0.098, data: 0.002) G_GAN: 0.845 G_L1: 0.000 D_real: 0.856 D_fake: 0.577 \n",
      "(epoch: 170, iters: 1380, time: 0.099, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.709 D_fake: 0.689 \n",
      "(epoch: 170, iters: 1480, time: 0.096, data: 0.002) G_GAN: 0.819 G_L1: 1.681 D_real: 0.564 D_fake: 0.627 \n",
      "(epoch: 170, iters: 1580, time: 0.099, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.728 D_fake: 0.662 \n",
      "(epoch: 170, iters: 1680, time: 0.107, data: 0.001) G_GAN: 0.717 G_L1: 0.000 D_real: 0.721 D_fake: 0.619 \n",
      "(epoch: 170, iters: 1780, time: 0.097, data: 0.002) G_GAN: 0.790 G_L1: 3.487 D_real: 0.524 D_fake: 0.655 \n",
      "(epoch: 170, iters: 1880, time: 0.097, data: 0.002) G_GAN: 0.777 G_L1: 0.000 D_real: 0.783 D_fake: 0.625 \n",
      "(epoch: 170, iters: 1980, time: 0.107, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.694 D_fake: 0.663 \n",
      "(epoch: 170, iters: 2080, time: 0.095, data: 0.002) G_GAN: 0.855 G_L1: 2.663 D_real: 0.547 D_fake: 0.630 \n",
      "(epoch: 170, iters: 2180, time: 0.099, data: 0.002) G_GAN: 0.665 G_L1: 0.000 D_real: 0.674 D_fake: 0.625 \n",
      "(epoch: 170, iters: 2280, time: 0.096, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.698 D_fake: 0.619 \n",
      "saving the model at the end of epoch 170, iters 387600\n",
      "End of epoch 170 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0000594\n",
      "(epoch: 171, iters: 100, time: 0.106, data: 0.279) G_GAN: 0.885 G_L1: 2.739 D_real: 0.559 D_fake: 0.716 \n",
      "(epoch: 171, iters: 200, time: 0.108, data: 0.001) G_GAN: 0.773 G_L1: 0.000 D_real: 0.777 D_fake: 0.633 \n",
      "(epoch: 171, iters: 300, time: 0.096, data: 0.001) G_GAN: 0.717 G_L1: 0.000 D_real: 0.723 D_fake: 0.691 \n",
      "(epoch: 171, iters: 400, time: 0.099, data: 0.002) G_GAN: 0.822 G_L1: 1.900 D_real: 0.531 D_fake: 0.610 \n",
      "(epoch: 171, iters: 500, time: 0.099, data: 0.002) G_GAN: 0.682 G_L1: 0.000 D_real: 0.682 D_fake: 0.706 \n",
      "(epoch: 171, iters: 600, time: 0.099, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.704 D_fake: 0.687 \n",
      "(epoch: 171, iters: 700, time: 0.099, data: 0.002) G_GAN: 1.111 G_L1: 2.269 D_real: 0.672 D_fake: 0.692 \n",
      "(epoch: 171, iters: 800, time: 0.100, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.770 D_fake: 0.691 \n",
      "(epoch: 171, iters: 900, time: 0.093, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.732 D_fake: 0.680 \n",
      "(epoch: 171, iters: 1000, time: 0.101, data: 0.002) G_GAN: 0.859 G_L1: 2.064 D_real: 0.551 D_fake: 0.607 \n",
      "(epoch: 171, iters: 1100, time: 0.098, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.734 D_fake: 0.604 \n",
      "(epoch: 171, iters: 1200, time: 0.098, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.707 D_fake: 0.682 \n",
      "(epoch: 171, iters: 1300, time: 0.100, data: 0.001) G_GAN: 0.948 G_L1: 3.100 D_real: 0.585 D_fake: 0.536 \n",
      "(epoch: 171, iters: 1400, time: 0.097, data: 0.002) G_GAN: 0.846 G_L1: 0.000 D_real: 0.866 D_fake: 0.640 \n",
      "(epoch: 171, iters: 1500, time: 0.110, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.736 D_fake: 0.663 \n",
      "(epoch: 171, iters: 1600, time: 0.098, data: 0.002) G_GAN: 0.853 G_L1: 1.704 D_real: 0.587 D_fake: 0.629 \n",
      "(epoch: 171, iters: 1700, time: 0.099, data: 0.001) G_GAN: 0.777 G_L1: 0.000 D_real: 0.785 D_fake: 0.620 \n",
      "(epoch: 171, iters: 1800, time: 0.106, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.729 D_fake: 0.668 \n",
      "(epoch: 171, iters: 1900, time: 0.099, data: 0.002) G_GAN: 0.881 G_L1: 4.005 D_real: 0.541 D_fake: 0.656 \n",
      "(epoch: 171, iters: 2000, time: 0.098, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.745 D_fake: 0.656 \n",
      "(epoch: 171, iters: 2100, time: 0.095, data: 0.002) G_GAN: 0.650 G_L1: 0.000 D_real: 0.652 D_fake: 0.684 \n",
      "(epoch: 171, iters: 2200, time: 0.099, data: 0.002) G_GAN: 0.821 G_L1: 1.935 D_real: 0.554 D_fake: 0.625 \n",
      "End of epoch 171 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000574\n",
      "(epoch: 172, iters: 20, time: 0.115, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.718 D_fake: 0.479 \n",
      "(epoch: 172, iters: 120, time: 0.099, data: 0.001) G_GAN: 0.658 G_L1: 0.000 D_real: 0.665 D_fake: 0.649 \n",
      "saving the latest model (epoch 172, total_steps 390000)\n",
      "(epoch: 172, iters: 220, time: 0.097, data: 0.001) G_GAN: 0.894 G_L1: 3.205 D_real: 0.558 D_fake: 0.580 \n",
      "(epoch: 172, iters: 320, time: 0.097, data: 0.001) G_GAN: 0.744 G_L1: 0.000 D_real: 0.747 D_fake: 0.654 \n",
      "(epoch: 172, iters: 420, time: 0.095, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.721 D_fake: 0.622 \n",
      "(epoch: 172, iters: 520, time: 0.096, data: 0.002) G_GAN: 0.907 G_L1: 1.603 D_real: 0.624 D_fake: 0.567 \n",
      "(epoch: 172, iters: 620, time: 0.109, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.730 D_fake: 0.634 \n",
      "(epoch: 172, iters: 720, time: 0.107, data: 0.001) G_GAN: 0.707 G_L1: 0.000 D_real: 0.711 D_fake: 0.661 \n",
      "(epoch: 172, iters: 820, time: 0.096, data: 0.001) G_GAN: 0.873 G_L1: 2.187 D_real: 0.561 D_fake: 0.590 \n",
      "(epoch: 172, iters: 920, time: 0.094, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.705 D_fake: 0.742 \n",
      "(epoch: 172, iters: 1020, time: 0.097, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.718 D_fake: 0.677 \n",
      "(epoch: 172, iters: 1120, time: 0.099, data: 0.001) G_GAN: 0.829 G_L1: 1.002 D_real: 0.631 D_fake: 0.609 \n",
      "(epoch: 172, iters: 1220, time: 0.098, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.729 D_fake: 0.663 \n",
      "(epoch: 172, iters: 1320, time: 0.100, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.723 D_fake: 0.675 \n",
      "(epoch: 172, iters: 1420, time: 0.098, data: 0.002) G_GAN: 0.861 G_L1: 2.201 D_real: 0.522 D_fake: 0.636 \n",
      "(epoch: 172, iters: 1520, time: 0.096, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.696 D_fake: 0.644 \n",
      "(epoch: 172, iters: 1620, time: 0.097, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.731 D_fake: 0.668 \n",
      "(epoch: 172, iters: 1720, time: 0.111, data: 0.002) G_GAN: 0.844 G_L1: 3.384 D_real: 0.533 D_fake: 0.586 \n",
      "(epoch: 172, iters: 1820, time: 0.097, data: 0.001) G_GAN: 0.747 G_L1: 0.000 D_real: 0.759 D_fake: 0.573 \n",
      "(epoch: 172, iters: 1920, time: 0.109, data: 0.002) G_GAN: 0.770 G_L1: 0.000 D_real: 0.779 D_fake: 0.673 \n",
      "(epoch: 172, iters: 2020, time: 0.099, data: 0.002) G_GAN: 0.800 G_L1: 1.903 D_real: 0.556 D_fake: 0.614 \n",
      "(epoch: 172, iters: 2120, time: 0.098, data: 0.002) G_GAN: 0.756 G_L1: 0.000 D_real: 0.763 D_fake: 0.633 \n",
      "(epoch: 172, iters: 2220, time: 0.100, data: 0.002) G_GAN: 0.654 G_L1: 0.000 D_real: 0.653 D_fake: 0.746 \n",
      "End of epoch 172 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000554\n",
      "(epoch: 173, iters: 40, time: 0.112, data: 0.002) G_GAN: 0.852 G_L1: 1.545 D_real: 0.561 D_fake: 0.615 \n",
      "(epoch: 173, iters: 140, time: 0.106, data: 0.001) G_GAN: 0.724 G_L1: 0.000 D_real: 0.726 D_fake: 0.663 \n",
      "(epoch: 173, iters: 240, time: 0.098, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.747 D_fake: 0.650 \n",
      "(epoch: 173, iters: 340, time: 0.099, data: 0.002) G_GAN: 0.765 G_L1: 0.576 D_real: 0.627 D_fake: 0.637 \n",
      "(epoch: 173, iters: 440, time: 0.106, data: 0.002) G_GAN: 0.770 G_L1: 0.000 D_real: 0.776 D_fake: 0.627 \n",
      "(epoch: 173, iters: 540, time: 0.093, data: 0.002) G_GAN: 0.686 G_L1: 0.000 D_real: 0.690 D_fake: 0.700 \n",
      "(epoch: 173, iters: 640, time: 0.095, data: 0.002) G_GAN: 0.927 G_L1: 3.338 D_real: 0.579 D_fake: 0.582 \n",
      "(epoch: 173, iters: 740, time: 0.093, data: 0.002) G_GAN: 0.779 G_L1: 0.000 D_real: 0.790 D_fake: 0.597 \n",
      "(epoch: 173, iters: 840, time: 0.094, data: 0.002) G_GAN: 0.700 G_L1: 0.000 D_real: 0.701 D_fake: 0.690 \n",
      "(epoch: 173, iters: 940, time: 0.099, data: 0.002) G_GAN: 0.842 G_L1: 1.224 D_real: 0.632 D_fake: 0.542 \n",
      "(epoch: 173, iters: 1040, time: 0.104, data: 0.002) G_GAN: 0.771 G_L1: 0.000 D_real: 0.780 D_fake: 0.656 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 173, iters: 1140, time: 0.095, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.715 D_fake: 0.675 \n",
      "(epoch: 173, iters: 1240, time: 0.098, data: 0.002) G_GAN: 0.937 G_L1: 2.557 D_real: 0.571 D_fake: 0.558 \n",
      "(epoch: 173, iters: 1340, time: 0.100, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.739 D_fake: 0.638 \n",
      "(epoch: 173, iters: 1440, time: 0.100, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.736 D_fake: 0.664 \n",
      "(epoch: 173, iters: 1540, time: 0.097, data: 0.002) G_GAN: 0.878 G_L1: 1.958 D_real: 0.553 D_fake: 0.591 \n",
      "(epoch: 173, iters: 1640, time: 0.107, data: 0.002) G_GAN: 0.723 G_L1: 0.000 D_real: 0.725 D_fake: 0.668 \n",
      "(epoch: 173, iters: 1740, time: 0.109, data: 0.002) G_GAN: 0.676 G_L1: 0.000 D_real: 0.688 D_fake: 0.550 \n",
      "(epoch: 173, iters: 1840, time: 0.098, data: 0.001) G_GAN: 0.826 G_L1: 0.311 D_real: 0.631 D_fake: 0.635 \n",
      "(epoch: 173, iters: 1940, time: 0.099, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.752 D_fake: 0.644 \n",
      "(epoch: 173, iters: 2040, time: 0.098, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.735 D_fake: 0.658 \n",
      "(epoch: 173, iters: 2140, time: 0.100, data: 0.001) G_GAN: 0.900 G_L1: 0.787 D_real: 0.643 D_fake: 0.608 \n",
      "(epoch: 173, iters: 2240, time: 0.113, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.720 D_fake: 0.681 \n",
      "End of epoch 173 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000535\n",
      "(epoch: 174, iters: 60, time: 0.115, data: 0.001) G_GAN: 0.677 G_L1: 0.000 D_real: 0.675 D_fake: 0.721 \n",
      "(epoch: 174, iters: 160, time: 0.105, data: 0.001) G_GAN: 0.817 G_L1: 3.185 D_real: 0.496 D_fake: 0.666 \n",
      "(epoch: 174, iters: 260, time: 0.099, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.764 D_fake: 0.581 \n",
      "(epoch: 174, iters: 360, time: 0.098, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.708 D_fake: 0.685 \n",
      "(epoch: 174, iters: 460, time: 0.099, data: 0.001) G_GAN: 0.897 G_L1: 2.593 D_real: 0.597 D_fake: 0.686 \n",
      "(epoch: 174, iters: 560, time: 0.108, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.759 D_fake: 0.660 \n",
      "saving the latest model (epoch 174, total_steps 395000)\n",
      "(epoch: 174, iters: 660, time: 0.097, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.718 D_fake: 0.680 \n",
      "(epoch: 174, iters: 760, time: 0.098, data: 0.002) G_GAN: 0.843 G_L1: 2.399 D_real: 0.576 D_fake: 0.634 \n",
      "(epoch: 174, iters: 860, time: 0.096, data: 0.002) G_GAN: 0.845 G_L1: 0.000 D_real: 0.854 D_fake: 0.583 \n",
      "(epoch: 174, iters: 960, time: 0.096, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.692 D_fake: 0.627 \n",
      "(epoch: 174, iters: 1060, time: 0.097, data: 0.002) G_GAN: 0.800 G_L1: 0.087 D_real: 0.685 D_fake: 0.654 \n",
      "(epoch: 174, iters: 1160, time: 0.097, data: 0.002) G_GAN: 0.793 G_L1: 0.000 D_real: 0.799 D_fake: 0.654 \n",
      "(epoch: 174, iters: 1260, time: 0.098, data: 0.002) G_GAN: 0.802 G_L1: 0.000 D_real: 0.810 D_fake: 0.626 \n",
      "(epoch: 174, iters: 1360, time: 0.096, data: 0.001) G_GAN: 0.800 G_L1: 4.502 D_real: 0.509 D_fake: 0.621 \n",
      "(epoch: 174, iters: 1460, time: 0.096, data: 0.001) G_GAN: 0.826 G_L1: 0.000 D_real: 0.843 D_fake: 0.672 \n",
      "(epoch: 174, iters: 1560, time: 0.095, data: 0.001) G_GAN: 0.678 G_L1: 0.000 D_real: 0.681 D_fake: 0.656 \n",
      "(epoch: 174, iters: 1660, time: 0.097, data: 0.002) G_GAN: 0.841 G_L1: 1.973 D_real: 0.561 D_fake: 0.606 \n",
      "(epoch: 174, iters: 1760, time: 0.099, data: 0.003) G_GAN: 0.810 G_L1: 0.000 D_real: 0.817 D_fake: 0.598 \n",
      "(epoch: 174, iters: 1860, time: 0.096, data: 0.001) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.699 \n",
      "(epoch: 174, iters: 1960, time: 0.098, data: 0.001) G_GAN: 0.801 G_L1: 0.417 D_real: 0.668 D_fake: 0.619 \n",
      "(epoch: 174, iters: 2060, time: 0.093, data: 0.001) G_GAN: 0.760 G_L1: 0.000 D_real: 0.764 D_fake: 0.646 \n",
      "(epoch: 174, iters: 2160, time: 0.110, data: 0.001) G_GAN: 0.718 G_L1: 0.000 D_real: 0.720 D_fake: 0.674 \n",
      "(epoch: 174, iters: 2260, time: 0.096, data: 0.002) G_GAN: 1.018 G_L1: 3.017 D_real: 0.619 D_fake: 0.638 \n",
      "End of epoch 174 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000515\n",
      "(epoch: 175, iters: 80, time: 0.103, data: 0.002) G_GAN: 0.769 G_L1: 0.000 D_real: 0.775 D_fake: 0.617 \n",
      "(epoch: 175, iters: 180, time: 0.097, data: 0.002) G_GAN: 0.688 G_L1: 0.000 D_real: 0.693 D_fake: 0.648 \n",
      "(epoch: 175, iters: 280, time: 0.098, data: 0.002) G_GAN: 0.775 G_L1: 1.052 D_real: 0.577 D_fake: 0.646 \n",
      "(epoch: 175, iters: 380, time: 0.098, data: 0.001) G_GAN: 0.729 G_L1: 0.000 D_real: 0.733 D_fake: 0.666 \n",
      "(epoch: 175, iters: 480, time: 0.097, data: 0.002) G_GAN: 0.667 G_L1: 0.000 D_real: 0.668 D_fake: 0.721 \n",
      "(epoch: 175, iters: 580, time: 0.099, data: 0.002) G_GAN: 0.854 G_L1: 4.208 D_real: 0.513 D_fake: 0.616 \n",
      "(epoch: 175, iters: 680, time: 0.097, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.734 D_fake: 0.666 \n",
      "(epoch: 175, iters: 780, time: 0.097, data: 0.001) G_GAN: 0.706 G_L1: 0.000 D_real: 0.705 D_fake: 0.698 \n",
      "(epoch: 175, iters: 880, time: 0.095, data: 0.002) G_GAN: 0.813 G_L1: 3.483 D_real: 0.485 D_fake: 0.496 \n",
      "(epoch: 175, iters: 980, time: 0.097, data: 0.003) G_GAN: 0.826 G_L1: 0.000 D_real: 0.830 D_fake: 0.608 \n",
      "(epoch: 175, iters: 1080, time: 0.095, data: 0.002) G_GAN: 0.624 G_L1: 0.000 D_real: 0.613 D_fake: 0.786 \n",
      "(epoch: 175, iters: 1180, time: 0.097, data: 0.001) G_GAN: 0.849 G_L1: 0.978 D_real: 0.627 D_fake: 0.583 \n",
      "(epoch: 175, iters: 1280, time: 0.099, data: 0.002) G_GAN: 0.846 G_L1: 0.000 D_real: 0.852 D_fake: 0.572 \n",
      "(epoch: 175, iters: 1380, time: 0.096, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.720 D_fake: 0.680 \n",
      "(epoch: 175, iters: 1480, time: 0.109, data: 0.001) G_GAN: 0.827 G_L1: 1.681 D_real: 0.564 D_fake: 0.603 \n",
      "(epoch: 175, iters: 1580, time: 0.108, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.738 D_fake: 0.590 \n",
      "(epoch: 175, iters: 1680, time: 0.097, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.719 D_fake: 0.636 \n",
      "(epoch: 175, iters: 1780, time: 0.097, data: 0.001) G_GAN: 0.780 G_L1: 3.487 D_real: 0.496 D_fake: 0.651 \n",
      "(epoch: 175, iters: 1880, time: 0.096, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.745 D_fake: 0.667 \n",
      "(epoch: 175, iters: 1980, time: 0.097, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.689 D_fake: 0.705 \n",
      "(epoch: 175, iters: 2080, time: 0.096, data: 0.001) G_GAN: 0.862 G_L1: 2.663 D_real: 0.543 D_fake: 0.576 \n",
      "(epoch: 175, iters: 2180, time: 0.097, data: 0.001) G_GAN: 0.683 G_L1: 0.000 D_real: 0.690 D_fake: 0.699 \n",
      "(epoch: 175, iters: 2280, time: 0.107, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.706 D_fake: 0.644 \n",
      "saving the model at the end of epoch 175, iters 399000\n",
      "End of epoch 175 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000495\n",
      "(epoch: 176, iters: 100, time: 0.121, data: 0.288) G_GAN: 0.892 G_L1: 2.739 D_real: 0.574 D_fake: 0.714 \n",
      "(epoch: 176, iters: 200, time: 0.098, data: 0.002) G_GAN: 0.798 G_L1: 0.000 D_real: 0.806 D_fake: 0.667 \n",
      "(epoch: 176, iters: 300, time: 0.096, data: 0.001) G_GAN: 0.786 G_L1: 0.000 D_real: 0.787 D_fake: 0.624 \n",
      "(epoch: 176, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.851 G_L1: 1.900 D_real: 0.555 D_fake: 0.659 \n",
      "(epoch: 176, iters: 500, time: 0.099, data: 0.002) G_GAN: 0.666 G_L1: 0.000 D_real: 0.667 D_fake: 0.722 \n",
      "(epoch: 176, iters: 600, time: 0.100, data: 0.001) G_GAN: 0.699 G_L1: 0.000 D_real: 0.701 D_fake: 0.665 \n",
      "(epoch: 176, iters: 700, time: 0.100, data: 0.002) G_GAN: 1.020 G_L1: 2.269 D_real: 0.596 D_fake: 0.528 \n",
      "(epoch: 176, iters: 800, time: 0.099, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.745 D_fake: 0.662 \n",
      "(epoch: 176, iters: 900, time: 0.105, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.719 D_fake: 0.693 \n",
      "(epoch: 176, iters: 1000, time: 0.099, data: 0.002) G_GAN: 0.974 G_L1: 2.064 D_real: 0.643 D_fake: 0.528 \n",
      "saving the latest model (epoch 176, total_steps 400000)\n",
      "(epoch: 176, iters: 1100, time: 0.100, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.741 D_fake: 0.658 \n",
      "(epoch: 176, iters: 1200, time: 0.100, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.723 D_fake: 0.667 \n",
      "(epoch: 176, iters: 1300, time: 0.097, data: 0.002) G_GAN: 0.948 G_L1: 3.100 D_real: 0.585 D_fake: 0.623 \n",
      "(epoch: 176, iters: 1400, time: 0.098, data: 0.002) G_GAN: 0.790 G_L1: 0.000 D_real: 0.796 D_fake: 0.656 \n",
      "(epoch: 176, iters: 1500, time: 0.100, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.745 D_fake: 0.655 \n",
      "(epoch: 176, iters: 1600, time: 0.098, data: 0.002) G_GAN: 0.874 G_L1: 1.704 D_real: 0.588 D_fake: 0.642 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 176, iters: 1700, time: 0.098, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.736 D_fake: 0.587 \n",
      "(epoch: 176, iters: 1800, time: 0.097, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.735 D_fake: 0.586 \n",
      "(epoch: 176, iters: 1900, time: 0.098, data: 0.002) G_GAN: 0.877 G_L1: 4.005 D_real: 0.524 D_fake: 0.581 \n",
      "(epoch: 176, iters: 2000, time: 0.097, data: 0.002) G_GAN: 0.786 G_L1: 0.000 D_real: 0.789 D_fake: 0.617 \n",
      "(epoch: 176, iters: 2100, time: 0.096, data: 0.002) G_GAN: 0.685 G_L1: 0.000 D_real: 0.697 D_fake: 0.627 \n",
      "(epoch: 176, iters: 2200, time: 0.111, data: 0.002) G_GAN: 0.807 G_L1: 1.935 D_real: 0.549 D_fake: 0.534 \n",
      "End of epoch 176 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000475\n",
      "(epoch: 177, iters: 20, time: 0.107, data: 0.001) G_GAN: 0.749 G_L1: 0.000 D_real: 0.757 D_fake: 0.619 \n",
      "(epoch: 177, iters: 120, time: 0.096, data: 0.002) G_GAN: 0.678 G_L1: 0.000 D_real: 0.683 D_fake: 0.718 \n",
      "(epoch: 177, iters: 220, time: 0.101, data: 0.001) G_GAN: 0.890 G_L1: 3.205 D_real: 0.555 D_fake: 0.602 \n",
      "(epoch: 177, iters: 320, time: 0.096, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.743 D_fake: 0.587 \n",
      "(epoch: 177, iters: 420, time: 0.096, data: 0.001) G_GAN: 0.705 G_L1: 0.000 D_real: 0.707 D_fake: 0.728 \n",
      "(epoch: 177, iters: 520, time: 0.096, data: 0.002) G_GAN: 0.847 G_L1: 1.603 D_real: 0.598 D_fake: 0.604 \n",
      "(epoch: 177, iters: 620, time: 0.097, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.739 D_fake: 0.664 \n",
      "(epoch: 177, iters: 720, time: 0.097, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.710 D_fake: 0.690 \n",
      "(epoch: 177, iters: 820, time: 0.095, data: 0.002) G_GAN: 0.890 G_L1: 2.187 D_real: 0.568 D_fake: 0.579 \n",
      "(epoch: 177, iters: 920, time: 0.095, data: 0.002) G_GAN: 0.702 G_L1: 0.000 D_real: 0.707 D_fake: 0.686 \n",
      "(epoch: 177, iters: 1020, time: 0.098, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.719 D_fake: 0.700 \n",
      "(epoch: 177, iters: 1120, time: 0.097, data: 0.001) G_GAN: 0.804 G_L1: 1.002 D_real: 0.609 D_fake: 0.604 \n",
      "(epoch: 177, iters: 1220, time: 0.098, data: 0.001) G_GAN: 0.712 G_L1: 0.000 D_real: 0.713 D_fake: 0.678 \n",
      "(epoch: 177, iters: 1320, time: 0.112, data: 0.001) G_GAN: 0.737 G_L1: 0.000 D_real: 0.740 D_fake: 0.596 \n",
      "(epoch: 177, iters: 1420, time: 0.097, data: 0.001) G_GAN: 0.867 G_L1: 2.201 D_real: 0.525 D_fake: 0.625 \n",
      "(epoch: 177, iters: 1520, time: 0.104, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.706 D_fake: 0.649 \n",
      "(epoch: 177, iters: 1620, time: 0.096, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.769 D_fake: 0.644 \n",
      "(epoch: 177, iters: 1720, time: 0.112, data: 0.002) G_GAN: 0.860 G_L1: 3.384 D_real: 0.531 D_fake: 0.640 \n",
      "(epoch: 177, iters: 1820, time: 0.100, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.732 D_fake: 0.649 \n",
      "(epoch: 177, iters: 1920, time: 0.097, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.747 D_fake: 0.672 \n",
      "(epoch: 177, iters: 2020, time: 0.101, data: 0.001) G_GAN: 0.833 G_L1: 1.903 D_real: 0.599 D_fake: 0.606 \n",
      "(epoch: 177, iters: 2120, time: 0.096, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.767 D_fake: 0.638 \n",
      "(epoch: 177, iters: 2220, time: 0.101, data: 0.002) G_GAN: 0.677 G_L1: 0.000 D_real: 0.685 D_fake: 0.537 \n",
      "End of epoch 177 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000455\n",
      "(epoch: 178, iters: 40, time: 0.109, data: 0.001) G_GAN: 0.845 G_L1: 1.545 D_real: 0.553 D_fake: 0.627 \n",
      "(epoch: 178, iters: 140, time: 0.097, data: 0.001) G_GAN: 0.715 G_L1: 0.000 D_real: 0.717 D_fake: 0.672 \n",
      "(epoch: 178, iters: 240, time: 0.097, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.746 D_fake: 0.650 \n",
      "(epoch: 178, iters: 340, time: 0.099, data: 0.002) G_GAN: 0.749 G_L1: 0.576 D_real: 0.605 D_fake: 0.578 \n",
      "(epoch: 178, iters: 440, time: 0.095, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.769 D_fake: 0.634 \n",
      "(epoch: 178, iters: 540, time: 0.094, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.713 D_fake: 0.607 \n",
      "(epoch: 178, iters: 640, time: 0.095, data: 0.002) G_GAN: 0.960 G_L1: 3.338 D_real: 0.596 D_fake: 0.533 \n",
      "(epoch: 178, iters: 740, time: 0.095, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.769 D_fake: 0.631 \n",
      "(epoch: 178, iters: 840, time: 0.096, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.701 D_fake: 0.690 \n",
      "(epoch: 178, iters: 940, time: 0.095, data: 0.002) G_GAN: 0.888 G_L1: 1.224 D_real: 0.679 D_fake: 0.559 \n",
      "(epoch: 178, iters: 1040, time: 0.094, data: 0.001) G_GAN: 0.798 G_L1: 0.000 D_real: 0.810 D_fake: 0.620 \n",
      "(epoch: 178, iters: 1140, time: 0.096, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.706 D_fake: 0.684 \n",
      "(epoch: 178, iters: 1240, time: 0.097, data: 0.001) G_GAN: 0.949 G_L1: 2.557 D_real: 0.597 D_fake: 0.547 \n",
      "(epoch: 178, iters: 1340, time: 0.099, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.762 D_fake: 0.648 \n",
      "(epoch: 178, iters: 1440, time: 0.097, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.741 D_fake: 0.661 \n",
      "saving the latest model (epoch 178, total_steps 405000)\n",
      "(epoch: 178, iters: 1540, time: 0.098, data: 0.001) G_GAN: 0.863 G_L1: 1.958 D_real: 0.546 D_fake: 0.618 \n",
      "(epoch: 178, iters: 1640, time: 0.097, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.723 D_fake: 0.637 \n",
      "(epoch: 178, iters: 1740, time: 0.099, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.736 D_fake: 0.659 \n",
      "(epoch: 178, iters: 1840, time: 0.098, data: 0.001) G_GAN: 0.836 G_L1: 0.311 D_real: 0.640 D_fake: 0.628 \n",
      "(epoch: 178, iters: 1940, time: 0.099, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.747 D_fake: 0.649 \n",
      "(epoch: 178, iters: 2040, time: 0.104, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.702 D_fake: 0.621 \n",
      "(epoch: 178, iters: 2140, time: 0.099, data: 0.001) G_GAN: 0.912 G_L1: 0.787 D_real: 0.626 D_fake: 0.575 \n",
      "(epoch: 178, iters: 2240, time: 0.098, data: 0.002) G_GAN: 0.621 G_L1: 0.000 D_real: 0.614 D_fake: 0.805 \n",
      "End of epoch 178 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000436\n",
      "(epoch: 179, iters: 60, time: 0.106, data: 0.002) G_GAN: 0.672 G_L1: 0.000 D_real: 0.677 D_fake: 0.670 \n",
      "(epoch: 179, iters: 160, time: 0.096, data: 0.002) G_GAN: 0.809 G_L1: 3.185 D_real: 0.494 D_fake: 0.639 \n",
      "(epoch: 179, iters: 260, time: 0.100, data: 0.001) G_GAN: 0.732 G_L1: 0.000 D_real: 0.745 D_fake: 0.625 \n",
      "(epoch: 179, iters: 360, time: 0.096, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.707 D_fake: 0.579 \n",
      "(epoch: 179, iters: 460, time: 0.099, data: 0.002) G_GAN: 0.875 G_L1: 2.593 D_real: 0.577 D_fake: 0.581 \n",
      "(epoch: 179, iters: 560, time: 0.097, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.761 D_fake: 0.641 \n",
      "(epoch: 179, iters: 660, time: 0.099, data: 0.001) G_GAN: 0.724 G_L1: 0.000 D_real: 0.727 D_fake: 0.673 \n",
      "(epoch: 179, iters: 760, time: 0.099, data: 0.001) G_GAN: 0.879 G_L1: 2.399 D_real: 0.557 D_fake: 0.559 \n",
      "(epoch: 179, iters: 860, time: 0.095, data: 0.002) G_GAN: 0.823 G_L1: 0.000 D_real: 0.834 D_fake: 0.601 \n",
      "(epoch: 179, iters: 960, time: 0.106, data: 0.001) G_GAN: 0.699 G_L1: 0.000 D_real: 0.700 D_fake: 0.692 \n",
      "(epoch: 179, iters: 1060, time: 0.097, data: 0.002) G_GAN: 0.779 G_L1: 0.087 D_real: 0.628 D_fake: 0.671 \n",
      "(epoch: 179, iters: 1160, time: 0.096, data: 0.002) G_GAN: 0.779 G_L1: 0.000 D_real: 0.783 D_fake: 0.626 \n",
      "(epoch: 179, iters: 1260, time: 0.107, data: 0.002) G_GAN: 0.787 G_L1: 0.000 D_real: 0.790 D_fake: 0.656 \n",
      "(epoch: 179, iters: 1360, time: 0.097, data: 0.001) G_GAN: 0.788 G_L1: 4.502 D_real: 0.472 D_fake: 0.628 \n",
      "(epoch: 179, iters: 1460, time: 0.099, data: 0.001) G_GAN: 0.810 G_L1: 0.000 D_real: 0.816 D_fake: 0.602 \n",
      "(epoch: 179, iters: 1560, time: 0.097, data: 0.001) G_GAN: 0.701 G_L1: 0.000 D_real: 0.702 D_fake: 0.690 \n",
      "(epoch: 179, iters: 1660, time: 0.108, data: 0.002) G_GAN: 0.865 G_L1: 1.973 D_real: 0.582 D_fake: 0.591 \n",
      "(epoch: 179, iters: 1760, time: 0.098, data: 0.002) G_GAN: 0.779 G_L1: 0.000 D_real: 0.789 D_fake: 0.622 \n",
      "(epoch: 179, iters: 1860, time: 0.096, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.709 D_fake: 0.688 \n",
      "(epoch: 179, iters: 1960, time: 0.099, data: 0.001) G_GAN: 0.801 G_L1: 0.417 D_real: 0.670 D_fake: 0.602 \n",
      "(epoch: 179, iters: 2060, time: 0.093, data: 0.002) G_GAN: 0.787 G_L1: 0.000 D_real: 0.793 D_fake: 0.615 \n",
      "(epoch: 179, iters: 2160, time: 0.097, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.730 D_fake: 0.694 \n",
      "(epoch: 179, iters: 2260, time: 0.093, data: 0.002) G_GAN: 0.918 G_L1: 3.017 D_real: 0.569 D_fake: 0.573 \n",
      "End of epoch 179 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 180, iters: 80, time: 0.113, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.744 D_fake: 0.658 \n",
      "(epoch: 180, iters: 180, time: 0.096, data: 0.001) G_GAN: 0.671 G_L1: 0.000 D_real: 0.670 D_fake: 0.720 \n",
      "(epoch: 180, iters: 280, time: 0.099, data: 0.002) G_GAN: 0.808 G_L1: 1.052 D_real: 0.599 D_fake: 0.620 \n",
      "(epoch: 180, iters: 380, time: 0.101, data: 0.001) G_GAN: 0.727 G_L1: 0.000 D_real: 0.730 D_fake: 0.667 \n",
      "(epoch: 180, iters: 480, time: 0.099, data: 0.001) G_GAN: 0.687 G_L1: 0.000 D_real: 0.688 D_fake: 0.701 \n",
      "(epoch: 180, iters: 580, time: 0.101, data: 0.002) G_GAN: 0.853 G_L1: 4.208 D_real: 0.511 D_fake: 0.614 \n",
      "(epoch: 180, iters: 680, time: 0.097, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.715 D_fake: 0.682 \n",
      "(epoch: 180, iters: 780, time: 0.096, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.707 D_fake: 0.646 \n",
      "(epoch: 180, iters: 880, time: 0.095, data: 0.002) G_GAN: 0.846 G_L1: 3.483 D_real: 0.486 D_fake: 0.507 \n",
      "(epoch: 180, iters: 980, time: 0.097, data: 0.001) G_GAN: 0.839 G_L1: 0.000 D_real: 0.843 D_fake: 0.595 \n",
      "(epoch: 180, iters: 1080, time: 0.097, data: 0.001) G_GAN: 0.677 G_L1: 0.000 D_real: 0.674 D_fake: 0.717 \n",
      "(epoch: 180, iters: 1180, time: 0.111, data: 0.001) G_GAN: 0.825 G_L1: 0.978 D_real: 0.621 D_fake: 0.602 \n",
      "(epoch: 180, iters: 1280, time: 0.110, data: 0.001) G_GAN: 0.790 G_L1: 0.000 D_real: 0.799 D_fake: 0.586 \n",
      "(epoch: 180, iters: 1380, time: 0.097, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.752 D_fake: 0.677 \n",
      "(epoch: 180, iters: 1480, time: 0.099, data: 0.002) G_GAN: 0.832 G_L1: 1.681 D_real: 0.569 D_fake: 0.620 \n",
      "(epoch: 180, iters: 1580, time: 0.096, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.747 D_fake: 0.646 \n",
      "(epoch: 180, iters: 1680, time: 0.100, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.708 D_fake: 0.687 \n",
      "(epoch: 180, iters: 1780, time: 0.097, data: 0.001) G_GAN: 0.800 G_L1: 3.487 D_real: 0.515 D_fake: 0.611 \n",
      "(epoch: 180, iters: 1880, time: 0.098, data: 0.001) G_GAN: 0.742 G_L1: 0.000 D_real: 0.745 D_fake: 0.656 \n",
      "saving the latest model (epoch 180, total_steps 410000)\n",
      "(epoch: 180, iters: 1980, time: 0.098, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.701 \n",
      "(epoch: 180, iters: 2080, time: 0.108, data: 0.002) G_GAN: 0.842 G_L1: 2.663 D_real: 0.514 D_fake: 0.619 \n",
      "(epoch: 180, iters: 2180, time: 0.098, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.692 D_fake: 0.697 \n",
      "(epoch: 180, iters: 2280, time: 0.097, data: 0.002) G_GAN: 0.687 G_L1: 0.000 D_real: 0.688 D_fake: 0.713 \n",
      "saving the model at the end of epoch 180, iters 410400\n",
      "End of epoch 180 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0000396\n",
      "(epoch: 181, iters: 100, time: 0.123, data: 0.291) G_GAN: 0.874 G_L1: 2.739 D_real: 0.561 D_fake: 0.692 \n",
      "(epoch: 181, iters: 200, time: 0.097, data: 0.002) G_GAN: 0.775 G_L1: 0.000 D_real: 0.781 D_fake: 0.611 \n",
      "(epoch: 181, iters: 300, time: 0.112, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.738 D_fake: 0.671 \n",
      "(epoch: 181, iters: 400, time: 0.104, data: 0.002) G_GAN: 0.924 G_L1: 1.900 D_real: 0.552 D_fake: 0.617 \n",
      "(epoch: 181, iters: 500, time: 0.102, data: 0.002) G_GAN: 0.678 G_L1: 0.000 D_real: 0.678 D_fake: 0.712 \n",
      "(epoch: 181, iters: 600, time: 0.101, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.699 D_fake: 0.654 \n",
      "(epoch: 181, iters: 700, time: 0.096, data: 0.002) G_GAN: 0.976 G_L1: 2.269 D_real: 0.570 D_fake: 0.586 \n",
      "(epoch: 181, iters: 800, time: 0.099, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.769 D_fake: 0.641 \n",
      "(epoch: 181, iters: 900, time: 0.091, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.760 D_fake: 0.657 \n",
      "(epoch: 181, iters: 1000, time: 0.111, data: 0.002) G_GAN: 0.921 G_L1: 2.064 D_real: 0.598 D_fake: 0.655 \n",
      "(epoch: 181, iters: 1100, time: 0.101, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.724 D_fake: 0.673 \n",
      "(epoch: 181, iters: 1200, time: 0.096, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.711 D_fake: 0.585 \n",
      "(epoch: 181, iters: 1300, time: 0.097, data: 0.002) G_GAN: 0.913 G_L1: 3.100 D_real: 0.549 D_fake: 0.573 \n",
      "(epoch: 181, iters: 1400, time: 0.099, data: 0.002) G_GAN: 0.818 G_L1: 0.000 D_real: 0.823 D_fake: 0.598 \n",
      "(epoch: 181, iters: 1500, time: 0.096, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.755 D_fake: 0.647 \n",
      "(epoch: 181, iters: 1600, time: 0.108, data: 0.002) G_GAN: 0.884 G_L1: 1.704 D_real: 0.592 D_fake: 0.586 \n",
      "(epoch: 181, iters: 1700, time: 0.099, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.757 D_fake: 0.646 \n",
      "(epoch: 181, iters: 1800, time: 0.107, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.706 D_fake: 0.686 \n",
      "(epoch: 181, iters: 1900, time: 0.098, data: 0.002) G_GAN: 0.857 G_L1: 4.005 D_real: 0.501 D_fake: 0.602 \n",
      "(epoch: 181, iters: 2000, time: 0.108, data: 0.002) G_GAN: 0.766 G_L1: 0.000 D_real: 0.770 D_fake: 0.634 \n",
      "(epoch: 181, iters: 2100, time: 0.095, data: 0.002) G_GAN: 0.650 G_L1: 0.000 D_real: 0.660 D_fake: 0.658 \n",
      "(epoch: 181, iters: 2200, time: 0.112, data: 0.003) G_GAN: 0.785 G_L1: 1.935 D_real: 0.518 D_fake: 0.668 \n",
      "End of epoch 181 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000376\n",
      "(epoch: 182, iters: 20, time: 0.104, data: 0.002) G_GAN: 0.787 G_L1: 0.000 D_real: 0.791 D_fake: 0.619 \n",
      "(epoch: 182, iters: 120, time: 0.097, data: 0.002) G_GAN: 0.688 G_L1: 0.000 D_real: 0.689 D_fake: 0.701 \n",
      "(epoch: 182, iters: 220, time: 0.099, data: 0.002) G_GAN: 0.875 G_L1: 3.205 D_real: 0.510 D_fake: 0.593 \n",
      "(epoch: 182, iters: 320, time: 0.099, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.750 D_fake: 0.592 \n",
      "(epoch: 182, iters: 420, time: 0.095, data: 0.001) G_GAN: 0.719 G_L1: 0.000 D_real: 0.722 D_fake: 0.686 \n",
      "(epoch: 182, iters: 520, time: 0.097, data: 0.002) G_GAN: 0.842 G_L1: 1.603 D_real: 0.602 D_fake: 0.605 \n",
      "(epoch: 182, iters: 620, time: 0.099, data: 0.002) G_GAN: 0.736 G_L1: 0.000 D_real: 0.741 D_fake: 0.616 \n",
      "(epoch: 182, iters: 720, time: 0.101, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.712 D_fake: 0.683 \n",
      "(epoch: 182, iters: 820, time: 0.095, data: 0.001) G_GAN: 0.899 G_L1: 2.187 D_real: 0.588 D_fake: 0.658 \n",
      "(epoch: 182, iters: 920, time: 0.093, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.698 D_fake: 0.624 \n",
      "(epoch: 182, iters: 1020, time: 0.096, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.718 D_fake: 0.678 \n",
      "(epoch: 182, iters: 1120, time: 0.096, data: 0.002) G_GAN: 0.823 G_L1: 1.002 D_real: 0.623 D_fake: 0.572 \n",
      "(epoch: 182, iters: 1220, time: 0.107, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.732 D_fake: 0.660 \n",
      "(epoch: 182, iters: 1320, time: 0.098, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.734 D_fake: 0.665 \n",
      "(epoch: 182, iters: 1420, time: 0.099, data: 0.002) G_GAN: 0.918 G_L1: 2.201 D_real: 0.552 D_fake: 0.593 \n",
      "(epoch: 182, iters: 1520, time: 0.099, data: 0.000) G_GAN: 0.748 G_L1: 0.000 D_real: 0.752 D_fake: 0.592 \n",
      "(epoch: 182, iters: 1620, time: 0.096, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.768 D_fake: 0.630 \n",
      "(epoch: 182, iters: 1720, time: 0.099, data: 0.002) G_GAN: 0.873 G_L1: 3.384 D_real: 0.539 D_fake: 0.601 \n",
      "(epoch: 182, iters: 1820, time: 0.099, data: 0.002) G_GAN: 0.768 G_L1: 0.000 D_real: 0.774 D_fake: 0.628 \n",
      "(epoch: 182, iters: 1920, time: 0.100, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.742 D_fake: 0.698 \n",
      "(epoch: 182, iters: 2020, time: 0.099, data: 0.001) G_GAN: 0.836 G_L1: 1.903 D_real: 0.586 D_fake: 0.605 \n",
      "(epoch: 182, iters: 2120, time: 0.097, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.757 D_fake: 0.647 \n",
      "(epoch: 182, iters: 2220, time: 0.100, data: 0.001) G_GAN: 0.686 G_L1: 0.000 D_real: 0.687 D_fake: 0.656 \n",
      "End of epoch 182 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000356\n",
      "(epoch: 183, iters: 40, time: 0.114, data: 0.002) G_GAN: 0.856 G_L1: 1.545 D_real: 0.563 D_fake: 0.638 \n",
      "saving the latest model (epoch 183, total_steps 415000)\n",
      "(epoch: 183, iters: 140, time: 0.098, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.725 D_fake: 0.665 \n",
      "(epoch: 183, iters: 240, time: 0.099, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.709 D_fake: 0.686 \n",
      "(epoch: 183, iters: 340, time: 0.098, data: 0.002) G_GAN: 0.748 G_L1: 0.576 D_real: 0.608 D_fake: 0.651 \n",
      "(epoch: 183, iters: 440, time: 0.096, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.735 D_fake: 0.666 \n",
      "(epoch: 183, iters: 540, time: 0.094, data: 0.002) G_GAN: 0.677 G_L1: 0.000 D_real: 0.678 D_fake: 0.714 \n",
      "(epoch: 183, iters: 640, time: 0.108, data: 0.002) G_GAN: 0.865 G_L1: 3.338 D_real: 0.539 D_fake: 0.603 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 183, iters: 740, time: 0.105, data: 0.001) G_GAN: 0.777 G_L1: 0.000 D_real: 0.784 D_fake: 0.544 \n",
      "(epoch: 183, iters: 840, time: 0.097, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.703 D_fake: 0.686 \n",
      "(epoch: 183, iters: 940, time: 0.098, data: 0.002) G_GAN: 0.846 G_L1: 1.224 D_real: 0.637 D_fake: 0.649 \n",
      "(epoch: 183, iters: 1040, time: 0.096, data: 0.002) G_GAN: 0.813 G_L1: 0.000 D_real: 0.827 D_fake: 0.612 \n",
      "(epoch: 183, iters: 1140, time: 0.098, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.730 D_fake: 0.662 \n",
      "(epoch: 183, iters: 1240, time: 0.098, data: 0.002) G_GAN: 1.000 G_L1: 2.557 D_real: 0.613 D_fake: 0.589 \n",
      "(epoch: 183, iters: 1340, time: 0.098, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.749 D_fake: 0.662 \n",
      "(epoch: 183, iters: 1440, time: 0.108, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.760 D_fake: 0.641 \n",
      "(epoch: 183, iters: 1540, time: 0.101, data: 0.002) G_GAN: 0.890 G_L1: 1.958 D_real: 0.584 D_fake: 0.636 \n",
      "(epoch: 183, iters: 1640, time: 0.097, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.718 D_fake: 0.619 \n",
      "(epoch: 183, iters: 1740, time: 0.099, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.734 D_fake: 0.663 \n",
      "(epoch: 183, iters: 1840, time: 0.110, data: 0.002) G_GAN: 0.841 G_L1: 0.311 D_real: 0.648 D_fake: 0.636 \n",
      "(epoch: 183, iters: 1940, time: 0.109, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.764 D_fake: 0.711 \n",
      "(epoch: 183, iters: 2040, time: 0.098, data: 0.002) G_GAN: 0.719 G_L1: 0.000 D_real: 0.720 D_fake: 0.673 \n",
      "(epoch: 183, iters: 2140, time: 0.099, data: 0.002) G_GAN: 0.963 G_L1: 0.787 D_real: 0.666 D_fake: 0.543 \n",
      "(epoch: 183, iters: 2240, time: 0.097, data: 0.002) G_GAN: 0.735 G_L1: 0.000 D_real: 0.738 D_fake: 0.662 \n",
      "End of epoch 183 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000337\n",
      "(epoch: 184, iters: 60, time: 0.108, data: 0.002) G_GAN: 0.677 G_L1: 0.000 D_real: 0.676 D_fake: 0.721 \n",
      "(epoch: 184, iters: 160, time: 0.099, data: 0.001) G_GAN: 0.845 G_L1: 3.185 D_real: 0.506 D_fake: 0.648 \n",
      "(epoch: 184, iters: 260, time: 0.098, data: 0.001) G_GAN: 0.761 G_L1: 0.000 D_real: 0.766 D_fake: 0.642 \n",
      "(epoch: 184, iters: 360, time: 0.096, data: 0.002) G_GAN: 0.703 G_L1: 0.000 D_real: 0.702 D_fake: 0.693 \n",
      "(epoch: 184, iters: 460, time: 0.108, data: 0.002) G_GAN: 0.876 G_L1: 2.593 D_real: 0.571 D_fake: 0.660 \n",
      "(epoch: 184, iters: 560, time: 0.099, data: 0.001) G_GAN: 0.756 G_L1: 0.000 D_real: 0.759 D_fake: 0.643 \n",
      "(epoch: 184, iters: 660, time: 0.098, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.725 D_fake: 0.675 \n",
      "(epoch: 184, iters: 760, time: 0.098, data: 0.001) G_GAN: 0.847 G_L1: 2.399 D_real: 0.556 D_fake: 0.709 \n",
      "(epoch: 184, iters: 860, time: 0.094, data: 0.001) G_GAN: 0.844 G_L1: 0.000 D_real: 0.848 D_fake: 0.591 \n",
      "(epoch: 184, iters: 960, time: 0.095, data: 0.002) G_GAN: 0.715 G_L1: 0.000 D_real: 0.716 D_fake: 0.675 \n",
      "(epoch: 184, iters: 1060, time: 0.109, data: 0.002) G_GAN: 0.836 G_L1: 0.087 D_real: 0.671 D_fake: 0.669 \n",
      "(epoch: 184, iters: 1160, time: 0.095, data: 0.001) G_GAN: 0.787 G_L1: 0.000 D_real: 0.793 D_fake: 0.630 \n",
      "(epoch: 184, iters: 1260, time: 0.100, data: 0.002) G_GAN: 0.797 G_L1: 0.000 D_real: 0.805 D_fake: 0.656 \n",
      "(epoch: 184, iters: 1360, time: 0.108, data: 0.002) G_GAN: 0.794 G_L1: 4.502 D_real: 0.486 D_fake: 0.579 \n",
      "(epoch: 184, iters: 1460, time: 0.097, data: 0.001) G_GAN: 0.794 G_L1: 0.000 D_real: 0.806 D_fake: 0.587 \n",
      "(epoch: 184, iters: 1560, time: 0.097, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.698 \n",
      "(epoch: 184, iters: 1660, time: 0.098, data: 0.002) G_GAN: 0.859 G_L1: 1.973 D_real: 0.565 D_fake: 0.577 \n",
      "(epoch: 184, iters: 1760, time: 0.099, data: 0.002) G_GAN: 0.808 G_L1: 0.000 D_real: 0.813 D_fake: 0.602 \n",
      "(epoch: 184, iters: 1860, time: 0.103, data: 0.002) G_GAN: 0.725 G_L1: 0.000 D_real: 0.728 D_fake: 0.622 \n",
      "(epoch: 184, iters: 1960, time: 0.099, data: 0.001) G_GAN: 0.799 G_L1: 0.417 D_real: 0.650 D_fake: 0.651 \n",
      "(epoch: 184, iters: 2060, time: 0.094, data: 0.002) G_GAN: 0.771 G_L1: 0.000 D_real: 0.773 D_fake: 0.632 \n",
      "(epoch: 184, iters: 2160, time: 0.098, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.730 D_fake: 0.636 \n",
      "(epoch: 184, iters: 2260, time: 0.094, data: 0.002) G_GAN: 0.957 G_L1: 3.017 D_real: 0.572 D_fake: 0.539 \n",
      "End of epoch 184 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000317\n",
      "(epoch: 185, iters: 80, time: 0.105, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.758 D_fake: 0.608 \n",
      "(epoch: 185, iters: 180, time: 0.099, data: 0.001) G_GAN: 0.685 G_L1: 0.000 D_real: 0.685 D_fake: 0.705 \n",
      "(epoch: 185, iters: 280, time: 0.096, data: 0.001) G_GAN: 0.783 G_L1: 1.052 D_real: 0.594 D_fake: 0.662 \n",
      "(epoch: 185, iters: 380, time: 0.098, data: 0.001) G_GAN: 0.754 G_L1: 0.000 D_real: 0.758 D_fake: 0.642 \n",
      "(epoch: 185, iters: 480, time: 0.098, data: 0.001) G_GAN: 0.695 G_L1: 0.000 D_real: 0.696 D_fake: 0.691 \n",
      "saving the latest model (epoch 185, total_steps 420000)\n",
      "(epoch: 185, iters: 580, time: 0.100, data: 0.002) G_GAN: 0.849 G_L1: 4.208 D_real: 0.511 D_fake: 0.692 \n",
      "(epoch: 185, iters: 680, time: 0.109, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.745 D_fake: 0.611 \n",
      "(epoch: 185, iters: 780, time: 0.098, data: 0.002) G_GAN: 0.699 G_L1: 0.000 D_real: 0.702 D_fake: 0.654 \n",
      "(epoch: 185, iters: 880, time: 0.095, data: 0.002) G_GAN: 0.853 G_L1: 3.483 D_real: 0.477 D_fake: 0.634 \n",
      "(epoch: 185, iters: 980, time: 0.100, data: 0.001) G_GAN: 0.845 G_L1: 0.000 D_real: 0.850 D_fake: 0.593 \n",
      "(epoch: 185, iters: 1080, time: 0.095, data: 0.002) G_GAN: 0.670 G_L1: 0.000 D_real: 0.672 D_fake: 0.653 \n",
      "(epoch: 185, iters: 1180, time: 0.108, data: 0.002) G_GAN: 0.802 G_L1: 0.978 D_real: 0.585 D_fake: 0.622 \n",
      "(epoch: 185, iters: 1280, time: 0.097, data: 0.001) G_GAN: 0.814 G_L1: 0.000 D_real: 0.818 D_fake: 0.596 \n",
      "(epoch: 185, iters: 1380, time: 0.096, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.743 D_fake: 0.659 \n",
      "(epoch: 185, iters: 1480, time: 0.098, data: 0.001) G_GAN: 0.839 G_L1: 1.681 D_real: 0.552 D_fake: 0.617 \n",
      "(epoch: 185, iters: 1580, time: 0.097, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.740 D_fake: 0.650 \n",
      "(epoch: 185, iters: 1680, time: 0.097, data: 0.001) G_GAN: 0.736 G_L1: 0.000 D_real: 0.739 D_fake: 0.614 \n",
      "(epoch: 185, iters: 1780, time: 0.107, data: 0.002) G_GAN: 0.800 G_L1: 3.487 D_real: 0.504 D_fake: 0.636 \n",
      "(epoch: 185, iters: 1880, time: 0.099, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.756 D_fake: 0.648 \n",
      "(epoch: 185, iters: 1980, time: 0.097, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.683 D_fake: 0.553 \n",
      "(epoch: 185, iters: 2080, time: 0.098, data: 0.002) G_GAN: 0.890 G_L1: 2.663 D_real: 0.537 D_fake: 0.599 \n",
      "(epoch: 185, iters: 2180, time: 0.097, data: 0.002) G_GAN: 0.701 G_L1: 0.000 D_real: 0.704 D_fake: 0.685 \n",
      "(epoch: 185, iters: 2280, time: 0.095, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.696 D_fake: 0.617 \n",
      "saving the model at the end of epoch 185, iters 421800\n",
      "End of epoch 185 / 200 \t Time Taken: 127 sec\n",
      "learning rate = 0.0000297\n",
      "(epoch: 186, iters: 100, time: 0.106, data: 0.294) G_GAN: 0.882 G_L1: 2.739 D_real: 0.557 D_fake: 0.594 \n",
      "(epoch: 186, iters: 200, time: 0.094, data: 0.001) G_GAN: 0.777 G_L1: 0.000 D_real: 0.782 D_fake: 0.608 \n",
      "(epoch: 186, iters: 300, time: 0.107, data: 0.002) G_GAN: 0.769 G_L1: 0.000 D_real: 0.771 D_fake: 0.672 \n",
      "(epoch: 186, iters: 400, time: 0.098, data: 0.002) G_GAN: 0.921 G_L1: 1.900 D_real: 0.542 D_fake: 0.613 \n",
      "(epoch: 186, iters: 500, time: 0.099, data: 0.001) G_GAN: 0.684 G_L1: 0.000 D_real: 0.687 D_fake: 0.609 \n",
      "(epoch: 186, iters: 600, time: 0.099, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.715 D_fake: 0.553 \n",
      "(epoch: 186, iters: 700, time: 0.100, data: 0.002) G_GAN: 1.078 G_L1: 2.269 D_real: 0.624 D_fake: 0.508 \n",
      "(epoch: 186, iters: 800, time: 0.100, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.747 D_fake: 0.557 \n",
      "(epoch: 186, iters: 900, time: 0.096, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.746 D_fake: 0.667 \n",
      "(epoch: 186, iters: 1000, time: 0.098, data: 0.002) G_GAN: 0.957 G_L1: 2.064 D_real: 0.620 D_fake: 0.539 \n",
      "(epoch: 186, iters: 1100, time: 0.111, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.736 D_fake: 0.660 \n",
      "(epoch: 186, iters: 1200, time: 0.097, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.734 D_fake: 0.657 \n",
      "(epoch: 186, iters: 1300, time: 0.097, data: 0.002) G_GAN: 0.949 G_L1: 3.100 D_real: 0.586 D_fake: 0.552 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 186, iters: 1400, time: 0.097, data: 0.002) G_GAN: 0.794 G_L1: 0.000 D_real: 0.798 D_fake: 0.642 \n",
      "(epoch: 186, iters: 1500, time: 0.098, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.746 D_fake: 0.573 \n",
      "(epoch: 186, iters: 1600, time: 0.098, data: 0.001) G_GAN: 0.870 G_L1: 1.704 D_real: 0.569 D_fake: 0.637 \n",
      "(epoch: 186, iters: 1700, time: 0.099, data: 0.002) G_GAN: 0.767 G_L1: 0.000 D_real: 0.776 D_fake: 0.597 \n",
      "(epoch: 186, iters: 1800, time: 0.095, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.717 D_fake: 0.675 \n",
      "(epoch: 186, iters: 1900, time: 0.098, data: 0.001) G_GAN: 0.887 G_L1: 4.005 D_real: 0.506 D_fake: 0.666 \n",
      "(epoch: 186, iters: 2000, time: 0.097, data: 0.001) G_GAN: 0.781 G_L1: 0.000 D_real: 0.785 D_fake: 0.611 \n",
      "(epoch: 186, iters: 2100, time: 0.094, data: 0.001) G_GAN: 0.703 G_L1: 0.000 D_real: 0.706 D_fake: 0.688 \n",
      "(epoch: 186, iters: 2200, time: 0.097, data: 0.001) G_GAN: 0.790 G_L1: 1.935 D_real: 0.523 D_fake: 0.656 \n",
      "End of epoch 186 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000277\n",
      "(epoch: 187, iters: 20, time: 0.108, data: 0.002) G_GAN: 0.745 G_L1: 0.000 D_real: 0.749 D_fake: 0.670 \n",
      "(epoch: 187, iters: 120, time: 0.096, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.699 D_fake: 0.691 \n",
      "(epoch: 187, iters: 220, time: 0.098, data: 0.001) G_GAN: 0.882 G_L1: 3.205 D_real: 0.538 D_fake: 0.588 \n",
      "(epoch: 187, iters: 320, time: 0.098, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.749 D_fake: 0.651 \n",
      "(epoch: 187, iters: 420, time: 0.097, data: 0.001) G_GAN: 0.712 G_L1: 0.000 D_real: 0.714 D_fake: 0.682 \n",
      "(epoch: 187, iters: 520, time: 0.095, data: 0.001) G_GAN: 0.876 G_L1: 1.603 D_real: 0.595 D_fake: 0.587 \n",
      "(epoch: 187, iters: 620, time: 0.097, data: 0.001) G_GAN: 0.723 G_L1: 0.000 D_real: 0.729 D_fake: 0.598 \n",
      "(epoch: 187, iters: 720, time: 0.097, data: 0.001) G_GAN: 0.704 G_L1: 0.000 D_real: 0.705 D_fake: 0.684 \n",
      "(epoch: 187, iters: 820, time: 0.095, data: 0.001) G_GAN: 0.889 G_L1: 2.187 D_real: 0.567 D_fake: 0.589 \n",
      "(epoch: 187, iters: 920, time: 0.095, data: 0.001) G_GAN: 0.689 G_L1: 0.000 D_real: 0.691 D_fake: 0.626 \n",
      "saving the latest model (epoch 187, total_steps 425000)\n",
      "(epoch: 187, iters: 1020, time: 0.096, data: 0.001) G_GAN: 0.716 G_L1: 0.000 D_real: 0.718 D_fake: 0.680 \n",
      "(epoch: 187, iters: 1120, time: 0.101, data: 0.002) G_GAN: 0.798 G_L1: 1.002 D_real: 0.596 D_fake: 0.627 \n",
      "(epoch: 187, iters: 1220, time: 0.099, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.714 D_fake: 0.692 \n",
      "(epoch: 187, iters: 1320, time: 0.096, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.735 D_fake: 0.707 \n",
      "(epoch: 187, iters: 1420, time: 0.096, data: 0.002) G_GAN: 0.932 G_L1: 2.201 D_real: 0.564 D_fake: 0.588 \n",
      "(epoch: 187, iters: 1520, time: 0.097, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.746 D_fake: 0.659 \n",
      "(epoch: 187, iters: 1620, time: 0.095, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.742 D_fake: 0.653 \n",
      "(epoch: 187, iters: 1720, time: 0.109, data: 0.002) G_GAN: 0.856 G_L1: 3.384 D_real: 0.508 D_fake: 0.606 \n",
      "(epoch: 187, iters: 1820, time: 0.099, data: 0.002) G_GAN: 0.758 G_L1: 0.000 D_real: 0.761 D_fake: 0.639 \n",
      "(epoch: 187, iters: 1920, time: 0.097, data: 0.002) G_GAN: 0.770 G_L1: 0.000 D_real: 0.775 D_fake: 0.713 \n",
      "(epoch: 187, iters: 2020, time: 0.100, data: 0.001) G_GAN: 0.846 G_L1: 1.903 D_real: 0.566 D_fake: 0.601 \n",
      "(epoch: 187, iters: 2120, time: 0.095, data: 0.002) G_GAN: 0.762 G_L1: 0.000 D_real: 0.765 D_fake: 0.638 \n",
      "(epoch: 187, iters: 2220, time: 0.115, data: 0.001) G_GAN: 0.685 G_L1: 0.000 D_real: 0.688 D_fake: 0.688 \n",
      "End of epoch 187 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000257\n",
      "(epoch: 188, iters: 40, time: 0.121, data: 0.001) G_GAN: 0.873 G_L1: 1.545 D_real: 0.563 D_fake: 0.521 \n",
      "(epoch: 188, iters: 140, time: 0.108, data: 0.001) G_GAN: 0.725 G_L1: 0.000 D_real: 0.726 D_fake: 0.665 \n",
      "(epoch: 188, iters: 240, time: 0.097, data: 0.001) G_GAN: 0.748 G_L1: 0.000 D_real: 0.750 D_fake: 0.648 \n",
      "(epoch: 188, iters: 340, time: 0.097, data: 0.002) G_GAN: 0.740 G_L1: 0.576 D_real: 0.606 D_fake: 0.685 \n",
      "(epoch: 188, iters: 440, time: 0.096, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.744 D_fake: 0.656 \n",
      "(epoch: 188, iters: 540, time: 0.094, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.711 D_fake: 0.687 \n",
      "(epoch: 188, iters: 640, time: 0.099, data: 0.001) G_GAN: 0.930 G_L1: 3.338 D_real: 0.568 D_fake: 0.558 \n",
      "(epoch: 188, iters: 740, time: 0.104, data: 0.002) G_GAN: 0.754 G_L1: 0.000 D_real: 0.760 D_fake: 0.639 \n",
      "(epoch: 188, iters: 840, time: 0.117, data: 0.001) G_GAN: 0.702 G_L1: 0.000 D_real: 0.704 D_fake: 0.686 \n",
      "(epoch: 188, iters: 940, time: 0.112, data: 0.001) G_GAN: 0.875 G_L1: 1.224 D_real: 0.651 D_fake: 0.570 \n",
      "(epoch: 188, iters: 1040, time: 0.096, data: 0.001) G_GAN: 0.795 G_L1: 0.000 D_real: 0.803 D_fake: 0.622 \n",
      "(epoch: 188, iters: 1140, time: 0.096, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.722 D_fake: 0.669 \n",
      "(epoch: 188, iters: 1240, time: 0.097, data: 0.002) G_GAN: 0.971 G_L1: 2.557 D_real: 0.602 D_fake: 0.577 \n",
      "(epoch: 188, iters: 1340, time: 0.098, data: 0.001) G_GAN: 0.755 G_L1: 0.000 D_real: 0.757 D_fake: 0.654 \n",
      "(epoch: 188, iters: 1440, time: 0.100, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.738 D_fake: 0.706 \n",
      "(epoch: 188, iters: 1540, time: 0.108, data: 0.002) G_GAN: 0.896 G_L1: 1.958 D_real: 0.569 D_fake: 0.587 \n",
      "(epoch: 188, iters: 1640, time: 0.110, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.732 D_fake: 0.661 \n",
      "(epoch: 188, iters: 1740, time: 0.100, data: 0.002) G_GAN: 0.732 G_L1: 0.000 D_real: 0.734 D_fake: 0.692 \n",
      "(epoch: 188, iters: 1840, time: 0.098, data: 0.002) G_GAN: 0.863 G_L1: 0.311 D_real: 0.649 D_fake: 0.622 \n",
      "(epoch: 188, iters: 1940, time: 0.109, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.729 D_fake: 0.581 \n",
      "(epoch: 188, iters: 2040, time: 0.099, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.711 D_fake: 0.681 \n",
      "(epoch: 188, iters: 2140, time: 0.100, data: 0.002) G_GAN: 0.898 G_L1: 0.787 D_real: 0.614 D_fake: 0.623 \n",
      "(epoch: 188, iters: 2240, time: 0.099, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.717 D_fake: 0.683 \n",
      "End of epoch 188 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000238\n",
      "(epoch: 189, iters: 60, time: 0.108, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.682 D_fake: 0.714 \n",
      "(epoch: 189, iters: 160, time: 0.100, data: 0.002) G_GAN: 0.832 G_L1: 3.185 D_real: 0.515 D_fake: 0.682 \n",
      "(epoch: 189, iters: 260, time: 0.098, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.758 D_fake: 0.612 \n",
      "(epoch: 189, iters: 360, time: 0.099, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.729 D_fake: 0.668 \n",
      "(epoch: 189, iters: 460, time: 0.097, data: 0.001) G_GAN: 0.890 G_L1: 2.593 D_real: 0.580 D_fake: 0.574 \n",
      "(epoch: 189, iters: 560, time: 0.101, data: 0.001) G_GAN: 0.741 G_L1: 0.000 D_real: 0.742 D_fake: 0.658 \n",
      "(epoch: 189, iters: 660, time: 0.097, data: 0.002) G_GAN: 0.738 G_L1: 0.000 D_real: 0.740 D_fake: 0.659 \n",
      "(epoch: 189, iters: 760, time: 0.095, data: 0.002) G_GAN: 0.893 G_L1: 2.399 D_real: 0.571 D_fake: 0.603 \n",
      "(epoch: 189, iters: 860, time: 0.105, data: 0.002) G_GAN: 0.833 G_L1: 0.000 D_real: 0.839 D_fake: 0.639 \n",
      "(epoch: 189, iters: 960, time: 0.097, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.732 D_fake: 0.628 \n",
      "(epoch: 189, iters: 1060, time: 0.107, data: 0.002) G_GAN: 0.847 G_L1: 0.087 D_real: 0.736 D_fake: 0.631 \n",
      "(epoch: 189, iters: 1160, time: 0.097, data: 0.001) G_GAN: 0.772 G_L1: 0.000 D_real: 0.774 D_fake: 0.633 \n",
      "(epoch: 189, iters: 1260, time: 0.097, data: 0.001) G_GAN: 0.811 G_L1: 0.000 D_real: 0.821 D_fake: 0.540 \n",
      "(epoch: 189, iters: 1360, time: 0.109, data: 0.002) G_GAN: 0.794 G_L1: 4.502 D_real: 0.468 D_fake: 0.629 \n",
      "saving the latest model (epoch 189, total_steps 430000)\n",
      "(epoch: 189, iters: 1460, time: 0.097, data: 0.001) G_GAN: 0.785 G_L1: 0.000 D_real: 0.792 D_fake: 0.591 \n",
      "(epoch: 189, iters: 1560, time: 0.096, data: 0.002) G_GAN: 0.691 G_L1: 0.000 D_real: 0.692 D_fake: 0.704 \n",
      "(epoch: 189, iters: 1660, time: 0.097, data: 0.001) G_GAN: 0.857 G_L1: 1.973 D_real: 0.572 D_fake: 0.608 \n",
      "(epoch: 189, iters: 1760, time: 0.099, data: 0.002) G_GAN: 0.798 G_L1: 0.000 D_real: 0.801 D_fake: 0.610 \n",
      "(epoch: 189, iters: 1860, time: 0.097, data: 0.002) G_GAN: 0.713 G_L1: 0.000 D_real: 0.714 D_fake: 0.683 \n",
      "(epoch: 189, iters: 1960, time: 0.097, data: 0.002) G_GAN: 0.811 G_L1: 0.417 D_real: 0.654 D_fake: 0.548 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 189, iters: 2060, time: 0.094, data: 0.002) G_GAN: 0.773 G_L1: 0.000 D_real: 0.775 D_fake: 0.636 \n",
      "(epoch: 189, iters: 2160, time: 0.097, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.743 D_fake: 0.579 \n",
      "(epoch: 189, iters: 2260, time: 0.095, data: 0.002) G_GAN: 0.917 G_L1: 3.017 D_real: 0.588 D_fake: 0.561 \n",
      "End of epoch 189 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000218\n",
      "(epoch: 190, iters: 80, time: 0.104, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.729 D_fake: 0.668 \n",
      "(epoch: 190, iters: 180, time: 0.098, data: 0.001) G_GAN: 0.693 G_L1: 0.000 D_real: 0.693 D_fake: 0.696 \n",
      "(epoch: 190, iters: 280, time: 0.098, data: 0.002) G_GAN: 0.800 G_L1: 1.052 D_real: 0.596 D_fake: 0.628 \n",
      "(epoch: 190, iters: 380, time: 0.098, data: 0.002) G_GAN: 0.739 G_L1: 0.000 D_real: 0.742 D_fake: 0.614 \n",
      "(epoch: 190, iters: 480, time: 0.099, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.709 D_fake: 0.680 \n",
      "(epoch: 190, iters: 580, time: 0.099, data: 0.002) G_GAN: 0.871 G_L1: 4.208 D_real: 0.534 D_fake: 0.588 \n",
      "(epoch: 190, iters: 680, time: 0.098, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.725 D_fake: 0.611 \n",
      "(epoch: 190, iters: 780, time: 0.095, data: 0.001) G_GAN: 0.678 G_L1: 0.000 D_real: 0.678 D_fake: 0.716 \n",
      "(epoch: 190, iters: 880, time: 0.094, data: 0.001) G_GAN: 0.861 G_L1: 3.483 D_real: 0.482 D_fake: 0.628 \n",
      "(epoch: 190, iters: 980, time: 0.096, data: 0.002) G_GAN: 0.844 G_L1: 0.000 D_real: 0.846 D_fake: 0.657 \n",
      "(epoch: 190, iters: 1080, time: 0.106, data: 0.002) G_GAN: 0.707 G_L1: 0.000 D_real: 0.707 D_fake: 0.687 \n",
      "(epoch: 190, iters: 1180, time: 0.109, data: 0.001) G_GAN: 0.809 G_L1: 0.978 D_real: 0.601 D_fake: 0.633 \n",
      "(epoch: 190, iters: 1280, time: 0.110, data: 0.001) G_GAN: 0.809 G_L1: 0.000 D_real: 0.813 D_fake: 0.600 \n",
      "(epoch: 190, iters: 1380, time: 0.096, data: 0.002) G_GAN: 0.744 G_L1: 0.000 D_real: 0.746 D_fake: 0.622 \n",
      "(epoch: 190, iters: 1480, time: 0.098, data: 0.001) G_GAN: 0.830 G_L1: 1.681 D_real: 0.569 D_fake: 0.620 \n",
      "(epoch: 190, iters: 1580, time: 0.107, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.738 D_fake: 0.625 \n",
      "(epoch: 190, iters: 1680, time: 0.098, data: 0.001) G_GAN: 0.724 G_L1: 0.000 D_real: 0.726 D_fake: 0.669 \n",
      "(epoch: 190, iters: 1780, time: 0.096, data: 0.001) G_GAN: 0.791 G_L1: 3.487 D_real: 0.505 D_fake: 0.633 \n",
      "(epoch: 190, iters: 1880, time: 0.099, data: 0.001) G_GAN: 0.749 G_L1: 0.000 D_real: 0.751 D_fake: 0.654 \n",
      "(epoch: 190, iters: 1980, time: 0.110, data: 0.001) G_GAN: 0.681 G_L1: 0.000 D_real: 0.682 D_fake: 0.712 \n",
      "(epoch: 190, iters: 2080, time: 0.097, data: 0.001) G_GAN: 0.880 G_L1: 2.663 D_real: 0.537 D_fake: 0.612 \n",
      "(epoch: 190, iters: 2180, time: 0.100, data: 0.001) G_GAN: 0.700 G_L1: 0.000 D_real: 0.704 D_fake: 0.638 \n",
      "(epoch: 190, iters: 2280, time: 0.098, data: 0.002) G_GAN: 0.696 G_L1: 0.000 D_real: 0.699 D_fake: 0.560 \n",
      "saving the model at the end of epoch 190, iters 433200\n",
      "End of epoch 190 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000198\n",
      "(epoch: 191, iters: 100, time: 0.105, data: 0.288) G_GAN: 0.906 G_L1: 2.739 D_real: 0.583 D_fake: 0.646 \n",
      "(epoch: 191, iters: 200, time: 0.096, data: 0.001) G_GAN: 0.782 G_L1: 0.000 D_real: 0.789 D_fake: 0.663 \n",
      "(epoch: 191, iters: 300, time: 0.096, data: 0.001) G_GAN: 0.772 G_L1: 0.000 D_real: 0.773 D_fake: 0.636 \n",
      "(epoch: 191, iters: 400, time: 0.097, data: 0.001) G_GAN: 0.943 G_L1: 1.900 D_real: 0.544 D_fake: 0.586 \n",
      "(epoch: 191, iters: 500, time: 0.097, data: 0.001) G_GAN: 0.690 G_L1: 0.000 D_real: 0.691 D_fake: 0.698 \n",
      "(epoch: 191, iters: 600, time: 0.096, data: 0.002) G_GAN: 0.718 G_L1: 0.000 D_real: 0.720 D_fake: 0.673 \n",
      "(epoch: 191, iters: 700, time: 0.108, data: 0.001) G_GAN: 1.035 G_L1: 2.269 D_real: 0.599 D_fake: 0.531 \n",
      "(epoch: 191, iters: 800, time: 0.111, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.746 D_fake: 0.661 \n",
      "(epoch: 191, iters: 900, time: 0.103, data: 0.002) G_GAN: 0.763 G_L1: 0.000 D_real: 0.765 D_fake: 0.729 \n",
      "(epoch: 191, iters: 1000, time: 0.100, data: 0.002) G_GAN: 0.943 G_L1: 2.064 D_real: 0.599 D_fake: 0.650 \n",
      "(epoch: 191, iters: 1100, time: 0.107, data: 0.001) G_GAN: 0.734 G_L1: 0.000 D_real: 0.737 D_fake: 0.683 \n",
      "(epoch: 191, iters: 1200, time: 0.109, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.721 D_fake: 0.669 \n",
      "(epoch: 191, iters: 1300, time: 0.098, data: 0.001) G_GAN: 0.948 G_L1: 3.100 D_real: 0.584 D_fake: 0.552 \n",
      "(epoch: 191, iters: 1400, time: 0.097, data: 0.002) G_GAN: 0.804 G_L1: 0.000 D_real: 0.807 D_fake: 0.612 \n",
      "(epoch: 191, iters: 1500, time: 0.108, data: 0.002) G_GAN: 0.743 G_L1: 0.000 D_real: 0.744 D_fake: 0.604 \n",
      "(epoch: 191, iters: 1600, time: 0.097, data: 0.001) G_GAN: 0.888 G_L1: 1.704 D_real: 0.570 D_fake: 0.630 \n",
      "(epoch: 191, iters: 1700, time: 0.100, data: 0.001) G_GAN: 0.749 G_L1: 0.000 D_real: 0.755 D_fake: 0.608 \n",
      "(epoch: 191, iters: 1800, time: 0.105, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.728 D_fake: 0.666 \n",
      "saving the latest model (epoch 191, total_steps 435000)\n",
      "(epoch: 191, iters: 1900, time: 0.099, data: 0.002) G_GAN: 0.903 G_L1: 4.005 D_real: 0.521 D_fake: 0.574 \n",
      "(epoch: 191, iters: 2000, time: 0.097, data: 0.002) G_GAN: 0.771 G_L1: 0.000 D_real: 0.772 D_fake: 0.633 \n",
      "(epoch: 191, iters: 2100, time: 0.098, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.696 D_fake: 0.629 \n",
      "(epoch: 191, iters: 2200, time: 0.097, data: 0.002) G_GAN: 0.837 G_L1: 1.935 D_real: 0.552 D_fake: 0.576 \n",
      "End of epoch 191 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000178\n",
      "(epoch: 192, iters: 20, time: 0.105, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.753 D_fake: 0.654 \n",
      "(epoch: 192, iters: 120, time: 0.109, data: 0.001) G_GAN: 0.692 G_L1: 0.000 D_real: 0.700 D_fake: 0.608 \n",
      "(epoch: 192, iters: 220, time: 0.100, data: 0.002) G_GAN: 0.885 G_L1: 3.205 D_real: 0.538 D_fake: 0.704 \n",
      "(epoch: 192, iters: 320, time: 0.098, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.763 D_fake: 0.640 \n",
      "(epoch: 192, iters: 420, time: 0.108, data: 0.001) G_GAN: 0.719 G_L1: 0.000 D_real: 0.720 D_fake: 0.670 \n",
      "(epoch: 192, iters: 520, time: 0.094, data: 0.002) G_GAN: 0.865 G_L1: 1.603 D_real: 0.621 D_fake: 0.697 \n",
      "(epoch: 192, iters: 620, time: 0.096, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.732 D_fake: 0.664 \n",
      "(epoch: 192, iters: 720, time: 0.097, data: 0.002) G_GAN: 0.698 G_L1: 0.000 D_real: 0.700 D_fake: 0.683 \n",
      "(epoch: 192, iters: 820, time: 0.096, data: 0.002) G_GAN: 0.948 G_L1: 2.187 D_real: 0.591 D_fake: 0.555 \n",
      "(epoch: 192, iters: 920, time: 0.106, data: 0.003) G_GAN: 0.697 G_L1: 0.000 D_real: 0.698 D_fake: 0.681 \n",
      "(epoch: 192, iters: 1020, time: 0.099, data: 0.001) G_GAN: 0.744 G_L1: 0.000 D_real: 0.746 D_fake: 0.653 \n",
      "(epoch: 192, iters: 1120, time: 0.098, data: 0.002) G_GAN: 0.809 G_L1: 1.002 D_real: 0.605 D_fake: 0.882 \n",
      "(epoch: 192, iters: 1220, time: 0.110, data: 0.003) G_GAN: 0.715 G_L1: 0.000 D_real: 0.717 D_fake: 0.602 \n",
      "(epoch: 192, iters: 1320, time: 0.098, data: 0.001) G_GAN: 0.740 G_L1: 0.000 D_real: 0.741 D_fake: 0.585 \n",
      "(epoch: 192, iters: 1420, time: 0.097, data: 0.002) G_GAN: 0.940 G_L1: 2.201 D_real: 0.557 D_fake: 0.586 \n",
      "(epoch: 192, iters: 1520, time: 0.096, data: 0.001) G_GAN: 0.730 G_L1: 0.000 D_real: 0.732 D_fake: 0.595 \n",
      "(epoch: 192, iters: 1620, time: 0.094, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.739 D_fake: 0.657 \n",
      "(epoch: 192, iters: 1720, time: 0.098, data: 0.002) G_GAN: 0.872 G_L1: 3.384 D_real: 0.513 D_fake: 0.593 \n",
      "(epoch: 192, iters: 1820, time: 0.099, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.752 D_fake: 0.581 \n",
      "(epoch: 192, iters: 1920, time: 0.097, data: 0.002) G_GAN: 0.785 G_L1: 0.000 D_real: 0.786 D_fake: 0.639 \n",
      "(epoch: 192, iters: 2020, time: 0.100, data: 0.002) G_GAN: 0.839 G_L1: 1.903 D_real: 0.581 D_fake: 0.604 \n",
      "(epoch: 192, iters: 2120, time: 0.108, data: 0.002) G_GAN: 0.776 G_L1: 0.000 D_real: 0.778 D_fake: 0.615 \n",
      "(epoch: 192, iters: 2220, time: 0.112, data: 0.001) G_GAN: 0.680 G_L1: 0.000 D_real: 0.684 D_fake: 0.547 \n",
      "End of epoch 192 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000158\n",
      "(epoch: 193, iters: 40, time: 0.107, data: 0.002) G_GAN: 0.861 G_L1: 1.545 D_real: 0.555 D_fake: 0.622 \n",
      "(epoch: 193, iters: 140, time: 0.098, data: 0.002) G_GAN: 0.721 G_L1: 0.000 D_real: 0.722 D_fake: 0.668 \n",
      "(epoch: 193, iters: 240, time: 0.095, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.756 D_fake: 0.641 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 193, iters: 340, time: 0.109, data: 0.002) G_GAN: 0.752 G_L1: 0.576 D_real: 0.615 D_fake: 0.648 \n",
      "(epoch: 193, iters: 440, time: 0.111, data: 0.001) G_GAN: 0.743 G_L1: 0.000 D_real: 0.746 D_fake: 0.664 \n",
      "(epoch: 193, iters: 540, time: 0.094, data: 0.002) G_GAN: 0.693 G_L1: 0.000 D_real: 0.697 D_fake: 0.604 \n",
      "(epoch: 193, iters: 640, time: 0.094, data: 0.001) G_GAN: 0.907 G_L1: 3.338 D_real: 0.550 D_fake: 0.576 \n",
      "(epoch: 193, iters: 740, time: 0.105, data: 0.002) G_GAN: 0.747 G_L1: 0.000 D_real: 0.752 D_fake: 0.597 \n",
      "(epoch: 193, iters: 840, time: 0.095, data: 0.001) G_GAN: 0.714 G_L1: 0.000 D_real: 0.717 D_fake: 0.613 \n",
      "(epoch: 193, iters: 940, time: 0.109, data: 0.002) G_GAN: 0.847 G_L1: 1.224 D_real: 0.639 D_fake: 0.605 \n",
      "(epoch: 193, iters: 1040, time: 0.095, data: 0.001) G_GAN: 0.805 G_L1: 0.000 D_real: 0.810 D_fake: 0.607 \n",
      "(epoch: 193, iters: 1140, time: 0.097, data: 0.001) G_GAN: 0.719 G_L1: 0.000 D_real: 0.720 D_fake: 0.534 \n",
      "(epoch: 193, iters: 1240, time: 0.096, data: 0.001) G_GAN: 0.972 G_L1: 2.557 D_real: 0.570 D_fake: 0.540 \n",
      "(epoch: 193, iters: 1340, time: 0.108, data: 0.001) G_GAN: 0.750 G_L1: 0.000 D_real: 0.751 D_fake: 0.656 \n",
      "(epoch: 193, iters: 1440, time: 0.103, data: 0.001) G_GAN: 0.724 G_L1: 0.000 D_real: 0.725 D_fake: 0.676 \n",
      "(epoch: 193, iters: 1540, time: 0.097, data: 0.001) G_GAN: 0.887 G_L1: 1.958 D_real: 0.570 D_fake: 0.602 \n",
      "(epoch: 193, iters: 1640, time: 0.106, data: 0.001) G_GAN: 0.711 G_L1: 0.000 D_real: 0.712 D_fake: 0.654 \n",
      "(epoch: 193, iters: 1740, time: 0.100, data: 0.002) G_GAN: 0.733 G_L1: 0.000 D_real: 0.734 D_fake: 0.676 \n",
      "(epoch: 193, iters: 1840, time: 0.099, data: 0.002) G_GAN: 0.871 G_L1: 0.311 D_real: 0.661 D_fake: 0.617 \n",
      "(epoch: 193, iters: 1940, time: 0.097, data: 0.002) G_GAN: 0.730 G_L1: 0.000 D_real: 0.731 D_fake: 0.663 \n",
      "(epoch: 193, iters: 2040, time: 0.098, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.724 D_fake: 0.669 \n",
      "(epoch: 193, iters: 2140, time: 0.108, data: 0.002) G_GAN: 0.908 G_L1: 0.787 D_real: 0.612 D_fake: 0.585 \n",
      "(epoch: 193, iters: 2240, time: 0.098, data: 0.001) G_GAN: 0.699 G_L1: 0.000 D_real: 0.700 D_fake: 0.665 \n",
      "saving the latest model (epoch 193, total_steps 440000)\n",
      "End of epoch 193 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000139\n",
      "(epoch: 194, iters: 60, time: 0.108, data: 0.001) G_GAN: 0.681 G_L1: 0.000 D_real: 0.681 D_fake: 0.716 \n",
      "(epoch: 194, iters: 160, time: 0.102, data: 0.002) G_GAN: 0.852 G_L1: 3.185 D_real: 0.525 D_fake: 0.611 \n",
      "(epoch: 194, iters: 260, time: 0.099, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.768 D_fake: 0.627 \n",
      "(epoch: 194, iters: 360, time: 0.098, data: 0.001) G_GAN: 0.724 G_L1: 0.000 D_real: 0.726 D_fake: 0.590 \n",
      "(epoch: 194, iters: 460, time: 0.100, data: 0.002) G_GAN: 0.898 G_L1: 2.593 D_real: 0.581 D_fake: 0.568 \n",
      "(epoch: 194, iters: 560, time: 0.100, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.741 D_fake: 0.658 \n",
      "(epoch: 194, iters: 660, time: 0.099, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.729 D_fake: 0.703 \n",
      "(epoch: 194, iters: 760, time: 0.097, data: 0.002) G_GAN: 0.913 G_L1: 2.399 D_real: 0.576 D_fake: 0.565 \n",
      "(epoch: 194, iters: 860, time: 0.094, data: 0.002) G_GAN: 0.847 G_L1: 0.000 D_real: 0.854 D_fake: 0.589 \n",
      "(epoch: 194, iters: 960, time: 0.095, data: 0.002) G_GAN: 0.714 G_L1: 0.000 D_real: 0.714 D_fake: 0.677 \n",
      "(epoch: 194, iters: 1060, time: 0.095, data: 0.002) G_GAN: 0.844 G_L1: 0.087 D_real: 0.673 D_fake: 0.635 \n",
      "(epoch: 194, iters: 1160, time: 0.095, data: 0.002) G_GAN: 0.781 G_L1: 0.000 D_real: 0.783 D_fake: 0.542 \n",
      "(epoch: 194, iters: 1260, time: 0.099, data: 0.002) G_GAN: 0.814 G_L1: 0.000 D_real: 0.817 D_fake: 0.642 \n",
      "(epoch: 194, iters: 1360, time: 0.097, data: 0.002) G_GAN: 0.803 G_L1: 4.502 D_real: 0.465 D_fake: 0.636 \n",
      "(epoch: 194, iters: 1460, time: 0.095, data: 0.002) G_GAN: 0.789 G_L1: 0.000 D_real: 0.793 D_fake: 0.627 \n",
      "(epoch: 194, iters: 1560, time: 0.097, data: 0.002) G_GAN: 0.690 G_L1: 0.000 D_real: 0.692 D_fake: 0.609 \n",
      "(epoch: 194, iters: 1660, time: 0.096, data: 0.002) G_GAN: 0.877 G_L1: 1.973 D_real: 0.571 D_fake: 0.655 \n",
      "(epoch: 194, iters: 1760, time: 0.099, data: 0.002) G_GAN: 0.806 G_L1: 0.000 D_real: 0.810 D_fake: 0.639 \n",
      "(epoch: 194, iters: 1860, time: 0.108, data: 0.002) G_GAN: 0.712 G_L1: 0.000 D_real: 0.714 D_fake: 0.624 \n",
      "(epoch: 194, iters: 1960, time: 0.100, data: 0.002) G_GAN: 0.811 G_L1: 0.417 D_real: 0.662 D_fake: 0.667 \n",
      "(epoch: 194, iters: 2060, time: 0.095, data: 0.002) G_GAN: 0.777 G_L1: 0.000 D_real: 0.779 D_fake: 0.674 \n",
      "(epoch: 194, iters: 2160, time: 0.101, data: 0.002) G_GAN: 0.734 G_L1: 0.000 D_real: 0.735 D_fake: 0.661 \n",
      "(epoch: 194, iters: 2260, time: 0.096, data: 0.002) G_GAN: 0.948 G_L1: 3.017 D_real: 0.559 D_fake: 0.512 \n",
      "End of epoch 194 / 200 \t Time Taken: 125 sec\n",
      "learning rate = 0.0000119\n",
      "(epoch: 195, iters: 80, time: 0.106, data: 0.001) G_GAN: 0.720 G_L1: 0.000 D_real: 0.721 D_fake: 0.674 \n",
      "(epoch: 195, iters: 180, time: 0.107, data: 0.002) G_GAN: 0.705 G_L1: 0.000 D_real: 0.706 D_fake: 0.684 \n",
      "(epoch: 195, iters: 280, time: 0.108, data: 0.002) G_GAN: 0.802 G_L1: 1.052 D_real: 0.591 D_fake: 0.705 \n",
      "(epoch: 195, iters: 380, time: 0.098, data: 0.002) G_GAN: 0.740 G_L1: 0.000 D_real: 0.742 D_fake: 0.621 \n",
      "(epoch: 195, iters: 480, time: 0.110, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.707 D_fake: 0.687 \n",
      "(epoch: 195, iters: 580, time: 0.099, data: 0.001) G_GAN: 0.843 G_L1: 4.208 D_real: 0.503 D_fake: 0.672 \n",
      "(epoch: 195, iters: 680, time: 0.099, data: 0.002) G_GAN: 0.729 G_L1: 0.000 D_real: 0.729 D_fake: 0.671 \n",
      "(epoch: 195, iters: 780, time: 0.097, data: 0.001) G_GAN: 0.686 G_L1: 0.000 D_real: 0.686 D_fake: 0.705 \n",
      "(epoch: 195, iters: 880, time: 0.094, data: 0.002) G_GAN: 0.854 G_L1: 3.483 D_real: 0.497 D_fake: 0.630 \n",
      "(epoch: 195, iters: 980, time: 0.108, data: 0.002) G_GAN: 0.852 G_L1: 0.000 D_real: 0.854 D_fake: 0.594 \n",
      "(epoch: 195, iters: 1080, time: 0.097, data: 0.002) G_GAN: 0.711 G_L1: 0.000 D_real: 0.712 D_fake: 0.683 \n",
      "(epoch: 195, iters: 1180, time: 0.105, data: 0.001) G_GAN: 0.811 G_L1: 0.978 D_real: 0.596 D_fake: 0.609 \n",
      "(epoch: 195, iters: 1280, time: 0.099, data: 0.002) G_GAN: 0.811 G_L1: 0.000 D_real: 0.815 D_fake: 0.602 \n",
      "(epoch: 195, iters: 1380, time: 0.096, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.755 D_fake: 0.649 \n",
      "(epoch: 195, iters: 1480, time: 0.108, data: 0.001) G_GAN: 0.854 G_L1: 1.681 D_real: 0.581 D_fake: 0.698 \n",
      "(epoch: 195, iters: 1580, time: 0.107, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.730 D_fake: 0.575 \n",
      "(epoch: 195, iters: 1680, time: 0.100, data: 0.002) G_GAN: 0.709 G_L1: 0.000 D_real: 0.709 D_fake: 0.685 \n",
      "(epoch: 195, iters: 1780, time: 0.098, data: 0.002) G_GAN: 0.792 G_L1: 3.487 D_real: 0.508 D_fake: 0.672 \n",
      "(epoch: 195, iters: 1880, time: 0.100, data: 0.002) G_GAN: 0.761 G_L1: 0.000 D_real: 0.763 D_fake: 0.608 \n",
      "(epoch: 195, iters: 1980, time: 0.112, data: 0.002) G_GAN: 0.694 G_L1: 0.000 D_real: 0.694 D_fake: 0.700 \n",
      "(epoch: 195, iters: 2080, time: 0.097, data: 0.002) G_GAN: 0.891 G_L1: 2.663 D_real: 0.542 D_fake: 0.661 \n",
      "(epoch: 195, iters: 2180, time: 0.096, data: 0.001) G_GAN: 0.710 G_L1: 0.000 D_real: 0.712 D_fake: 0.662 \n",
      "(epoch: 195, iters: 2280, time: 0.096, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.708 D_fake: 0.689 \n",
      "saving the model at the end of epoch 195, iters 444600\n",
      "End of epoch 195 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0000099\n",
      "(epoch: 196, iters: 100, time: 0.116, data: 0.278) G_GAN: 0.875 G_L1: 2.739 D_real: 0.545 D_fake: 0.653 \n",
      "(epoch: 196, iters: 200, time: 0.097, data: 0.002) G_GAN: 0.794 G_L1: 0.000 D_real: 0.797 D_fake: 0.631 \n",
      "(epoch: 196, iters: 300, time: 0.098, data: 0.002) G_GAN: 0.784 G_L1: 0.000 D_real: 0.784 D_fake: 0.614 \n",
      "(epoch: 196, iters: 400, time: 0.098, data: 0.001) G_GAN: 0.967 G_L1: 1.900 D_real: 0.574 D_fake: 0.574 \n",
      "saving the latest model (epoch 196, total_steps 445000)\n",
      "(epoch: 196, iters: 500, time: 0.099, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.710 D_fake: 0.654 \n",
      "(epoch: 196, iters: 600, time: 0.097, data: 0.001) G_GAN: 0.713 G_L1: 0.000 D_real: 0.714 D_fake: 0.654 \n",
      "(epoch: 196, iters: 700, time: 0.110, data: 0.001) G_GAN: 1.035 G_L1: 2.269 D_real: 0.606 D_fake: 0.700 \n",
      "(epoch: 196, iters: 800, time: 0.099, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.745 D_fake: 0.657 \n",
      "(epoch: 196, iters: 900, time: 0.093, data: 0.002) G_GAN: 0.780 G_L1: 0.000 D_real: 0.781 D_fake: 0.639 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 196, iters: 1000, time: 0.100, data: 0.002) G_GAN: 0.920 G_L1: 2.064 D_real: 0.580 D_fake: 0.636 \n",
      "(epoch: 196, iters: 1100, time: 0.099, data: 0.002) G_GAN: 0.727 G_L1: 0.000 D_real: 0.727 D_fake: 0.671 \n",
      "(epoch: 196, iters: 1200, time: 0.098, data: 0.002) G_GAN: 0.726 G_L1: 0.000 D_real: 0.726 D_fake: 0.664 \n",
      "(epoch: 196, iters: 1300, time: 0.098, data: 0.001) G_GAN: 0.949 G_L1: 3.100 D_real: 0.566 D_fake: 0.699 \n",
      "(epoch: 196, iters: 1400, time: 0.098, data: 0.002) G_GAN: 0.795 G_L1: 0.000 D_real: 0.796 D_fake: 0.560 \n",
      "(epoch: 196, iters: 1500, time: 0.107, data: 0.001) G_GAN: 0.759 G_L1: 0.000 D_real: 0.760 D_fake: 0.641 \n",
      "(epoch: 196, iters: 1600, time: 0.099, data: 0.002) G_GAN: 0.907 G_L1: 1.704 D_real: 0.563 D_fake: 0.591 \n",
      "(epoch: 196, iters: 1700, time: 0.109, data: 0.001) G_GAN: 0.759 G_L1: 0.000 D_real: 0.763 D_fake: 0.585 \n",
      "(epoch: 196, iters: 1800, time: 0.095, data: 0.001) G_GAN: 0.720 G_L1: 0.000 D_real: 0.721 D_fake: 0.622 \n",
      "(epoch: 196, iters: 1900, time: 0.097, data: 0.001) G_GAN: 0.903 G_L1: 4.005 D_real: 0.528 D_fake: 0.551 \n",
      "(epoch: 196, iters: 2000, time: 0.097, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.759 D_fake: 0.642 \n",
      "(epoch: 196, iters: 2100, time: 0.096, data: 0.002) G_GAN: 0.706 G_L1: 0.000 D_real: 0.707 D_fake: 0.690 \n",
      "(epoch: 196, iters: 2200, time: 0.098, data: 0.002) G_GAN: 0.836 G_L1: 1.935 D_real: 0.551 D_fake: 0.623 \n",
      "End of epoch 196 / 200 \t Time Taken: 127 sec\n",
      "learning rate = 0.0000079\n",
      "(epoch: 197, iters: 20, time: 0.115, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.765 D_fake: 0.641 \n",
      "(epoch: 197, iters: 120, time: 0.098, data: 0.002) G_GAN: 0.697 G_L1: 0.000 D_real: 0.699 D_fake: 0.680 \n",
      "(epoch: 197, iters: 220, time: 0.099, data: 0.001) G_GAN: 0.883 G_L1: 3.205 D_real: 0.542 D_fake: 0.587 \n",
      "(epoch: 197, iters: 320, time: 0.108, data: 0.001) G_GAN: 0.744 G_L1: 0.000 D_real: 0.745 D_fake: 0.595 \n",
      "(epoch: 197, iters: 420, time: 0.096, data: 0.002) G_GAN: 0.717 G_L1: 0.000 D_real: 0.717 D_fake: 0.673 \n",
      "(epoch: 197, iters: 520, time: 0.095, data: 0.002) G_GAN: 0.854 G_L1: 1.603 D_real: 0.582 D_fake: 0.613 \n",
      "(epoch: 197, iters: 620, time: 0.108, data: 0.002) G_GAN: 0.722 G_L1: 0.000 D_real: 0.723 D_fake: 0.675 \n",
      "(epoch: 197, iters: 720, time: 0.109, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.708 D_fake: 0.632 \n",
      "(epoch: 197, iters: 820, time: 0.095, data: 0.002) G_GAN: 0.940 G_L1: 2.187 D_real: 0.571 D_fake: 0.564 \n",
      "(epoch: 197, iters: 920, time: 0.094, data: 0.001) G_GAN: 0.709 G_L1: 0.000 D_real: 0.709 D_fake: 0.684 \n",
      "(epoch: 197, iters: 1020, time: 0.109, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.737 D_fake: 0.660 \n",
      "(epoch: 197, iters: 1120, time: 0.107, data: 0.001) G_GAN: 0.800 G_L1: 1.002 D_real: 0.599 D_fake: 0.594 \n",
      "(epoch: 197, iters: 1220, time: 0.098, data: 0.002) G_GAN: 0.716 G_L1: 0.000 D_real: 0.717 D_fake: 0.593 \n",
      "(epoch: 197, iters: 1320, time: 0.098, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.766 D_fake: 0.584 \n",
      "(epoch: 197, iters: 1420, time: 0.098, data: 0.001) G_GAN: 0.937 G_L1: 2.201 D_real: 0.539 D_fake: 0.645 \n",
      "(epoch: 197, iters: 1520, time: 0.099, data: 0.002) G_GAN: 0.764 G_L1: 0.000 D_real: 0.765 D_fake: 0.606 \n",
      "(epoch: 197, iters: 1620, time: 0.092, data: 0.002) G_GAN: 0.757 G_L1: 0.000 D_real: 0.760 D_fake: 0.654 \n",
      "(epoch: 197, iters: 1720, time: 0.099, data: 0.002) G_GAN: 0.863 G_L1: 3.384 D_real: 0.507 D_fake: 0.568 \n",
      "(epoch: 197, iters: 1820, time: 0.098, data: 0.002) G_GAN: 0.746 G_L1: 0.000 D_real: 0.747 D_fake: 0.651 \n",
      "(epoch: 197, iters: 1920, time: 0.098, data: 0.002) G_GAN: 0.813 G_L1: 0.000 D_real: 0.814 D_fake: 0.621 \n",
      "(epoch: 197, iters: 2020, time: 0.100, data: 0.002) G_GAN: 0.824 G_L1: 1.903 D_real: 0.563 D_fake: 0.615 \n",
      "(epoch: 197, iters: 2120, time: 0.099, data: 0.002) G_GAN: 0.753 G_L1: 0.000 D_real: 0.754 D_fake: 0.617 \n",
      "(epoch: 197, iters: 2220, time: 0.113, data: 0.002) G_GAN: 0.695 G_L1: 0.000 D_real: 0.696 D_fake: 0.702 \n",
      "End of epoch 197 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000059\n",
      "(epoch: 198, iters: 40, time: 0.104, data: 0.002) G_GAN: 0.866 G_L1: 1.545 D_real: 0.555 D_fake: 0.615 \n",
      "(epoch: 198, iters: 140, time: 0.097, data: 0.001) G_GAN: 0.718 G_L1: 0.000 D_real: 0.719 D_fake: 0.671 \n",
      "(epoch: 198, iters: 240, time: 0.101, data: 0.002) G_GAN: 0.755 G_L1: 0.000 D_real: 0.756 D_fake: 0.641 \n",
      "(epoch: 198, iters: 340, time: 0.096, data: 0.001) G_GAN: 0.759 G_L1: 0.576 D_real: 0.615 D_fake: 0.643 \n",
      "(epoch: 198, iters: 440, time: 0.095, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.749 D_fake: 0.680 \n",
      "(epoch: 198, iters: 540, time: 0.094, data: 0.001) G_GAN: 0.724 G_L1: 0.000 D_real: 0.725 D_fake: 0.653 \n",
      "(epoch: 198, iters: 640, time: 0.095, data: 0.001) G_GAN: 0.936 G_L1: 3.338 D_real: 0.579 D_fake: 0.616 \n",
      "(epoch: 198, iters: 740, time: 0.096, data: 0.002) G_GAN: 0.751 G_L1: 0.000 D_real: 0.752 D_fake: 0.645 \n",
      "(epoch: 198, iters: 840, time: 0.096, data: 0.001) G_GAN: 0.722 G_L1: 0.000 D_real: 0.722 D_fake: 0.669 \n",
      "saving the latest model (epoch 198, total_steps 450000)\n",
      "(epoch: 198, iters: 940, time: 0.107, data: 0.001) G_GAN: 0.815 G_L1: 1.224 D_real: 0.599 D_fake: 0.612 \n",
      "(epoch: 198, iters: 1040, time: 0.093, data: 0.002) G_GAN: 0.833 G_L1: 0.000 D_real: 0.835 D_fake: 0.602 \n",
      "(epoch: 198, iters: 1140, time: 0.097, data: 0.001) G_GAN: 0.714 G_L1: 0.000 D_real: 0.714 D_fake: 0.677 \n",
      "(epoch: 198, iters: 1240, time: 0.094, data: 0.002) G_GAN: 0.948 G_L1: 2.557 D_real: 0.563 D_fake: 0.565 \n",
      "(epoch: 198, iters: 1340, time: 0.098, data: 0.002) G_GAN: 0.759 G_L1: 0.000 D_real: 0.760 D_fake: 0.665 \n",
      "(epoch: 198, iters: 1440, time: 0.102, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.720 D_fake: 0.681 \n",
      "(epoch: 198, iters: 1540, time: 0.096, data: 0.002) G_GAN: 0.896 G_L1: 1.958 D_real: 0.554 D_fake: 0.638 \n",
      "(epoch: 198, iters: 1640, time: 0.112, data: 0.002) G_GAN: 0.724 G_L1: 0.000 D_real: 0.724 D_fake: 0.681 \n",
      "(epoch: 198, iters: 1740, time: 0.100, data: 0.002) G_GAN: 0.752 G_L1: 0.000 D_real: 0.753 D_fake: 0.622 \n",
      "(epoch: 198, iters: 1840, time: 0.096, data: 0.002) G_GAN: 0.877 G_L1: 0.311 D_real: 0.657 D_fake: 0.614 \n",
      "(epoch: 198, iters: 1940, time: 0.101, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.732 D_fake: 0.664 \n",
      "(epoch: 198, iters: 2040, time: 0.097, data: 0.002) G_GAN: 0.720 G_L1: 0.000 D_real: 0.721 D_fake: 0.610 \n",
      "(epoch: 198, iters: 2140, time: 0.099, data: 0.002) G_GAN: 0.872 G_L1: 0.787 D_real: 0.570 D_fake: 0.617 \n",
      "(epoch: 198, iters: 2240, time: 0.099, data: 0.002) G_GAN: 0.731 G_L1: 0.000 D_real: 0.730 D_fake: 0.670 \n",
      "End of epoch 198 / 200 \t Time Taken: 124 sec\n",
      "learning rate = 0.0000040\n",
      "(epoch: 199, iters: 60, time: 0.104, data: 0.002) G_GAN: 0.683 G_L1: 0.000 D_real: 0.683 D_fake: 0.623 \n",
      "(epoch: 199, iters: 160, time: 0.103, data: 0.001) G_GAN: 0.845 G_L1: 3.185 D_real: 0.512 D_fake: 0.583 \n",
      "(epoch: 199, iters: 260, time: 0.095, data: 0.001) G_GAN: 0.745 G_L1: 0.000 D_real: 0.745 D_fake: 0.655 \n",
      "(epoch: 199, iters: 360, time: 0.095, data: 0.001) G_GAN: 0.746 G_L1: 0.000 D_real: 0.747 D_fake: 0.604 \n",
      "(epoch: 199, iters: 460, time: 0.099, data: 0.001) G_GAN: 0.881 G_L1: 2.593 D_real: 0.564 D_fake: 0.618 \n",
      "(epoch: 199, iters: 560, time: 0.112, data: 0.002) G_GAN: 0.742 G_L1: 0.000 D_real: 0.742 D_fake: 0.659 \n",
      "(epoch: 199, iters: 660, time: 0.098, data: 0.001) G_GAN: 0.752 G_L1: 0.000 D_real: 0.753 D_fake: 0.648 \n",
      "(epoch: 199, iters: 760, time: 0.096, data: 0.001) G_GAN: 0.909 G_L1: 2.399 D_real: 0.572 D_fake: 0.654 \n",
      "(epoch: 199, iters: 860, time: 0.095, data: 0.001) G_GAN: 0.850 G_L1: 0.000 D_real: 0.850 D_fake: 0.586 \n",
      "(epoch: 199, iters: 960, time: 0.095, data: 0.002) G_GAN: 0.708 G_L1: 0.000 D_real: 0.708 D_fake: 0.600 \n",
      "(epoch: 199, iters: 1060, time: 0.097, data: 0.002) G_GAN: 0.906 G_L1: 0.087 D_real: 0.701 D_fake: 0.578 \n",
      "(epoch: 199, iters: 1160, time: 0.096, data: 0.002) G_GAN: 0.765 G_L1: 0.000 D_real: 0.765 D_fake: 0.643 \n",
      "(epoch: 199, iters: 1260, time: 0.098, data: 0.002) G_GAN: 0.857 G_L1: 0.000 D_real: 0.859 D_fake: 0.605 \n",
      "(epoch: 199, iters: 1360, time: 0.098, data: 0.002) G_GAN: 0.811 G_L1: 4.502 D_real: 0.471 D_fake: 0.657 \n",
      "(epoch: 199, iters: 1460, time: 0.095, data: 0.002) G_GAN: 0.792 G_L1: 0.000 D_real: 0.793 D_fake: 0.608 \n",
      "(epoch: 199, iters: 1560, time: 0.099, data: 0.001) G_GAN: 0.696 G_L1: 0.000 D_real: 0.696 D_fake: 0.697 \n",
      "(epoch: 199, iters: 1660, time: 0.098, data: 0.001) G_GAN: 0.859 G_L1: 1.973 D_real: 0.563 D_fake: 0.600 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 199, iters: 1760, time: 0.098, data: 0.002) G_GAN: 0.800 G_L1: 0.000 D_real: 0.801 D_fake: 0.613 \n",
      "(epoch: 199, iters: 1860, time: 0.099, data: 0.001) G_GAN: 0.738 G_L1: 0.000 D_real: 0.738 D_fake: 0.660 \n",
      "(epoch: 199, iters: 1960, time: 0.098, data: 0.002) G_GAN: 0.819 G_L1: 0.417 D_real: 0.666 D_fake: 0.606 \n",
      "(epoch: 199, iters: 2060, time: 0.095, data: 0.002) G_GAN: 0.790 G_L1: 0.000 D_real: 0.790 D_fake: 0.628 \n",
      "(epoch: 199, iters: 2160, time: 0.097, data: 0.002) G_GAN: 0.741 G_L1: 0.000 D_real: 0.741 D_fake: 0.586 \n",
      "(epoch: 199, iters: 2260, time: 0.096, data: 0.002) G_GAN: 0.873 G_L1: 3.017 D_real: 0.522 D_fake: 0.606 \n",
      "End of epoch 199 / 200 \t Time Taken: 123 sec\n",
      "learning rate = 0.0000020\n",
      "(epoch: 200, iters: 80, time: 0.107, data: 0.002) G_GAN: 0.728 G_L1: 0.000 D_real: 0.728 D_fake: 0.668 \n",
      "(epoch: 200, iters: 180, time: 0.110, data: 0.001) G_GAN: 0.719 G_L1: 0.000 D_real: 0.719 D_fake: 0.673 \n",
      "(epoch: 200, iters: 280, time: 0.096, data: 0.002) G_GAN: 0.811 G_L1: 1.052 D_real: 0.597 D_fake: 0.590 \n",
      "(epoch: 200, iters: 380, time: 0.096, data: 0.002) G_GAN: 0.748 G_L1: 0.000 D_real: 0.749 D_fake: 0.616 \n",
      "(epoch: 200, iters: 480, time: 0.108, data: 0.001) G_GAN: 0.719 G_L1: 0.000 D_real: 0.719 D_fake: 0.671 \n",
      "(epoch: 200, iters: 580, time: 0.099, data: 0.001) G_GAN: 0.836 G_L1: 4.208 D_real: 0.491 D_fake: 0.612 \n",
      "(epoch: 200, iters: 680, time: 0.109, data: 0.002) G_GAN: 0.737 G_L1: 0.000 D_real: 0.737 D_fake: 0.660 \n",
      "(epoch: 200, iters: 780, time: 0.091, data: 0.001) G_GAN: 0.688 G_L1: 0.000 D_real: 0.688 D_fake: 0.703 \n",
      "(epoch: 200, iters: 880, time: 0.093, data: 0.001) G_GAN: 0.874 G_L1: 3.483 D_real: 0.497 D_fake: 0.613 \n",
      "(epoch: 200, iters: 980, time: 0.096, data: 0.002) G_GAN: 0.845 G_L1: 0.000 D_real: 0.846 D_fake: 0.689 \n",
      "(epoch: 200, iters: 1080, time: 0.097, data: 0.002) G_GAN: 0.749 G_L1: 0.000 D_real: 0.749 D_fake: 0.647 \n",
      "(epoch: 200, iters: 1180, time: 0.100, data: 0.002) G_GAN: 0.785 G_L1: 0.978 D_real: 0.570 D_fake: 0.638 \n",
      "(epoch: 200, iters: 1280, time: 0.100, data: 0.002) G_GAN: 0.800 G_L1: 0.000 D_real: 0.800 D_fake: 0.656 \n",
      "saving the latest model (epoch 200, total_steps 455000)\n",
      "(epoch: 200, iters: 1380, time: 0.108, data: 0.001) G_GAN: 0.776 G_L1: 0.000 D_real: 0.776 D_fake: 0.631 \n",
      "(epoch: 200, iters: 1480, time: 0.100, data: 0.002) G_GAN: 0.851 G_L1: 1.681 D_real: 0.559 D_fake: 0.600 \n",
      "(epoch: 200, iters: 1580, time: 0.095, data: 0.001) G_GAN: 0.739 G_L1: 0.000 D_real: 0.740 D_fake: 0.611 \n",
      "(epoch: 200, iters: 1680, time: 0.101, data: 0.001) G_GAN: 0.735 G_L1: 0.000 D_real: 0.735 D_fake: 0.661 \n",
      "(epoch: 200, iters: 1780, time: 0.096, data: 0.001) G_GAN: 0.801 G_L1: 3.487 D_real: 0.503 D_fake: 0.634 \n",
      "(epoch: 200, iters: 1880, time: 0.099, data: 0.001) G_GAN: 0.760 G_L1: 0.000 D_real: 0.761 D_fake: 0.570 \n",
      "(epoch: 200, iters: 1980, time: 0.100, data: 0.002) G_GAN: 0.681 G_L1: 0.000 D_real: 0.681 D_fake: 0.712 \n",
      "(epoch: 200, iters: 2080, time: 0.099, data: 0.002) G_GAN: 0.911 G_L1: 2.663 D_real: 0.534 D_fake: 0.624 \n",
      "(epoch: 200, iters: 2180, time: 0.096, data: 0.002) G_GAN: 0.710 G_L1: 0.000 D_real: 0.711 D_fake: 0.682 \n",
      "(epoch: 200, iters: 2280, time: 0.096, data: 0.002) G_GAN: 0.692 G_L1: 0.000 D_real: 0.692 D_fake: 0.708 \n",
      "saving the model at the end of epoch 200, iters 456000\n",
      "End of epoch 200 / 200 \t Time Taken: 126 sec\n",
      "learning rate = 0.0000000\n"
     ]
    }
   ],
   "source": [
    "init_types = ['normal','kaiming','xavier']\n",
    "for init_type in init_types:\n",
    "        new_opt = Map(opt)\n",
    "        new_opt.init_type = init_type\n",
    "        new_opt.name = 'prostate_cyc_batch_'+'_init_type_'+str(init_type)\n",
    "        if not os.path.exists(os.path.join(new_opt.checkpoints_dir,new_opt.name)):\n",
    "            os.mkdir(os.path.join(new_opt.checkpoints_dir,new_opt.name))\n",
    "        train(new_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
